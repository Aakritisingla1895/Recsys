AB	AD	AID	AU	AUID	CI	CIN	CN	COIS	CON	CRDT	DCOM	DEP	DP	EDAT	EIN	FAU	FIR	GR	IP	IR	IS	JID	JT	LA	LID	LR	MH	MHDA	MID	OT	OTO	OWN	PG	PHST	PL	PMC	PMCR	PMID	PST	PT	RF	RN	SB	SI	SO	STAT	TA	TI	TT	VI	Year
BACKGROUND: Deciphering the meaning of the human DNA is an outstanding goal which would revolutionize medicine and our way for treating diseases. In recent years, non-coding RNAs have attracted much attention and shown to be functional in part. Yet the importance of these RNAs especially for higher biological functions remains under investigation. METHODS: In this paper, we analyze RNA-seq data, including non-coding and protein coding RNAs, from lung adenocarcinoma patients, a histologic subtype of non-small-cell lung cancer, with deep learning neural networks and other state-of-the-art classification methods. The purpose of our paper is three-fold. First, we compare the classification performance of different versions of deep belief networks with SVMs, decision trees and random forests. Second, we compare the classification capabilities of protein coding and non-coding RNAs. Third, we study the influence of feature selection on the classification performance. RESULTS: As a result, we find that deep belief networks perform at least competitively to other state-of-the-art classifiers. Second, data from non-coding RNAs perform better than coding RNAs across a number of different classification methods. This demonstrates the equivalence of predictive information as captured by non-coding RNAs compared to protein coding RNAs, conventionally used in computational diagnostics tasks. Third, we find that feature selection has in general a negative effect on the classification performance which means that unfiltered data with all features give the best classification results. CONCLUSIONS: Our study is the first to use ncRNAs beyond miRNAs for the computational classification of cancer and for performing a direct comparison of the classification capabilities of protein coding RNAs and non-coding RNAs.	['Predictive Society and Data Analytics Lab, Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland.', 'Turku Centre for Biotechnology, University of Turku, Turku, Finland.', 'Department of Oncology, School of Medicine, Johns Hopkins University, Baltimore, USA.', 'Department of Biomedical Informatics, University of Arkansas for Medical Sciences, Little Rock, USA.', 'Institute for Intelligent Production, Faculty for Management, University of Applied Sciences Upper Austria, Steyr, Austria.', 'Department of Mechatronics and Biomedical Computer Science, UMIT, Hall in Tyrol, Austria.', 'College of Artificial Intelligence, Nankai University, China, Tianjin, China.', 'Predictive Society and Data Analytics Lab, Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland. v@bio-complexity.com.', 'Institute of Biosciences and Medical Technology, Tampere, Finland. v@bio-complexity.com.']	['10.1186/s12885-019-6338-1 [doi]', '10.1186/s12885-019-6338-1 [pii]']	['Smolander J', 'Stupnikov A', 'Glazko G', 'Dehmer M', 'Emmert-Streib F']	['ORCID: http://orcid.org/0000-0003-0745-5641']						['2019/12/05 06:00']		20191203	2019 Dec 3	2019/12/05 06:00		['Smolander, Johannes', 'Stupnikov, Alexey', 'Glazko, Galina', 'Dehmer, Matthias', 'Emmert-Streib, Frank']			1		1471-2407 (Electronic) 1471-2407 (Linking)	100967800	BMC cancer	['eng']	10.1186/s12885-019-6338-1 [doi]	20191204		2019/12/05 06:00		['Classification', 'Deep belief network', 'Deep learning', 'Lung cancer and Machine learning', 'Non-coding RNA']	['NOTNLM']	NLM	1176	['2019/02/13 00:00 [received]', '2019/11/06 00:00 [accepted]', '2019/12/05 06:00 [entrez]', '2019/12/05 06:00 [pubmed]', '2019/12/05 06:00 [medline]']	England			31796020	epublish	['Journal Article']			IM		BMC Cancer. 2019 Dec 3;19(1):1176. doi: 10.1186/s12885-019-6338-1.	In-Process	BMC Cancer	Comparing biological information contained in mRNA and non-coding RNAs for classification of lung cancer patients.		19	Comparing biological information contained in mRNA and non-coding RNAs for classification of lung cancer patients.
PURPOSE: Lung cancer is the commonest cause of cancer deaths worldwide, and its mortality can be reduced significantly by performing early diagnosis and screening. Since the 1960s, driven by the pressing needs to accurately and effectively interpret the massive volume of chest images generated daily, computer-assisted diagnosis of pulmonary nodule has opened up new opportunities to relax the limitation from physicians' subjectivity, experiences and fatigue. And the fair access to the reliable and affordable computer-assisted diagnosis will fight the inequalities in incidence and mortality between populations. It has been witnessed that significant and remarkable advances have been achieved since the 1980s, and consistent endeavors have been exerted to deal with the grand challenges on how to accurately detect the pulmonary nodules with high sensitivity at low false-positive rate as well as on how to precisely differentiate between benign and malignant nodules. There is a lack of comprehensive examination of the techniques' development which is evolving the pulmonary nodules diagnosis from classical approaches to machine learning-assisted decision support. The main goal of this investigation is to provide a comprehensive state-of-the-art review of the computer-assisted nodules detection and benign-malignant classification techniques developed over three decades, which have evolved from the complicated ad hoc analysis pipeline of conventional approaches to the simplified seamlessly integrated deep learning techniques. This review also identifies challenges and highlights opportunities for future work in learning models, learning algorithms and enhancement schemes for bridging current state to future prospect and satisfying future demand. CONCLUSION: It is the first literature review of the past 30 years' development in computer-assisted diagnosis of lung nodules. The challenges indentified and the research opportunities highlighted in this survey are significant for bridging current state to future prospect and satisfying future demand. The values of multifaceted driving forces and multidisciplinary researches are acknowledged that will make the computer-assisted diagnosis of pulmonary nodules enter into the main stream of clinical medicine and raise the state-of-the-art clinical applications as well as increase both welfares of physicians and patients. We firmly hold the vision that fair access to the reliable, faithful, and affordable computer-assisted diagnosis for early cancer diagnosis would fight the inequalities in incidence and mortality between populations, and save more lives.	['Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China. bliu@amss.ac.cn.', 'Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China.', 'University of Chinese Academy of Sciences, Beijing, China.', 'Department of Mathematics, University of Wisconsin-Madison, Madison, WI, 53706, USA.', 'Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China.', 'Department of Thoracic Surgery and Oncology, The First Affiliated Hospital of Guangzhou Medical University, Guangzhou, China.', 'China State Key Laboratory of Respiratory Disease, Guangzhou, China.', 'PET/CT Center, The First Affiliated Hospital of Guangzhou Medical University, Guangzhou, China.', 'China State Key Laboratory of Respiratory Disease, Guangzhou, China.', 'Department of Thoracic Surgery and Oncology, The First Affiliated Hospital of Guangzhou Medical University, Guangzhou, China.', 'China State Key Laboratory of Respiratory Disease, Guangzhou, China.', 'Department of Thoracic Surgery and Oncology, The First Affiliated Hospital of Guangzhou Medical University, Guangzhou, China. drjianxing.he@gmail.com.', 'China State Key Laboratory of Respiratory Disease, Guangzhou, China. drjianxing.he@gmail.com.']	['10.1007/s00432-019-03098-5 [doi]', '10.1007/s00432-019-03098-5 [pii]']	['Liu B', 'Chi W', 'Li X', 'Li P', 'Liang W', 'Liu H', 'Wang W', 'He J']	['ORCID: http://orcid.org/0000-0002-6615-6601']						['2019/12/02 06:00']		20191130	2019 Nov 30	2019/12/02 06:00		['Liu, Bo', 'Chi, Wenhao', 'Li, Xinran', 'Li, Peng', 'Liang, Wenhua', 'Liu, Haiping', 'Wang, Wei', 'He, Jianxing']		['QYZDB-SSW-SYS020/Key Research Program of Frontier Sciences, Chinese Academy of', 'Sciences', '2016-999999-65-01-000696-01/National Development and Reform Commission', 'GJHZ1006/Collaboration Research Project of Guangdong Education Department', '2014KGJHZ010/Collaboration Research Project of Guangdong Education Department', '20161A011060/Medical and Health Science and Technology Project of Guangzhou', 'Municipal Health Commission', '2017A020215110/Science and Technology Planning Project of Guangdong Province', '2018A030313534/Natural Science Foundation of Guangdong Province']			1432-1335 (Electronic) 0171-5216 (Linking)	7902060	Journal of cancer research and clinical oncology	['eng']	10.1007/s00432-019-03098-5 [doi]	20191201		2019/12/02 06:00		['Artificial intelligence', 'Computer-aided diagnosis', 'Deep learning', 'Lung cancer', 'Pulmonary nodules', 'Review']	['NOTNLM']	NLM		['2019/05/13 00:00 [received]', '2019/11/25 00:00 [accepted]', '2019/12/02 06:00 [entrez]', '2019/12/02 06:00 [pubmed]', '2019/12/02 06:00 [medline]']	Germany			31786740	aheadofprint	['Journal Article', 'Review']			IM		J Cancer Res Clin Oncol. 2019 Nov 30. pii: 10.1007/s00432-019-03098-5. doi: 10.1007/s00432-019-03098-5.	Publisher	J Cancer Res Clin Oncol	Evolving the pulmonary nodules diagnosis from classical approaches to deep learning-aided decision support: three decades' development course and future prospect.			Evolving the pulmonary nodules diagnosis from classical approaches to deep learning-aided decision support: three decades' development course and future prospect.
Multiple recent advances in machine learning enabled computer systems to exceed human performance in many tasks including voice, text, and speech recognition and complex strategy games. Aging is a complex multifactorial process driven by and resulting in the many minute changes transpiring at every level of the human organism. Deep learning systems trained on the many measurable features changing in time can generalize and learn the many biological processes on the population and individual levels. The deep age predictors can help advance aging research by establishing causal relationships in non-linear systems. Deep aging clocks can be used for identification of novel therapeutic targets, evaluating the efficacy of the various interventions, data quality control, data economics, prediction of health trajectories, mortality, and many other applications. Here we present the current state of development of the deep aging clocks in the context of the pharmaceutical research and development and clinical applications.	['Insilico Medicine, Hong Kong Science and Technology Park, Hong Kong, China.', 'The Buck Institute for Research on Aging, Novato, CA 84945, USA.', 'The Biogerontology Research Foundation, London, UK.', 'Sinovation Ventures, Beijing, China.', 'Sinovation AI Institute, Beijing, China.', 'Deep Longevity, Ltd, Hong Kong Science and Technology Park, Hong Kong, China.']	['102475 [pii]', '10.18632/aging.102475 [doi]']	['Zhavoronkov A', 'Li R', 'Ma C', 'Mamoshina P']							['2019/11/27 06:00']		20191125	2019 Nov 25	2019/11/27 06:00		['Zhavoronkov, Alex', 'Li, Ricky', 'Ma, Candice', 'Mamoshina, Polina']			22		1945-4589 (Electronic) 1945-4589 (Linking)	101508617	Aging	['eng']	10.18632/aging.102475 [doi]	20191205		2019/11/27 06:00		['aging biomarkers', 'aging clock', 'artificial intelligence', 'deep aging clocks', 'deep learning']	['NOTNLM']	NLM	10771-10780	['2019/09/02 00:00 [received]', '2019/11/08 00:00 [accepted]', '2019/11/27 06:00 [pubmed]', '2019/11/27 06:00 [medline]', '2019/11/27 06:00 [entrez]']	United States			31767810	ppublish	['Journal Article']			IM		Aging (Albany NY). 2019 Nov 25;11(22):10771-10780. doi: 10.18632/aging.102475. Epub 2019 Nov 25.	In-Data-Review	Aging (Albany NY)	Deep biomarkers of aging and longevity: from research to applications.		11	Deep biomarkers of aging and longevity: from research to applications.
Human-in-the-loop (HITL) AI may enable an ideal symbiosis of human experts and AI models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning AI models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning technology outperformed either method alone. The superior diagnostic accuracy of the combined HITL AI solution compared to radiologists and AI alone has broad implications for the surging clinical AI deployment and implementation strategies in future practice.	['1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', 'Unanimous AI, 2443 Fillmore Street #116, San Francisco, CA 94115-1814 USA.', 'Unanimous AI, 2443 Fillmore Street #116, San Francisco, CA 94115-1814 USA.', 'Unanimous AI, 2443 Fillmore Street #116, San Francisco, CA 94115-1814 USA.', 'Unanimous AI, 2443 Fillmore Street #116, San Francisco, CA 94115-1814 USA.', '3Department of Computer Science, Stanford University School of Medicine, 353 Serra Mall (Gates Building), Stanford, CA 94305 USA.0000000419368956grid.168010.e', '3Department of Computer Science, Stanford University School of Medicine, 353 Serra Mall (Gates Building), Stanford, CA 94305 USA.0000000419368956grid.168010.e', '4Department of Radiology, Duke University Medical Center, Box 3808 Erwin Rd, Durham, NC 27710 USA.0000000100241216grid.189509.c', '4Department of Radiology, Duke University Medical Center, Box 3808 Erwin Rd, Durham, NC 27710 USA.0000000100241216grid.189509.c', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '4Department of Radiology, Duke University Medical Center, Box 3808 Erwin Rd, Durham, NC 27710 USA.0000000100241216grid.189509.c', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e', '1Department of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA 94305 USA.0000000419368956grid.168010.e']	['10.1038/s41746-019-0189-7 [doi]', '189 [pii]']	['Patel BN', 'Rosenberg L', 'Willcox G', 'Baltaxe D', 'Lyons M', 'Irvin J', 'Rajpurkar P', 'Amrhein T', 'Gupta R', 'Halabi S', 'Langlotz C', 'Lo E', 'Mammarappallil J', 'Mariano AJ', 'Riley G', 'Seekins J', 'Shen L', 'Zucker E', 'Lungren M']	['ORCID: 0000-0001-5157-9903', 'ORCID: 0000-0002-9354-9486', 'ORCID: 0000-0003-1317-984X', 'ORCID: 0000-0002-8972-8051']	['(c) The Author(s) 2019.']			['Competing interestsThe authors had control of the data and the information', 'submitted for publication. Four authors (L.R., D.B., G.W. and M.L.) are employees', 'of Unanimous AI, who developed the swarm platform used in this study. All other', 'authors are not employees of or consultants for Unanimous AI and had control of', 'the study methodology, data analysis, and results. There was no industry support', 'specifically for this study. This study was supported in part by NSF through', 'Award ID 1840937.']		['2019/11/23 06:00']		20191118	2019	2019/11/23 06:00		['Patel, Bhavik N', 'Rosenberg, Louis', 'Willcox, Gregg', 'Baltaxe, David', 'Lyons, Mimi', 'Irvin, Jeremy', 'Rajpurkar, Pranav', 'Amrhein, Timothy', 'Gupta, Rajan', 'Halabi, Safwan', 'Langlotz, Curtis', 'Lo, Edward', 'Mammarappallil, Joseph', 'Mariano, A J', 'Riley, Geoffrey', 'Seekins, Jayne', 'Shen, Luyao', 'Zucker, Evan', 'Lungren, Matthew']					2398-6352 (Electronic) 2398-6352 (Linking)	101731738	NPJ digital medicine	['eng']	10.1038/s41746-019-0189-7 [doi]	20191126		2019/11/23 06:01		['Computer science', 'Radiography']	['NOTNLM']	NLM	111	['2019/02/25 00:00 [received]', '2019/10/23 00:00 [accepted]', '2019/11/23 06:00 [entrez]', '2019/11/23 06:00 [pubmed]', '2019/11/23 06:01 [medline]']	England	PMC6861262		31754637	epublish	['Journal Article']					NPJ Digit Med. 2019 Nov 18;2:111. doi: 10.1038/s41746-019-0189-7. eCollection 2019.	PubMed-not-MEDLINE	NPJ Digit Med	Human-machine partnership with artificial intelligence for chest radiograph diagnosis.		2	Human-machine partnership with artificial intelligence for chest radiograph diagnosis.
Despite great advances, molecular cancer pathology is often limited to the use of a small number of biomarkers rather than the whole transcriptome, partly due to computational challenges. Here, we introduce a novel architecture of Deep Neural Networks (DNNs) that is capable of simultaneous inference of various properties of biological samples, through multi-task and transfer learning. It encodes the whole transcription profile into a strikingly low-dimensional latent vector of size 8, and then recovers mRNA and miRNA expression profiles, tissue and disease type from this vector. This latent space is significantly better than the original gene expression profiles for discriminating samples based on their tissue and disease. We employed this architecture on mRNA transcription profiles of 10750 clinical samples from 34 classes (one healthy and 33 different types of cancer) from 27 tissues. Our method significantly outperforms prior works and classical machine learning approaches in predicting tissue-of-origin, normal or disease state and cancer type of each sample. For tissues with more than one type of cancer, it reaches 99.4% accuracy in identifying the correct cancer subtype. We also show this system is very robust against noise and missing values. Collectively, our results highlight applications of artificial intelligence in molecular cancer pathology and oncological research. DeePathology is freely available at https://github.com/SharifBioinf/DeePathology .	['Department of Stem Cell Biology and Technology, Royan Institute, Tehran, Iran.', 'Department of Mathematics and Computer Science, Sharif University of Technology, Tehran, Iran.', 'Department of Computer Engineering, Sharif University of Technology, Tehran, Iran.', 'Department of Computer Science, Colorado State University, Fort Collins, CO, USA.', 'Department of Computer Engineering, Sharif University of Technology, Tehran, Iran. asharifi@sharif.edu.']	['10.1038/s41598-019-52937-5 [doi]', '10.1038/s41598-019-52937-5 [pii]']	['Azarkhalili B', 'Saberi A', 'Chitsaz H', 'Sharifi-Zarchi A']	['ORCID: http://orcid.org/0000-0002-0087-7596']						['2019/11/13 06:00']		20191111	2019 Nov 11	2019/11/13 06:00		['Azarkhalili, Behrooz', 'Saberi, Ali', 'Chitsaz, Hamidreza', 'Sharifi-Zarchi, Ali']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-019-52937-5 [doi]	20191120		2019/11/13 06:00				NLM	16526	['2018/12/13 00:00 [received]', '2019/10/23 00:00 [accepted]', '2019/11/13 06:00 [entrez]', '2019/11/13 06:00 [pubmed]', '2019/11/13 06:00 [medline]']	England	PMC6848155		31712594	epublish	['Journal Article']			IM		Sci Rep. 2019 Nov 11;9(1):16526. doi: 10.1038/s41598-019-52937-5.	In-Data-Review	Sci Rep	DeePathology: Deep Multi-Task Learning for Inferring Molecular Pathology from Cancer Transcriptome.		9	DeePathology: Deep Multi-Task Learning for Inferring Molecular Pathology from Cancer Transcriptome.
	['Charite Department of Radiology, Humboldt University Medical School, 10117 Berlin, Germany. Electronic address: marc.dewey@charite.de.', 'Jena University Hospital, Institute for Medical Statistics, Computer Science and Data Science, Jena, Germany.']	['S0140-6736(19)32498-5 [pii]', '10.1016/S0140-6736(19)32498-5 [doi]']	['Dewey M', 'Schlattmann P']			['Lancet. 2019 Nov 9;394(10210):1711. PMID: 31709996']			['Lancet. 2018 Dec 1;392(10162):2388-2396. PMID: 30318264']	['2019/11/12 06:00']	20191126		2019 Nov 9	2019/11/12 06:00		['Dewey, Marc', 'Schlattmann, Peter']			10210		1474-547X (Electronic) 0140-6736 (Linking)	2985213R	Lancet (London, England)	['eng']	S0140-6736(19)32498-5 [pii] 10.1016/S0140-6736(19)32498-5 [doi]	20191126	['*Algorithms', '*Deep Learning', 'Machine Learning', 'Retrospective Studies', 'Tomography, X-Ray Computed']	2019/11/27 06:00				NLM	1710-1711	['2018/10/25 00:00 [received]', '2019/09/12 00:00 [accepted]', '2019/11/12 06:00 [entrez]', '2019/11/12 06:00 [pubmed]', '2019/11/27 06:00 [medline]']	England			31709995	ppublish	['Letter', 'Comment']			AIM IM		Lancet. 2019 Nov 9;394(10210):1710-1711. doi: 10.1016/S0140-6736(19)32498-5.	MEDLINE	Lancet	Deep learning and medical diagnosis.		394	Deep learning and medical diagnosis.
Evidence now suggests that precision psychiatry is becoming a cornerstone of medical practices by providing the patient of psychiatric disorders with the right medication at the right dose at the right time. In light of recent advances in neuroimaging and multi-omics, more and more biomarkers associated with psychiatric diseases and treatment responses are being discovered in precision psychiatry applications by leveraging machine learning and neural network approaches. In this article, we focus on the most recent developments for research in precision psychiatry using machine learning, deep learning, and neural network algorithms, together with neuroimaging and multi-omics data. First, we describe different machine learning approaches that are employed to assess prediction for diagnosis, prognosis, and treatment in various precision psychiatry studies. We also survey probable biomarkers that have been identified to be involved in psychiatric diseases and treatment responses. Furthermore, we summarize the limitations with respect to the mentioned precision psychiatry studies. Finally, we address a discussion of future directions and challenges.	['Department of Electrical & Computer Engineering, University of Washington, Seattle, WA, 98195, USA.', 'Department of Biostatistics, University of Washington, Seattle, WA, 98195, USA.', 'Graduate Institute of Biomedical Sciences, China Medical University, Taichung, Taiwan.', 'Department of Psychiatry, Taipei Veterans General Hospital, No. 201, Shih-Pai Road, Sec. 2, 11217, Taipei, Taiwan. tsai610913@gmail.com.', 'Division of Psychiatry, National Yang-Ming University, Taipei, Taiwan. tsai610913@gmail.com.', 'Institute of Brain Science, National Yang-Ming University, Taipei, Taiwan. tsai610913@gmail.com.']	['10.1007/978-981-32-9721-0_7 [doi]']	['Lin E', 'Tsai SJ']							['2019/11/10 06:00']	20191118		2019	2019/11/11 06:00		['Lin, Eugene', 'Tsai, Shih-Jen']					0065-2598 (Print) 0065-2598 (Linking)	0121103	Advances in experimental medicine and biology	['eng']	10.1007/978-981-32-9721-0_7 [doi]	20191118	['*Artificial Intelligence', 'Humans', '*Machine Learning', '*Mental Disorders', '*Neural Networks (Computer)', 'Neuroimaging', '*Psychiatry']	2019/11/19 06:00		['Artificial intelligence', 'Biomarker', 'Genomics', 'Multi-omics', 'Neural networks', 'Neuroimaging', 'Precision medicine']	['NOTNLM']	NLM	127-137	['2019/11/10 06:00 [entrez]', '2019/11/11 06:00 [pubmed]', '2019/11/19 06:00 [medline]']	United States			31705493	ppublish	['Journal Article']			IM		Adv Exp Med Biol. 2019;1192:127-137. doi: 10.1007/978-981-32-9721-0_7.	MEDLINE	Adv Exp Med Biol	Machine Learning in Neural Networks.		1192	Machine Learning in Neural Networks.
Measuring conditional relatedness, the degree of relation between a pair of genes in a certain condition, is a basic but difficult task in bioinformatics, as traditional co-expression analysis methods rely on co-expression similarities, well known with high false positive rate. Complement with prior-knowledge similarities is a feasible way to tackle the problem. However, classical combination machine learning algorithms fail in detection and application of the complex mapping relations between similarities and conditional relatedness, so a powerful predictive model will have enormous benefit for measuring this kind of complex mapping relations. To this need, we propose a novel deep learning model of convolutional neural network with a fully connected first layer, named fully convolutional neural network (FCNN), to measure conditional relatedness between genes using both co-expression and prior-knowledge similarities. The results on validation and test datasets show FCNN model yields an average 3.0% and 2.7% higher accuracy values for identifying gene-gene interactions collected from the COXPRESdb, KEGG, and TRRUST databases, and a benchmark dataset of Xiao-Yong et al. research, by grid-search 10-fold cross validation, respectively. In order to estimate the FCNN model, we conduct a further verification on the GeneFriends and DIP datasets, and the FCNN model obtains an average of 1.8% and 7.6% higher accuracy, respectively. Then the FCNN model is applied to construct cancer gene networks, and also calls more practical results than other compared models and methods. A website of the FCNN model and relevant datasets can be accessed from https://bmbl.bmi.osumc.edu/FCNN.	['Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, China.', 'School of Artificial Intelligence, Jilin University, Changchun, China.', 'Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, China.', 'Department of Obstetrics, The First Hospital of Jilin University, Changchun, China.', 'Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, China.', 'School of Artificial Intelligence, Jilin University, Changchun, China.', 'Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH, United States.']	['10.3389/fgene.2019.01009 [doi]']	['Wang Y', 'Zhang S', 'Yang L', 'Yang S', 'Tian Y', 'Ma Q']		['Copyright (c) 2019 Wang, Zhang, Yang, Yang, Tian and Ma.']					['2019/11/08 06:00']		20191022	2019	2019/11/07 06:00		['Wang, Yan', 'Zhang, Shuangquan', 'Yang, Lili', 'Yang, Sen', 'Tian, Yuan', 'Ma, Qin']					1664-8021 (Print) 1664-8021 (Linking)	101560621	Frontiers in genetics	['eng']	10.3389/fgene.2019.01009 [doi]	20191108		2019/11/07 06:01		['co-expression similarity', 'conditional relatedness between genes', 'fully convolutional neural network', 'gene network', 'prior-knowledge similarity']	['NOTNLM']	NLM	1009	['2019/04/18 00:00 [received]', '2019/09/23 00:00 [accepted]', '2019/11/08 06:00 [entrez]', '2019/11/07 06:00 [pubmed]', '2019/11/07 06:01 [medline]']	Switzerland	PMC6818468		31695723	epublish	['Journal Article']					Front Genet. 2019 Oct 22;10:1009. doi: 10.3389/fgene.2019.01009. eCollection 2019.	PubMed-not-MEDLINE	Front Genet	Measurement of Conditional Relatedness Between Genes Using Fully Convolutional Neural Network.		10	Measurement of Conditional Relatedness Between Genes Using Fully Convolutional Neural Network.
"Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on ""Diabetic Retinopathy - Segmentation and Grading"" was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular."	['Shri Guru Gobind Singhji Institute of Engineering and Technology, Nanded, India; School of Biomedical Informatics, University of Texas Health Science Center at Houston, USA. Electronic address: porwal.prasanna@sggs.ac.in.', 'Shri Guru Gobind Singhji Institute of Engineering and Technology, Nanded, India; School of Biomedical Informatics, University of Texas Health Science Center at Houston, USA.', 'Shri Guru Gobind Singhji Institute of Engineering and Technology, Nanded, India.', 'Eye Clinic, Sushrusha Hospital, Nanded, Maharashtra, India.', 'VUNO Inc., Seoul, Republic of Korea.', 'VUNO Inc., Seoul, Republic of Korea.', 'Ping An Technology (Shenzhen) Co.,Ltd, China.', 'Ping An Technology (Shenzhen) Co.,Ltd, China.', 'Ping An Technology (Shenzhen) Co.,Ltd, China.', 'Ping An Technology (Shenzhen) Co.,Ltd, China.', 'Ping An Technology (Shenzhen) Co.,Ltd, China.', 'Ping An Technology (Shenzhen) Co.,Ltd, China.', 'iFLYTEK Research, Hefei, China.', 'iFLYTEK Research, Hefei, China.', 'School of Electrical and Computer Engineering, University of Oklahoma, USA.', 'School of Electrical and Computer Engineering, University of Oklahoma, USA.', 'School of Electrical and Computer Engineering, University of Oklahoma, USA.', 'Samsung Advanced Institute for Health Sciences & Technology (SAIHST), Sungkyunkwan University, Seoul, Republic of Korea.', 'Samsung Advanced Institute for Health Sciences & Technology (SAIHST), Sungkyunkwan University, Seoul, Republic of Korea.', 'Samsung Advanced Institute for Health Sciences & Technology (SAIHST), Sungkyunkwan University, Seoul, Republic of Korea.', 'Department of Computer Science, University of North Carolina at Charlotte, USA.', 'School of Information Science and Engineering, Shandong Normal University, China.', 'Cleerly Inc., New York, United States.', 'Virginia Tech, Virginia, United States.', 'University at Buffalo, New York, United States.', 'University of Debrecen, Faculty of Informatics 4002 Debrecen, POB 400, Hungary.', 'University of Debrecen, Faculty of Informatics 4002 Debrecen, POB 400, Hungary.', 'Individual Researcher, India.', 'Individual Researcher, India.', 'Individual Researcher, India.', 'Individual Researcher, India.', 'College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Machine Learning for Bioimage Analysis Group, Bioinformatics Institute, A*STAR, Singapore.', 'Machine Learning for Bioimage Analysis Group, Bioinformatics Institute, A*STAR, Singapore; Department of Electric and Computer Engineering, University of Alberta, Canada.', 'School of Computing, National University of Singapore, Singapore.', 'School of Computing, National University of Singapore, Singapore.', 'Beijing Shanggong Medical Technology Co., Ltd., China.', 'College of Computer Science and Technology, Zhejiang University, Hangzhou, China.', 'Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China.', 'Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China.', 'Indian Institute of Technology Kharagpur, India.', 'Indian Institute of Technology Kharagpur, India.', 'INESC TEC - Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal.', 'INESC TEC - Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; FEUP - Faculty of Engineering of the University of Porto, Porto, Portugal.', 'University of Debrecen, Faculty of Informatics 4002 Debrecen, POB 400, Hungary.', 'Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China.', 'J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, USA.', 'Indian Institute of Technology Kharagpur, India.', 'University of Debrecen, Faculty of Informatics 4002 Debrecen, POB 400, Hungary.', 'School of Information Science and Engineering, Shandong Normal University, China.', 'INESC TEC - Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; FEUP - Faculty of Engineering of the University of Porto, Porto, Portugal.', 'Department of Computer Science, University of North Carolina at Charlotte, USA.', 'INESC TEC - Institute for Systems and Computer Engineering, Technology and Science, Porto, Portugal; FEUP - Faculty of Engineering of the University of Porto, Porto, Portugal.', 'School of Electrical and Computer Engineering, University of Oklahoma, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, USA.', 'School of Biomedical Informatics, University of Texas Health Science Center at Houston, USA.', 'INSERM, UMR 1101, Brest, France.', 'Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS, Malaysia; ImViA/IFTIM, Universite de Bourgogne, Dijon, France.']	['S1361-8415(19)30103-3 [pii]', '10.1016/j.media.2019.101561 [doi]']	['Porwal P', 'Pachade S', 'Kokare M', 'Deshmukh G', 'Son J', 'Bae W', 'Liu L', 'Wang J', 'Liu X', 'Gao L', 'Wu T', 'Xiao J', 'Wang F', 'Yin B', 'Wang Y', 'Danala G', 'He L', 'Choi YH', 'Lee YC', 'Jung SH', 'Li Z', 'Sui X', 'Wu J', 'Li X', 'Zhou T', 'Toth J', 'Baran A', 'Kori A', 'Chennamsetty SS', 'Safwan M', 'Alex V', 'Lyu X', 'Cheng L', 'Chu Q', 'Li P', 'Ji X', 'Zhang S', 'Shen Y', 'Dai L', 'Saha O', 'Sathish R', 'Melo T', 'Araujo T', 'Harangi B', 'Sheng B', 'Fang R', 'Sheet D', 'Hajdu A', 'Zheng Y', 'Mendonca AM', 'Zhang S', 'Campilho A', 'Zheng B', 'Shen D', 'Giancardo L', 'Quellec G', 'Meriaudeau F']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/11/01 06:00']		20191003	2020 Jan	2019/11/02 06:00		['Porwal, Prasanna', 'Pachade, Samiksha', 'Kokare, Manesh', 'Deshmukh, Girish', 'Son, Jaemin', 'Bae, Woong', 'Liu, Lihong', 'Wang, Jianzong', 'Liu, Xinhui', 'Gao, Liangxin', 'Wu, TianBo', 'Xiao, Jing', 'Wang, Fengyan', 'Yin, Baocai', 'Wang, Yunzhi', 'Danala, Gopichandh', 'He, Linsheng', 'Choi, Yoon Ho', 'Lee, Yeong Chan', 'Jung, Sang-Hyuk', 'Li, Zhongyu', 'Sui, Xiaodan', 'Wu, Junyan', 'Li, Xiaolong', 'Zhou, Ting', 'Toth, Janos', 'Baran, Agnes', 'Kori, Avinash', 'Chennamsetty, Sai Saketh', 'Safwan, Mohammed', 'Alex, Varghese', 'Lyu, Xingzheng', 'Cheng, Li', 'Chu, Qinhao', 'Li, Pengcheng', 'Ji, Xin', 'Zhang, Sanyuan', 'Shen, Yaxin', 'Dai, Ling', 'Saha, Oindrila', 'Sathish, Rachana', 'Melo, Tania', 'Araujo, Teresa', 'Harangi, Balazs', 'Sheng, Bin', 'Fang, Ruogu', 'Sheet, Debdoot', 'Hajdu, Andras', 'Zheng, Yuanjie', 'Mendonca, Ana Maria', 'Zhang, Shaoting', 'Campilho, Aurelio', 'Zheng, Bin', 'Shen, Dinggang', 'Giancardo, Luca', 'Quellec, Gwenole', 'Meriaudeau, Fabrice']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(19)30103-3 [pii] 10.1016/j.media.2019.101561 [doi]	20191124		2019/11/02 06:00		['Challenge', 'Deep learning', 'Diabetic Retinopathy', 'Retinal image analysis']	['NOTNLM']	NLM	101561	['2019/01/11 00:00 [received]', '2019/09/09 00:00 [revised]', '2019/09/16 00:00 [accepted]', '2019/11/02 06:00 [pubmed]', '2019/11/02 06:00 [medline]', '2019/11/01 06:00 [entrez]']	Netherlands			31671320	ppublish	['Journal Article']			IM		Med Image Anal. 2020 Jan;59:101561. doi: 10.1016/j.media.2019.101561. Epub 2019 Oct 3.	In-Data-Review	Med Image Anal	IDRiD: Diabetic Retinopathy - Segmentation and Grading Challenge.		59	IDRiD: Diabetic Retinopathy - Segmentation and Grading Challenge.
BACKGROUND: One of the main challenges for the CRISPR-Cas9 system is selecting optimal single-guide RNAs (sgRNAs). Recently, deep learning has enhanced sgRNA prediction in eukaryotes. However, the prokaryotic chromatin structure is different from eukaryotes, so models trained on eukaryotes may not apply to prokaryotes. RESULTS: We designed and implemented a convolutional neural network to predict sgRNA activity in Escherichia coli. The network was trained and tested on the recently-released sgRNA activity dataset. Our convolutional neural network achieved excellent performance, yielding average Spearman correlation coefficients of 0.5817, 0.7105, and 0.3602, respectively for Cas9, eSpCas9 and Cas9 with a recA coding region deletion. We confirmed that the sgRNA prediction models trained on prokaryotes do not apply to eukaryotes and vice versa. We adopted perturbation-based approaches to analyze distinct biological patterns between prokaryotic and eukaryotic editing. Then, we improved the predictive performance of the prokaryotic Cas9 system by transfer learning. Finally, we determined that potential off-target scores accumulated on a genome-wide scale affect on-target activity, which could slightly improve on-target predictive performance. CONCLUSIONS: We developed convolutional neural networks to predict sgRNA activity for wild type and mutant Cas9 in prokaryotes. Our results show that the prediction accuracy of our method is improved over state-of-the-art models.	['School of Life Science, Beijing Institute of Technology, South Zhongguancun Street, Beijing, 100081, China.', 'School of Life Science, Beijing Institute of Technology, South Zhongguancun Street, Beijing, 100081, China. jhzhang@bit.edu.cn.', 'Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, The Ministry of Industry and Information Technology, Beijing Institute of Technology, Beijing, China. jhzhang@bit.edu.cn.']	['10.1186/s12859-019-3151-4 [doi]', '10.1186/s12859-019-3151-4 [pii]']	['Wang L', 'Zhang J']	['ORCID: http://orcid.org/0000-0002-4231-8223']						['2019/10/26 06:00']	20191119	20191024	2019 Oct 24	2019/10/28 06:00		['Wang, Lei', 'Zhang, Juhua']			1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-3151-4 [doi]	20191119	['Bacteria/*genetics', 'CRISPR-Cas Systems', '*Deep Learning', '*Gene Editing', '*Neural Networks (Computer)', 'RNA, Guide/*genetics', 'Sequence Deletion']	2019/11/20 06:00		['CRISPR-Cas9', 'Deep learning', 'On-target activity', 'Prokaryotes']	['NOTNLM']	NLM	517	['2019/05/26 00:00 [received]', '2019/10/04 00:00 [accepted]', '2019/10/26 06:00 [entrez]', '2019/10/28 06:00 [pubmed]', '2019/11/20 06:00 [medline]']	England	PMC6814057		31651233	epublish	['Journal Article']		['0 (RNA, Guide)']	IM		BMC Bioinformatics. 2019 Oct 24;20(1):517. doi: 10.1186/s12859-019-3151-4.	MEDLINE	BMC Bioinformatics	Prediction of sgRNA on-target activity in bacteria by deep learning.		20	Prediction of sgRNA on-target activity in bacteria by deep learning.
The application of data science in cancer research has been boosted by major advances in three primary areas: (1) Data: diversity, amount, and availability of biomedical data; (2) Advances in Artificial Intelligence (AI) and Machine Learning (ML) algorithms that enable learning from complex, large-scale data; and (3) Advances in computer architectures allowing unprecedented acceleration of simulation and machine learning algorithms. These advances help build in silico ML models that can provide transformative insights from data including: molecular dynamics simulations, next-generation sequencing, omics, imaging, and unstructured clinical text documents. Unique challenges persist, however, in building ML models related to cancer, including: (1) access, sharing, labeling, and integration of multimodal and multi-institutional data across different cancer types; (2) developing AI models for cancer research capable of scaling on next generation high performance computers; and (3) assessing robustness and reliability in the AI models. In this paper, we review the National Cancer Institute (NCI) -Department of Energy (DOE) collaboration, Joint Design of Advanced Computing Solutions for Cancer (JDACS4C), a multi-institution collaborative effort focused on advancing computing and data technologies to accelerate cancer research on three levels: molecular, cellular, and population. This collaboration integrates various types of generated data, pre-exascale compute resources, and advances in ML models to increase understanding of basic cancer biology, identify promising new treatment options, predict outcomes, and eventually prescribe specialized treatments for patients with cancer.	['Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, United States.', 'Computing, Environment and Life Sciences Directorate, Argonne National Laboratory, Lemont, IL, United States.', 'Division of Cancer Treatment and Diagnosis, National Cancer Institute, Bethesda, MD, United States.', 'Applied Development and Research Directorate, Frederick National Laboratory for Cancer Research, Frederick, MD, United States.', 'Center for Biomedical Informatics and Information Technology, National Cancer Institute, Bethesda, MD, United States.', 'Physical and Life Sciences Directorate, Lawrence Livermore National Laboratory, Livermore, CA, United States.', 'National Nuclear Security Administration, U.S. Department of Energy, Advanced Simulation and Computing, Washington, DC, United States.', 'Office of Science, U.S. Department of Energy, Advanced Scientific Computing Research, Washington, DC, United States.', 'NCI RAS Initiative, Cancer Research Technology Program, Frederick National Laboratory for Cancer Research, Frederick, MD, United States.', 'Division of Cancer Control and Population Sciences, National Cancer Institute, Bethesda, MD, United States.', 'Biomedical Informatics and Data Science Directorate, Frederick National Laboratory for Cancer Research, Frederick, MD, United States.', 'Computing, Environment and Life Sciences Directorate, Argonne National Laboratory, Lemont, IL, United States.', 'Computer Science Department, University of Chicago, Chicago, IL, United States.', 'High Performance Computing Innovation Center, Lawrence Livermore National Laboratory, Livermore, CA, United States.', 'Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States.', 'Data Science and Learning Division, Argonne National Laboratory, Lemont, IL, United States.', 'Biomedical Informatics and Data Science Directorate, Frederick National Laboratory for Cancer Research, Frederick, MD, United States.']	['10.3389/fonc.2019.00984 [doi]']	['Bhattacharya T', 'Brettin T', 'Doroshow JH', 'Evrard YA', 'Greenspan EJ', 'Gryshuk AL', 'Hoang TT', 'Lauzon CBV', 'Nissley D', 'Penberthy L', 'Stahlberg E', 'Stevens R', 'Streitz F', 'Tourassi G', 'Xia F', 'Zaki G']		['Copyright (c) 2019 Bhattacharya, Brettin, Doroshow, Evrard, Greenspan, Gryshuk,', 'Hoang, Lauzon, Nissley, Penberthy, Stahlberg, Stevens, Streitz, Tourassi, Xia and', 'Zaki.']					['2019/10/22 06:00']		20191002	2019	2019/10/22 06:00		['Bhattacharya, Tanmoy', 'Brettin, Thomas', 'Doroshow, James H', 'Evrard, Yvonne A', 'Greenspan, Emily J', 'Gryshuk, Amy L', 'Hoang, Thuc T', 'Lauzon, Carolyn B Vea', 'Nissley, Dwight', 'Penberthy, Lynne', 'Stahlberg, Eric', 'Stevens, Rick', 'Streitz, Fred', 'Tourassi, Georgia', 'Xia, Fangfang', 'Zaki, George']					2234-943X (Print) 2234-943X (Linking)	101568867	Frontiers in oncology	['eng']	10.3389/fonc.2019.00984 [doi]	20191024		2019/10/22 06:01		['artificial intelligence', 'cancer research', 'deep learning', 'high performance computing', 'multi-scale modeling', 'natural language processing', 'precision medicine', 'uncertainty quantification']	['NOTNLM']	NLM	984	['2019/05/06 00:00 [received]', '2019/09/16 00:00 [accepted]', '2019/10/22 06:00 [entrez]', '2019/10/22 06:00 [pubmed]', '2019/10/22 06:01 [medline]']	Switzerland	PMC6783509		31632915	epublish	['Journal Article', 'Review']					Front Oncol. 2019 Oct 2;9:984. doi: 10.3389/fonc.2019.00984. eCollection 2019.	PubMed-not-MEDLINE	Front Oncol	AI Meets Exascale Computing: Advancing Cancer Research With Large-Scale High Performance Computing.		9	AI Meets Exascale Computing: Advancing Cancer Research With Large-Scale High Performance Computing.
The application of minimally invasive surgical tool detection and tracking technology based on deep learning in minimally invasive surgery is currently a research hotspot. This paper firstly expounds the relevant technical content of the minimally invasive surgery tool detection and tracking, which mainly introduces the advantages based on deep learning algorithm. Then, this paper summarizes the algorithm for detection and tracking surgical tools based on fully supervised deep neural network and the emerging algorithm for detection and tracking surgical tools based on weakly supervised deep neural network. Several typical algorithm frameworks and their flow charts based on deep convolutional and recurrent neural networks are summarized emphatically, so as to enable researchers in relevant fields to understand the current research progress more systematically and provide reference for minimally invasive surgeons to select navigation technology. In the end, this paper provides a general direction for the further research of minimally invasive surgical tool detection and tracking technology based on deep learning.	['School of Control Science and Engineering, Shandong University, Jinan 250061, P.R.China.', 'School of Control Science and Engineering, Shandong University, Jinan 250061, P.R.China.']	['10.7507/1001-5515.201904061 [doi]']	['Liu Y', 'Zhao Z']							['2019/10/22 06:00']	20191105		2019 Oct 25	2019/10/22 06:00		['Liu, Yuying', 'Zhao, Zijian']			5		1001-5515 (Print) 1001-5515 (Linking)	9426398	Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi	['chi']	10.7507/1001-5515.201904061 [doi]	20191105	['Algorithms', '*Deep Learning', 'Minimally Invasive Surgical Procedures/*instrumentation', '*Neural Networks (Computer)']	2019/11/07 06:00		['convolutional neural network', 'deep learning', 'fully supervised', 'surgical tool detection and tracking', 'weakly supervised']	['NOTNLM']	NLM	870-878	['2019/10/22 06:00 [entrez]', '2019/10/22 06:00 [pubmed]', '2019/11/07 06:00 [medline]']	China			31631638	ppublish	['Journal Article', 'Review']			IM		Sheng Wu Yi Xue Gong Cheng Xue Za Zhi. 2019 Oct 25;36(5):870-878. doi: 10.7507/1001-5515.201904061.	MEDLINE	Sheng Wu Yi Xue Gong Cheng Xue Za Zhi	[Review of research on detection and tracking of minimally invasive surgical tools based on deep learning].		36	[Review of research on detection and tracking of minimally invasive surgical tools based on deep learning].
Glaucoma is one of the leading causes of irreversible but preventable blindness in working age populations. Color fundus photography (CFP) is the most cost-effective imaging modality to screen for retinal disorders. However, its application to glaucoma has been limited to the computation of a few related biomarkers such as the vertical cup-to-disc ratio. Deep learning approaches, although widely applied for medical image analysis, have not been extensively used for glaucoma assessment due to the limited size of the available data sets. Furthermore, the lack of a standardize benchmark strategy makes difficult to compare existing methods in a uniform way. In order to overcome these issues we set up the Retinal Fundus Glaucoma Challenge, REFUGE (https://refuge.grand-challenge.org), held in conjunction with MICCAI 2018. The challenge consisted of two primary tasks, namely optic disc/cup segmentation and glaucoma classification. As part of REFUGE, we have publicly released a data set of 1200 fundus images with ground truth segmentations and clinical glaucoma labels, currently the largest existing one. We have also built an evaluation framework to ease and ensure fairness in the comparison of different models, encouraging the development of novel techniques in the field. 12 teams qualified and participated in the online challenge. This paper summarizes their methods and analyzes their corresponding results. In particular, we observed that two of the top-ranked teams outperformed two human experts in the glaucoma classification task. Furthermore, the segmentation results were in general consistent with the ground truth annotations, with complementary outcomes that can be further exploited by ensembling the results.	['Christian Doppler Laboratory for Ophthalmic Image Analysis (OPTIMA), Vienna Reading Center (VRC), Department of Ophthalmology and Optometry, Medical University of Vienna, Spitalgasse 23, 1090 Vienna, Austria.', 'Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates.', 'Surgery and Physiology Department, Ophthalmology Unit, Faculty of Medicine, University of Porto, Porto, Portugal; Research Group Ophthalmology, KU Leuven, Leuven, Belgium.', 'Research Group Ophthalmology, KU Leuven, Leuven, Belgium.', 'Department of Computer Science & Engineering at Indian Institute of Technology (IIT) Ropar,Rupnagar, 140001 Punjab, India.', 'Instituto de Investigacion e Innovacion en Bioingenieria, I3B, Universitat Politecnica de Valencia, Valencia 46022, Spain.', 'J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, 32611 USA.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, 999077 Hong Kong.', 'Gachon University, 461-701 Gyeonggi-do, Korea.', 'Samsung SDS AI Research Center, 06765 Seoul, Korea.', 'Samsung SDS AI Research Center, 06765 Seoul, Korea.', 'Yale University, 06510 New Haven, CT USA.', 'J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, 32611 USA.', 'Faculty of Science, Beijing University of Chemical Technology, Beijing 100029, China.', 'Healthcare Technology Innovation Centre, IIT-Madras, India.', 'Instituto de Investigacion e Innovacion en Bioingenieria, I3B, Universitat Politecnica de Valencia, Valencia 46022, Spain.', 'Department of Computer Science & Engineering at Indian Institute of Technology (IIT) Ropar,Rupnagar, 140001 Punjab, India.', 'Department of Electrical Engineering, IIT-Madras, India.', 'Department of Computer Science & Engineering at Indian Institute of Technology (IIT) Ropar,Rupnagar, 140001 Punjab, India.', 'VUNO Inc., Seoul, 137-810 Korea.', 'Australian Institute for Machine Learning, Australia.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, 999077 Hong Kong.', 'Cleerly Inc. 10022 New York City, NY USA.', 'Australian Institute for Machine Learning, Australia.', 'South China University of Technology, Guangzhou 510006, China.', 'Faculty of Science, Beijing University of Chemical Technology, Beijing 100029, China.', 'South China University of Technology, Guangzhou 510006, China.', 'Zhongshan Ophthalmic Center, Sun Yat-sen University, China.', 'Zhongshan Ophthalmic Center, Sun Yat-sen University, China. Electronic address: zhangxl2@mail.sysu.edu.cn.', 'Artificial Intelligence Innovation Business, Baidu Inc., China and Cixi Institute of BioMedical Engineering, Chinese Academy of Sciences, China. Electronic address: ywxu@ieee.org.', 'Christian Doppler Laboratory for Ophthalmic Image Analysis (OPTIMA), Vienna Reading Center (VRC), Department of Ophthalmology and Optometry, Medical University of Vienna, Spitalgasse 23, 1090 Vienna, Austria.']	['S1361-8415(19)30110-0 [pii]', '10.1016/j.media.2019.101570 [doi]']	['Orlando JI', 'Fu H', 'Barbosa Breda J', 'van Keer K', 'Bathula DR', 'Diaz-Pinto A', 'Fang R', 'Heng PA', 'Kim J', 'Lee J', 'Lee J', 'Li X', 'Liu P', 'Lu S', 'Murugesan B', 'Naranjo V', 'Phaye SSR', 'Shankaranarayana SM', 'Sikka A', 'Son J', 'van den Hengel A', 'Wang S', 'Wu J', 'Wu Z', 'Xu G', 'Xu Y', 'Yin P', 'Li F', 'Zhang X', 'Xu Y', 'Bogunovic H']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/10/21 06:00']		20191008	2020 Jan	2019/10/21 06:00		['Orlando, Jose Ignacio', 'Fu, Huazhu', 'Barbosa Breda, Joao', 'van Keer, Karel', 'Bathula, Deepti R', 'Diaz-Pinto, Andres', 'Fang, Ruogu', 'Heng, Pheng-Ann', 'Kim, Jeyoung', 'Lee, JoonHo', 'Lee, Joonseok', 'Li, Xiaoxiao', 'Liu, Peng', 'Lu, Shuai', 'Murugesan, Balamurali', 'Naranjo, Valery', 'Phaye, Sai Samarth R', 'Shankaranarayana, Sharath M', 'Sikka, Apoorva', 'Son, Jaemin', 'van den Hengel, Anton', 'Wang, Shujun', 'Wu, Junyan', 'Wu, Zifeng', 'Xu, Guanghui', 'Xu, Yongli', 'Yin, Pengshuai', 'Li, Fei', 'Zhang, Xiulan', 'Xu, Yanwu', 'Bogunovic, Hrvoje']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(19)30110-0 [pii] 10.1016/j.media.2019.101570 [doi]	20191204		2019/10/21 06:00		['Deep learning', 'Fundus photography', 'Glaucoma', 'Image classification', 'Image segmentation']	['NOTNLM']	NLM	101570	['2019/04/05 00:00 [received]', '2019/07/26 00:00 [revised]', '2019/10/01 00:00 [accepted]', '2019/10/21 06:00 [pubmed]', '2019/10/21 06:00 [medline]', '2019/10/21 06:00 [entrez]']	Netherlands			31630011	ppublish	['Journal Article']			IM		Med Image Anal. 2020 Jan;59:101570. doi: 10.1016/j.media.2019.101570. Epub 2019 Oct 8.	In-Data-Review	Med Image Anal	REFUGE Challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs.		59	REFUGE Challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs.
Background: Software systems using artificial intelligence for medical purposes have been developed in recent years. The success of deep neural networks (DNN) in 2012 in the image recognition challenge ImageNet LSVRC 2010 fueled expectations of the potential for using such systems in dermatology.Objective: To evaluate the ways in which machine learning has been utilized in dermatology to date and provide an overview of the findings in current literature on the subject.Methods: We conducted a systematic review of existing literature, identifying the literature through a systematic search of the PubMed database. Two doctors assessed screening and eligibility with respect to pre-determined inclusion and exclusion criteria.Results: A total of 2175 publications were identified, and 64 publications were included. We identified eight major categories where machine learning tools were tested in dermatology. Most systems involved image recognition tools that were primarily aimed at binary classification of malignant melanoma (MM). Short system descriptions and results of all included systems are presented in tables.Conclusions: We present a complete overview of artificial intelligence implemented in dermatology. Impressive outcomes were reported in all of the identified eight categories, but head-to-head comparison proved difficult. The many areas of dermatology where we identified machine learning tools indicate the diversity of machine learning.	['Department of Dermatology and Venerology, Aarhus University Hospital, Aarhus, Denmark.', 'Department of Dermatology and Venerology, Aarhus University Hospital, Aarhus, Denmark.', 'Margrethevej, Vojens, Denmark.', 'Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark.', 'Center for Genomic Medicine, Rigshospitalet, Copenhagen University Hospital, Kobenhavn, Denmark.', 'Bioinformatics Centre, Department of Biology, University of Copenhagen, Kobenhavn, Denmark.']	['10.1080/09546634.2019.1682500 [doi]']	['Thomsen K', 'Iversen L', 'Titlestad TL', 'Winther O']	['ORCID: http://orcid.org/0000-0002-2337-7746', 'ORCID: http://orcid.org/0000-0003-1816-4508', 'ORCID: http://orcid.org/0000-0002-1966-3205']						['2019/10/19 06:00']		20191031	2019 Oct 31	2019/10/19 06:00		['Thomsen, Kenneth', 'Iversen, Lars', 'Titlestad, Therese Louise', 'Winther, Ole']					1471-1753 (Electronic) 0954-6634 (Linking)	8918133	The Journal of dermatological treatment	['eng']	10.1080/09546634.2019.1682500 [doi]	20191031		2019/10/19 06:00		['Dermatology', 'artificial intelligence', 'computer assisted diagnostics', 'deep neural network']	['NOTNLM']	NLM	1-15	['2019/10/19 06:00 [pubmed]', '2019/10/19 06:00 [medline]', '2019/10/19 06:00 [entrez]']	England			31625775	aheadofprint	['Journal Article']			IM		J Dermatolog Treat. 2019 Oct 31:1-15. doi: 10.1080/09546634.2019.1682500.	Publisher	J Dermatolog Treat	Systematic review of machine learning for diagnosis and prognosis in dermatology.			Systematic review of machine learning for diagnosis and prognosis in dermatology.
Artificial intelligence (AI) will pave the way to a new era in medicine. However, currently available AI systems do not interact with a patient, e.g., for anamnesis, and thus are only used by the physicians for predictions in diagnosis or prognosis. However, these systems are widely used, e.g., in diabetes or cancer prediction. In the current study, we developed an AI that is able to interact with a patient (virtual doctor) by using a speech recognition and speech synthesis system and thus can autonomously interact with the patient, which is particularly important for, e.g., rural areas, where the availability of primary medical care is strongly limited by low population densities. As a proof-of-concept, the system is able to predict type 2 diabetes mellitus (T2DM) based on non-invasive sensors and deep neural networks. Moreover, the system provides an easy-to-interpret probability estimation for T2DM for a given patient. Besides the development of the AI, we further analyzed the acceptance of young people for AI in healthcare to estimate the impact of such a system in the future.	['Department of Bioinformatics, Faculty of Mathematics and Computer Science, Philipps-University of Marburg, Hans-Meerwein-Str. 6, 35037 Marburg, Germany.', 'Chair of Marketing and Management of Biogenic Resources, Weihenstephan-Triesdorf University of Applied Sciences/TUM Campus Straubing for Biotechnology and Sustainability, Petersgasse 18, 94315 Straubing, Germany.', 'Department of Gastroenterology, Hepatology and Infectious Diseases, Otto-von-Guericke University Magdeburg, Leipziger Str. 44, 39120 Magdeburg, Germany.', 'Department of Gastroenterology, Hepatology and Infectious Diseases, Otto-von-Guericke University Magdeburg, Leipziger Str. 44, 39120 Magdeburg, Germany.', 'Chair of Marketing and Management of Biogenic Resources, Weihenstephan-Triesdorf University of Applied Sciences/TUM Campus Straubing for Biotechnology and Sustainability, Petersgasse 18, 94315 Straubing, Germany.', 'Department of Bioinformatics, Faculty of Mathematics and Computer Science, Philipps-University of Marburg, Hans-Meerwein-Str. 6, 35037 Marburg, Germany. Electronic address: dominik.heider@uni-marburg.de.']	['S0933-3657(19)30108-3 [pii]', '10.1016/j.artmed.2019.101706 [doi]']	['Spanig S', 'Emberger-Klein A', 'Sowa JP', 'Canbay A', 'Menrad K', 'Heider D']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/10/15 06:00']		20190821	2019 Sep	2019/10/15 06:00		['Spanig, Sebastian', 'Emberger-Klein, Agnes', 'Sowa, Jan-Peter', 'Canbay, Ali', 'Menrad, Klaus', 'Heider, Dominik']					1873-2860 (Electronic) 0933-3657 (Linking)	8915031	Artificial intelligence in medicine	['eng']	S0933-3657(19)30108-3 [pii] 10.1016/j.artmed.2019.101706 [doi]	20191014		2019/10/15 06:00		['Artificial intelligence', 'Deep learning', 'Diabetes', 'Diagnostics', 'E-health', 'Machine learning']	['NOTNLM']	NLM	101706	['2019/02/19 00:00 [received]', '2019/06/27 00:00 [revised]', '2019/08/18 00:00 [accepted]', '2019/10/15 06:00 [entrez]', '2019/10/15 06:00 [pubmed]', '2019/10/15 06:00 [medline]']	Netherlands			31607340	ppublish	['Journal Article']			IM		Artif Intell Med. 2019 Sep;100:101706. doi: 10.1016/j.artmed.2019.101706. Epub 2019 Aug 21.	In-Data-Review	Artif Intell Med	The virtual doctor: An interactive clinical-decision-support system based on deep learning for non-invasive prediction of diabetes.		100	The virtual doctor: An interactive clinical-decision-support system based on deep learning for non-invasive prediction of diabetes.
		['10.1038/d41586-019-03013-5 [doi]', '10.1038/d41586-019-03013-5 [pii]']	['Heaven D']							['2019/10/11 06:00']	20191030		2019 Oct	2019/10/11 06:00		['Heaven, Douglas']			7777		1476-4687 (Electronic) 0028-0836 (Linking)	0410462	Nature	['eng']	10.1038/d41586-019-03013-5 [doi]	20191030	['Deep Learning/*standards', 'Games, Experimental', 'Human Activities', 'Humans', 'Pattern Recognition, Automated/*methods/*standards', '*Research Design', 'Robotics/methods/standards']	2019/10/31 06:00		['*Computer science', '*Information technology']	['NOTNLM']	NLM	163-166	['2019/10/11 06:00 [entrez]', '2019/10/11 06:00 [pubmed]', '2019/10/31 06:00 [medline]']	England			31597977	ppublish	['Journal Article']			IM		Nature. 2019 Oct;574(7777):163-166. doi: 10.1038/d41586-019-03013-5.	MEDLINE	Nature	Why deep-learning AIs are so easy to fool.		574	Why deep-learning AIs are so easy to fool.
BACKGROUND AND PURPOSE: Acute stroke caused by large vessel occlusions (LVOs) requires emergent detection and treatment by endovascular thrombectomy. However, radiologic LVO detection and treatment is subject to variable delays and human expertise, resulting in morbidity. Imaging software using artificial intelligence (AI) and machine learning (ML), a branch of AI, may improve rapid frontline detection of LVO strokes. This report is a systematic review of AI in acute LVO stroke identification and triage, and characterizes LVO detection software. METHODS: A systematic review of acute stroke diagnostic-focused AI studies from January 2014 to February 2019 in PubMed, Medline, and Embase using terms: 'artificial intelligence' or 'machine learning or deep learning' and 'ischemic stroke' or 'large vessel occlusion' was performed. RESULTS: Variations of AI, including ML methods of random forest learning (RFL) and convolutional neural networks (CNNs), are used to detect LVO strokes. Twenty studies were identified that use ML. Alberta Stroke Program Early CT Score (ASPECTS) commonly used RFL, while LVO detection typically used CNNs. Image feature detection had greater sensitivity with CNN than with RFL, 85% versus 68%. However, AI algorithm performance metrics use different standards, precluding ideal objective comparison. Four current software platforms incorporate ML: Brainomix (greatest validation of AI for ASPECTS, uses CNNs to automatically detect LVOs), General Electric, iSchemaView (largest number of perfusion study validations for thrombectomy), and Viz.ai (uses CNNs to automatically detect LVOs, then automatically activates emergency stroke treatment systems). CONCLUSIONS: AI may improve LVO stroke detection and rapid triage necessary for expedited treatment. Standardization of performance assessment is needed in future studies.	['Department of Neurology & Neurological Sciences, Stanford University, Stanford, California, USA.', 'Malone Center for Engineering in Healthcare, Johns Hopkins University, Baltimore, Maryland, USA.', 'Malone Center for Engineering in Healthcare, Johns Hopkins University, Baltimore, Maryland, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, Maryland, USA.', 'Malone Center for Engineering in Healthcare, Johns Hopkins University, Baltimore, Maryland, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, Maryland, USA.', 'Malone Center for Engineering in Healthcare, Johns Hopkins University, Baltimore, Maryland, USA.', 'Department of Radiology, Johns Hopkins University, Baltimore, Maryland, USA.']	['neurintsurg-2019-015135 [pii]', '10.1136/neurintsurg-2019-015135 [doi]']	['Murray NM', 'Unberath M', 'Hager GD', 'Hui FK']	['ORCID: http://orcid.org/0000-0003-3861-0958', 'ORCID: http://orcid.org/0000-0003-3759-7886']	['(c) Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and', 'permissions. Published by BMJ.']			['Competing interests: None declared.']		['2019/10/10 06:00']		20191008	2019 Oct 8	2019/10/09 06:00		['Murray, Nick M', 'Unberath, Mathias', 'Hager, Gregory D', 'Hui, Ferdinand K']					1759-8486 (Electronic) 1759-8478 (Linking)	101517079	Journal of neurointerventional surgery	['eng']	neurintsurg-2019-015135 [pii] 10.1136/neurintsurg-2019-015135 [doi]	20191009		2019/10/09 06:00		['artificial intelligence', 'ischemic stroke diagnosis', 'large vessel occlusion detection', 'machine learning']	['NOTNLM']	NLM		['2019/05/20 00:00 [received]', '2019/07/29 00:00 [revised]', '2019/07/29 00:00 [accepted]', '2019/10/10 06:00 [entrez]', '2019/10/09 06:00 [pubmed]', '2019/10/09 06:00 [medline]']	England			31594798	aheadofprint	['Journal Article', 'Review']			IM		J Neurointerv Surg. 2019 Oct 8. pii: neurintsurg-2019-015135. doi: 10.1136/neurintsurg-2019-015135.	Publisher	J Neurointerv Surg	Artificial intelligence to diagnose ischemic stroke and identify large vessel occlusions: a systematic review.			Artificial intelligence to diagnose ischemic stroke and identify large vessel occlusions: a systematic review.
BACKGROUND: Postoperative mortality occurs in 1-2% of patients undergoing major inpatient surgery. The currently available prediction tools using summaries of intraoperative data are limited by their inability to reflect shifting risk associated with intraoperative physiological perturbations. We sought to compare similar benchmarks to a deep-learning algorithm predicting postoperative 30-day mortality. METHODS: We constructed a multipath convolutional neural network model using patient characteristics, co-morbid conditions, preoperative laboratory values, and intraoperative numerical data from patients undergoing surgery with tracheal intubation at a single medical centre. Data for 60 min prior to a randomly selected time point were utilised. Model performance was compared with a deep neural network, a random forest, a support vector machine, and a logistic regression using predetermined summary statistics of intraoperative data. RESULTS: Of 95 907 patients, 941 (1%) died within 30 days. The multipath convolutional neural network predicted postoperative 30-day mortality with an area under the receiver operating characteristic curve of 0.867 (95% confidence interval [CI]: 0.835-0.899). This was higher than that for the deep neural network (0.825; 95% CI: 0.790-0.860), random forest (0.848; 95% CI: 0.815-0.882), support vector machine (0.836; 95% CI: 0.802-870), and logistic regression (0.837; 95% CI: 0.803-0.871). CONCLUSIONS: A deep-learning time-series model improves prediction compared with models with simple summaries of intraoperative data. We have created a model that can be used in real time to detect dynamic changes in a patient's risk for postoperative mortality.	['Department of Anesthesiology, Washington University in St Louis, St Louis, MO, USA. Electronic address: bafritz@wustl.edu.', 'Department of Computer Science and Engineering, Washington University in St Louis, St Louis, MO, USA.', 'Department of Computer Science and Engineering, Washington University in St Louis, St Louis, MO, USA.', 'Department of Computer Science and Engineering, Washington University in St Louis, St Louis, MO, USA.', 'Department of Computer Science and Engineering, Washington University in St Louis, St Louis, MO, USA.', 'Department of Anesthesiology, Washington University in St Louis, St Louis, MO, USA.', 'Department of Anesthesiology, Washington University in St Louis, St Louis, MO, USA.', 'Department of Anesthesiology, Washington University in St Louis, St Louis, MO, USA.', 'Department of Anesthesiology, Washington University in St Louis, St Louis, MO, USA.']	['S0007-0912(19)30636-1 [pii]', '10.1016/j.bja.2019.07.025 [doi]']	['Fritz BA', 'Cui Z', 'Zhang M', 'He Y', 'Chen Y', 'Kronzer A', 'Ben Abdallah A', 'King CR', 'Avidan MS']		['Copyright (c) 2019 British Journal of Anaesthesia. Published by Elsevier Ltd. All', 'rights reserved.']					['2019/09/28 06:00']	20191024	20190923	2019 Nov	2019/09/29 06:00		['Fritz, Bradley A', 'Cui, Zhicheng', 'Zhang, Muhan', 'He, Yujie', 'Chen, Yixin', 'Kronzer, Alex', 'Ben Abdallah, Arbi', 'King, Christopher R', 'Avidan, Michael S']		['T32 GM108539/GM/NIGMS NIH HHS/United States', 'R21 HS024581/HS/AHRQ HHS/United States']	5		1471-6771 (Electronic) 0007-0912 (Linking)	0372541	British journal of anaesthesia	['eng']	S0007-0912(19)30636-1 [pii] 10.1016/j.bja.2019.07.025 [doi]	20191112	['Algorithms', 'Comorbidity', '*Deep Learning', 'Humans', 'Missouri/epidemiology', 'Neural Networks (Computer)', 'Postoperative Complications/*mortality', 'Postoperative Period', 'Predictive Value of Tests', 'Retrospective Studies', 'Risk Assessment/methods', 'Support Vector Machine', 'Surgical Procedures, Operative/*mortality']	2019/10/28 06:00		['*anaesthesiology', '*deep learning', '*machine learning', '*postoperative complications', '*risk prediction', '*surgery']	['NOTNLM']	NLM	688-695	['2019/01/06 00:00 [received]', '2019/06/21 00:00 [revised]', '2019/07/22 00:00 [accepted]', '2019/09/29 06:00 [pubmed]', '2019/10/28 06:00 [medline]', '2019/09/28 06:00 [entrez]']	England			31558311	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Br J Anaesth. 2019 Nov;123(5):688-695. doi: 10.1016/j.bja.2019.07.025. Epub 2019 Sep 23.	MEDLINE	Br J Anaesth	Deep-learning model for predicting 30-day postoperative mortality.		123	Deep-learning model for predicting 30-day postoperative mortality.
Although computer-aided diagnosis (CAD) is widely used in mammography, conventional CAD programs that use prompts to indicate potential cancers on the mammograms have not led to an improvement in diagnostic accuracy. Because of the advances in machine learning, especially with use of deep (multilayered) convolutional neural networks, artificial intelligence has undergone a transformation that has improved the quality of the predictions of the models. Recently, such deep learning algorithms have been applied to mammography and digital breast tomosynthesis (DBT). In this review, the authors explain how deep learning works in the context of mammography and DBT and define the important technical challenges. Subsequently, they discuss the current status and future perspectives of artificial intelligence-based clinical applications for mammography, DBT, and radiomics. Available algorithms are advanced and approach the performance of radiologists-especially for cancer detection and risk prediction at mammography. However, clinical validation is largely lacking, and it is not clear how the power of deep learning should be used to optimize practice. Further development of deep learning models is necessary for DBT, and this requires collection of larger databases. It is expected that deep learning will eventually have an important role in DBT, including the generation of synthetic images.	['From the Center for Biomedical Imaging (K.J.G., L.M.), Center for Data Science (K.J.G.), Center for Advanced Imaging Innovation and Research (L.M.), and Laura and Isaac Perlmutter Cancer Center (L.M.), New York University School of Medicine, 160 E 34th St, 3rd Floor, New York, NY 10016; Department of Radiology and Nuclear Medicine, Radboud University Medical Centre, Nijmegen, the Netherlands (R.M.M.); and Department of Radiology, the Netherlands Cancer Institute-Antoni van Leeuwenhoek Hospital, Amsterdam, the Netherlands (R.M.M.).', 'From the Center for Biomedical Imaging (K.J.G., L.M.), Center for Data Science (K.J.G.), Center for Advanced Imaging Innovation and Research (L.M.), and Laura and Isaac Perlmutter Cancer Center (L.M.), New York University School of Medicine, 160 E 34th St, 3rd Floor, New York, NY 10016; Department of Radiology and Nuclear Medicine, Radboud University Medical Centre, Nijmegen, the Netherlands (R.M.M.); and Department of Radiology, the Netherlands Cancer Institute-Antoni van Leeuwenhoek Hospital, Amsterdam, the Netherlands (R.M.M.).', 'From the Center for Biomedical Imaging (K.J.G., L.M.), Center for Data Science (K.J.G.), Center for Advanced Imaging Innovation and Research (L.M.), and Laura and Isaac Perlmutter Cancer Center (L.M.), New York University School of Medicine, 160 E 34th St, 3rd Floor, New York, NY 10016; Department of Radiology and Nuclear Medicine, Radboud University Medical Centre, Nijmegen, the Netherlands (R.M.M.); and Department of Radiology, the Netherlands Cancer Institute-Antoni van Leeuwenhoek Hospital, Amsterdam, the Netherlands (R.M.M.).']	['10.1148/radiol.2019182627 [doi]']	['Geras KJ', 'Mann RM', 'Moy L']	['ORCID: http://orcid.org/0000-0003-0549-1446', 'ORCID: http://orcid.org/0000-0001-8111-1930', 'ORCID: http://orcid.org/0000-0001-9564-9360']	['(c) RSNA, 2019.']					['2019/09/25 06:00']		20190924	2019 Nov	2019/09/25 06:00		['Geras, Krzysztof J', 'Mann, Ritse M', 'Moy, Linda']			2		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2019182627 [doi]	20191103		2019/09/25 06:00				NLM	246-259	['2019/09/25 06:00 [pubmed]', '2019/09/25 06:00 [medline]', '2019/09/25 06:00 [entrez]']	United States	PMC6822772		31549948	ppublish	['Journal Article']			AIM IM		Radiology. 2019 Nov;293(2):246-259. doi: 10.1148/radiol.2019182627. Epub 2019 Sep 24.	In-Data-Review	Radiology	Artificial Intelligence for Mammography and Digital Breast Tomosynthesis: Current Concepts and Future Perspectives.		293	Artificial Intelligence for Mammography and Digital Breast Tomosynthesis: Current Concepts and Future Perspectives.
Pipe bursts in water distribution networks lead to considerable water loss and pose risks of bacteria and pollutant contamination. Pipe burst localisation methods help water service providers repair the burst pipes and restore water supply timely and efficiently. Although methods have been reported on burst detection and localisation, there is a lack of studies on accurate localisation of a burst within a potential district by accessible meters. To address this, a novel Burst Location Identification Framework by Fully-linear DenseNet (BLIFF) is proposed. In this framework, additional pressure meters are placed at limited, optimised places for a short period (minutes to hours) to monitor system behaviour after the burst. The fully-linear DenseNet (FL-DenseNet) newly developed in this study modifies the state-of-the-art deep learning algorithm to effectively extract features in the limited pressure signals for accurate burst localisation. BLIFF was tested on a benchmark network with different parameter settings, which showed that accurate burst localisation results can be achieved even with high model uncertainties. The framework was also applied to a real-life network, in which 57 of the total 58 synthetic bursts in the potential burst district were correctly located when the top five most possible pipes are considered and among them, 37 were successfully located when considering only the top one. Only one failed because of the very small pipe diameter and remote location. Comparisons with DenseNet and the traditional fully linear neural network demonstrate that the framework can effectively narrow the potential burst district to one or several pipes with good robustness and applicability. Codes are available at https://github.com/wizard1203/waternn.	['College of Environmental Science and Engineering, Tongji University, 200092, Shanghai, China; Centre for Water Systems, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, EX4 4QF, UK.', 'Department of Computer Science, Hong Kong Baptist University, Hong Kong, China.', 'College of Environmental Science and Engineering, Tongji University, 200092, Shanghai, China.', 'Centre for Water Systems, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, EX4 4QF, UK. Electronic address: m.fanlin@exeter.ac.uk.', 'Department of Computer Science, Hong Kong Baptist University, Hong Kong, China.', 'College of Environmental Science and Engineering, Tongji University, 200092, Shanghai, China; Shanghai Institute of Pollution Control and Ecological Security, 200092, Shanghai, China. Electronic address: xkl@mail.tongji.edu.cn.', 'Centre for Water Systems, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, EX4 4QF, UK; The Alan Turing Institute, 96 Euston Road, London, NW1 2DB, UK.']	['S0043-1354(19)30832-2 [pii]', '10.1016/j.watres.2019.115058 [doi]']	['Zhou X', 'Tang Z', 'Xu W', 'Meng F', 'Chu X', 'Xin K', 'Fu G']		['Copyright (c) 2019 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2019/09/20 06:00']	20191125	20190906	2019 Dec 1	2019/09/20 06:00		['Zhou, Xiao', 'Tang, Zhenheng', 'Xu, Weirong', 'Meng, Fanlin', 'Chu, Xiaowen', 'Xin, Kunlun', 'Fu, Guangtao']					1879-2448 (Electronic) 0043-1354 (Linking)	0105072	Water research	['eng']	S0043-1354(19)30832-2 [pii] 10.1016/j.watres.2019.115058 [doi]	20191125	['Algorithms', '*Deep Learning', 'Neural Networks (Computer)', '*Water', 'Water Supply']	2019/11/26 06:00		['Burst localisation', 'Deep learning', 'DenseNet', 'Pipe burst', 'Water distribution network']	['NOTNLM']	NLM	115058	['2019/04/01 00:00 [received]', '2019/08/31 00:00 [revised]', '2019/09/05 00:00 [accepted]', '2019/09/20 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/09/20 06:00 [entrez]']	England			31536886	ppublish	['Journal Article']		['059QF0KO0R (Water)']	IM		Water Res. 2019 Dec 1;166:115058. doi: 10.1016/j.watres.2019.115058. Epub 2019 Sep 6.	MEDLINE	Water Res	Deep learning identifies accurate burst locations in water distribution networks.		166	Deep learning identifies accurate burst locations in water distribution networks.
A great diversity of factors contribute to the pathogenesis of autism and autism spectrum disorder (ASD). Early detection is known to correlate with improved long term outcomes. There is therefore intense scientific interest in the pathogenesis of and early prediction of autism. Recent reports suggest that epigenetic alterations may play a vital role in disease pathophysiology. We conducted an epigenome-wide analysis of newborn leucocyte (blood spot) DNA in autism as defined at the time of sample collection. Our goal was to investigate the epigenetic basis of autism and identification of early biomarkers for disease prediction. Infinium HumanMethylation450 BeadChip assay was performed to measure DNA methylation level in 14 autism cases and 10 controls. The accuracy of cytosine methylation for autism detection using six different Machine Learning/Artificial Intelligence (AI) approaches including Deep-Learning (DL) was determined. Ingenuity Pathway Analysis (IPA) was further used to interrogate autism pathogenesis by identifying over-represented biological pathways. We found highly significant dysregulation of CpG methylation in 230 loci (249 genes). DL yielded an AUC (95% CI)=1.00 (0.80-1.00) with 97.5% sensitivity and 100.0% specificity for autism detection. Epigenetic dysregulation was identified in several important candidate genes including some previously linked to autism development e.g.: EIF4E, FYN, SHANK1, VIM, LMX1B, GABRB1, SDHAP3 and PACS2. We observed significant enrichment of molecular pathways involved in neuroinflammation signaling, synaptic long term potentiation, serotonin degradation, mTOR signaling and signaling by Rho-Family GTPases. Our findings suggest significant epigenetic role in autism development and epigenetic markers appeared highly accurate for newborn prediction.	['Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI, USA.', 'Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI, USA.', 'Department of Mathematics & Computer Science, Albion College, Albion, MI, USA.', 'Department of Genetics, Cell Biology & Anatomy, College of Medicine, University of Nebraska Medical Center, Omaha, NE, USA.', 'Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI, USA.', 'Department of Genetics, Cell Biology & Anatomy, College of Medicine, University of Nebraska Medical Center, Omaha, NE, USA.', 'Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI, USA. Electronic address: Uppala.radhakrishna@beaumont.edu.']	['S0006-8993(19)30511-6 [pii]', '10.1016/j.brainres.2019.146457 [doi]']	['Bahado-Singh RO', 'Vishweswaraiah S', 'Aydas B', 'Mishra NK', 'Yilmaz A', 'Guda C', 'Radhakrishna U']		['Copyright (c) 2019. Published by Elsevier B.V.']					['2019/09/16 06:00']		20190912	2019 Dec 1	2019/09/16 06:00		['Bahado-Singh, Ray O', 'Vishweswaraiah, Sangeetha', 'Aydas, Buket', 'Mishra, Nitish K', 'Yilmaz, Ali', 'Guda, Chittibabu', 'Radhakrishna, Uppala']					1872-6240 (Electronic) 0006-8993 (Linking)	0045503	Brain research	['eng']	S0006-8993(19)30511-6 [pii] 10.1016/j.brainres.2019.146457 [doi]	20191007		2019/09/16 06:00		['Artificial intelligence', 'Autism', 'DNA methylation', 'Epigenetics', 'Newborns']	['NOTNLM']	NLM	146457	['2019/07/02 00:00 [received]', '2019/09/10 00:00 [revised]', '2019/09/11 00:00 [accepted]', '2019/09/16 06:00 [pubmed]', '2019/09/16 06:00 [medline]', '2019/09/16 06:00 [entrez]']	Netherlands			31521637	ppublish	['Journal Article']			IM		Brain Res. 2019 Dec 1;1724:146457. doi: 10.1016/j.brainres.2019.146457. Epub 2019 Sep 12.	In-Data-Review	Brain Res	Artificial intelligence analysis of newborn leucocyte epigenomic markers for the prediction of autism.		1724	Artificial intelligence analysis of newborn leucocyte epigenomic markers for the prediction of autism.
Treatment planning is an essential step of the radiotherapy workflow. It has become more sophisticated over the past couple of decades with the help of computer science, enabling planners to design highly complex radiotherapy plans to minimize the normal tissue damage while persevering sufficient tumor control. As a result, treatment planning has become more labor intensive, requiring hours or even days of planner effort to optimize an individual patient case in a trial-and-error fashion. More recently, artificial intelligence has been utilized to automate and improve various aspects of medical science. For radiotherapy treatment planning, many algorithms have been developed to better support planners. These algorithms focus on automating the planning process and/or optimizing dosimetric trade-offs, and they have already made great impact on improving treatment planning efficiency and plan quality consistency. In this review, the smart planning tools in current clinical use are summarized in 3 main categories: automated rule implementation and reasoning, modeling of prior knowledge in clinical practice, and multicriteria optimization. Novel artificial intelligence-based treatment planning applications, such as deep learning-based algorithms and emerging research directions, are also reviewed. Finally, the challenges of artificial intelligence-based treatment planning are discussed for future works.	['1 Department of Radiation Oncology, Duke University Medical Center, Durham, NC, USA.', '2 Department of Radiation Oncology, Georgetown University Hospital, Rockville, MD, USA.', '1 Department of Radiation Oncology, Duke University Medical Center, Durham, NC, USA.', '3 Department of Radiation Oncology, University of California, San Francisco, CA, USA.', '4 Department of Radiation Oncology, University of Nebraska Medical Center, Omaha, NE, USA.']	['10.1177/1533033819873922 [doi]']	['Wang C', 'Zhu X', 'Hong JC', 'Zheng D']	['ORCID: 0000-0002-6945-7119', 'ORCID: 0000-0001-5172-6889', 'ORCID: 0000-0003-2259-1633']						['2019/09/10 06:00']			2019 Jan 1	2019/09/10 06:00		['Wang, Chunhao', 'Zhu, Xiaofeng', 'Hong, Julian C', 'Zheng, Dandan']					1533-0338 (Electronic) 1533-0338 (Linking)	101140941	Technology in cancer research & treatment	['eng']	10.1177/1533033819873922 [doi]	20191015		2019/09/10 06:00		['*artificial intelligence machine learning radiotherapy treatment planning', 'automation']	['NOTNLM']	NLM	1533033819873922	['2019/09/10 06:00 [entrez]', '2019/09/10 06:00 [pubmed]', '2019/09/10 06:00 [medline]']	United States	PMC6732844		31495281	ppublish	['Journal Article']			IM		Technol Cancer Res Treat. 2019 Jan 1;18:1533033819873922. doi: 10.1177/1533033819873922.	In-Process	Technol Cancer Res Treat	Artificial Intelligence in Radiotherapy Treatment Planning: Present and Future.		18	Artificial Intelligence in Radiotherapy Treatment Planning: Present and Future.
Currently, the use of artificial intelligence (AI) in radiology, particularly machine learning (ML), has become a reality in clinical practice. Since the end of the last century, several ML algorithms have been introduced for a wide range of common imaging tasks, not only for diagnostic purposes but also for image acquisition and postprocessing. AI is now recognized to be a driving initiative in every aspect of radiology. There is growing evidence of the advantages of AI in radiology creating seamless imaging workflows for radiologists or even replacing radiologists. Most of the current AI methods have some internal and external disadvantages that are impeding their ultimate implementation in the clinical arena. As such, AI can be considered a portion of a business trying to be introduced in the health care market. For this reason, this review analyzes the current status of AI, and specifically ML, applied to radiology from the scope of strengths, weaknesses, opportunities, and threats (SWOT) analysis.	['MRI Unit, Radiology Department, Health Time, Jaen, Spain.', '3D Printing Unit, Engineering Department, Health Time, Jaen, Spain.', 'SINAI Research Group, Computer Science Department, Advanced Studies Center in ICT (CEATIC), Universidad de Jaen, Jaen, Spain.', 'Department of Radiology, Mayo Clinic, Scottsdale, Arizona.', 'MRI Unit, Radiology Department, Health Time, Jaen, Spain. Electronic address: aluna70@htime.org.']	['S1546-1440(19)30699-4 [pii]', '10.1016/j.jacr.2019.05.047 [doi]']	['Martin Noguerol T', 'Paulano-Godino F', 'Martin-Valdivia MT', 'Menias CO', 'Luna A']		['Copyright (c) 2019 American College of Radiology. Published by Elsevier Inc. All', 'rights reserved.']					['2019/09/08 06:00']			2019 Sep	2019/09/08 06:00		['Martin Noguerol, Teodoro', 'Paulano-Godino, Felix', 'Martin-Valdivia, Maria Teresa', 'Menias, Christine O', 'Luna, Antonio']			9 Pt B		1558-349X (Electronic) 1546-1440 (Linking)	101190326	Journal of the American College of Radiology : JACR	['eng']	S1546-1440(19)30699-4 [pii] 10.1016/j.jacr.2019.05.047 [doi]	20190907		2019/09/08 06:00		['Artificial intelligence', 'deep learning', 'machine learning', 'opportunity', 'radiomics', 'strength', 'threat', 'weakness']	['NOTNLM']	NLM	1239-1247	['2019/05/13 00:00 [received]', '2019/05/26 00:00 [revised]', '2019/05/29 00:00 [accepted]', '2019/09/08 06:00 [entrez]', '2019/09/08 06:00 [pubmed]', '2019/09/08 06:00 [medline]']	United States			31492401	ppublish	['Journal Article']			IM		J Am Coll Radiol. 2019 Sep;16(9 Pt B):1239-1247. doi: 10.1016/j.jacr.2019.05.047.	In-Data-Review	J Am Coll Radiol	Strengths, Weaknesses, Opportunities, and Threats Analysis of Artificial Intelligence and Machine Learning Applications in Radiology.		16	Strengths, Weaknesses, Opportunities, and Threats Analysis of Artificial Intelligence and Machine Learning Applications in Radiology.
Deep learning, a state-of-the-art machine learning approach, has shown outstanding performance over traditional machine learning in identifying intricate structures in complex high-dimensional data, especially in the domain of computer vision. The application of deep learning to early detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention, as rapid progress in neuroimaging techniques has generated large-scale multimodal neuroimaging data. A systematic review of publications using deep learning approaches and neuroimaging data for diagnostic classification of AD was performed. A PubMed and Google Scholar search was used to identify deep learning papers on AD published between January 2013 and July 2018. These papers were reviewed, evaluated, and classified by algorithm and neuroimaging type, and the findings were summarized. Of 16 studies meeting full inclusion criteria, 4 used a combination of deep learning and traditional machine learning approaches, and 12 used only deep learning approaches. The combination of traditional machine learning for classification and stacked auto-encoder (SAE) for feature selection produced accuracies of up to 98.8% for AD classification and 83.7% for prediction of conversion from mild cognitive impairment (MCI), a prodromal stage of AD, to AD. Deep learning approaches, such as convolutional neural network (CNN) or recurrent neural network (RNN), that use neuroimaging data without pre-processing for feature selection have yielded accuracies of up to 96.0% for AD classification and 84.2% for MCI conversion prediction. The best classification performance was obtained when multimodal neuroimaging and fluid biomarkers were combined. Deep learning approaches continue to improve in performance and appear to hold promise for diagnostic classification of AD using multimodal neuroimaging data. AD research that uses deep learning is still evolving, improving performance by incorporating additional hybrid data types, such as-omics data, increasing transparency with explainable approaches that add knowledge of specific disease-related features and mechanisms.	['Department of Radiology and Imaging Sciences, Center for Neuroimaging, Indiana University School of Medicine, Indianapolis, IN, United States.', 'Indiana Alzheimer Disease Center, Indiana University School of Medicine, Indianapolis, IN, United States.', 'Indiana University Network Science Institute, Bloomington, IN, United States.', 'Department of Radiology and Imaging Sciences, Center for Neuroimaging, Indiana University School of Medicine, Indianapolis, IN, United States.', 'Indiana Alzheimer Disease Center, Indiana University School of Medicine, Indianapolis, IN, United States.', 'Indiana University Network Science Institute, Bloomington, IN, United States.', 'Department of Radiology and Imaging Sciences, Center for Neuroimaging, Indiana University School of Medicine, Indianapolis, IN, United States.', 'Indiana Alzheimer Disease Center, Indiana University School of Medicine, Indianapolis, IN, United States.', 'Indiana University Network Science Institute, Bloomington, IN, United States.']	['10.3389/fnagi.2019.00220 [doi]']	['Jo T', 'Nho K', 'Saykin AJ']							['2019/09/05 06:00']		20190820	2019	2019/09/05 06:00		['Jo, Taeho', 'Nho, Kwangsik', 'Saykin, Andrew J']					1663-4365 (Print) 1663-4365 (Linking)	101525824	Frontiers in aging neuroscience	['eng']	10.3389/fnagi.2019.00220 [doi]	20190906		2019/09/05 06:01		"[""Alzheimer's disease"", 'artificial intelligence', 'classification', 'deep learning', 'machine learning', 'magnetic resonance imaging', 'neuroimaging', 'positron emission tomography']"	['NOTNLM']	NLM	220	['2019/03/01 00:00 [received]', '2019/08/02 00:00 [accepted]', '2019/09/05 06:00 [entrez]', '2019/09/05 06:00 [pubmed]', '2019/09/05 06:01 [medline]']	Switzerland	PMC6710444		31481890	epublish	['Systematic Review']					Front Aging Neurosci. 2019 Aug 20;11:220. doi: 10.3389/fnagi.2019.00220. eCollection 2019.	PubMed-not-MEDLINE	Front Aging Neurosci	Deep Learning in Alzheimer's Disease: Diagnostic Classification and Prognostic Prediction Using Neuroimaging Data.		11	Deep Learning in Alzheimer's Disease: Diagnostic Classification and Prognostic Prediction Using Neuroimaging Data.
Machine learning leverages statistical and computer science principles to develop algorithms capable of improving performance through interpretation of data rather than through explicit instructions. Alongside widespread use in image recognition, language processing, and data mining, machine learning techniques have received increasing attention in medical applications, ranging from automated imaging analysis to disease forecasting. This review examines the parallel progress made in epilepsy, highlighting applications in automated seizure detection from electroencephalography (EEG), video, and kinetic data, automated imaging analysis and pre-surgical planning, prediction of medication response, and prediction of medical and surgical outcomes using a wide variety of data sources. A brief overview of commonly used machine learning approaches, as well as challenges in further application of machine learning techniques in epilepsy, is also presented. With increasing computational capabilities, availability of effective machine learning algorithms, and accumulation of larger datasets, clinicians and researchers will increasingly benefit from familiarity with these techniques and the significant progress already made in their application in epilepsy.	['Department of Neurology, Beth Israel Deaconess Medical Center, Boston, MA, USA.', 'Department of Neurology, Beth Israel Deaconess Medical Center, Boston, MA, USA.']	['10.1111/epi.16333 [doi]']	['Abbasi B', 'Goldenholz DM']	['ORCID: https://orcid.org/0000-0001-6593-5550', 'ORCID: https://orcid.org/0000-0002-8370-2758']	['Wiley Periodicals, Inc. (c) 2019 International League Against Epilepsy.']					['2019/09/04 06:00']		20190903	2019 Oct	2019/09/04 06:00		['Abbasi, Bardia', 'Goldenholz, Daniel M']			10		1528-1167 (Electronic) 0013-9580 (Linking)	2983306R	Epilepsia	['eng']	10.1111/epi.16333 [doi]	20191010		2019/09/04 06:00		['artificial intelligence', 'deep learning', 'epilepsy imaging', 'epilepsy surgery', 'seizure detection']	['NOTNLM']	NLM	2037-2047	['2019/04/23 00:00 [received]', '2019/07/25 00:00 [revised]', '2019/08/12 00:00 [accepted]', '2019/09/04 06:00 [pubmed]', '2019/09/04 06:00 [medline]', '2019/09/04 06:00 [entrez]']	United States			31478577	ppublish	['Journal Article', 'Review']			IM		Epilepsia. 2019 Oct;60(10):2037-2047. doi: 10.1111/epi.16333. Epub 2019 Sep 3.	In-Data-Review	Epilepsia	Machine learning applications in epilepsy.		60	Machine learning applications in epilepsy.
We have developed a deep generative model, generative tensorial reinforcement learning (GENTRL), for de novo small-molecule design. GENTRL optimizes synthetic feasibility, novelty, and biological activity. We used GENTRL to discover potent inhibitors of discoidin domain receptor 1 (DDR1), a kinase target implicated in fibrosis and other diseases, in 21 days. Four compounds were active in biochemical assays, and two were validated in cell-based assays. One lead candidate was tested and demonstrated favorable pharmacokinetics in mice.	['Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong. alex@insilico.com.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'Insilico Medicine Hong Kong Ltd, Pak Shek Kok, New Territories, Hong Kong.', 'WuXi AppTec Co., Ltd, Shanghai, China.', 'WuXi AppTec Co., Ltd, Shanghai, China.', 'WuXi AppTec Co., Ltd, Shanghai, China.', 'WuXi AppTec Co., Ltd, Shanghai, China.', 'WuXi AppTec Co., Ltd, Shanghai, China.', 'Department of Chemistry, University of Toronto, Toronto, Ontario, Canada.', 'Department of Computer Science, University of Toronto, Toronto, Ontario, Canada.', 'Vector Institute for Artificial Intelligence, Toronto, Ontario, Canada.', 'Canadian Institute for Advanced Research, Toronto, Ontario, Canada.']	['10.1038/s41587-019-0224-x [doi]', '10.1038/s41587-019-0224-x [pii]']	['Zhavoronkov A', 'Ivanenkov YA', 'Aliper A', 'Veselov MS', 'Aladinskiy VA', 'Aladinskaya AV', 'Terentiev VA', 'Polykovskiy DA', 'Kuznetsov MD', 'Asadulaev A', 'Volkov Y', 'Zholus A', 'Shayakhmetov RR', 'Zhebrak A', 'Minaeva LI', 'Zagribelnyy BA', 'Lee LH', 'Soll R', 'Madge D', 'Xing L', 'Guo T', 'Aspuru-Guzik A']	['ORCID: http://orcid.org/0000-0001-7067-8966', 'ORCID: http://orcid.org/0000-0002-7102-5446', 'ORCID: http://orcid.org/0000-0001-6055-0985']						['2019/09/04 06:00']	20191106	20190902	2019 Sep	2019/09/04 06:00		['Zhavoronkov, Alex', 'Ivanenkov, Yan A', 'Aliper, Alex', 'Veselov, Mark S', 'Aladinskiy, Vladimir A', 'Aladinskaya, Anastasiya V', 'Terentiev, Victor A', 'Polykovskiy, Daniil A', 'Kuznetsov, Maksim D', 'Asadulaev, Arip', 'Volkov, Yury', 'Zholus, Artem', 'Shayakhmetov, Rim R', 'Zhebrak, Alexander', 'Minaeva, Lidiya I', 'Zagribelnyy, Bogdan A', 'Lee, Lennart H', 'Soll, Richard', 'Madge, David', 'Xing, Li', 'Guo, Tao', 'Aspuru-Guzik, Alan']			9		1546-1696 (Electronic) 1087-0156 (Linking)	9604648	Nature biotechnology	['eng']	10.1038/s41587-019-0224-x [doi]	20191115	['Animals', '*Deep Learning', 'Discoidin Domain Receptor 1/*antagonists & inhibitors/genetics/*metabolism', 'Dogs', 'Drug Evaluation, Preclinical/*methods', 'Enzyme Inhibitors', 'Humans', 'Mice', 'Microsomes, Liver/metabolism', 'Models, Molecular', 'Molecular Structure', 'Protein Conformation', 'Rats']	2019/11/07 06:00				NLM	1038-1040	['2018/11/01 00:00 [received]', '2019/07/12 00:00 [accepted]', '2019/09/04 06:00 [pubmed]', '2019/11/07 06:00 [medline]', '2019/09/04 06:00 [entrez]']	United States			31477924	ppublish	['Journal Article']		['0 (Enzyme Inhibitors)', 'EC 2.7.10.1 (Discoidin Domain Receptor 1)']	IM		Nat Biotechnol. 2019 Sep;37(9):1038-1040. doi: 10.1038/s41587-019-0224-x. Epub 2019 Sep 2.	MEDLINE	Nat Biotechnol	Deep learning enables rapid identification of potent DDR1 kinase inhibitors.		37	Deep learning enables rapid identification of potent DDR1 kinase inhibitors.
Position-Specific Scoring Matrix (PSSM) is an excellent feature extraction method that was proposed early in protein classifying prediction, but within the restriction of feature shape in PSSM, researchers make a lot attempts to process it so that PSSM can be input to the traditional machine learning algorithms. These processes drop information provided by PSSM in a way thus the feature representation is limited. Moreover, the high-dimensional feature representation of PSSM makes it incompatible with other feature extraction methods. We use the PSSM as the input of Recurrent Neural Network without any post-processing, the amino acids in protein sequences are regarded as time step in RNN. This way takes full advantage of the information that PSSM provides. In this study, the PSSM is input to the model directly and the internal information of PSSM is fully utilized, we propose an end-to-end solution and achieve state-of-the-art performance. Ultimately, the exploration of how to combine PSSM with traditional feature extraction methods is carried out and achieve slightly improved performance. Our network architecture is implemented in Python and is available at https://github.com/YellowcardD/RNN-for-membrane-protein-types-prediction.	['Department of Computer Science and Engineering, School of Information Science and Engineering, Yunnan University, Kunming 650504, PR China. Electronic address: sfwang_66@ynu.edu.cn.', 'Department of Computer Science and Engineering, School of Information Science and Engineering, Yunnan University, Kunming 650504, PR China.', 'Department of Computer Science and Engineering, School of Information Science and Engineering, Yunnan University, Kunming 650504, PR China.', 'School of Public Health (Shenzhen), Sun Yat-sen University, Guangzhou 510006, PR China.', 'School of Statistics and Mathematics, Yunnan University of Finance and Economics, Kunming 650221, PR China. Electronic address: feiyukm@aliyun.com.']	['S1476-9271(19)30060-X [pii]', '10.1016/j.compbiolchem.2019.107094 [doi]']	['Wang S', 'Li M', 'Guo L', 'Cao Z', 'Fei Y']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/09/01 06:00']	20191023	20190808	2019 Aug	2019/09/01 06:00		['Wang, Shunfang', 'Li, Mingyuan', 'Guo, Lei', 'Cao, Zicheng', 'Fei, Yu']					1476-928X (Electronic) 1476-9271 (Linking)	101157394	Computational biology and chemistry	['eng']	S1476-9271(19)30060-X [pii] 10.1016/j.compbiolchem.2019.107094 [doi]	20191023	['Computational Biology/methods', 'Databases, Protein/statistics & numerical data', 'Membrane Proteins/chemistry/*classification', '*Neural Networks (Computer)', '*Position-Specific Scoring Matrices']	2019/10/24 06:00		['Deep learning', 'Long short-term memory', 'Membrane protein types prediction', 'Position-Specific scoring matrix']	['NOTNLM']	NLM	9-15	['2019/01/23 00:00 [received]', '2019/05/24 00:00 [revised]', '2019/07/10 00:00 [accepted]', '2019/09/01 06:00 [pubmed]', '2019/10/24 06:00 [medline]', '2019/09/01 06:00 [entrez]']	England			31472418	ppublish	['Journal Article']		['0 (Membrane Proteins)']	IM		Comput Biol Chem. 2019 Aug;81:9-15. doi: 10.1016/j.compbiolchem.2019.107094. Epub 2019 Aug 8.	MEDLINE	Comput Biol Chem	Efficient utilization on PSSM combining with recurrent neural network for membrane protein types prediction.		81	Efficient utilization on PSSM combining with recurrent neural network for membrane protein types prediction.
BACKGROUND: Due to the recent advances in deep learning, this model attracted researchers who have applied it to medical image analysis. However, pathological image analysis based on deep learning networks faces a number of challenges, such as the high resolution (gigapixel) of pathological images and the lack of annotation capabilities. To address these challenges, we propose a training strategy called deep-reverse active learning (DRAL) and atrous DenseNet (ADN) for pathological image classification. The proposed DRAL can improve the classification accuracy of widely used deep learning networks such as VGG-16 and ResNet by removing mislabeled patches in the training set. As the size of a cancer area varies widely in pathological images, the proposed ADN integrates the atrous convolutions with the dense block for multiscale feature extraction. RESULTS: The proposed DRAL and ADN are evaluated using the following three pathological datasets: BACH, CCG, and UCSB. The experiment results demonstrate the excellent performance of the proposed DRAL + ADN framework, achieving patch-level average classification accuracies (ACA) of 94.10%, 92.05% and 97.63% on the BACH, CCG, and UCSB validation sets, respectively. CONCLUSIONS: The DRAL + ADN framework is a potential candidate for boosting the performance of deep learning models for partially mislabeled training datasets.	"['Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China.', 'Youtu Lab, Tencent, Shenzhen, China.', 'Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China.', 'Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China. llshen@szu.edu.cn.', 'Marshall Laboratory of Biomedical Engineering, School of Biomedical Engineering, Shenzhen University, Shenzhen, China. llshen@szu.edu.cn.', 'Guangdong Key Laboratory of IntelligentInformation Processing, Shenzhen University, Shenzhen, China. llshen@szu.edu.cn.', 'The National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen, China. llshen@szu.edu.cn.', ""The Sixth People's Hospital of Shenzhen, Shenzhen, China.""]"	['10.1186/s12859-019-2979-y [doi]', '10.1186/s12859-019-2979-y [pii]']	['Li Y', 'Xie X', 'Shen L', 'Liu S']	['ORCID: http://orcid.org/0000-0003-1420-0815']						['2019/08/29 06:00']	20191101	20190828	2019 Aug 28	2019/08/29 06:00		['Li, Yuexiang', 'Xie, Xinpeng', 'Shen, Linlin', 'Liu, Shaoxiong']		['61672357/National Natural Science Foundation of China', '61702339 and U1713214/National Natural Science Foundation of China', '2018A050501014/Science and Technology Project of Guangdong Province']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2979-y [doi]	20191101	['Algorithms', 'Databases as Topic', '*Deep Learning', 'Humans', '*Image Processing, Computer-Assisted', 'Models, Theoretical', 'Neoplasms/*pathology', '*Problem-Based Learning', 'Reproducibility of Results']	2019/11/02 06:00		['Active learning', 'Atrous convolution', 'Pathological image classification', 'deep learning']	['NOTNLM']	NLM	445	['2018/12/06 00:00 [received]', '2019/07/01 00:00 [accepted]', '2019/08/29 06:00 [entrez]', '2019/08/29 06:00 [pubmed]', '2019/11/02 06:00 [medline]']	England	PMC6712615		31455228	epublish	['Journal Article']			IM		BMC Bioinformatics. 2019 Aug 28;20(1):445. doi: 10.1186/s12859-019-2979-y.	MEDLINE	BMC Bioinformatics	Reverse active learning based atrous DenseNet for pathological image classification.		20	Reverse active learning based atrous DenseNet for pathological image classification.
Diatom examinations have been widely used to perform drowning diagnosis in forensic practice. However, current methods for recognizing diatoms, which use light or electron microscopy, are time-consuming and laborious and often result in false positive or negative decisions. In this study, we demonstrated an artificial intelligence (AI)-based system to automatically identify diatoms in conjunction with a classical chemical digestion approach. By employing transfer learning and data augmentation methods, we trained convolutional neural network (CNN) models on thousands or tens of thousands of tiles from digital whole-slide images of diatom smears. The results showed that the trained model identified the regions containing diatoms in the tiles. In an independent test, where the slide samples were collected in forensic casework, the best CNN model demonstrated a performance competitive with those of 5 forensic pathologists with experience in diatom quantification. This pilot study paves the way for future intelligent diatom examinations; many efficient diatom extraction methods could be incorporated into our automated system.	"['Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China; Department of Forensic Medicine, Inner Mongolia Medical University, Huhhot, Inner Mongolia, 010110, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China.', 'Department of Forensic Medicine, Xuzhou Medical University, Xuzhou 221000, Jiangsu, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China.', ""Department of Forensic Pathology, College of Forensic Medicine, Xian Jiaotong University, Xi'an, Shaanxi, 710061, China."", 'Molecular Oncology Laboratory, Eastern Hepatobiliary Surgery Hospital, Second Military Medical University, Shanghai, 200438, China.', 'Department of Biochemistry and Physiology, Shanghai University of Medicine and Health Sciences, Shanghai, 201318, China.', 'Department of Forensic Medicine, Inner Mongolia Medical University, Huhhot, Inner Mongolia, 010110, China. Electronic address: lqchenyj@163.com.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China. Electronic address: cyj1347@163.com.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Ministry of Justice, Shanghai, 200063, China. Electronic address: huangp@ssfjd.cn.']"	['S0379-0738(19)30334-2 [pii]', '10.1016/j.forsciint.2019.109922 [doi]']	['Zhou Y', 'Zhang J', 'Huang J', 'Deng K', 'Zhang J', 'Qin Z', 'Wang Z', 'Zhang X', 'Tuo Y', 'Chen L', 'Chen Y', 'Huang P']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/08/24 06:00']	20191126	20190808	2019 Sep	2019/08/24 06:00		['Zhou, Yuanyuan', 'Zhang, Ji', 'Huang, Jiao', 'Deng, Kaifei', 'Zhang, Jianhua', 'Qin, Zhiqiang', 'Wang, Zhenyuan', 'Zhang, Xiaofeng', 'Tuo, Ya', 'Chen, Liqin', 'Chen, Yijiu', 'Huang, Ping']					1872-6283 (Electronic) 0379-0738 (Linking)	7902034	Forensic science international	['eng']	S0379-0738(19)30334-2 [pii] 10.1016/j.forsciint.2019.109922 [doi]	20191126	['*Algorithms', 'Deep Learning', '*Diatoms', 'Drowning/*diagnosis', 'Forensic Pathology/methods', 'Humans', 'Lung/*pathology', '*Neural Networks (Computer)', 'Sensitivity and Specificity']	2019/11/27 06:00		['Artificial intelligence', 'Convolutional neural network', 'Diatom examination', 'Drowning', 'Forensic pathology']	['NOTNLM']	NLM	109922	['2019/05/15 00:00 [received]', '2019/08/05 00:00 [revised]', '2019/08/06 00:00 [accepted]', '2019/08/24 06:00 [pubmed]', '2019/11/27 06:00 [medline]', '2019/08/24 06:00 [entrez]']	Ireland			31442682	ppublish	['Journal Article']			IM		Forensic Sci Int. 2019 Sep;302:109922. doi: 10.1016/j.forsciint.2019.109922. Epub 2019 Aug 8.	MEDLINE	Forensic Sci Int	Digital whole-slide image analysis for automated diatom test in forensic cases of drowning using a convolutional neural network algorithm.		302	Digital whole-slide image analysis for automated diatom test in forensic cases of drowning using a convolutional neural network algorithm.
Computer-aided diagnosis based on computed tomography (CT) image can realize the detection and classification of pulmonary nodules, and improve the survival rate of early lung cancer, which has important clinical significance. In recent years, with the rapid development of medical big data and artificial intelligence technology, the auxiliary diagnosis of lung cancer based on deep learning has gradually become one of the most active research directions in this field. In order to promote the deep learning in the detection and classification of pulmonary nodules, we reviewed the research progress in this field based on the relevant literatures published at domestic and overseas in recent years. This paper begins with a brief introduction of two widely used lung CT image databases: lung image database consortium and image database resource initiative (LIDC-IDRI) and Data Science Bowl 2017. Then, the detection and classification of pulmonary nodules based on different network structures are introduced in detail. Finally, some problems of deep learning in lung CT image nodule detection and classification are discussed and conclusions are given. The development prospect is also forecasted, which provides reference for future application research in this field.	['College of Life Science and Bio-engineering, Beijing University of Technology, Beijing 100124, P.R.China.', 'College of Life Science and Bio-engineering, Beijing University of Technology, Beijing 100124, P.R.China.lanlin@bjut.edu.cn.', 'College of software engineering, Beijing University of Technology, Beijing 100124, P.R.China.', 'College of Life Science and Bio-engineering, Beijing University of Technology, Beijing 100124, P.R.China.', 'College of Life Science and Bio-engineering, Beijing University of Technology, Beijing 100124, P.R.China.']	['10.7507/1001-5515.201806019 [doi]']	['Wang J', 'Lin L', 'Zhao S', 'Wu X', 'Wu S']							['2019/08/24 06:00']	20190925		2019 Aug 25	2019/08/24 06:00		['Wang, Jingxuan', 'Lin, Lan', 'Zhao, Siyuan', 'Wu, Xuetao', 'Wu, Shuicai']			4		1001-5515 (Print) 1001-5515 (Linking)	9426398	Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi	['chi']	10.7507/1001-5515.201806019 [doi]	20190925	['*Deep Learning', 'Humans', 'Lung Neoplasms/*diagnostic imaging', 'Radiographic Image Interpretation, Computer-Assisted', 'Reproducibility of Results', 'Solitary Pulmonary Nodule/*diagnostic imaging', '*Tomography, X-Ray Computed']	2019/09/26 06:00		['classification', 'deep learning', 'detection', 'pulmonary nodules']	['NOTNLM']	NLM	670-676	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/26 06:00 [medline]']	China			31441270	ppublish	['Journal Article', 'Review']			IM		Sheng Wu Yi Xue Gong Cheng Xue Za Zhi. 2019 Aug 25;36(4):670-676. doi: 10.7507/1001-5515.201806019.	MEDLINE	Sheng Wu Yi Xue Gong Cheng Xue Za Zhi	[Research progress on computed tomography image detection and classification of pulmonary nodule based on deep learning].		36	[Research progress on computed tomography image detection and classification of pulmonary nodule based on deep learning].
"Recently, the National Institutes of Health (NIH) published a chest X-ray image database named ""ChestX-ray8"", which contains 108,948 X-ray images that are labeled with eight types of diseases. Identifying the pathologies from the clinical images is a challenging task even for human experts, and to develop computer-aided diagnosis systems to help humans identify the pathologies from images is an urgent need. In this study, we applied the deep learning methods to identify the cardiomegaly from the X-ray images. We tested our algorithms on a dataset containing 600 images, and obtained the best performance with an area under the curve (AUC) of 0.87 using the transfer learning method. This result indicates the feasibility of developing computer-aided diagnosis systems for different pathologies from X-rays using deep learning techniques."	['Institute for Health Informatics, University of Minnesota Twin Cities, Minneapolis, Minnesota, USA.', 'School of Biomedical Informatics, University of Texas Health Science Center, Houston, Texas, USA.', 'Institute for Health Informatics, University of Minnesota Twin Cities, Minneapolis, Minnesota, USA.', 'Department of Pharmaceutical Care & Health Systems, University of Minnesota Twin Cities, Minneapolis, Minnesota, USA.']	['SHTI190268 [pii]', '10.3233/SHTI190268 [doi]']	['Zhou S', 'Zhang X', 'Zhang R']							['2019/08/24 06:00']	20190911		2019 Aug 21	2019/08/24 06:00		['Zhou, Sicheng', 'Zhang, Xinyuan', 'Zhang, Rui']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190268 [doi]	20190911	['*Algorithms', 'Area Under Curve', '*Cardiomegaly', 'Deep Learning', '*Diagnosis, Computer-Assisted', 'Humans']	2019/09/12 06:00		['Cardiomegaly', 'Machine Learning', 'X-rays']	['NOTNLM']	NLM	482-486	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/12 06:00 [medline]']	Netherlands			31437970	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2019 Aug 21;264:482-486. doi: 10.3233/SHTI190268.	MEDLINE	Stud Health Technol Inform	Identifying Cardiomegaly in ChestX-ray8 Using Transfer Learning.		264	Identifying Cardiomegaly in ChestX-ray8 Using Transfer Learning.
Huntington Disease (HD) is a genetic neurodegenerative disease which leads to involuntary movements and impaired balance. These changes have been quantified using footstep pressure sensor mats such as Protokinetics' Zeno Walkway. Drawing from distances between recorded footsteps, patients' disease severity have been measured in terms of high level gait characteristics such as gait width and stride length. However, little attention has been paid to the pressure data collected during formation of individual footsteps. This work investigates the potential of classifying patient disease severity based on individual footstep pressure data using deep learning techniques. Using the Motor Subscale of the Unified HD Rating Scale (UHDRS) as the gold standard, our experiments showed that using VGG16 and similar modules can achieve classification accuracy of 89%. Image pre-processing are key steps for better model performance. This classification accuracy is compared to results based on 3D CNN (82%) and SVM (86.9%).	['School of AMME, Faculty of Engineering & IT, The University of Sydney, Sydney, Australia.', 'School of Computer Science, The University of Sydney, Sydney, Australia.', 'Sydney School of Public Health, The University of Sydney, Sydney, Australia.', 'School of AMME, Faculty of Engineering & IT, The University of Sydney, Sydney, Australia.', 'Sydney School of Public Health, The University of Sydney, Sydney, Australia.']	['SHTI190267 [pii]', '10.3233/SHTI190267 [doi]']	['Zhang S', 'Poon SK', 'Vuong K', 'Sneddon A', 'Loy CT']							['2019/08/24 06:00']	20190911		2019 Aug 21	2019/08/24 06:00		['Zhang, Shisheng', 'Poon, Simon K', 'Vuong, Kenny', 'Sneddon, Alexandra', 'Loy, Clement T']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190267 [doi]	20190911	['Deep Learning', 'Gait', 'Gait Analysis', 'Humans', '*Huntington Disease', '*Neurodegenerative Diseases']	2019/09/12 06:00		['Deep Learning', 'Diskynesias', 'Gait Analysis', 'Huntington Disease']	['NOTNLM']	NLM	477-481	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/12 06:00 [medline]']	Netherlands			31437969	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2019 Aug 21;264:477-481. doi: 10.3233/SHTI190267.	MEDLINE	Stud Health Technol Inform	A Deep Learning-Based Approach for Gait Analysis in Huntington Disease.		264	A Deep Learning-Based Approach for Gait Analysis in Huntington Disease.
The onset of acute kidney injury (AKI) during an intensive care unit (ICU) admission is associated with increased morbidity and mortality. Developing novel methods to identify early AKI onset is of critical importance in preventing or reducing AKI complications. We built and applied multiple machine learning models to integrate clinical notes and structured physiological measurements and estimate the risk of new AKI onset using the MIMIC-III database. From the clinical notes, we generated clinically meaningful word representations and embeddings. Four supervised learning classifiers and mixed-feature deep learning architecture were used to construct prediction models. The best configurations consistently utilized both structured and unstructured clinical features and yielded competitive AUCs above 0.83. Our work suggests that integrating structured and unstructured clinical features can be effectively applied to assist clinicians in identifying the risk of incident AKI onset in critically-ill patients upon admission to the ICU.	['Chicago, IL, USA.', 'Department of Pathology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Pathology, Massachusetts General Hospital, Boston, MA, USA.', 'Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA, USA.', 'Feinberg School of Medicine, Northwestern University, Chicago, IL, USA.', 'Feinberg School of Medicine, Northwestern University, Chicago, IL, USA.', 'Feinberg School of Medicine, Northwestern University, Chicago, IL, USA.']	['SHTI190245 [pii]', '10.3233/SHTI190245 [doi]']	['Sun M', 'Baron J', 'Dighe A', 'Szolovits P', 'Wunderink RG', 'Isakova T', 'Luo Y']							['2019/08/24 06:00']	20190911		2019 Aug 21	2019/08/24 06:00		['Sun, Mengxin', 'Baron, Jason', 'Dighe, Anand', 'Szolovits, Peter', 'Wunderink, Richard G', 'Isakova, Tamara', 'Luo, Yuan']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190245 [doi]	20190911	['*Acute Kidney Injury', 'Area Under Curve', 'Critical Care', 'Critical Illness', 'Humans', 'Intensive Care Units']	2019/09/12 06:00		['Acute Kidney Injury', 'Clinical Decision Support', 'Natural Language Processing']	['NOTNLM']	NLM	368-372	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/12 06:00 [medline]']	Netherlands			31437947	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2019 Aug 21;264:368-372. doi: 10.3233/SHTI190245.	MEDLINE	Stud Health Technol Inform	Early Prediction of Acute Kidney Injury in Critical Care Setting Using Clinical Notes and Structured Multivariate Physiological Measurements.		264	Early Prediction of Acute Kidney Injury in Critical Care Setting Using Clinical Notes and Structured Multivariate Physiological Measurements.
Clinical text de-identification enables collaborative research while protecting patient privacy and confidentiality; however, concerns persist about the reduction in the utility of the de-identified text for information extraction and machine learning tasks. In the context of a deep learning experiment to detect altered mental status in emergency department provider notes, we tested several classifiers on clinical notes in their original form and on their automatically de-identified counterpart. We tested both traditional bag-of-words based machine learning models as well as word-embedding based deep learning models. We evaluated the models on 1,113 history of present illness notes. A total of 1,795 protected health information tokens were replaced in the de-identification process across all notes. The deep learning models had the best performance with accuracies of 95% on both original and de-identified notes. However, there was no significant difference in the performance of any of the models on the original vs. the de-identified notes.	['Biomedical Informatics Center, Medical University of South Carolina, Charleston, SC, USA.', 'Biomedical Informatics Center, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Clinical Pharmacy and Outcome Sciences, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Emergency Medicine, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Emergency Medicine, Medical University of South Carolina, Charleston, SC, USA.', 'Biomedical Informatics Center, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Computer Science, University of South Carolina, Columbia, SC, USA.', 'Biomedical Informatics Center, Medical University of South Carolina, Charleston, SC, USA.', 'Biomedical Informatics Center, Medical University of South Carolina, Charleston, SC, USA.']	['SHTI190228 [pii]', '10.3233/SHTI190228 [doi]']	['Obeid JS', 'Heider PM', 'Weeda ER', 'Matuskowitz AJ', 'Carr CM', 'Gagnon K', 'Crawford T', 'Meystre SM']							['2019/08/24 06:00']	20190910		2019 Aug 21	2019/08/24 06:00		['Obeid, Jihad S', 'Heider, Paul M', 'Weeda, Erin R', 'Matuskowitz, Andrew J', 'Carr, Christine M', 'Gagnon, Kevin', 'Crawford, Tami', 'Meystre, Stephane M']		['U54 GM104941/GM/NIGMS NIH HHS/United States', 'UL1 TR001450/TR/NCATS NIH HHS/United States']			1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190228 [doi]	20191023	['Confidentiality', '*Data Anonymization', '*Deep Learning', 'Electronic Health Records', 'Humans', 'Machine Learning']	2019/09/11 06:00	['NIHMS1051218']	['Data Anonymization', 'Machine Learning', 'Natural Language Processing']	['NOTNLM']	NLM	283-287	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/11 06:00 [medline]']	Netherlands	PMC6779034		31437930	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2019 Aug 21;264:283-287. doi: 10.3233/SHTI190228.	MEDLINE	Stud Health Technol Inform	Impact of De-Identification on Clinical Text Classification Using Traditional and Deep Learning Classifiers.		264	Impact of De-Identification on Clinical Text Classification Using Traditional and Deep Learning Classifiers.
Sugar Sweetened Beverages (SSB) are the primary source of artificially added sugar and have a casual association with chronic diseases. Taxation of SSB has been proposed, but limited evidence exists to guide this public health policy. Grocery transaction data, with price, discounting and other information for beverage products, present an opportunity to evaluate the likely effects of taxation policy. Sales are often non-linearly associated with price and are affected by the prices of multiple competing brands. We evaluated the predictive performance of Boosted Decision Tree Regression (B-DTR) and Deep Neural Networks (DNN) that account for the non-linearity and competition across brands, and compared their performance to a benchmark regression, the Least Absolute Shrinkage and Selection Operator (LASSO). B-DTR and DNN showed a lower Mean Squared Error (MSE) of prediction in the sales of most major SSB brands in comparison to LASSO, indicating a superior accuracy in predicting the effectiveness of SSB taxation. We demonstrated the application of machine learning methods and large transactional data from grocery stores to forecast the effectiveness food taxation.	['Surveillance Lab, McGill Clinical and Health Informatics, McGill University, Montreal, Quebec, Canada.', 'School of Computer Science, McGill University, Montreal, Quebec, Canada.', 'Surveillance Lab, McGill Clinical and Health Informatics, McGill University, Montreal, Quebec, Canada.', 'School of Computer Science, McGill University, Montreal, Quebec, Canada.', 'Desautels Faculty of Management, McGill University, Montreal, Quebec, Canada.', 'Surveillance Lab, McGill Clinical and Health Informatics, McGill University, Montreal, Quebec, Canada.']	['SHTI190221 [pii]', '10.3233/SHTI190221 [doi]']	['Lu XH', 'Mamiya H', 'Vybihal J', 'Ma Y', 'Buckeridge DL']							['2019/08/24 06:00']	20190910		2019 Aug 21	2019/08/24 06:00		['Lu, Xing Han', 'Mamiya, Hiroshi', 'Vybihal, Joseph', 'Ma, Yu', 'Buckeridge, David L']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190221 [doi]	20190910	['Beverages', 'Commerce', 'Machine Learning', 'Sweetening Agents', '*Taxes']	2019/09/11 06:00		['Beverages', 'Machine learning', 'Public policy']	['NOTNLM']	NLM	248-252	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/11 06:00 [medline]']	Netherlands			31437923	ppublish	['Journal Article']		['0 (Sweetening Agents)']	T		Stud Health Technol Inform. 2019 Aug 21;264:248-252. doi: 10.3233/SHTI190221.	MEDLINE	Stud Health Technol Inform	Application of Machine Learning and Grocery Transaction Data to Forecast Effectiveness of Beverage Taxation.		264	Application of Machine Learning and Grocery Transaction Data to Forecast Effectiveness of Beverage Taxation.
As the problem of drug abuse intensifies in the U.S., many studies that primarily utilize social media data, such as postings on Twitter, to study drug abuse-related activities use machine learning as a powerful tool for text classification and filtering. However, given the wide range of topics of Twitter users, tweets related to drug abuse are rare in most of the datasets. This imbalanced data remains a major issue in building effective tweet classifiers, and is especially obvious for studies that include abuse-related slang terms. In this study, we approach this problem by designing an ensemble deep learning model that leverages both word-level and character-level features to classify abuse-related tweets. Experiments are reported on a Twitter dataset, where we can configure the percentages of the two classes (abuse vs. non abuse) to simulate the data imbalance with different amplitudes. Results show that our ensemble deep learning models exhibit better performance than ensembles of traditional machine learning models, especially on heavily imbalanced datasets.	['Ying Wu College of Computing, New Jersey Institute of Technology, Newark, NJ, USA.', 'Ying Wu College of Computing, New Jersey Institute of Technology, Newark, NJ, USA.', 'Ying Wu College of Computing, New Jersey Institute of Technology, Newark, NJ, USA.', 'Ying Wu College of Computing, New Jersey Institute of Technology, Newark, NJ, USA.', 'Department of Computer Science, The City College of New York, New York, NY, USA.', 'Computer and Information Science, University of Oregon, Eugene, OR, USA.', 'Information Systems & Informatics, City University of New York, Staten Island, NY, USA.']	['SHTI190204 [pii]', '10.3233/SHTI190204 [doi]']	['Hu H', 'Phan N', 'Geller J', 'Iezzi S', 'Vo H', 'Dou D', 'Chun SA']							['2019/08/24 06:00']	20190910		2019 Aug 21	2019/08/24 06:00		['Hu, Han', 'Phan, NhatHai', 'Geller, James', 'Iezzi, Stephen', 'Vo, Huy', 'Dou, Dejing', 'Chun, Soon Ae']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190204 [doi]	20190910	['Data Collection', 'Deep Learning', 'Machine Learning', '*Social Media', 'Substance Abuse Detection']	2019/09/11 06:00		['Machine Learning', 'Social Media', 'Substance-Related Disorders']	['NOTNLM']	NLM	163-167	['2019/08/24 06:00 [entrez]', '2019/08/24 06:00 [pubmed]', '2019/09/11 06:00 [medline]']	Netherlands			31437906	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2019 Aug 21;264:163-167. doi: 10.3233/SHTI190204.	MEDLINE	Stud Health Technol Inform	An Ensemble Deep Learning Model for Drug Abuse Detection in Sparse Twitter-Sphere.		264	An Ensemble Deep Learning Model for Drug Abuse Detection in Sparse Twitter-Sphere.
BACKGROUND AND OBJECTIVE: Prostate cancer is one of the most common male tumors. The increasing use of whole slide digital scanners has led to an enormous interest in the application of machine learning techniques to histopathological image classification. Here we introduce a novel family of morphological descriptors which, extracted in the appropriate image space and combined with shallow and deep Gaussian process based classifiers, improves early prostate cancer diagnosis. METHOD: We decompose the acquired RGB image in its RGB and optical density hematoxylin and eosin components. Then, we define two novel granulometry-based descriptors which work in both, RGB and optical density, spaces but perform better when used on the latter. In this space they clearly encapsulate knowledge used by pathologists to identify cancer lesions. The obtained features become the inputs to shallow and deep Gaussian process classifiers which achieve an accurate prediction of cancer. RESULTS: We have used a real and unique dataset. The dataset is composed of 60 Whole Slide Images. For a five fold cross validation, shallow and deep Gaussian Processes obtain area under ROC curve values higher than 0.98. They outperform current state of the art patch based shallow classifiers and are very competitive to the best performing deep learning method. Models were also compared on 17 Whole Slide test Images using the FROC curve. With the cost of one false positive, the best performing method, the one layer Gaussian process, identifies 83.87% (sensitivity) of all annotated cancer in the Whole Slide Image. This result corroborates the quality of the extracted features, no more than a layer is needed to achieve excellent generalization results. CONCLUSION: Two new descriptors to extract morphological features from histological images have been proposed. They collect very relevant information for cancer detection. From these descriptors, shallow and deep Gaussian Processes are capable of extracting the complex structure of prostate histological images. The new space/descriptor/classifier paradigm outperforms state-of-art shallow classifiers. Furthermore, despite being much simpler, it is competitive to state-of-art CNN architectures both on the proposed SICAPv1 database and on an external database.	['Institute of Research and Innovation in Bioengineering, I3B, Polytechnic University of Valencia, Valencia, Spain. Electronic address: ngeesav@i3b.upv.es.', 'Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain. Electronic address: mlopez@decsai.ugr.es.', 'Institute of Research and Innovation in Bioengineering, I3B, Polytechnic University of Valencia, Valencia, Spain. Electronic address: adcogra@i3b.upv.es.', 'Anatomical Pathology Service, University Clinical Hospital of Valencia, Valencia, Spain. Electronic address: salesman@gva.es.', 'Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain. Electronic address: rms@decsai.ugr.es.', 'Institute of Research and Innovation in Bioengineering, I3B, Polytechnic University of Valencia, Valencia, Spain. Electronic address: vnaranjo@dcom.upv.es.']	['S0169-2607(19)30390-6 [pii]', '10.1016/j.cmpb.2019.07.003 [doi]']	['Esteban AE', 'Lopez-Perez M', 'Colomer A', 'Sales MA', 'Molina R', 'Naranjo V']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/08/17 06:00']		20190704	2019 Sep	2019/08/17 06:00		['Esteban, Angel E', 'Lopez-Perez, Miguel', 'Colomer, Adrian', 'Sales, Maria A', 'Molina, Rafael', 'Naranjo, Valery']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(19)30390-6 [pii] 10.1016/j.cmpb.2019.07.003 [doi]	20190816		2019/08/17 06:00		['Deep Gaussian processes', 'Gaussian processes', 'Granulometries', 'Histopathological images', 'Prostate cancer', 'Variational inference']	['NOTNLM']	NLM	303-317	['2019/03/29 00:00 [received]', '2019/06/28 00:00 [revised]', '2019/07/03 00:00 [accepted]', '2019/08/17 06:00 [entrez]', '2019/08/17 06:00 [pubmed]', '2019/08/17 06:00 [medline]']	Ireland			31416557	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2019 Sep;178:303-317. doi: 10.1016/j.cmpb.2019.07.003. Epub 2019 Jul 4.	In-Process	Comput Methods Programs Biomed	A new optical density granulometry-based descriptor for the classification of prostate histological images using shallow and deep Gaussian processes.		178	A new optical density granulometry-based descriptor for the classification of prostate histological images using shallow and deep Gaussian processes.
To fully utilize the power of single-cell RNA sequencing (scRNA-seq) technologies for identifying cell lineages and bona fide transcriptional signals, it is necessary to combine data from multiple experiments. We present BERMUDA (Batch Effect ReMoval Using Deep Autoencoders), a novel transfer-learning-based method for batch effect correction in scRNA-seq data. BERMUDA effectively combines different batches of scRNA-seq data with vastly different cell population compositions and amplifies biological signals by transferring information among batches. We demonstrate that BERMUDA outperforms existing methods for removing batch effects and distinguishing cell types in multiple simulated and real scRNA-seq datasets.	['Department of Computer Science, Indiana University Bloomington, Bloomington, IN, USA.', 'Department of Biomedical Informatics, The Ohio State University, Columbus, OH, USA.', 'Department of Medicine, Indiana University School of Medicine, Indianapolis, IN, USA.', 'Department of Medicine, Indiana University School of Medicine, Indianapolis, IN, USA.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, Southern Medical University, Guangzhou, China.', 'Department of Medicine, Indiana University School of Medicine, Indianapolis, IN, USA.', 'Department of Medical and Molecular Genetics, Indiana University School of Medicine, Indianapolis, IN, USA. jizhan@iu.edu.', 'Department of Medicine, Indiana University School of Medicine, Indianapolis, IN, USA. kunhuang@iu.edu.', 'Regenstrief Institute, Indianapolis, IN, USA. kunhuang@iu.edu.']	['10.1186/s13059-019-1764-6 [doi]', '10.1186/s13059-019-1764-6 [pii]']	['Wang T', 'Johnson TS', 'Shao W', 'Lu Z', 'Helm BR', 'Zhang J', 'Huang K']	['ORCID: 0000-0001-5826-1842']						['2019/08/14 06:00']	20191025	20190812	2019 Aug 12	2019/08/14 06:00		['Wang, Tongxin', 'Johnson, Travis S', 'Shao, Wei', 'Lu, Zixiao', 'Helm, Bryan R', 'Zhang, Jie', 'Huang, Kun']		['U01CA188547/National Cancer Institute Informatics Technology for Cancer', 'Research/International', 'F31 LM013056/LM/NLM NIH HHS/United States']	1		1474-760X (Electronic) 1474-7596 (Linking)	100960660	Genome biology	['eng']	10.1186/s13059-019-1764-6 [doi]	20191025	['Algorithms', '*Deep Learning', 'Gene Expression Profiling/*methods', 'Humans', 'Leukocytes, Mononuclear/metabolism', 'Pancreas/cytology/metabolism', 'Sequence Analysis, RNA/*methods', 'Single-Cell Analysis/methods', 'T-Lymphocytes/metabolism']	2019/10/28 06:00		['*Autoencoder', '*Batch effect', '*RNA-seq', '*Single cell', '*Transfer learning']	['NOTNLM']	NLM	165	['2019/05/09 00:00 [received]', '2019/07/17 00:00 [accepted]', '2019/08/14 06:00 [entrez]', '2019/08/14 06:00 [pubmed]', '2019/10/28 06:00 [medline]']	England	PMC6691531		31405383	epublish	['Evaluation Studies', 'Journal Article', 'Research Support, N.I.H., Extramural']			IM		Genome Biol. 2019 Aug 12;20(1):165. doi: 10.1186/s13059-019-1764-6.	MEDLINE	Genome Biol	BERMUDA: a novel deep transfer learning method for single-cell RNA sequencing batch correction reveals hidden high-resolution cellular subtypes.		20	BERMUDA: a novel deep transfer learning method for single-cell RNA sequencing batch correction reveals hidden high-resolution cellular subtypes.
BACKGROUND: Predicting the effect of drug-drug interactions (DDIs) precisely is important for safer and more effective drug co-prescription. Many computational approaches to predict the effect of DDIs have been proposed, with the aim of reducing the effort of identifying these interactions in vivo or in vitro, but room remains for improvement in prediction performance. RESULTS: In this study, we propose a novel deep learning model to predict the effect of DDIs more accurately.. The proposed model uses autoencoders and a deep feed-forward network that are trained using the structural similarity profiles (SSP), Gene Ontology (GO) term similarity profiles (GSP), and target gene similarity profiles (TSP) of known drug pairs to predict the pharmacological effects of DDIs. The results show that GSP and TSP increase the prediction accuracy when using SSP alone, and the autoencoder is more effective than PCA for reducing the dimensions of each profile. Our model showed better performance than the existing methods, and identified a number of novel DDIs that are supported by medical databases or existing research. CONCLUSIONS: We present a novel deep learning model for more accurate prediction of DDIs and their effects, which may assist in future research to discover novel DDIs and their pharmacological effects.	['Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea.', 'Department of Computer Sciences, Yonsei University, Seoul, 03722, South Korea.', 'Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea. jgahn@inu.ac.kr.']	['10.1186/s12859-019-3013-0 [doi]', '10.1186/s12859-019-3013-0 [pii]']	['Lee G', 'Park C', 'Ahn J']	['ORCID: http://orcid.org/0000-0002-7020-7002']						['2019/08/08 06:00']	20191004	20190806	2019 Aug 6	2019/08/08 06:00		['Lee, Geonhee', 'Park, Chihyun', 'Ahn, Jaegyoon']		['NRF-2016R1D1A1B03934135/Basic Science Research Program through the National', 'Research Foundation of Korea (NRF) funded by the Ministry of Education', 'NRF-2019R1A2C3005212/Basic Science Research Program through the National Research', 'Foundation of Korea (NRF) funded by the Ministry of Science and ICT']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-3013-0 [doi]	20191007	['Area Under Curve', 'Databases, Factual', '*Deep Learning', '*Drug Interactions', 'Humans', '*Models, Theoretical', 'Neural Networks (Computer)', 'Support Vector Machine']	2019/10/08 06:00		['Autoencoder', 'Deep learning', 'Drug-drug interaction', 'Similarity profile']	['NOTNLM']	NLM	415	['2019/03/24 00:00 [received]', '2019/07/30 00:00 [accepted]', '2019/08/08 06:00 [entrez]', '2019/08/08 06:00 [pubmed]', '2019/10/08 06:00 [medline]']	England	PMC6685287		31387547	epublish	['Journal Article']			IM		BMC Bioinformatics. 2019 Aug 6;20(1):415. doi: 10.1186/s12859-019-3013-0.	MEDLINE	BMC Bioinformatics	Novel deep learning model for more accurate prediction of drug-drug interaction effects.		20	Novel deep learning model for more accurate prediction of drug-drug interaction effects.
Artificial Intelligence (AI) is an area of computer science that simulates the structures and operating principles of the human brain. Machine learning (ML) belongs to the area of AI and endeavors to develop models from exposure to training data. Deep Learning (DL) is another subset of AI, where models represent geometric transformations over many different layers. This technology has shown tremendous potential in areas such as computer vision, speech recognition and natural language processing. More recently, DL has also been successfully applied in drug discovery. Here, I analyze several relevant DL applications and case studies, providing a detailed view of the current state-of-the-art in drug discovery and highlighting not only the problematic issues, but also the successes and opportunities for further advances.	"['Department of Pharmacy, ""Drug Discovery"" Laboratory, University of Napoli ""Federico II"", via D. Montesano 49, I-80131 Napoli, Italy. Electronic address: antonio.lavecchia@unina.it.']"	['S1359-6446(19)30282-X [pii]', '10.1016/j.drudis.2019.07.006 [doi]']	['Lavecchia A']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/08/05 06:00']		20190801	2019 Oct	2019/08/05 06:00		['Lavecchia, Antonio']			10		1878-5832 (Electronic) 1359-6446 (Linking)	9604391	Drug discovery today	['eng']	S1359-6446(19)30282-X [pii] 10.1016/j.drudis.2019.07.006 [doi]	20191109		2019/08/05 06:00				NLM	2017-2032	['2019/04/06 00:00 [received]', '2019/06/11 00:00 [revised]', '2019/07/18 00:00 [accepted]', '2019/08/05 06:00 [pubmed]', '2019/08/05 06:00 [medline]', '2019/08/05 06:00 [entrez]']	England			31377227	ppublish	['Journal Article', 'Review']			IM		Drug Discov Today. 2019 Oct;24(10):2017-2032. doi: 10.1016/j.drudis.2019.07.006. Epub 2019 Aug 1.	In-Data-Review	Drug Discov Today	Deep learning in drug discovery: opportunities, challenges and future prospects.		24	Deep learning in drug discovery: opportunities, challenges and future prospects.
The identification of transcription factor binding sites and cis-regulatory motifs is a frontier whereupon the rules governing protein-DNA binding are being revealed. Here, we developed a new method (DEep Sequence and Shape mOtif or DESSO) for cis-regulatory motif prediction using deep neural networks and the binomial distribution model. DESSO outperformed existing tools, including DeepBind, in predicting motifs in 690 human ENCODE ChIP-sequencing datasets. Furthermore, the deep-learning framework of DESSO expanded motif discovery beyond the state-of-the-art by allowing the identification of known and new protein-protein-DNA tethering interactions in human transcription factors (TFs). Specifically, 61 putative tethering interactions were identified among the 100 TFs expressed in the K562 cell line. In this work, the power of DESSO was further expanded by integrating the detection of DNA shape features. We found that shape information has strong predictive power for TF-DNA binding and provides new putative shape motif information for human TFs. Thus, DESSO improves in the identification and structural analysis of TF binding sites, by integrating the complexities of DNA binding into a deep-learning framework.	['Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH 43210, USA.', 'Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX 76010, USA.', 'Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH 43210, USA.', 'Department of Chemistry and Biochemistry, South Dakota State University, Brookings, SD 57007, USA.', 'BioSNTR, Brookings, SD 57007, USA.', 'Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH 43210, USA.', 'School of Mathematics, Shandong University, Jinan 250100, China.', 'Department of Medical and Molecular Genetics, School of Medicine, Indiana University, Indianapolis, IN 46202, USA.', 'School of Artificial Intelligence, Jilin University, Changchun 130012, China.', 'School of Mathematics, Shandong University, Jinan 250100, China.', 'Department of Biomedical Informatics, College of Medicine, The Ohio State University, Columbus, OH 43210, USA.']	['5542889 [pii]', '10.1093/nar/gkz672 [doi]']	['Yang J', 'Ma A', 'Hoppe AD', 'Wang C', 'Li Y', 'Zhang C', 'Wang Y', 'Liu B', 'Ma Q']		['(c) The Author(s) 2019. Published by Oxford University Press on behalf of Nucleic', 'Acids Research.']					['2019/08/03 06:00']	20191203		2019 Sep 5	2019/08/03 06:00		['Yang, Jinyu', 'Ma, Anjun', 'Hoppe, Adam D', 'Wang, Cankun', 'Li, Yang', 'Zhang, Chi', 'Wang, Yan', 'Liu, Bingqiang', 'Ma, Qin']			15		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gkz672 [doi]	20191203	['Binding Sites', 'Computational Biology/methods/*statistics & numerical data', 'DNA/*chemistry/genetics/metabolism', '*Deep Learning', 'Gene Expression Regulation', 'Humans', 'K562 Cells', 'Nucleotide Motifs', 'Protein Binding', 'Transcription Factors/classification/*genetics/metabolism']	2019/12/04 06:00				NLM	7809-7824	['2019/07/23 00:00 [accepted]', '2019/07/12 00:00 [received]', '2019/08/03 06:00 [pubmed]', '2019/12/04 06:00 [medline]', '2019/08/03 06:00 [entrez]']	England	PMC6735894		31372637	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Transcription Factors)', '9007-49-2 (DNA)']	IM		Nucleic Acids Res. 2019 Sep 5;47(15):7809-7824. doi: 10.1093/nar/gkz672.	MEDLINE	Nucleic Acids Res	Prediction of regulatory motifs from human Chip-sequencing data using a deep learning framework.		47	Prediction of regulatory motifs from human Chip-sequencing data using a deep learning framework.
PURPOSE OF REVIEW: This paper systematically reviews the recent progress in diabetic retinopathy screening. It provides an integrated overview of the current state of knowledge of emerging techniques using artificial intelligence integration in national screening programs around the world. Existing methodological approaches and research insights are evaluated. An understanding of existing gaps and future directions is created. RECENT FINDINGS: Over the past decades, artificial intelligence has emerged into the scientific consciousness with breakthroughs that are sparking increasing interest among computer science and medical communities. Specifically, machine learning and deep learning (a subtype of machine learning) applications of artificial intelligence are spreading into areas that previously were thought to be only the purview of humans, and a number of applications in ophthalmology field have been explored. Multiple studies all around the world have demonstrated that such systems can behave on par with clinical experts with robust diagnostic performance in diabetic retinopathy diagnosis. However, only few tools have been evaluated in clinical prospective studies. Given the rapid and impressive progress of artificial intelligence technologies, the implementation of deep learning systems into routinely practiced diabetic retinopathy screening could represent a cost-effective alternative to help reduce the incidence of preventable blindness around the world.	['Singapore National Eye Centre, Singapore Eye Research Institute, 11 Third Hospital Avenue, Singapore, 168751, Singapore.', 'Singapore National Eye Centre, Singapore Eye Research Institute, 11 Third Hospital Avenue, Singapore, 168751, Singapore.', 'School of Computing, National University of Singapore, Singapore, Singapore.', 'Singapore National Eye Centre, Singapore Eye Research Institute, 11 Third Hospital Avenue, Singapore, 168751, Singapore.', 'Duke-NUS Medical School, Singapore, Singapore.', 'Singapore National Eye Centre, Singapore Eye Research Institute, 11 Third Hospital Avenue, Singapore, 168751, Singapore.', 'Duke-NUS Medical School, Singapore, Singapore.', 'Department of Ophthalmology and Visual Sciences, The Chinese University of Hong Kong, Shatin, Hong Kong.', 'Doheny Eye Institute, University of California, Los Angeles, CA, USA.', 'Center of Eye Research Australia, Melbourne, Victoria, Australia.', 'Moorfields Eye Hospital & Institute of Ophthalmology, UCL, London, UK.', 'School of Computing, National University of Singapore, Singapore, Singapore.', 'School of Computing, National University of Singapore, Singapore, Singapore.', 'Singapore National Eye Centre, Singapore Eye Research Institute, 11 Third Hospital Avenue, Singapore, 168751, Singapore. daniel.ting.s.w@singhealth.com.sg.', 'Duke-NUS Medical School, Singapore, Singapore. daniel.ting.s.w@singhealth.com.sg.']	['10.1007/s11892-019-1189-3 [doi]', '10.1007/s11892-019-1189-3 [pii]']	['Bellemo V', 'Lim G', 'Rim TH', 'Tan GSW', 'Cheung CY', 'Sadda S', 'He MG', 'Tufail A', 'Lee ML', 'Hsu W', 'Ting DSW']							['2019/08/02 06:00']		20190731	2019 Jul 31	2019/08/02 06:00		['Bellemo, Valentina', 'Lim, Gilbert', 'Rim, Tyler Hyungtaek', 'Tan, Gavin S W', 'Cheung, Carol Y', 'Sadda, SriniVas', 'He, Ming-Guang', 'Tufail, Adnan', 'Lee, Mong Li', 'Hsu, Wynne', 'Ting, Daniel Shu Wei']		['Ref: 14102418/Research Grants Council - General Research Fund, Hong Kong']	9		1539-0829 (Electronic) 1534-4827 (Linking)	101093791	Current diabetes reports	['eng']	10.1007/s11892-019-1189-3 [doi]	20190831		2019/08/02 06:00		['Artificial intelligence', 'Deep learning', 'Diabetic retinopathy screening', 'Retinal images', 'Survey', 'Tele-medicine']	['NOTNLM']	NLM	72	['2019/08/02 06:00 [entrez]', '2019/08/02 06:00 [pubmed]', '2019/08/02 06:00 [medline]']	United States			31367962	epublish	['Journal Article', 'Review']			IM		Curr Diab Rep. 2019 Jul 31;19(9):72. doi: 10.1007/s11892-019-1189-3.	In-Data-Review	Curr Diab Rep	Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application.		19	Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application.
Although structures determined at near-atomic resolution are now routinely reported by cryo-electron microscopy (cryo-EM), many density maps are determined at an intermediate resolution, and extracting structure information from these maps is still a challenge. We report a computational method, Emap2sec, that identifies the secondary structures of proteins (alpha-helices, beta-sheets and other structures) in EM maps at resolutions of between 5 and 10 A. Emap2sec uses a three-dimensional deep convolutional neural network to assign secondary structure to each grid point in an EM map. We tested Emap2sec on EM maps simulated from 34 structures at resolutions of 6.0 and 10.0 A, as well as on 43 maps determined experimentally at resolutions of between 5.0 and 9.5 A. Emap2sec was able to clearly identify the secondary structures in many maps tested, and showed substantially better performance than existing methods.	['Department of Computer Science, Purdue University, West Lafayette, IN, USA.', 'Department of Biological Sciences, Purdue University, West Lafayette, IN, USA.', 'Department of Computer Science, Purdue University, West Lafayette, IN, USA. dkihara@purdue.edu.', 'Department of Biological Sciences, Purdue University, West Lafayette, IN, USA. dkihara@purdue.edu.']	['10.1038/s41592-019-0500-1 [doi]', '10.1038/s41592-019-0500-1 [pii]']	['Maddhuri Venkata Subramaniya SR', 'Terashi G', 'Kihara D']	['ORCID: http://orcid.org/0000-0002-5339-909X', 'ORCID: http://orcid.org/0000-0003-4091-6614']						['2019/07/31 06:00']	20191108	20190729	2019 Sep	2019/07/31 06:00		['Maddhuri Venkata Subramaniya, Sai Raghavendra', 'Terashi, Genki', 'Kihara, Daisuke']		['R01 GM123055/GM/NIGMS NIH HHS/United States']	9		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/s41592-019-0500-1 [doi]	20191115	['Cryoelectron Microscopy/*methods', '*Deep Learning', 'Humans', 'Models, Molecular', '*Neural Networks (Computer)', '*Protein Structure, Secondary', 'Proteins/*chemistry', '*Software']	2019/11/09 06:00	['NIHMS1532783']			NLM	911-917	['2018/12/03 00:00 [received]', '2019/06/24 00:00 [accepted]', '2020/01/29 00:00 [pmc-release]', '2019/07/31 06:00 [pubmed]', '2019/11/09 06:00 [medline]', '2019/07/31 06:00 [entrez]']	United States	PMC6717539	['2020/01/29 00:00']	31358979	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Proteins)']	IM		Nat Methods. 2019 Sep;16(9):911-917. doi: 10.1038/s41592-019-0500-1. Epub 2019 Jul 29.	MEDLINE	Nat Methods	Protein secondary structure detection in intermediate-resolution cryo-EM maps using deep learning.		16	Protein secondary structure detection in intermediate-resolution cryo-EM maps using deep learning.
PURPOSE: The purpose of this study was to report procedures developed to annotate abdominal computed tomography (CT) images from subjects without pancreatic disease that will be used as the input for deep convolutional neural networks (DNN) for development of deep learning algorithms for automatic recognition of a normal pancreas. MATERIALS AND METHODS: Dual-phase contrast-enhanced volumetric CT acquired from 2005 to 2009 from potential kidney donors were retrospectively assessed. Four trained human annotators manually and sequentially annotated 22 structures in each datasets, then expert radiologists confirmed the annotation. For efficient annotation and data management, a commercial software package that supports three-dimensional segmentation was used. RESULTS: A total of 1150 dual-phase CT datasets from 575 subjects were annotated. There were 229 men and 346 women (mean age: 45+/-12years; range: 18-79years). The mean intra-observer intra-subject dual-phase CT volume difference of all annotated structures was 4.27mL (7.65%). The deep network prediction for multi-organ segmentation showed high fidelity with 89.4% and 1.29mm in terms of mean Dice similarity coefficients and mean surface distances, respectively. CONCLUSIONS: A reliable data collection/annotation process for abdominal structures was developed. This process can be used to generate large datasets appropriate for deep learning.	['The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'Department of Computer Science, Johns Hopkins University, School of Arts and Sciences, Baltimore, MD 21218, USA.', 'Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University, School of Medicine, Baltimore, MD 21287, USA; Johns Hopkins University, School of Medicine, Ludwig Center for Cancer Genetics and Therapeutics, Baltimore, MD 21205, USA.', 'Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins University, School of Medicine, Baltimore, MD 21287, USA; Johns Hopkins University, School of Medicine, Ludwig Center for Cancer Genetics and Therapeutics, Baltimore, MD 21205, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'Department of Pathology, The Sol Goldman Pancreatic Cancer Research Center, Johns Hopkins University, School of Medicine, Baltimore, MD 21205, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University, School of Medicine, 601N. Caroline Street, Baltimore, MD 21287, USA. Electronic address: skawamo1@jhmi.edu.']	['S2211-5684(19)30139-1 [pii]', '10.1016/j.diii.2019.05.008 [doi]']	['Park S', 'Chu LC', 'Fishman EK', 'Yuille AL', 'Vogelstein B', 'Kinzler KW', 'Horton KM', 'Hruban RH', 'Zinreich ES', 'Fadaei Fouladi D', 'Shayesteh S', 'Graves J', 'Kawamoto S']		['Copyright (c) 2019 Societe francaise de radiologie. Published by Elsevier Masson', 'SAS. All rights reserved.']					['2019/07/31 06:00']		20190726	2019 Jul 26	2019/07/31 06:00		['Park, S', 'Chu, L C', 'Fishman, E K', 'Yuille, A L', 'Vogelstein, B', 'Kinzler, K W', 'Horton, K M', 'Hruban, R H', 'Zinreich, E S', 'Fadaei Fouladi, D', 'Shayesteh, S', 'Graves, J', 'Kawamoto, S']					2211-5684 (Electronic) 2211-5684 (Linking)	101568499	Diagnostic and interventional imaging	['eng']	S2211-5684(19)30139-1 [pii] 10.1016/j.diii.2019.05.008 [doi]	20190730		2019/07/31 06:00		['Abdominal computed tomography (CT)', 'Artificial intelligence (AI)', 'Image segmentation', 'Machine learning', 'Normal structures']	['NOTNLM']	NLM		['2019/05/10 00:00 [received]', '2019/05/23 00:00 [revised]', '2019/05/28 00:00 [accepted]', '2019/07/31 06:00 [entrez]', '2019/07/31 06:00 [pubmed]', '2019/07/31 06:00 [medline]']	France			31358460	aheadofprint	['Journal Article']			IM		Diagn Interv Imaging. 2019 Jul 26. pii: S2211-5684(19)30139-1. doi: 10.1016/j.diii.2019.05.008.	Publisher	Diagn Interv Imaging	Annotated normal CT data of the abdomen for deep learning: Challenges and strategies for implementation.			Annotated normal CT data of the abdomen for deep learning: Challenges and strategies for implementation.
BACKGROUND: Understanding the phenotypic drug response on cancer cell lines plays a vital role in anti-cancer drug discovery and re-purposing. The Genomics of Drug Sensitivity in Cancer (GDSC) database provides open data for researchers in phenotypic screening to build and test their models. Previously, most research in these areas starts from the molecular fingerprints or physiochemical features of drugs, instead of their structures. RESULTS: In this paper, a model called twin Convolutional Neural Network for drugs in SMILES format (tCNNS) is introduced for phenotypic screening. tCNNS uses a convolutional network to extract features for drugs from their simplified molecular input line entry specification (SMILES) format and uses another convolutional network to extract features for cancer cell lines from the genetic feature vectors respectively. After that, a fully connected network is used to predict the interaction between the drugs and the cancer cell lines. When the training set and the testing set are divided based on the interaction pairs between drugs and cell lines, tCNNS achieves 0.826, 0.831 for the mean and top quartile of the coefficient of determinant (R(2)) respectively and 0.909, 0.912 for the mean and top quartile of the Pearson correlation (Rp) respectively, which are significantly better than those of the previous works (Ammad-Ud-Din et al., J Chem Inf Model 54:2347-9, 2014), (Haider et al., PLoS ONE 10:0144490, 2015), (Menden et al., PLoS ONE 8:61318, 2013). However, when the training set and the testing set are divided exclusively based on drugs or cell lines, the performance of tCNNS decreases significantly and Rp and R(2) drop to barely above 0. CONCLUSIONS: Our approach is able to predict the drug effects on cancer cell lines with high accuracy, and its performance remains stable with less but high-quality data, and with fewer features for the cancer cell lines. tCNNS can also solve the problem of outliers in other feature space. Besides achieving high scores in these statistical metrics, tCNNS also provides some insights into the phenotypic screening. However, the performance of tCNNS drops in the blind test.	['Department of Computer Science and Engineering, the Chinese University of Hong Kong, Sha Tin, N.T., Hong Kong, China. pfliu@cse.cuhk.edu.hk.', 'SDIVF R&D Centre, Hong Kong Science Park, Sha Tin, N.T., Hong Kong, China.', 'CUHK-SDU Reproductive Genetics Joint Laboratory, School of Biomedical Sciences, the Chinese University of Hong Kong, Sha Tin, N.T., Hong Kong, China.', 'Department of Computer Science and Engineering, the Chinese University of Hong Kong, Sha Tin, N.T., Hong Kong, China.', 'Department of Computer Science and Engineering, the Chinese University of Hong Kong, Sha Tin, N.T., Hong Kong, China.']	['10.1186/s12859-019-2910-6 [doi]', '10.1186/s12859-019-2910-6 [pii]']	['Liu P', 'Li H', 'Li S', 'Leung KS']	['ORCID: http://orcid.org/0000-0003-1510-0621']						['2019/07/31 06:00']	20190920	20190729	2019 Jul 29	2019/07/31 06:00		['Liu, Pengfei', 'Li, Hongjian', 'Li, Shuai', 'Leung, Kwong-Sak']			1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2910-6 [doi]	20190920	['Antineoplastic Agents/pharmacology/*therapeutic use', 'Cell Line, Tumor', 'Databases, Factual', '*Deep Learning', 'Genomics', 'Humans', 'Inhibitory Concentration 50', 'Neoplasms/*drug therapy', '*Neural Networks (Computer)', 'Organ Specificity/drug effects', 'Phenotype', 'Regression Analysis']	2019/09/21 06:00		['Convolutional network', 'Deep learning', 'GDSC', 'Phenotypic screening']	['NOTNLM']	NLM	408	['2018/10/13 00:00 [received]', '2019/05/21 00:00 [accepted]', '2019/07/31 06:00 [entrez]', '2019/07/31 06:00 [pubmed]', '2019/09/21 06:00 [medline]']	England	PMC6664725		31357929	epublish	['Journal Article']		['0 (Antineoplastic Agents)']	IM		BMC Bioinformatics. 2019 Jul 29;20(1):408. doi: 10.1186/s12859-019-2910-6.	MEDLINE	BMC Bioinformatics	Improving prediction of phenotypic drug response on cancer cell lines using deep convolutional network.		20	Improving prediction of phenotypic drug response on cancer cell lines using deep convolutional network.
Human genes often, through alternative splicing of pre-messenger RNAs, produce multiple mRNAs and protein isoforms that may have similar or completely different functions. Identification of splice sites is, therefore, crucial to understand the gene structure and variants of mRNA and protein isoforms produced by the primary RNA transcripts. Although many computational methods have been developed to detect the splice sites in humans, this is still substantially a challenging problem and further improvement of the computational model is still foreseeable. Accordingly, we developed DeepDSSR (deep donor splice site recognizer), a novel deep learning based architecture, for predicting human donor splice sites. The proposed method, built upon publicly available and highly imbalanced benchmark dataset, is comparable with the leading deep learning based methods for detecting human donor splice sites. Performance evaluation metrics show that DeepDSSR outperformed the existing deep learning based methods. Future work will improve the predictive capabilities of our model, and we will build a model for the prediction of acceptor splice sites.	['Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University (HBKU), Doha, Qatar.', 'Computer Science Department, Southern Connecticut State University, USA.', 'Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University (HBKU), Doha, Qatar.', 'Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University (HBKU), Doha, Qatar.', 'School of Electrical, Computer and Telecommunications Engineering University of Wollongong, Wollongong, NSW, Australia.', 'Department of Computing, East Tennessee State University, USA.']	['SHTI190062 [pii]', '10.3233/SHTI190062 [doi]']	['Alam T', 'Islam MT', 'Househ M', 'Bouzerdoum A', 'Kawsar FA']							['2019/07/27 06:00']	20190902		2019 Jul 4	2019/07/28 06:00		['Alam, Tanvir', 'Islam, Mohammad Tariqul', 'Househ, Mowafa', 'Bouzerdoum, Abdesselam', 'Kawsar, Ferdaus Ahmed']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190062 [doi]	20190902	['*Deep Learning', 'Humans', '*RNA Splice Sites', 'RNA, Messenger']	2019/09/03 06:00		['bidirectional long short-term memory', 'convolution neural network', 'deep learning', 'donor splice sites']	['NOTNLM']	NLM	236-239	['2019/07/27 06:00 [entrez]', '2019/07/28 06:00 [pubmed]', '2019/09/03 06:00 [medline]']	Netherlands			31349311	ppublish	['Journal Article']		['0 (RNA Splice Sites)', '0 (RNA, Messenger)']	T		Stud Health Technol Inform. 2019 Jul 4;262:236-239. doi: 10.3233/SHTI190062.	MEDLINE	Stud Health Technol Inform	DeepDSSR: Deep Learning Structure for Human Donor Splice Sites Recognition.		262	DeepDSSR: Deep Learning Structure for Human Donor Splice Sites Recognition.
Promoter region of protein-coding genes are gradually being well understood, yet no comparable studies exist for the promoter of long non-coding RNA (lncRNA) genes which has emerged as a global potential regulator in multiple cellular process and different diseases for human. To understand the difference in the transcriptional regulation pattern of these genes, previously, we proposed a machine learning based model to classify the promoter of protein-coding genes and lncRNA genes. In this study, we are presenting DeepCNPP (deep coding non-coding promoter predictor), an improved model based on deep learning (DL) framework to classify the promoter of lncRNA genes and protein-coding genes. We used convolution neural network (CNN) based deep network to classify the promoter of these two broad categories of human genes. Our computational model, built upon the sequence information only, was able to classify these two groups of promoters from human at a rate of 83.34% accuracy and outperformed the existing model. Further analysis and interpretation of the output from DeepCNPP architecture will enable us to understand the difference in transcription regulatory pattern for these two groups of genes.	['Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University (HBKU), Doha, Qatar.', 'Computer Science Department, Southern Connecticut State University, USA.', 'Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University (HBKU), Doha, Qatar.', 'Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University (HBKU), Doha, Qatar.', 'Department of Computing, East Tennessee State University, USA.']	['SHTI190061 [pii]', '10.3233/SHTI190061 [doi]']	['Alam T', 'Islam MT', 'Househ M', 'Belhaouari SB', 'Kawsar FA']							['2019/07/27 06:00']	20190902		2019 Jul 4	2019/07/28 06:00		['Alam, Tanvir', 'Islam, Mohammad Tariqul', 'Househ, Mowafa', 'Belhaouari, Samir Brahim', 'Kawsar, Ferdaus Ahmed']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']	10.3233/SHTI190061 [doi]	20190902	['Computational Biology', '*Deep Learning', 'Humans', 'Machine Learning', 'Models, Theoretical', '*Promoter Regions, Genetic', '*RNA, Long Noncoding']	2019/09/03 06:00		['convolution neural network', 'deep learning', 'long non-coding RNA', 'promoter']	['NOTNLM']	NLM	232-235	['2019/07/27 06:00 [entrez]', '2019/07/28 06:00 [pubmed]', '2019/09/03 06:00 [medline]']	Netherlands			31349310	ppublish	['Journal Article']		['0 (RNA, Long Noncoding)']	T		Stud Health Technol Inform. 2019 Jul 4;262:232-235. doi: 10.3233/SHTI190061.	MEDLINE	Stud Health Technol Inform	DeepCNPP: Deep Learning Architecture to Distinguish the Promoter of Human Long Non-Coding RNA Genes and Protein-Coding Genes.		262	DeepCNPP: Deep Learning Architecture to Distinguish the Promoter of Human Long Non-Coding RNA Genes and Protein-Coding Genes.
Importance: Immunohistochemistry (IHC) is the most widely used assay for identification of molecular biomarkers. However, IHC is time consuming and costly, depends on tissue-handling protocols, and relies on pathologists' subjective interpretation. Image analysis by machine learning is gaining ground for various applications in pathology but has not been proposed to replace chemical-based assays for molecular detection. Objective: To assess the prediction feasibility of molecular expression of biomarkers in cancer tissues, relying only on tissue architecture as seen in digitized hematoxylin-eosin (H&E)-stained specimens. Design, Setting, and Participants: This single-institution retrospective diagnostic study assessed the breast cancer tissue microarrays library of patients from Vancouver General Hospital, British Columbia, Canada. The study and analysis were conducted from July 1, 2015, through July 1, 2018. A machine learning method, termed morphological-based molecular profiling (MBMP), was developed. Logistic regression was used to explore correlations between histomorphology and biomarker expression, and a deep convolutional neural network was used to predict the biomarker expression in examined tissues. Main Outcomes and Measures: Positive predictive value (PPV), negative predictive value (NPV), and area under the receiver operating characteristics curve measures of MBMP for assessment of molecular biomarkers. Results: The database consisted of 20600 digitized, publicly available H&E-stained sections of 5356 patients with breast cancer from 2 cohorts. The median age at diagnosis was 61 years for cohort 1 (412 patients) and 62 years for cohort 2 (4944 patients), and the median follow-up was 12.0 years and 12.4 years, respectively. Tissue histomorphology was significantly correlated with the molecular expression of all 19 biomarkers assayed, including estrogen receptor (ER), progesterone receptor (PR), and ERBB2 (formerly HER2). Expression of ER was predicted for 105 of 207 validation patients in cohort 1 (50.7%) and 1059 of 2046 validation patients in cohort 2 (51.8%), with PPVs of 97% and 98%, respectively, NPVs of 68% and 76%, respectively, and accuracy of 91% and 92%, respectively, which were noninferior to traditional IHC (PPV, 91%-98%; NPV, 51%-78%; and accuracy, 81%-90%). Diagnostic accuracy improved given more data. Morphological analysis of patients with ER-negative/PR-positive status by IHC revealed resemblance to patients with ER-positive status (Bhattacharyya distance, 0.03) and not those with ER-negative/PR-negative status (Bhattacharyya distance, 0.25). This suggests a false-negative IHC finding and warrants antihormonal therapy for these patients. Conclusions and Relevance: For at least half of the patients in this study, MBMP appeared to predict biomarker expression with noninferiority to IHC. Results suggest that prediction accuracy is likely to improve as data used for training expand. Morphological-based molecular profiling could be used as a general approach for mass-scale molecular profiling based on digitized H&E-stained images, allowing quick, accurate, and inexpensive methods for simultaneous profiling of multiple biomarkers in cancer tissues.	['Department of Electrical Engineering, Technion Israel Institute of Technology, Haifa, Israel.', 'Laboratory of Pediatric Oncology, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel.', 'Laboratory for Applied Cancer Research, Rambam Healthcare Campus, Rappaport Institute of Medicine and Research, Haifa, Israel.', 'Departmemt of Computer Science, Technion Israel Institute of Technology, Haifa, Israel.', 'Department of Otolaryngology-Head and Neck Surgery, Rambam Health Care Campus, Haifa, Israel.', 'Laboratory for Applied Cancer Research, Rambam Healthcare Campus, Rappaport Institute of Medicine and Research, Haifa, Israel.', 'Department of Otolaryngology-Head and Neck Surgery, Rambam Health Care Campus, Haifa, Israel.', 'Departmemt of Computer Science, Technion Israel Institute of Technology, Haifa, Israel.']	['2739045 [pii]', '10.1001/jamanetworkopen.2019.7700 [doi]']	['Shamai G', 'Binenbaum Y', 'Slossberg R', 'Duek I', 'Gil Z', 'Kimmel R']							['2019/07/27 06:00']		20190703	2019 Jul 3	2019/07/28 06:00	['JAMA Netw Open. 2019 Aug 2;2(8):e1911247. PMID: 31418800']	['Shamai, Gil', 'Binenbaum, Yoav', 'Slossberg, Ron', 'Duek, Irit', 'Gil, Ziv', 'Kimmel, Ron']			7		2574-3805 (Electronic) 2574-3805 (Linking)	101729235	JAMA network open	['eng']	10.1001/jamanetworkopen.2019.7700 [doi]	20190813		2019/07/28 06:00				NLM	e197700	['2019/07/27 06:00 [entrez]', '2019/07/28 06:00 [pubmed]', '2019/07/28 06:00 [medline]']	United States	PMC6661721		31348505	epublish	['Journal Article']			IM		JAMA Netw Open. 2019 Jul 3;2(7):e197700. doi: 10.1001/jamanetworkopen.2019.7700.	In-Data-Review	JAMA Netw Open	Artificial Intelligence Algorithms to Assess Hormonal Status From Tissue Microarrays in Patients With Breast Cancer.		2	Artificial Intelligence Algorithms to Assess Hormonal Status From Tissue Microarrays in Patients With Breast Cancer.
BACKGROUND: Automatically understanding chemical-disease relations (CDRs) is crucial in various areas of biomedical research and health care. Supervised machine learning provides a feasible solution to automatically extract relations between biomedical entities from scientific literature, its success, however, heavily depends on large-scale biomedical corpora manually annotated with intensive labor and tremendous investment. RESULTS: We present an attention-based distant supervision paradigm for the BioCreative-V CDR extraction task. Training examples at both intra- and inter-sentence levels are generated automatically from the Comparative Toxicogenomics Database (CTD) without any human intervention. An attention-based neural network and a stacked auto-encoder network are applied respectively to induce learning models and extract relations at both levels. After merging the results of both levels, the document-level CDRs can be finally extracted. It achieves the precision/recall/F1-score of 60.3%/73.8%/66.4%, outperforming the state-of-the-art supervised learning systems without using any annotated corpus. CONCLUSION: Our experiments demonstrate that distant supervision is promising for extracting chemical disease relations from biomedical literature, and capturing both local and global attention features simultaneously is effective in attention-based distantly supervised learning.	['Natural Language Processing Lab, School of Computer Science and Technology, Soochow University, 1 Shizi Street, Suzhou, China.', 'Big Data Group, Baidu Inc., Beijing, China.', 'Department of Gynecology Minimally Invasive Center, Beijing Obstetrics and Gynecology Hospital, Capital Medical University, Beijing, China.', 'Natural Language Processing Lab, School of Computer Science and Technology, Soochow University, 1 Shizi Street, Suzhou, China. qianlonghua@suda.edu.cn.', 'Natural Language Processing Lab, School of Computer Science and Technology, Soochow University, 1 Shizi Street, Suzhou, China.']	['10.1186/s12859-019-2884-4 [doi]', '10.1186/s12859-019-2884-4 [pii]']	['Gu J', 'Sun F', 'Qian L', 'Zhou G']	['ORCID: http://orcid.org/0000-0002-6335-0433']						['2019/07/24 06:00']	20190920	20190722	2019 Jul 22	2019/07/25 06:00		['Gu, Jinghang', 'Sun, Fuqing', 'Qian, Longhua', 'Zhou, Guodong']			1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2884-4 [doi]	20190920	['*Algorithms', 'Databases as Topic', 'Databases, Factual', '*Disease', 'Humans', 'Neural Networks (Computer)', '*Supervised Machine Learning', '*Toxicogenetics', 'Workflow']	2019/09/21 06:00		['Attention', 'Biomedical relation extraction', 'Deep learning', 'Distant supervision']	['NOTNLM']	NLM	403	['2018/09/15 00:00 [received]', '2019/05/08 00:00 [accepted]', '2019/07/24 06:00 [entrez]', '2019/07/25 06:00 [pubmed]', '2019/09/21 06:00 [medline]']	England	PMC6647285		31331263	epublish	['Journal Article']			IM		BMC Bioinformatics. 2019 Jul 22;20(1):403. doi: 10.1186/s12859-019-2884-4.	MEDLINE	BMC Bioinformatics	Chemical-induced disease relation extraction via attention-based distant supervision.		20	Chemical-induced disease relation extraction via attention-based distant supervision.
BACKGROUND: Visualization tools for deep learning models typically focus on discovering key input features without considering how such low level features are combined in intermediate layers to make decisions. Moreover, many of these methods examine a network's response to specific input examples that may be insufficient to reveal the complexity of model decision making. RESULTS: We present DeepResolve, an analysis framework for deep convolutional models of genome function that visualizes how input features contribute individually and combinatorially to network decisions. Unlike other methods, DeepResolve does not depend upon the analysis of a predefined set of inputs. Rather, it uses gradient ascent to stochastically explore intermediate feature maps to 1) discover important features, 2) visualize their contribution and interaction patterns, and 3) analyze feature sharing across tasks that suggests shared biological mechanism. We demonstrate the visualization of decision making using our proposed method on deep neural networks trained on both experimental and synthetic data. DeepResolve is competitive with existing visualization tools in discovering key sequence features, and identifies certain negative features and non-additive feature interactions that are not easily observed with existing tools. It also recovers similarities between poorly correlated classes which are not observed by traditional methods. DeepResolve reveals that DeepSEA's learned decision structure is shared across genome annotations including histone marks, DNase hypersensitivity, and transcription factor binding. We identify groups of TFs that suggest known shared biological mechanism, and recover correlation between DNA hypersensitivities and TF/Chromatin marks. CONCLUSIONS: DeepResolve is capable of visualizing complex feature contribution patterns and feature interactions that contribute to decision making in genomic deep convolutional networks. It also recovers feature sharing and class similarities which suggest interesting biological mechanisms. DeepResolve is compatible with existing visualization tools and provides complementary insights.	['Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA. gifford@mit.edu.']	['10.1186/s12859-019-2957-4 [doi]', '10.1186/s12859-019-2957-4 [pii]']	['Liu G', 'Zeng H', 'Gifford DK']	['ORCID: http://orcid.org/0000-0003-1709-4034']						['2019/07/21 06:00']	20190920	20190719	2019 Jul 19	2019/07/22 06:00		['Liu, Ge', 'Zeng, Haoyang', 'Gifford, David K']		['U01HG007037/National Institutes of Health', 'R01CA218094/National Institutes of Health']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2957-4 [doi]	20190920	['*Algorithms', 'Base Sequence', 'Databases, Genetic', '*Deep Learning', '*Genomics', 'Histone Code', 'Histones/metabolism', '*Neural Networks (Computer)', 'Transcription Factors/metabolism']	2019/09/21 06:00		['Combinatorial interactions', 'Deep neural networks', 'Visualization']	['NOTNLM']	NLM	401	['2018/11/14 00:00 [received]', '2019/06/18 00:00 [accepted]', '2019/07/21 06:00 [entrez]', '2019/07/22 06:00 [pubmed]', '2019/09/21 06:00 [medline]']	England	PMC6642501		31324140	epublish	['Journal Article']		['0 (Histones)', '0 (Transcription Factors)']	IM		BMC Bioinformatics. 2019 Jul 19;20(1):401. doi: 10.1186/s12859-019-2957-4.	MEDLINE	BMC Bioinformatics	Visualizing complex feature interactions and feature sharing in genomic deep neural networks.		20	Visualizing complex feature interactions and feature sharing in genomic deep neural networks.
Artificial intelligence (AI) is expected to affect various fields of medicine substantially and has the potential to improve many aspects of healthcare. However, AI has been creating much hype, too. In applying AI technology to patients, medical professionals should be able to resolve any anxiety, confusion, and questions that patients and the public may have. Also, they are responsible for ensuring that AI becomes a technology beneficial for patient care. These make the acquisition of sound knowledge and experience about AI a task of high importance for medical students. Preparing for AI does not merely mean learning information technology such as computer programming. One should acquire sufficient knowledge of basic and clinical medicines, data science, biostatistics, and evidence-based medicine. As a medical student, one should not passively accept stories related to AI in medicine in the media and on the Internet. Medical students should try to develop abilities to distinguish correct information from hype and spin and even capabilities to create thoroughly validated, trustworthy information for patients and the public.	['Department of Radiology and Research Institute of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Korea.', 'Department of Radiology and Research Institute of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Korea.', 'Department of Radiology, Research Institute of Radiological Science and Center for Clinical Image Data Science, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea.', 'Department of Medical Education, University of Ulsan College of Medicine, Seoul, Korea.', 'Department of Gastroenterology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Korea.']	['jeehp.2019.16.18 [pii]', '10.3352/jeehp.2019.16.18 [doi]']	['Park SH', 'Do KH', 'Kim S', 'Park JH', 'Lim YS']							['2019/07/19 06:00']		20190703	2019	2019/07/19 06:00		['Park, Seong Ho', 'Do, Kyung-Hyun', 'Kim, Sungwon', 'Park, Joo Hyun', 'Lim, Young-Suk']					1975-5937 (Electronic) 1975-5937 (Linking)	101490061	Journal of educational evaluation for health professions	['eng']	10.3352/jeehp.2019.16.18 [doi]	20190725		2019/07/19 06:00		['Artificial intelligence', 'Deep learning', 'Machine learning', 'Medical students']	['NOTNLM']	NLM	18	['2019/06/15 00:00 [received]', '2019/07/03 00:00 [accepted]', '2019/07/19 06:00 [entrez]', '2019/07/19 06:00 [pubmed]', '2019/07/19 06:00 [medline]']	Korea (South)	PMC6639123		31319450	ppublish	['Journal Article', 'Review']			IM		J Educ Eval Health Prof. 2019;16:18. doi: 10.3352/jeehp.2019.16.18. Epub 2019 Jul 3.	In-Process	J Educ Eval Health Prof	What should medical students know about artificial intelligence in medicine?		16	What should medical students know about artificial intelligence in medicine?
BACKGROUND: With the advancement of powerful image processing and machine learning techniques, Computer Aided Diagnosis has become ever more prevalent in all fields of medicine including ophthalmology. These methods continue to provide reliable and standardized large scale screening of various image modalities to assist clinicians in identifying diseases. Since optic disc is the most important part of retinal fundus image for glaucoma detection, this paper proposes a two-stage framework that first detects and localizes optic disc and then classifies it into healthy or glaucomatous. METHODS: The first stage is based on Regions with Convolutional Neural Network (RCNN) and is responsible for localizing and extracting optic disc from a retinal fundus image while the second stage uses Deep Convolutional Neural Network to classify the extracted disc into healthy or glaucomatous. Unfortunately, none of the publicly available retinal fundus image datasets provides any bounding box ground truth required for disc localization. Therefore, in addition to the proposed solution, we also developed a rule-based semi-automatic ground truth generation method that provides necessary annotations for training RCNN based model for automated disc localization. RESULTS: The proposed method is evaluated on seven publicly available datasets for disc localization and on ORIGA dataset, which is the largest publicly available dataset with healthy and glaucoma labels, for glaucoma classification. The results of automatic localization mark new state-of-the-art on six datasets with accuracy reaching 100% on four of them. For glaucoma classification we achieved Area Under the Receiver Operating Characteristic Curve equal to 0.874 which is 2.7% relative improvement over the state-of-the-art results previously obtained for classification on ORIGA dataset. CONCLUSION: Once trained on carefully annotated data, Deep Learning based methods for optic disc detection and localization are not only robust, accurate and fully automated but also eliminates the need for dataset-dependent heuristic algorithms. Our empirical evaluation of glaucoma classification on ORIGA reveals that reporting only Area Under the Curve, for datasets with class imbalance and without pre-defined train and test splits, does not portray true picture of the classifier's performance and calls for additional performance metrics to substantiate the results.	['Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663, Kaiserslautern, Germany. bajwa@dfki.uni-kl.de.', 'Deutsche Forschungszentrum fur KunstlicheIntelligenz GmbH (DFKI), 67663, Kaiserslautern, Germany. bajwa@dfki.uni-kl.de.', 'Deep Learning Laboratory, National Center of Artificial Intelligence, Islamabad, 46000, Pakistan.', 'School of Electrical Engineering and Computer Science (SEECS), National University of Sciences and Technology, H-12, Islamabad, 46000, Pakistan.', 'Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663, Kaiserslautern, Germany.', 'Deutsche Forschungszentrum fur KunstlicheIntelligenz GmbH (DFKI), 67663, Kaiserslautern, Germany.', 'Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663, Kaiserslautern, Germany.', 'Deutsche Forschungszentrum fur KunstlicheIntelligenz GmbH (DFKI), 67663, Kaiserslautern, Germany.', 'Deep Learning Laboratory, National Center of Artificial Intelligence, Islamabad, 46000, Pakistan.', 'School of Electrical Engineering and Computer Science (SEECS), National University of Sciences and Technology, H-12, Islamabad, 46000, Pakistan.', 'Ophthalmology Clinic, Rittersberg 9, 67657, Kaiserslautern, Germany.', 'Deutsche Forschungszentrum fur KunstlicheIntelligenz GmbH (DFKI), 67663, Kaiserslautern, Germany.']	['10.1186/s12911-019-0842-8 [doi]', '10.1186/s12911-019-0842-8 [pii]']	['Bajwa MN', 'Malik MI', 'Siddiqui SA', 'Dengel A', 'Shafait F', 'Neumeier W', 'Ahmed S']	['ORCID: 0000-0002-4821-1056']						['2019/07/19 06:00']		20190717	2019 Jul 17	2019/07/19 06:00	['BMC Med Inform Decis Mak. 2019 Jul 31;19(1):153. PMID: 31366347']	['Bajwa, Muhammad Naseer', 'Malik, Muhammad Imran', 'Siddiqui, Shoaib Ahmed', 'Dengel, Andreas', 'Shafait, Faisal', 'Neumeier, Wolfgang', 'Ahmed, Sheraz']			1		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-019-0842-8 [doi]	20190820		2019/07/19 06:00		['*Computer aided diagnosis', '*Deep learning', '*Glaucoma detection', '*Machine learning', '*Medical image analysis', '*Optic disc localization']	['NOTNLM']	NLM	136	['2018/10/16 00:00 [received]', '2019/06/19 00:00 [accepted]', '2019/07/19 06:00 [entrez]', '2019/07/19 06:00 [pubmed]', '2019/07/19 06:00 [medline]']	England	PMC6637616		31315618	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Inform Decis Mak. 2019 Jul 17;19(1):136. doi: 10.1186/s12911-019-0842-8.	In-Process	BMC Med Inform Decis Mak	Two-stage framework for optic disc localization and glaucoma classification in retinal fundus images using deep learning.		19	Two-stage framework for optic disc localization and glaucoma classification in retinal fundus images using deep learning.
"Abstract: Artificial Intelligence (AI) and access to ""Big Data"" together with the evolving techniques in biotechnology will change the medical practice a big way. Many diseases such as type II diabetes will no longer be considered as a single disease. Many familiar cancers such as cancer of liver or pancreas will have hundreds of subtypes whose management will be very different. The way we think about diseases will change. It will no longer be possible for clinicians to make a diagnosis, remember the names of diseases, the names of drugs or management protocols without the help of computers. As computer intelligence becomes more important than human intelligence in deciding diagnosis and treatment there will be a paradigm in the role of doctors. Internet, computers and social media will become more important than individuals in decision making. As a result, medicine will go more and more egalitarian (""wiki"") with increasing community participation in health decision making and management. A socialistic pattern will evolve over time globally as an adaptive reaction to the pressures put by artificial intelligence. This is because the individual differences in knowledge or intellect between human beings will become less apparent compared to the super powers of artificial intelligence. Qualities which are unique for humans such as compassion, empathy and emotional care will decide the professional success of future physicians even more than today. Today we are using artificial intelligence in diagnosis and prediction to help clinicians. Clinical algorithms and human experience cannot be replaced by machines. It will take many years to completely merge or replace humans with machines. However, we need to modify our medical education system in order to prepare the medical community and sensitize the society well in advance for a smooth transition."	['Assistant Professor, Department of Molecular and Cellular Medicine, Institute of Liver and Biliary Sciences, New Delhi.', 'Professor, Department of Computer Science and Engineering, Indian Institute of Technology Delhi, New Delhi.', 'Additional Professor (Liver Transplantation), Institute of Liver and Biliary Sciences, New Delhi.', 'Formerly Director General of ICMR, Director, PGIMER and President of JIPMER, Translational Health Science and Technology Institute, NCR Biotech Science Cluster, Faridabad, Haryana.']		['Sanal MG', 'Paul K', 'Kumar S', 'Ganguly NK']		['(c) Journal of the Association of Physicians of India 2011.']					['2019/07/17 06:00']	20190808		2019 Apr	2019/07/17 06:00		['Sanal, Madhusudana Girija', 'Paul, Kolin', 'Kumar, Senthil', 'Ganguly, Nirmal Kumar']			4		0004-5772 (Print) 0004-5772 (Linking)	7505585	The Journal of the Association of Physicians of India	['eng']		20190808	['Algorithms', '*Artificial Intelligence', '*Deep Learning', '*Delivery of Health Care', 'Diabetes Mellitus, Type 2', 'Humans', 'Physicians']	2019/08/09 06:00				NLM	71-73	['2019/07/17 06:00 [entrez]', '2019/07/17 06:00 [pubmed]', '2019/08/09 06:00 [medline]']	India			31309802	ppublish	['Journal Article']					J Assoc Physicians India. 2019 Apr;67(4):71-73.	MEDLINE	J Assoc Physicians India	Artificial Intelligence and Deep Learning: The Future of Medicine and Medical Practice.		67	Artificial Intelligence and Deep Learning: The Future of Medicine and Medical Practice.
Visual pollution is a relatively new concern amidst the existing plethora of mainstream environmental pollution, recommending the necessity for research to conceptualize, formalize, quantify and assess it from different dimensions. The purpose of this study is to create a new field of automated visual pollutant classification, harnessing the technological prowess of the 21(st) century for applications in environmental management. From the wide range of visual pollutants, four categories have been considered viz. (i) billboards and signage, (ii) telephone and communication wires, (iii) network and communication towers and (iv) street litter. The deep learning model used in this study simulates the human learning experience in the context of image recognition for visual pollutant classification by training and testing a convolutional neural network with several layers of artificial neurons. Data augmentation using image processing techniques and a train-test split ratio of 80:20 have been used. Training accuracy of 95% and validation accuracy of 85% have been achieved by the deep learning model. The results indicate that the upper limit of accuracy i.e. the asymptote, depends on the dataset size for this type of task. This study has several applications in environmental management. For example, the deployment of the trained model for processing of video/live footage from smartphone applications, closed-circuit television and drones/unmanned aerial vehicles can be applied for both the removal and management of visual pollutants in the natural and built environment. Furthermore, generating the 'visual pollution score/index' of urban regions such as towns and cities will create a new 'metric/indicator' in the field of urban environmental management.	['Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka 1229, Bangladesh.', 'Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka 1229, Bangladesh.', 'Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka 1229, Bangladesh.', 'Department of Electrical and Computer Engineering, North South University, Bashundhara, Dhaka 1229, Bangladesh; Pi Labs Bangladesh LTD, ARA Bhaban,39, Kazi Nazrul Islam Avenue, Kawran Bazar, Dhaka 1215, Bangladesh.', 'Department of Environmental Science and Management, North South University, Bashundhara, Dhaka 1229, Bangladesh. Electronic address: mohammad.sujauddin@gmail.com.']	['S0301-4797(19)30955-7 [pii]', '10.1016/j.jenvman.2019.07.024 [doi]']	['Ahmed N', 'Islam MN', 'Tuba AS', 'Mahdy MRC', 'Sujauddin M']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/07/16 06:00']	20190924	20190712	2019 Oct 15	2019/07/16 06:00		['Ahmed, Nahian', 'Islam, M Nazmul', 'Tuba, Ahmad Saraf', 'Mahdy, M R C', 'Sujauddin, Mohammad']					1095-8630 (Electronic) 0301-4797 (Linking)	0401664	Journal of environmental management	['eng']	S0301-4797(19)30955-7 [pii] 10.1016/j.jenvman.2019.07.024 [doi]	20190925	['*Deep Learning', 'Environmental Pollution', 'Humans', 'Image Processing, Computer-Assisted', '*Machine Learning', 'Neural Networks (Computer)']	2019/09/26 06:00		['Convolutional neural network', 'Deep learning', 'Environmental management', 'Image recognition', 'Pollutant classification', 'Visual pollution']	['NOTNLM']	NLM	109253	['2019/03/20 00:00 [received]', '2019/06/12 00:00 [revised]', '2019/07/07 00:00 [accepted]', '2019/07/16 06:00 [pubmed]', '2019/09/26 06:00 [medline]', '2019/07/16 06:00 [entrez]']	England			31306925	ppublish	['Journal Article']			IM		J Environ Manage. 2019 Oct 15;248:109253. doi: 10.1016/j.jenvman.2019.07.024. Epub 2019 Jul 12.	MEDLINE	J Environ Manage	Solving visual pollution with deep learning: A new nexus in environmental management.		248	Solving visual pollution with deep learning: A new nexus in environmental management.
Over 80,000 endocrine-disrupting chemicals (EDCs) are considered emerging contaminants (ECs), which are of great concern due to their effects on human health. Quantitative structure-activity relationship (QSAR) models are a promising alternative to in vitro methods to predict the toxicological effects of chemicals on human health. In this study, we assessed a deep-learning based QSAR (DL-QSAR) model to predict the qualitative and the quantitative effects of EDCs on the human endocrine system, and especially sex-hormone binding globulin (SHBG) and estrogen receptor (ER). Statistical analyses of the qualitative responses indicated that the accuracies of all three DL-QSAR methods were above 90%, and greater than the other statistical and machine learning models, indicating excellent classification performance. The quantitative analyses, as assessed using deep-neural-network-based QSAR (DNN-QSAR), resulted in a coefficient of determination (R(2)) of 0.80 and predictive square correlation coefficient (Q(2)) of 0.86, which implied satisfactory goodness of fit and predictive ability. Thus, DNN was able to transform sparse molecular descriptors into higher dimensional spaces, and was superior for assessment qualitative responses. Moreover, DNN-QSAR demonstrated excellent performance in the discipline of computational chemistry by handling multicollinearity and overfitting problems.	['Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Gicheung-gu, Yongin-Si, Gyeonggi-Do, 446-701, Republic of Korea.', 'Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Gicheung-gu, Yongin-Si, Gyeonggi-Do, 446-701, Republic of Korea.', 'Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Gicheung-gu, Yongin-Si, Gyeonggi-Do, 446-701, Republic of Korea. Electronic address: ckyoo@khu.ac.kr.']	['S0269-7491(19)30495-6 [pii]', '10.1016/j.envpol.2019.06.081 [doi]']	['Heo S', 'Safder U', 'Yoo C']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/07/15 06:00']	20191107	20190706	2019 Oct	2019/07/16 06:00		['Heo, SungKu', 'Safder, Usman', 'Yoo, ChangKyoo']					1873-6424 (Electronic) 0269-7491 (Linking)	8804476	Environmental pollution (Barking, Essex : 1987)	['eng']	S0269-7491(19)30495-6 [pii] 10.1016/j.envpol.2019.06.081 [doi]	20191107	['Computational Biology', '*Deep Learning', '*Ecotoxicology', 'Endocrine Disruptors/metabolism/*toxicity', 'Environmental Pollutants/metabolism/*toxicity', 'Humans', 'Neural Networks (Computer)', '*Quantitative Structure-Activity Relationship', 'Receptors, Estrogen/metabolism', 'Sex Hormone-Binding Globulin']	2019/11/08 06:00		['Deep learning (DL)', 'Emerging contaminants (ECs)', 'Endocrine disrupting chemicals (EDCs)', 'Estrogen receptor (ER)', 'Quantitative structure-activity relationship (QSAR)', 'Sex hormone binding globulin (SHBG)']	['NOTNLM']	NLM	29-38	['2019/01/25 00:00 [received]', '2019/06/04 00:00 [revised]', '2019/06/21 00:00 [accepted]', '2019/07/16 06:00 [pubmed]', '2019/11/08 06:00 [medline]', '2019/07/15 06:00 [entrez]']	England			31302400	ppublish	['Journal Article']		['0 (Endocrine Disruptors)', '0 (Environmental Pollutants)', '0 (Receptors, Estrogen)', '0 (Sex Hormone-Binding Globulin)']	IM		Environ Pollut. 2019 Oct;253:29-38. doi: 10.1016/j.envpol.2019.06.081. Epub 2019 Jul 6.	MEDLINE	Environ Pollut	Deep learning driven QSAR model for environmental toxicology: Effects of endocrine disrupting chemicals on human health.		253	Deep learning driven QSAR model for environmental toxicology: Effects of endocrine disrupting chemicals on human health.
BACKGROUND: Unsupervised machine learning methods (deep learning) have shown their usefulness with noisy single cell mRNA-sequencing data (scRNA-seq), where the models generalize well, despite the zero-inflation of the data. A class of neural networks, namely autoencoders, has been useful for denoising of single cell data, imputation of missing values and dimensionality reduction. RESULTS: Here, we present a striking feature with the potential to greatly increase the usability of autoencoders: With specialized training, the autoencoder is not only able to generalize over the data, but also to tease apart biologically meaningful modules, which we found encoded in the representation layer of the network. Our model can, from scRNA-seq data, delineate biological meaningful modules that govern a dataset, as well as give information as to which modules are active in each single cell. Importantly, most of these modules can be explained by known biological functions, as provided by the Hallmark gene sets. CONCLUSIONS: We discover that tailored training of an autoencoder makes it possible to deconvolute biological modules inherent in the data, without any assumptions. By comparisons with gene signatures of canonical pathways we see that the modules are directly interpretable. The scope of this discovery has important implications, as it makes it possible to outline the drivers behind a given effect of a cell. In comparison with other dimensionality reduction methods, or supervised models for classification, our approach has the benefit of both handling well the zero-inflated nature of scRNA-seq, and validating that the model captures relevant information, by establishing a link between input and decoded data. In perspective, our model in combination with clustering methods is able to provide information about which subtype a given single cell belongs to, as well as which biological functions determine that membership.	"['Centre for Genomic Medicine Rigshospitalet, University of Copenhagen, Copenhagen, Denmark.', 'Centre for Genomic Medicine Rigshospitalet, University of Copenhagen, Copenhagen, Denmark.', 'Centre for Genomic Medicine Rigshospitalet, University of Copenhagen, Copenhagen, Denmark.', 'Section for Cognitive Systems Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark.', 'Bioinformatics Centre Department of Biology, University of Copenhagen, Copenhagen, Denmark.', 'Centre for Genomic Medicine Rigshospitalet, University of Copenhagen, Copenhagen, Denmark. frederik@binf.ku.dk.', ""University Children's Hospital Basel and Department of Biomedicine, University of Basel, Basel, Switzerland. frederik@binf.ku.dk."", 'Swiss Institute of Bioinformatics, Basel, Switzerland. frederik@binf.ku.dk.']"	['10.1186/s12859-019-2952-9 [doi]', '10.1186/s12859-019-2952-9 [pii]']	['Kinalis S', 'Nielsen FC', 'Winther O', 'Bagger FO']	['ORCID: http://orcid.org/0000-0003-0636-8845']						['2019/07/10 06:00']	20190823	20190708	2019 Jul 8	2019/07/10 06:00		['Kinalis, Savvas', 'Nielsen, Finn Cilius', 'Winther, Ole', 'Bagger, Frederik Otzen']		['R159-A6890/Rigshospitalet']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2952-9 [doi]	20190823	['Cluster Analysis', 'Gene Expression Profiling/*methods', '*Neural Networks (Computer)', 'RNA, Messenger/*chemistry/metabolism', 'Sequence Analysis, RNA/*methods', 'Single-Cell Analysis', '*Unsupervised Machine Learning']	2019/08/24 06:00		['Biological pathway analysis', 'Deep learning', 'Expression profiles', 'Functional analysis', 'Gene set enrichment analysis', 'Interpretable machine learning', 'Manifold learning', 'Neural networks', 'Single-cell RNA-sequencing']	['NOTNLM']	NLM	379	['2019/02/04 00:00 [received]', '2019/06/13 00:00 [accepted]', '2019/07/10 06:00 [entrez]', '2019/07/10 06:00 [pubmed]', '2019/08/24 06:00 [medline]']	England	PMC6615267		31286861	epublish	['Journal Article']		['0 (RNA, Messenger)']			BMC Bioinformatics. 2019 Jul 8;20(1):379. doi: 10.1186/s12859-019-2952-9.	MEDLINE	BMC Bioinformatics	Deconvolution of autoencoders to learn biological regulatory modules from single cell mRNA sequencing data.		20	Deconvolution of autoencoders to learn biological regulatory modules from single cell mRNA sequencing data.
Macular edema (ME) is a retinal condition in which central vision of a patient is affected. ME leads to accumulation of fluid in the surrounding macular region resulting in a swollen macula. Optical coherence tomography (OCT) and the fundus photography are the two widely used retinal examination techniques that can effectively detect ME. Many researchers have utilized retinal fundus and OCT imaging for detecting ME. However, to the best of our knowledge, no work is found in the literature that fuses the findings from both retinal imaging modalities for the effective and more reliable diagnosis of ME. In this paper, we proposed an automated framework for the classification of ME and healthy eyes using retinal fundus and OCT scans. The proposed framework is based on deep ensemble learning where the input fundus and OCT scans are recognized through the deep convolutional neural network (CNN) and are processed accordingly. The processed scans are further passed to the second layer of the deep CNN model, which extracts the required feature descriptors from both images. The extracted descriptors are then concatenated together and are passed to the supervised hybrid classifier made through the ensemble of the artificial neural networks, support vector machines and naive Bayes. The proposed framework has been trained on 73,791 retinal scans and is validated on 5100 scans of publicly available Zhang dataset and Rabbani dataset. The proposed framework achieved the accuracy of 94.33% for diagnosing ME and healthy subjects and achieved the mean dice coefficient of 0.9019 +/- 0.04 for accurately extracting the retinal fluids, 0.7069 +/- 0.11 for accurately extracting hard exudates and 0.8203 +/- 0.03 for accurately extracting retinal blood vessels against the clinical markings.	['School of Automation Science and Electrical Engineering, Beihang University (BUAA), Beijing 100191, China.', 'Department of Electrical Engineering, Bahria University (BU), Islamabad 44000, Pakistan.', 'School of Computer Science and Engineering, Beihang University (BUAA), Beijing 100191, China. libo@buaa.edu.cn.', 'School of Computer and Communication Engineering, University of Science & Technology Beijing (USTB), Beijing 100083, China.', 'Department of Electrical and Computer Engineering, Sir Syed CASE Institute of Technology (SSCIT), Islamabad 44000, Pakistan.']	['s19132970 [pii]', '10.3390/s19132970 [doi]']	['Hassan B', 'Hassan T', 'Li B', 'Ahmed R', 'Hassan O']	['ORCID: 0000-0003-3672-8100', 'ORCID: 0000-0002-5896-8677', 'ORCID: 0000-0002-9337-1921']						['2019/07/10 06:00']		20190705	2019 Jul 5	2019/07/10 06:00		['Hassan, Bilal', 'Hassan, Taimur', 'Li, Bo', 'Ahmed, Ramsha', 'Hassan, Omar']		['2017YFB0202601/National Key R&D Program of China']	13		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2970 [pii] 10.3390/s19132970 [doi]	20190809		2019/07/10 06:00		['biomedical image processing', 'fundus photography', 'image analysis', 'image classification', 'machine intelligence', 'machine vision', 'optical coherence tomography']	['NOTNLM']	NLM		['2019/05/26 00:00 [received]', '2019/06/21 00:00 [revised]', '2019/06/26 00:00 [accepted]', '2019/07/10 06:00 [entrez]', '2019/07/10 06:00 [pubmed]', '2019/07/10 06:00 [medline]']	Switzerland	PMC6651513		31284442	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Jul 5;19(13). pii: s19132970. doi: 10.3390/s19132970.	In-Process	Sensors (Basel)	Deep Ensemble Learning Based Objective Grading of Macular Edema by Extracting Clinically Significant Findings from Fused Retinal Imaging Modalities.		19	Deep Ensemble Learning Based Objective Grading of Macular Edema by Extracting Clinically Significant Findings from Fused Retinal Imaging Modalities.
Intelligent image-activated cell sorting (iIACS) is a machine-intelligence technology that performs real-time intelligent image-based sorting of single cells with high throughput. iIACS extends beyond the capabilities of fluorescence-activated cell sorting (FACS) from fluorescence intensity profiles of cells to multidimensional images, thereby enabling high-content sorting of cells or cell clusters with unique spatial chemical and morphological traits. Therefore, iIACS serves as an integral part of holistic single-cell analysis by enabling direct links between population-level analysis (flow cytometry), cell-level analysis (microscopy), and gene-level analysis (sequencing). Specifically, iIACS is based on a seamless integration of high-throughput cell microscopy (e.g., multicolor fluorescence imaging, bright-field imaging), cell focusing, cell sorting, and deep learning on a hybrid software-hardware data management infrastructure, enabling real-time automated operation for data acquisition, data processing, intelligent decision making, and actuation. Here, we provide a practical guide to iIACS that describes how to design, build, characterize, and use an iIACS machine. The guide includes the consideration of several important design parameters, such as throughput, sensitivity, dynamic range, image quality, sort purity, and sort yield; the development and integration of optical, microfluidic, electrical, computational, and mechanical components; and the characterization and practical usage of the integrated system. Assuming that all components are readily available, a team of several researchers experienced in optics, electronics, digital signal processing, microfluidics, mechatronics, and flow cytometry can complete this protocol in ~3 months.	['Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan.', 'Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan.', 'Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, Japan.', 'Laboratory of Applied Molecular Microbiology, Kyoto University, Kyoto, Japan.', 'Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo, Japan.', 'ExaWizards Inc., Tokyo, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Japan Science and Technology Agency, Saitama, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Department of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University, Kyoto, Japan.', 'Clinical Research and Regional Innovation, Faculty of Medicine, University of Tsukuba, Ibaraki, Japan.', 'Department of Precision Mechanics, Chuo University, Tokyo, Japan.', 'Laboratory of Applied Molecular Microbiology, Kyoto University, Kyoto, Japan.', 'Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo, Japan.', 'Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Department of Bioengineering, University of California, Los Angeles, Los Angeles, CA, USA.', 'Department of Mechanical Engineering, University of California, Los Angeles, Los Angeles, CA, USA.', 'California NanoSystems Institute, University of California, Los Angeles, Los Angeles, CA, USA.', 'Department of Neurosurgery, Graduate School of Medicine, Tohoku University, Sendai, Japan.', 'Department of Chemical Engineering, Kyushu University, Fukuoka, Japan.', 'Division of Materials Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Japan Science and Technology Agency, Saitama, Japan.', 'Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan.', 'Japan Science and Technology Agency, Saitama, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo, Japan. goda@chem.s.u-tokyo.ac.jp.', 'Japan Science and Technology Agency, Saitama, Japan. goda@chem.s.u-tokyo.ac.jp.', 'Department of Electrical Engineering, University of California, Los Angeles, Los Angeles, CA, USA. goda@chem.s.u-tokyo.ac.jp.']	['10.1038/s41596-019-0183-1 [doi]', '10.1038/s41596-019-0183-1 [pii]']	['Isozaki A', 'Mikami H', 'Hiramatsu K', 'Sakuma S', 'Kasai Y', 'Iino T', 'Yamano T', 'Yasumoto A', 'Oguchi Y', 'Suzuki N', 'Shirasaki Y', 'Endo T', 'Ito T', 'Hiraki K', 'Yamada M', 'Matsusaka S', 'Hayakawa T', 'Fukuzawa H', 'Yatomi Y', 'Arai F', 'Di Carlo D', 'Nakagawa A', 'Hoshino Y', 'Hosokawa Y', 'Uemura S', 'Sugimura T', 'Ozeki Y', 'Nitta N', 'Goda K']	['ORCID: http://orcid.org/0000-0002-4145-7264', 'ORCID: http://orcid.org/0000-0003-0637-4575', 'ORCID: http://orcid.org/0000-0001-9628-6979', 'ORCID: http://orcid.org/0000-0002-9004-0799', 'ORCID: http://orcid.org/0000-0002-9093-9016']						['2019/07/07 06:00']	20191126	20190705	2019 Aug	2019/07/07 06:00	['Nat Protoc. 2019 Oct 17;:. PMID: 31624371']	['Isozaki, Akihiro', 'Mikami, Hideharu', 'Hiramatsu, Kotaro', 'Sakuma, Shinya', 'Kasai, Yusuke', 'Iino, Takanori', 'Yamano, Takashi', 'Yasumoto, Atsushi', 'Oguchi, Yusuke', 'Suzuki, Nobutake', 'Shirasaki, Yoshitaka', 'Endo, Taichiro', 'Ito, Takuro', 'Hiraki, Kei', 'Yamada, Makoto', 'Matsusaka, Satoshi', 'Hayakawa, Takeshi', 'Fukuzawa, Hideya', 'Yatomi, Yutaka', 'Arai, Fumihito', 'Di Carlo, Dino', 'Nakagawa, Atsuhiro', 'Hoshino, Yu', 'Hosokawa, Yoichiroh', 'Uemura, Sotaro', 'Sugimura, Takeaki', 'Ozeki, Yasuyuki', 'Nitta, Nao', 'Goda, Keisuke']			8		1750-2799 (Electronic) 1750-2799 (Linking)	101284307	Nature protocols	['eng']	10.1038/s41596-019-0183-1 [doi]	20191126	['Cells, Cultured', 'Flow Cytometry/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Lab-On-A-Chip Devices', 'Microalgae/cytology', '*Neural Networks (Computer)', 'Signal Processing, Computer-Assisted', 'Single-Cell Analysis/*methods', 'Software']	2019/11/27 06:00				NLM	2370-2415	['2019/01/21 00:00 [received]', '2019/04/18 00:00 [accepted]', '2019/07/07 06:00 [pubmed]', '2019/11/27 06:00 [medline]', '2019/07/07 06:00 [entrez]']	England			31278398	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Protoc. 2019 Aug;14(8):2370-2415. doi: 10.1038/s41596-019-0183-1. Epub 2019 Jul 5.	MEDLINE	Nat Protoc	A practical guide to intelligent image-activated cell sorting.		14	A practical guide to intelligent image-activated cell sorting.
Automatic speech recognition (ASR) is increasingly becoming an integral component of our daily lives. This trend is in large part due to recent advances in machine learning, and specifically in deep learning, that have led to accurate ASR across numerous tasks. This has led to renewed interest in providing technological support to populations whose speech patterns are atypical, including identifying the presence of a specific pathology and its severity, comparing speech characteristics before and after a surgery and enhancing the quality of life of individuals with speech pathologies. The purpose of this primer is to bring readers with relatively little technical background up to speed on fundamentals and recent advances in ASR. It presents a detailed account of the anatomy of modern ASR, with examples of how it has been used in speech-language pathology research.	['a Department of Computer Science , Bar-Ilan University , Ramat Gan , Israel.']	['10.1080/17549507.2018.1510033 [doi]']	['Keshet J']							['2019/07/06 06:00']	20191104		2018 Nov	2019/07/06 06:00		['Keshet, Joseph']			6		1754-9515 (Electronic) 1754-9507 (Linking)	101320232	International journal of speech-language pathology	['eng']	10.1080/17549507.2018.1510033 [doi]	20191104	['*Deep Learning/trends', 'Humans', '*Speech', '*Speech Recognition Software/trends', 'Speech-Language Pathology/*methods/trends']	2019/11/05 06:00		['*assessment of speech intelligibility', '*automatic speech recognition', '*monitoring', '*speech pathologies']	['NOTNLM']	NLM	599-609	['2019/07/06 06:00 [entrez]', '2019/07/06 06:00 [pubmed]', '2019/11/05 06:00 [medline]']	England			31274357	ppublish	['Journal Article']			IM		Int J Speech Lang Pathol. 2018 Nov;20(6):599-609. doi: 10.1080/17549507.2018.1510033.	MEDLINE	Int J Speech Lang Pathol	Automatic speech recognition: A primer for speech-language pathology researchers.		20	Automatic speech recognition: A primer for speech-language pathology researchers.
BACKGROUND & AIMS: Capsule endoscopy has revolutionized investigation of the small bowel. However, this technique produces a video that is 8-10 hours long, so analysis is time consuming for gastroenterologists. Deep convolutional neural networks (CNNs) can recognize specific images among a large variety. We aimed to develop a CNN-based algorithm to assist in the evaluation of small bowel capsule endoscopy (SB-CE) images. METHODS: We collected 113,426,569 images from 6970 patients who had SB-CE at 77 medical centers from July 2016 through July 2018. A CNN-based auxiliary reading model was trained to differentiate abnormal from normal images using 158,235 SB-CE images from 1970 patients. Images were categorized as normal, inflammation, ulcer, polyps, lymphangiectasia, bleeding, vascular disease, protruding lesion, lymphatic follicular hyperplasia, diverticulum, parasite, and other. The model was further validated in 5000 patients (no patient was overlap with the 1970 patients in the training set); the same patients were evaluated by conventional analysis and CNN-based auxiliary analysis by 20 gastroenterologists. If there was agreement in image categorization between the conventional analysis and CNN model, no further evaluation was performed. If there was disagreement between the conventional analysis and CNN model, the gastroenterologists re-evaluated the image to confirm or reject the CNN categorization. RESULTS: In the SB-CE images from the validation set, 4206 abnormalities in 3280 patients were identified after final consensus evaluation. The CNN-based auxiliary model identified abnormalities with 99.88% sensitivity in the per-patient analysis (95% CI, 99.67-99.96) and 99.90% sensitivity in the per-lesion analysis (95% CI, 99.74-99.97). Conventional reading by the gastroenterologists identified abnormalities with 74.57% sensitivity (95% CI, 73.05-76.03) in the per-patient analysis and 76.89% in the per-lesion analysis (95% CI, 75.58-78.15). The mean reading time per patient was 96.6 +/- 22.53 minutes by conventional reading and 5.9 +/- 2.23 minutes by CNN-based auxiliary reading (P < .001). CONCLUSIONS: We validated the ability of a CNN-based algorithm to identify abnormalities in SB-CE images. The CNN-based auxiliary model identified abnormalities with higher levels of sensitivity and significantly shorter reading times than conventional analysis by gastroenterologists. This algorithm provides an important tool to help gastroenterologists analyze SB-CE images more efficiently and more accurately.	['Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Ankon Medical Technologies Co, Ltd, Shanghai, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Ankon Medical Technologies Co, Ltd, Shanghai, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Ankon Medical Technologies Co, Ltd, Shanghai, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China. Electronic address: selinalin35@hotmail.com.', 'Department of Gastroenterology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430022, China.']	['S0016-5085(19)41032-9 [pii]', '10.1053/j.gastro.2019.06.025 [doi]']	['Ding Z', 'Shi H', 'Zhang H', 'Meng L', 'Fan M', 'Han C', 'Zhang K', 'Ming F', 'Xie X', 'Liu H', 'Liu J', 'Lin R', 'Hou X']		['Copyright (c) 2019 AGA Institute. Published by Elsevier Inc. All rights reserved.']					['2019/06/29 06:00']	20191022	20190625	2019 Oct	2019/06/30 06:00		['Ding, Zhen', 'Shi, Huiying', 'Zhang, Hao', 'Meng, Lingjun', 'Fan, Mengke', 'Han, Chaoqun', 'Zhang, Kun', 'Ming, Fanhua', 'Xie, Xiaoping', 'Liu, Hao', 'Liu, Jun', 'Lin, Rong', 'Hou, Xiaohua']			4		1528-0012 (Electronic) 0016-5085 (Linking)	0374630	Gastroenterology	['eng']	S0016-5085(19)41032-9 [pii] 10.1053/j.gastro.2019.06.025 [doi]	20191022	['Capsule Endoscopy/*methods', 'China', 'Clinical Competence', '*Deep Learning', 'Diagnosis, Differential', '*Gastroenterologists', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Intestinal Diseases/*pathology', 'Intestine, Small/*pathology', 'Observer Variation', 'Predictive Value of Tests', 'Prognosis', 'Reproducibility of Results', 'Retrospective Studies']	2019/10/23 06:00		['*Artificial Intelligence', '*Imaging', '*Intestine', '*Lesion']	['NOTNLM']	NLM	1044-1054.e5	['2018/12/07 00:00 [received]', '2019/06/02 00:00 [revised]', '2019/06/17 00:00 [accepted]', '2019/06/30 06:00 [pubmed]', '2019/10/23 06:00 [medline]', '2019/06/29 06:00 [entrez]']	United States			31251929	ppublish	"['Journal Article', 'Multicenter Study', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			AIM IM		Gastroenterology. 2019 Oct;157(4):1044-1054.e5. doi: 10.1053/j.gastro.2019.06.025. Epub 2019 Jun 25.	MEDLINE	Gastroenterology	Gastroenterologist-Level Identification of Small-Bowel Diseases and Normal Variants by Capsule Endoscopy Using a Deep-Learning Model.		157	Gastroenterologist-Level Identification of Small-Bowel Diseases and Normal Variants by Capsule Endoscopy Using a Deep-Learning Model.
Geometric features, such as the topological and manifold properties, are utilized to extract geometric properties. Geometric methods that exploit the applications of geometrics, e.g., geometric features, are widely used in computer graphics and computer vision problems. This review presents a literature review on geometric concepts, geometric methods, and their applications in human-related analysis, e.g., human shape analysis, human pose analysis, and human action analysis. This review proposes to categorize geometric methods based on the scope of the geometric properties that are extracted: object-oriented geometric methods, feature-oriented geometric methods, and routine-based geometric methods. Considering the broad applications of deep learning methods, this review also studies geometric deep learning, which has recently become a popular topic of research. Validation datasets are collected, and method performances are collected and compared. Finally, research trends and possible research topics are discussed.	['The College of Computer Science and Communication Engineering, China University of Petroleum (East China), Qingdao 257061, China. wenjuangong@upc.edu.cn.', 'The Beijing University of Posts and Telecommunications, Beijing 100876, China. fealie28@163.com.', 'The College of Computer Science and Communication Engineering, China University of Petroleum (East China), Qingdao 257061, China. wcq86451612@163.com.', 'The College of Computer Science and Communication Engineering, China University of Petroleum (East China), Qingdao 257061, China. iceyueHB@163.com.', 'The College of Computer Science and Communication Engineering, China University of Petroleum (East China), Qingdao 257061, China. china_lichuantao@163.com.', 'Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China. csljxing@gmail.com.', 'Key Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China. yu.qiao@siat.ac.cn.', 'The College of Computer Science and Communication Engineering, China University of Petroleum (East China), Qingdao 257061, China. zhangws@upc.edu.cn.', 'The College of Computer Science and Communication Engineering, China University of Petroleum (East China), Qingdao 257061, China. gfaming@163.com.']	['s19122809 [pii]', '10.3390/s19122809 [doi]']	['Gong W', 'Zhang B', 'Wang C', 'Yue H', 'Li C', 'Xing L', 'Qiao Y', 'Zhang W', 'Gong F']	['ORCID: 0000-0003-1239-6332', 'ORCID: 0000-0001-9800-1068']						['2019/06/26 06:00']	20191203	20190623	2019 Jun 23	2019/06/27 06:00		['Gong, Wenjuan', 'Zhang, Bin', 'Wang, Chaoqi', 'Yue, Hanbing', 'Li, Chuantao', 'Xing, Linjie', 'Qiao, Yu', 'Zhang, Weishan', 'Gong, Faming']			12		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2809 [pii] 10.3390/s19122809 [doi]	20191203	['*Artificial Intelligence', '*Computer Graphics', '*Deep Learning', 'Humans']	2019/12/04 06:00		['geometric methods', 'human action recognition', 'human body shape analysis', 'human pose estimation']	['NOTNLM']	NLM		['2019/04/01 00:00 [received]', '2019/05/26 00:00 [revised]', '2019/06/06 00:00 [accepted]', '2019/06/26 06:00 [entrez]', '2019/06/27 06:00 [pubmed]', '2019/12/04 06:00 [medline]']	Switzerland	PMC6630373		31234601	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Jun 23;19(12). pii: s19122809. doi: 10.3390/s19122809.	MEDLINE	Sensors (Basel)	A Literature Review: Geometric Methods and Their Applications in Human-Related Analysis.		19	A Literature Review: Geometric Methods and Their Applications in Human-Related Analysis.
Mosquito control is important as mosquitoes are extremely harmful pests that spread various infectious diseases. In this research, we present the preliminary results of an automated system that detects the presence of mosquitoes via image processing using multiple deep learning networks. The Fully Convolutional Network (FCN) and neural network-based regression demonstrated an accuracy of 84%. Meanwhile, the single image classifier demonstrated an accuracy of only 52%. The overall processing time also decreased from 4.64 to 2.47 s compared to the conventional classifying network. After detection, a larvicide made from toxic protein crystals of the Bacillus thuringiensis serotype israelensis bacteria was injected into static water to stop the proliferation of mosquitoes. This system demonstrates a higher efficiency than hunting adult mosquitos while avoiding damage to other insects.	['Department of Biological Sciences, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Daejeon 34141, Korea. kkim0214@kaist.ac.kr.', 'Department of Civil and Environmental Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Daejeon 34141, Korea. jimi.hyun@kaist.ac.kr.', 'Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Daejeon 34141, Korea. hkkim1227@kaist.ac.kr.', 'School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Daejeon 34141, Korea. wjuni@kaist.ac.kr.', 'School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Daejeon 34141, Korea. hmyung@kaist.ac.kr.']	['s19122785 [pii]', '10.3390/s19122785 [doi]']	['Kim K', 'Hyun J', 'Kim H', 'Lim H', 'Myung H']	['ORCID: 0000-0001-8694-4659', 'ORCID: 0000-0002-5799-2026']						['2019/06/26 06:00']	20191203	20190621	2019 Jun 21	2019/06/27 06:00		['Kim, Kyukwang', 'Hyun, Jieum', 'Kim, Hyeongkeun', 'Lim, Hwijoon', 'Myung, Hyun']		['2016-0-00563/Institute for Information and communications Technology Promotion']	12		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2785 [pii] 10.3390/s19122785 [doi]	20191203	['Animals', 'Bacillus thuringiensis/chemistry', 'Bacterial Proteins/*chemistry', 'Biosensing Techniques', '*Deep Learning', '*Ecosystem', 'Image Processing, Computer-Assisted/methods', 'Mosquito Control/*methods', 'Neural Networks (Computer)']	2019/12/04 06:00		['deep learning', 'drug spray', 'mosquito', 'urban habitat', 'vector control']	['NOTNLM']	NLM		['2019/04/09 00:00 [received]', '2019/06/16 00:00 [revised]', '2019/06/18 00:00 [accepted]', '2019/06/26 06:00 [entrez]', '2019/06/27 06:00 [pubmed]', '2019/12/04 06:00 [medline]']	Switzerland	PMC6631209		31234294	epublish	['Journal Article']		['0 (Bacterial Proteins)']	IM		Sensors (Basel). 2019 Jun 21;19(12). pii: s19122785. doi: 10.3390/s19122785.	MEDLINE	Sensors (Basel)	A Deep Learning-Based Automatic Mosquito Sensing and Control System for Urban Mosquito Habitats.		19	A Deep Learning-Based Automatic Mosquito Sensing and Control System for Urban Mosquito Habitats.
Existing arrhythmia classification methods usually use manual selection of electrocardiogram (ECG) signal features, so that the feature selection is subjective, and the feature extraction is complex, leaving the classification accuracy usually affected. Based on this situation, a new method of arrhythmia automatic classification based on discriminative deep belief networks (DDBNs) is proposed. The morphological features of heart beat signals are automatically extracted from the constructed generative restricted Boltzmann machine (GRBM), then the discriminative restricted Boltzmann machine (DRBM) with feature learning and classification ability is introduced, and arrhythmia classification is performed according to the extracted morphological features and RR interval features. In order to further improve the classification performance of DDBNs, DDBNs are converted to deep neural network (DNN) using the Softmax regression layer for supervised classification in this paper, and the network is fine-tuned by backpropagation. Finally, the Massachusetts Institute of Technology and Beth Israel Hospital Arrhythmia Database (MIT-BIH AR) is used for experimental verification. For training sets and test sets with consistent data sources, the overall classification accuracy of the method is up to 99.84% +/- 0.04%. For training sets and test sets with inconsistent data sources, a small number of training sets are extended by the active learning (AL) method, and the overall classification accuracy of the method is up to 99.31% +/- 0.23%. The experimental results show the effectiveness of the method in arrhythmia automatic feature extraction and classification. It provides a new solution for the automatic extraction of ECG signal features and classification for deep learning.	['School of Electrical and Electronic Engineering, Harbin University of Science and Technology, Harbin 150080, P.R.China.lixinsong@hrbust.edu.cn.', 'School of Electrical and Electronic Engineering, Harbin University of Science and Technology, Harbin 150080, P.R.China.', 'School of Computer Science and Technology, Harbin University of Science and Technology, Harbin 150080, P.R.China.', 'School of Electrical and Electronic Engineering, Harbin University of Science and Technology, Harbin 150080, P.R.China.']	['10.7507/1001-5515.201810053 [doi]']	['Song L', 'Sun D', 'Wang Q', 'Wang Y']							['2019/06/25 06:00']	20190911		2019 Jun 25	2019/06/25 06:00		['Song, Lixin', 'Sun, Dongzi', 'Wang, Qian', 'Wang, Yujing']			3		1001-5515 (Print) 1001-5515 (Linking)	9426398	Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi	['chi']	10.7507/1001-5515.201810053 [doi]	20190911	['Arrhythmias, Cardiac/*classification', 'Databases, Factual', '*Electrocardiography', 'Heart Rate', 'Humans', '*Neural Networks (Computer)']	2019/09/12 06:00		['arrhythmia', 'discriminative deep belief networks', 'feature extraction', 'restricted Boltzmann machine', 'softmax regression']	['NOTNLM']	NLM	444-452	['2019/06/25 06:00 [entrez]', '2019/06/25 06:00 [pubmed]', '2019/09/12 06:00 [medline]']	China			31232548	ppublish	['Journal Article']			IM		Sheng Wu Yi Xue Gong Cheng Xue Za Zhi. 2019 Jun 25;36(3):444-452. doi: 10.7507/1001-5515.201810053.	MEDLINE	Sheng Wu Yi Xue Gong Cheng Xue Za Zhi	[Automatic classification method of arrhythmia based on discriminative deep belief networks].		36	[Automatic classification method of arrhythmia based on discriminative deep belief networks].
BACKGROUND: To determine if mammographic features from deep learning networks can be applied in breast cancer to identify groups at interval invasive cancer risk due to masking beyond using traditional breast density measures. METHODS: Full-field digital screening mammograms acquired in our clinics between 2006 and 2015 were reviewed. Transfer learning of a deep learning network with weights initialized from ImageNet was performed to classify mammograms that were followed by an invasive interval or screen-detected cancer within 12 months of the mammogram. Hyperparameter optimization was performed and the network was visualized through saliency maps. Prediction loss and accuracy were calculated using this deep learning network. Receiver operating characteristic (ROC) curves and area under the curve (AUC) values were generated with the outcome of interval cancer using the deep learning network and compared to predictions from conditional logistic regression with errors quantified through contingency tables. RESULTS: Pre-cancer mammograms of 182 interval and 173 screen-detected cancers were split into training/test cases at an 80/20 ratio. Using Breast Imaging-Reporting and Data System (BI-RADS) density alone, the ability to correctly classify interval cancers was moderate (AUC = 0.65). The optimized deep learning model achieved an AUC of 0.82. Contingency table analysis showed the network was correctly classifying 75.2% of the mammograms and that incorrect classifications were slightly more common for the interval cancer mammograms. Saliency maps of each cancer case found that local information could highly drive classification of cases more than global image information. CONCLUSIONS: Pre-cancerous mammograms contain imaging information beyond breast density that can be identified with deep learning networks to predict the probability of breast cancer detection.	['Department of Bioengineering, University of California-San Francisco Berkeley Joint Program, Room A-C106-B, 1 Irving St, San Francisco, CA, 94143, USA. bhinton@berkeley.edu.', 'Department of Radiology and Biomedical Imaging, UC-San Francisco, San Francisco, CA, 94143, USA. bhinton@berkeley.edu.', 'Kaiser Permanente Division of Research, Oakland, CA, USA.', 'Accenture, San Francisco, CA, 94143, USA.', 'Applied Materials, Santa Clara, CA, USA.', 'Department of Bioengineering, University of California-San Francisco Berkeley Joint Program, Room A-C106-B, 1 Irving St, San Francisco, CA, 94143, USA.', 'Department of Radiology and Biomedical Imaging, UC-San Francisco, San Francisco, CA, 94143, USA.', 'Department of Radiology and Biomedical Imaging, UC-San Francisco, San Francisco, CA, 94143, USA.', 'Research Advocate, UCSF Breast Science Advocacy Core, San Francisco, CA, 94143, USA.', 'Departments of Medicine and Epidemiology and Biostatistics, UCSF, San Francisco, CA, 94143, USA.', 'Cancer Epidemiology, University of Hawaii Cancer Center, Honolulu, HI, 96813, USA.']	['10.1186/s40644-019-0227-3 [doi]', '10.1186/s40644-019-0227-3 [pii]']	['Hinton B', 'Ma L', 'Mahmoudzadeh AP', 'Malkov S', 'Fan B', 'Greenwood H', 'Joe B', 'Lee V', 'Kerlikowske K', 'Shepherd J']	['ORCID: http://orcid.org/0000-0001-9587-5536']						['2019/06/24 06:00']	20190903	20190622	2019 Jun 22	2019/06/24 06:00		['Hinton, Benjamin', 'Ma, Lin', 'Mahmoudzadeh, Amir Pasha', 'Malkov, Serghei', 'Fan, Bo', 'Greenwood, Heather', 'Joe, Bonnie', 'Lee, Vivian', 'Kerlikowske, Karla', 'Shepherd, John']		['21IB-0130/California Breast Cancer Research Program', 'R01CA166945/National Institutes of Health', 'P01CA154292/National Institutes of Health', '1144247/National Science Foundation']	1		1470-7330 (Electronic) 1470-7330 (Linking)	101172931	Cancer imaging : the official publication of the International Cancer Imaging Society	['eng']	10.1186/s40644-019-0227-3 [doi]	20190903	['Breast Neoplasms/*diagnostic imaging', '*Deep Learning', 'Early Detection of Cancer', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods/standards', 'Limit of Detection', 'Mammography/*methods/standards']	2019/09/04 06:00		['Breast Cancer', 'Breast density', 'Deep learning', 'Interval Cancer', 'Mammography', 'Masking', 'Neural network', 'Transfer learning']	['NOTNLM']	NLM	41	['2019/03/04 00:00 [received]', '2019/06/13 00:00 [accepted]', '2019/06/24 06:00 [entrez]', '2019/06/24 06:00 [pubmed]', '2019/09/04 06:00 [medline]']	England	PMC6589178		31228956	epublish	['Journal Article']			IM		Cancer Imaging. 2019 Jun 22;19(1):41. doi: 10.1186/s40644-019-0227-3.	MEDLINE	Cancer Imaging	Deep learning networks find unique mammographic differences in previous negative mammograms between interval and screen-detected cancers: a case-case study.		19	Deep learning networks find unique mammographic differences in previous negative mammograms between interval and screen-detected cancers: a case-case study.
Resistance to drought stress is one of the most favorable traits in breeding programs yet drought stress is one of the most poorly addressed biological processes for both phenomics and genetics. In this study, we investigated the potential of using a time-series chlorophyll fluorescence (ChlF) analysis to dissect the ChlF fingerprints of salt overly sensitive (SOS) mutants under drought stress. Principle component analysis (PCA) was used to identify a shifting pattern of different genotypes including sos mutants and wild type (WT) Col-0. A time-series deep-learning algorithm, sparse auto encoders (SAEs) neural network, was applied to extract time-series ChlF features which were used in four classification models including linear discriminant analysis (LDA), k-nearest neighbor classifier (KNN), Gaussian naive Bayes (NB) and support vector machine (SVM). The results showed that the discrimination accuracy of sos mutants SOS1-1, SOS2-3, and wild type Col-0 reached 95% with LDA classification model. Sequential forward selection (SFS) algorithm was used to obtain ChlF fingerprints of the shifting pattern, which could address the response of sos mutants and Col-0 to drought stress over time. Parameters including QY, NPQ and Fm, etc. were significantly different between sos mutants and WT. This research proved the potential of ChlF imaging for gene function analysis and the study of drought stress using ChlF in a time-series manner.	['College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou 310058, China. dzs0015@zju.edu.cn.', 'Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, Hangzhou 310058, China. dzs0015@zju.edu.cn.', 'College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou 310058, China. zhukvo@zju.edu.cn.', 'Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, Hangzhou 310058, China. zhukvo@zju.edu.cn.', 'College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou 310058, China. haixiaxu@zju.edu.cn.', 'Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, Hangzhou 310058, China. haixiaxu@zju.edu.cn.', 'College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou 310058, China. yhe@zju.edu.cn.', 'Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, Hangzhou 310058, China. yhe@zju.edu.cn.', 'State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou 310058, China. yhe@zju.edu.cn.', 'College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou 310058, China. hycen@zju.edu.cn.', 'Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, Hangzhou 310058, China. hycen@zju.edu.cn.', 'State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou 310058, China. hycen@zju.edu.cn.']	['s19122649 [pii]', '10.3390/s19122649 [doi]']	['Sun D', 'Zhu Y', 'Xu H', 'He Y', 'Cen H']	['ORCID: 0000-0001-6752-1757']						['2019/06/20 06:00']	20191202	20190612	2019 Jun 12	2019/06/20 06:00		['Sun, Dawei', 'Zhu, Yueming', 'Xu, Haixia', 'He, Yong', 'Cen, Haiyan']		['31801256/National Natural Science Foundation of China']	12		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2649 [pii] 10.3390/s19122649 [doi]	20191202	['Algorithms', 'Arabidopsis/genetics/ultrastructure', 'Bayes Theorem', 'Chlorophyll/*chemistry/isolation & purification', 'Droughts', 'Neural Networks (Computer)', '*Optical Imaging', 'Photosynthesis/*genetics', 'Principal Component Analysis', 'Sodium Chloride/toxicity', 'Son of Sevenless Protein, Drosophila/*chemistry/genetics', 'Stress, Physiological/genetics', 'Support Vector Machine']	2019/12/04 06:00		['Arabidopsis thaliana', 'chlorophyll fluorescence imaging', 'drought stress', 'salt overly sensitive (SOS) pathway']	['NOTNLM']	NLM		['2019/05/07 00:00 [received]', '2019/06/03 00:00 [revised]', '2019/06/10 00:00 [accepted]', '2019/06/20 06:00 [entrez]', '2019/06/20 06:00 [pubmed]', '2019/12/04 06:00 [medline]']	Switzerland	PMC6631407		31212744	epublish	['Journal Article']		['0 (Son of Sevenless Protein, Drosophila)', '1406-65-1 (Chlorophyll)', '451W47IQ8X (Sodium Chloride)']	IM		Sensors (Basel). 2019 Jun 12;19(12). pii: s19122649. doi: 10.3390/s19122649.	MEDLINE	Sensors (Basel)	Time-Series Chlorophyll Fluorescence Imaging Reveals Dynamic Photosynthetic Fingerprints of sos Mutants to Drought Stress.		19	Time-Series Chlorophyll Fluorescence Imaging Reveals Dynamic Photosynthetic Fingerprints of sos Mutants to Drought Stress.
BACKGROUND: Protein secondary structure (PSS) is critical to further predict the tertiary structure, understand protein function and design drugs. However, experimental techniques of PSS are time consuming and expensive, and thus it's very urgent to develop efficient computational approaches for predicting PSS based on sequence information alone. Moreover, the feature matrix of a protein contains two dimensions: the amino-acid residue dimension and the feature vector dimension. Existing deep learning based methods have achieved remarkable performances of PSS prediction, but the methods often utilize the features from the amino-acid dimension. Thus, there is still room to improve computational methods of PSS prediction. RESULTS: We propose a novel deep neural network method, called DeepACLSTM, to predict 8-category PSS from protein sequence features and profile features. Our method efficiently applies asymmetric convolutional neural networks (ACNNs) combined with bidirectional long short-term memory (BLSTM) neural networks to predict PSS, leveraging the feature vector dimension of the protein feature matrix. In DeepACLSTM, the ACNNs extract the complex local contexts of amino-acids; the BLSTM neural networks capture the long-distance interdependencies between amino-acids. Furthermore, the prediction module predicts the category of each amino-acid residue based on both local contexts and long-distance interdependencies. To evaluate performances of DeepACLSTM, we conduct experiments on three publicly available datasets: CB513, CASP10 and CASP12. Results indicate that the performance of our method is superior to the state-of-the-art baselines on three publicly datasets. CONCLUSIONS: Experiments demonstrate that DeepACLSTM is an efficient predication method for predicting 8-category PSS and has the ability to extract more complex sequence-structure relationships between amino-acid residues. Moreover, experiments also indicate the feature vector dimension contains the useful information for improving PSS prediction.	['School of Information Science and Engineering, Yunnan University, Kunming, 650091, China.', 'School of Information Science and Engineering, Yunnan University, Kunming, 650091, China. liweihua@ynu.edu.cn.', 'Research Institute of Resource Insects, Chinese Academy of Forestry, Kunming, 650224, China. wbykm@aliyun.com.', 'School of Information Science and Engineering, Yunnan University, Kunming, 650091, China.', 'School of Information Science and Engineering, Yunnan University, Kunming, 650091, China.']	['10.1186/s12859-019-2940-0 [doi]', '10.1186/s12859-019-2940-0 [pii]']	['Guo Y', 'Li W', 'Wang B', 'Liu H', 'Zhou D']	['ORCID: http://orcid.org/0000-0002-9401-9145']						['2019/06/19 06:00']	20190806	20190617	2019 Jun 17	2019/06/19 06:00		['Guo, Yanbu', 'Li, Weihua', 'Wang, Bingyi', 'Liu, Huiqing', 'Zhou, Dongming']		['NO.2018HB096/Personnel Training Program of Academic and Technical Leaders of', 'Yunnan Province', '2018HC019/The Project of Innovative Research Team of Yunnan Province', 'NO. 61762090/National Science Foundation of China', 'NO.2016FA026/Key projects of National Science Foundation of Yunnan Province']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2940-0 [doi]	20190806	['*Algorithms', '*Deep Learning', '*Models, Theoretical', '*Neural Networks (Computer)', 'Protein Domains', 'Protein Structure, Secondary', 'Proteins/*chemistry']	2019/08/07 06:00		['Asymmetric convolutional neural network', 'Deep learning', 'Long short-term memory', 'Protein secondary structure']	['NOTNLM']	NLM	341	['2018/09/04 00:00 [received]', '2019/06/07 00:00 [accepted]', '2019/06/19 06:00 [entrez]', '2019/06/19 06:00 [pubmed]', '2019/08/07 06:00 [medline]']	England	PMC6580607		31208331	epublish	['Journal Article']		['0 (Proteins)']			BMC Bioinformatics. 2019 Jun 17;20(1):341. doi: 10.1186/s12859-019-2940-0.	MEDLINE	BMC Bioinformatics	DeepACLSTM: deep asymmetric convolutional long short-term memory neural models for protein secondary structure prediction.		20	DeepACLSTM: deep asymmetric convolutional long short-term memory neural models for protein secondary structure prediction.
BACKGROUND: The advent of high-throughput experimental techniques paved the way to genome-wide computational analysis and predictive annotation studies. When considering the joint annotation of a large set of related entities, like all proteins of a certain genome, many candidate annotations could be inconsistent, or very unlikely, given the existing knowledge. A sound predictive framework capable of accounting for this type of constraints in making predictions could substantially contribute to the quality of machine-generated annotations at a genomic scale. RESULTS: We present OCELOT, a predictive pipeline which simultaneously addresses functional and interaction annotation of all proteins of a given genome. The system combines sequence-based predictors for functional and protein-protein interaction (PPI) prediction with a consistency layer enforcing (soft) constraints as fuzzy logic rules. The enforced rules represent the available prior knowledge about the classification task, including taxonomic constraints over each GO hierarchy (e.g. a protein labeled with a GO term should also be labeled with all ancestor terms) as well as rules combining interaction and function prediction. An extensive experimental evaluation on the Yeast genome shows that the integration of prior knowledge via rules substantially improves the quality of the predictions. The system largely outperforms GoFDR, the only high-ranking system at the last CAFA challenge with a readily available implementation, when GoFDR is given access to intra-genome information only (as OCELOT), and has comparable or better results (depending on the hierarchy and performance measure) when GoFDR is allowed to use information from other genomes. Our system also compares favorably to recent methods based on deep learning.	['Computer Science Department, KULeuven, Celestijnenlaan 200 A bus 2402, Leuven, 3001, Belgium.', 'Department of Information Engineering and Computer Science, University of Trento, Via Sommarive, 5, Povo di Trento, 38123, Italy.', 'Department of Information Engineering and Mathematics, University of Siena, San Niccolo, via Roma, 56, Siena, 53100, Italy.', 'Department of Information Engineering and Computer Science, University of Trento, Via Sommarive, 5, Povo di Trento, 38123, Italy. andrea.passerini@unitn.it.']	['10.1186/s12859-019-2875-5 [doi]', '10.1186/s12859-019-2875-5 [pii]']	['Teso S', 'Masera L', 'Diligenti M', 'Passerini A']	['ORCID: http://orcid.org/0000-0002-2765-5395']						['2019/06/19 06:00']	20190806	20190617	2019 Jun 17	2019/06/19 06:00		['Teso, Stefano', 'Masera, Luca', 'Diligenti, Michelangelo', 'Passerini, Andrea']		['Google Faculty Research Award: Integrated Prediction of Protein Function,', 'Interactions and Pathways with Statistical Relational Learning/Google', 'ERC Advanced Grant SYNTH - Synthesising inductive data models./European Research', 'Council/International']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2875-5 [doi]	20190806	['Algorithms', 'Decision Making', 'Gene Ontology', '*Genome, Fungal', 'Genomics/*methods', '*Molecular Sequence Annotation', 'Proteins/*genetics', 'Saccharomyces cerevisiae/*genetics']	2019/08/07 06:00		['Genome annotation', 'Kernel methods', 'Protein function prediction', 'Protein-protein interaction']	['NOTNLM']	NLM	338	['2018/11/05 00:00 [received]', '2019/05/03 00:00 [accepted]', '2019/06/19 06:00 [entrez]', '2019/06/19 06:00 [pubmed]', '2019/08/07 06:00 [medline]']	England	PMC6580517		31208327	epublish	['Journal Article']		['0 (Proteins)']			BMC Bioinformatics. 2019 Jun 17;20(1):338. doi: 10.1186/s12859-019-2875-5.	MEDLINE	BMC Bioinformatics	Combining learning and constraints for genome-wide protein annotation.		20	Combining learning and constraints for genome-wide protein annotation.
Artificial intelligence (AI) is currently regaining enormous interest due to the success of machine learning (ML), and in particular deep learning (DL). Image analysis, and thus radiomics, strongly benefits from this research. However, effectively and efficiently integrating diverse clinical, imaging, and molecular profile data is necessary to understand complex diseases, and to achieve accurate diagnosis in order to provide the best possible treatment. In addition to the need for sufficient computing resources, suitable algorithms, models, and data infrastructure, three important aspects are often neglected: (1) the need for multiple independent, sufficiently large and, above all, high-quality data sets; (2) the need for domain knowledge and ontologies; and (3) the requirement for multiple networks that provide relevant relationships among biological entities. While one will always get results out of high-dimensional data, all three aspects are essential to provide robust training and validation of ML models, to provide explainable hypotheses and results, and to achieve the necessary trust in AI and confidence for clinical applications.	['Institute for Medical Informatics / Statistics, Medical University Graz, Auenbruggerplatz 2/V, 8036, Graz, Austria.', 'Princess Margaret Cancer Centre, University Health Network, Toronto, ON, Canada.', 'Departments of Medical Biophysics and Computer Science, University of Toronto, Toronto, Canada.', 'Departments of Medical Biophysics and Computer Science, University of Toronto, Toronto, Canada. juris@ai.utoronto.ca.', 'Krembil Research Institute, UHN, 60 Leonard Avenue, 5KD-407, Toronto, Ontario, M5T 0S8, Canada. juris@ai.utoronto.ca.', 'Institute of Neuroimmunology, Slovak Academy of Sciences, Bratislava, Slovakia. juris@ai.utoronto.ca.']	['10.1007/s00259-019-04382-9 [doi]', '10.1007/s00259-019-04382-9 [pii]']	['Holzinger A', 'Haibe-Kains B', 'Jurisica I']	['ORCID: http://orcid.org/0000-0002-2507-946X']						['2019/06/17 06:00']		20190615	2019 Dec	2019/06/17 06:00		['Holzinger, Andreas', 'Haibe-Kains, Benjamin', 'Jurisica, Igor']		['34876/Ontario Research Fund']	13		1619-7089 (Electronic) 1619-7070 (Linking)	101140988	European journal of nuclear medicine and molecular imaging	['eng']	10.1007/s00259-019-04382-9 [doi]	20191129		2019/06/17 06:00		['Artificial intelligence', 'Decision support', 'Integrative computational biology', 'Machine learning', 'Network-based analysis', 'Precision medicine', 'Radiomics']	['NOTNLM']	NLM	2722-2730	['2019/05/12 00:00 [received]', '2019/05/28 00:00 [accepted]', '2019/06/17 06:00 [pubmed]', '2019/06/17 06:00 [medline]', '2019/06/17 06:00 [entrez]']	Germany			31203421	ppublish	['Journal Article']			IM		Eur J Nucl Med Mol Imaging. 2019 Dec;46(13):2722-2730. doi: 10.1007/s00259-019-04382-9. Epub 2019 Jun 15.	In-Data-Review	Eur J Nucl Med Mol Imaging	Why imaging data alone is not enough: AI-based integration of imaging, omics, and clinical data.		46	Why imaging data alone is not enough: AI-based integration of imaging, omics, and clinical data.
Identification of drug-target interactions (DTIs) plays a key role in drug discovery. The high cost and labor-intensive nature of in vitro and in vivo experiments have highlighted the importance of in silico-based DTI prediction approaches. In several computational models, conventional protein descriptors have been shown to not be sufficiently informative to predict accurate DTIs. Thus, in this study, we propose a deep learning based DTI prediction model capturing local residue patterns of proteins participating in DTIs. When we employ a convolutional neural network (CNN) on raw protein sequences, we perform convolution on various lengths of amino acids subsequences to capture local residue patterns of generalized protein classes. We train our model with large-scale DTI information and demonstrate the performance of the proposed model using an independent dataset that is not seen during the training phase. As a result, our model performs better than previous protein descriptor-based models. Also, our model performs better than the recently developed deep learning models for massive prediction of DTIs. By examining pooled convolution results, we confirmed that our model can detect binding sites of proteins for DTIs. In conclusion, our prediction model for detecting local residue patterns of target proteins successfully enriches the protein features of a raw protein sequence, yielding better prediction results than previous approaches. Our code is available at https://github.com/GIST-CSBL/DeepConv-DTI.	['School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Buk-ku, Gwangju, Republic of Korea.', 'School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Buk-ku, Gwangju, Republic of Korea.', 'School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Buk-ku, Gwangju, Republic of Korea.']	['10.1371/journal.pcbi.1007129 [doi]', 'PCOMPBIOL-D-18-01686 [pii]']	['Lee I', 'Keum J', 'Nam H']	['ORCID: 0000-0002-8958-2945', 'ORCID: 0000-0002-5109-9114']				['No authors have competing interests.']		['2019/06/15 06:00']	20191202	20190614	2019 Jun	2019/06/15 06:00		['Lee, Ingoo', 'Keum, Jongsoo', 'Nam, Hojung']			6		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1007129 [doi]	20191202	['Amino Acid Sequence', 'Binding Sites', 'Computational Biology', 'Computer Simulation', '*Deep Learning', 'Drug Discovery/*methods', 'Ligands', 'Models, Molecular', '*Proteins/chemistry/metabolism', 'Sequence Analysis, Protein/*methods']	2019/12/04 06:00				NLM	e1007129	['2018/10/01 00:00 [received]', '2019/05/24 00:00 [accepted]', '2019/06/26 00:00 [revised]', '2019/06/15 06:00 [pubmed]', '2019/12/04 06:00 [medline]', '2019/06/15 06:00 [entrez]']	United States	PMC6594651		31199797	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Ligands)', '0 (Proteins)']	IM		PLoS Comput Biol. 2019 Jun 14;15(6):e1007129. doi: 10.1371/journal.pcbi.1007129. eCollection 2019 Jun.	MEDLINE	PLoS Comput Biol	DeepConv-DTI: Prediction of drug-target interactions via deep learning with convolution on protein sequences.		15	DeepConv-DTI: Prediction of drug-target interactions via deep learning with convolution on protein sequences.
BACKGROUND: An important task of macromolecular structure determination by cryo-electron microscopy (cryo-EM) is the identification of single particles in micrographs (particle picking). Due to the necessity of human involvement in the process, current particle picking techniques are time consuming and often result in many false positives and negatives. Adjusting the parameters to eliminate false positives often excludes true particles in certain orientations. The supervised machine learning (e.g. deep learning) methods for particle picking often need a large training dataset, which requires extensive manual annotation. Other reference-dependent methods rely on low-resolution templates for particle detection, matching and picking, and therefore, are not fully automated. These issues motivate us to develop a fully automated, unbiased framework for particle picking. RESULTS: We design a fully automated, unsupervised approach for single particle picking in cryo-EM micrographs. Our approach consists of three stages: image preprocessing, particle clustering, and particle picking. The image preprocessing is based on multiple techniques including: image averaging, normalization, cryo-EM image contrast enhancement correction (CEC), histogram equalization, restoration, adaptive histogram equalization, guided image filtering, and morphological operations. Image preprocessing significantly improves the quality of original cryo-EM images. Our particle clustering method is based on an intensity distribution model which is much faster and more accurate than traditional K-means and Fuzzy C-Means (FCM) algorithms for single particle clustering. Our particle picking method, based on image cleaning and shape detection with a modified Circular Hough Transform algorithm, effectively detects the shape and the center of each particle and creates a bounding box encapsulating the particles. CONCLUSIONS: AutoCryoPicker can automatically and effectively recognize particle-like objects from noisy cryo-EM micrographs without the need of labeled training data or human intervention making it a useful tool for cryo-EM protein structure determination.	['Electrical Engineering and Computer Science Department, University of Missouri, Columbia, MO, 65211, USA.', 'Electrical Engineering and Computer Science Department, University of Missouri, Columbia, MO, 65211, USA.', 'Departments of Biochemistry and Chemistry, University of Missouri, Columbia, MO, 65211-2060, USA.', 'Electrical Engineering and Computer Science Department, University of Missouri, Columbia, MO, 65211, USA. chengji@missouri.edu.', 'Informatics Institute, University of Missouri, Columbia, MO, 65211, USA. chengji@missouri.edu.']	['10.1186/s12859-019-2926-y [doi]', '10.1186/s12859-019-2926-y [pii]']	['Al-Azzawi A', 'Ouadou A', 'Tanner JJ', 'Cheng J']	['ORCID: http://orcid.org/0000-0003-0305-2853']						['2019/06/15 06:00']	20190730	20190613	2019 Jun 13	2019/06/15 06:00		['Al-Azzawi, Adil', 'Ouadou, Anes', 'Tanner, John J', 'Cheng, Jianlin']		['R01 GM065546/GM/NIGMS NIH HHS/United States', 'IIS1763246/National Science Foundation', 'R01GM065546/GM/NIGMS NIH HHS/United States', 'DBI1759934/National Science Foundation', 'R01 GM093123/GM/NIGMS NIH HHS/United States', 'R01GM093123/GM/NIGMS NIH HHS/United States']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2926-y [doi]	20190817	['*Algorithms', 'Automation', 'Cluster Analysis', 'Cryoelectron Microscopy/*methods', 'Image Processing, Computer-Assisted/*methods', 'Software', '*Unsupervised Machine Learning']	2019/07/31 06:00		['Clustering', 'Cryo-EM', 'Intensity based clustering (IBC)', 'Micrograph', 'Protein structure determination', 'Single particle picking']	['NOTNLM']	NLM	326	['2018/11/19 00:00 [received]', '2019/05/31 00:00 [accepted]', '2019/06/15 06:00 [entrez]', '2019/06/15 06:00 [pubmed]', '2019/07/31 06:00 [medline]']	England	PMC6567647		31195977	epublish	['Journal Article']					BMC Bioinformatics. 2019 Jun 13;20(1):326. doi: 10.1186/s12859-019-2926-y.	MEDLINE	BMC Bioinformatics	AutoCryoPicker: an unsupervised learning approach for fully automated single particle picking in Cryo-EM images.		20	AutoCryoPicker: an unsupervised learning approach for fully automated single particle picking in Cryo-EM images.
BACKGROUND: Deep learning techniques have been successfully applied to bioimaging problems; however, these methods are highly data demanding. An approach to deal with the lack of data and avoid overfitting is the application of data augmentation, a technique that generates new training samples from the original dataset by applying different kinds of transformations. Several tools exist to apply data augmentation in the context of image classification, but it does not exist a similar tool for the problems of localization, detection, semantic segmentation or instance segmentation that works not only with 2 dimensional images but also with multi-dimensional images (such as stacks or videos). RESULTS: In this paper, we present a generic strategy that can be applied to automatically augment a dataset of images, or multi-dimensional images, devoted to classification, localization, detection, semantic segmentation or instance segmentation. The augmentation method presented in this paper has been implemented in the open-source package CLoDSA. To prove the benefits of using CLoDSA, we have employed this library to improve the accuracy of models for Malaria parasite classification, stomata detection, and automatic segmentation of neural structures. CONCLUSIONS: CLoDSA is the first, at least up to the best of our knowledge, image augmentation library for object classification, localization, detection, semantic segmentation, and instance segmentation that works not only with 2 dimensional images but also with multi-dimensional images.	['Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain.', 'Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain.', 'Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain.', 'Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain. jonathan.heras@unirioja.es.', 'Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain.', 'Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain.', 'Department of Mathematics and Computer Science, University of La Rioja, Ed. CCT. C/ Madre de Dios 53, Logrono, 26006, Spain.']	['10.1186/s12859-019-2931-1 [doi]', '10.1186/s12859-019-2931-1 [pii]']	['Casado-Garcia A', 'Dominguez C', 'Garcia-Dominguez M', 'Heras J', 'Ines A', 'Mata E', 'Pascual V']	['ORCID: http://orcid.org/0000-0003-4775-1306']						['2019/06/15 06:00']	20190730	20190613	2019 Jun 13	2019/06/15 06:00		['Casado-Garcia, Angela', 'Dominguez, Cesar', 'Garcia-Dominguez, Manuel', 'Heras, Jonathan', 'Ines, Adrian', 'Mata, Eloy', 'Pascual, Vico']		['MTM2017-88804-P/Ministerio de Economia, Industria y Competitividad, Gobierno de', 'Espana', '2017-I-IDD-00018/Agencia de Desarrollo Economico de La Rioja (ES)', 'FPU16/06903/Ministerio de Educacion y Ciencia (ES)', 'FPI2018/Comunidad Autonoma de La Rioja (ES)']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2931-1 [doi]	20190730	['*Algorithms', 'Animals', 'Deep Learning', 'Humans', '*Image Processing, Computer-Assisted', 'Malaria/parasitology', 'Models, Theoretical', 'Parasites/classification', '*Semantics']	2019/07/31 06:00		['Classification', 'Data augmentation', 'Detection', 'Multi-dimensional images', 'Segmentation']	['NOTNLM']	NLM	323	['2019/03/04 00:00 [received]', '2019/06/04 00:00 [accepted]', '2019/06/15 06:00 [entrez]', '2019/06/15 06:00 [pubmed]', '2019/07/31 06:00 [medline]']	England	PMC6567576		31195959	epublish	['Journal Article']					BMC Bioinformatics. 2019 Jun 13;20(1):323. doi: 10.1186/s12859-019-2931-1.	MEDLINE	BMC Bioinformatics	CLoDSA: a tool for augmentation in classification, localization, detection, semantic segmentation and instance segmentation tasks.		20	CLoDSA: a tool for augmentation in classification, localization, detection, semantic segmentation and instance segmentation tasks.
BACKGROUND: CRISPR-Cpf1 has recently been reported as another RNA-guided endonuclease of class 2 CRISPR-Cas system, which expands the molecular biology toolkit for genome editing. However, most of the online tools and applications to date have been developed primarily for the Cas9. There are a limited number of tools available for the Cpf1. RESULTS: We present DeepCpf1, a deep convolution neural networks (CNN) approach to predict Cpf1 guide RNAs on-target activity and off-target effects using their matched and mismatched DNA sequences. Trained on published data sets, DeepCpf1 is superior to other machine learning algorithms and reliably predicts the most efficient and less off-target effects guide RNAs for a given gene. Combined with a permutation importance analysis, the key features of guide RNA sequences are identified, which determine the activity and specificity of genome editing. CONCLUSIONS: DeepCpf1 can significantly improve the accuracy of Cpf1-based genome editing and facilitates the generation of optimized guide RNAs libraries.	['Department of Pharmacology, Key Laboratory for Aging and Regenerative Medicine, School of Pharmacy, Southwest Medical University, Luzhou, Sichuan, China. ljs@swmu.edu.cn.', 'Center for Bioinformatics and Systems Biology and Department of Radiology, Wake Forest School of Medicine, Winston-Salem, NC, 27157, USA. ljs@swmu.edu.cn.', 'Center for Bioinformatics and Systems Biology and Department of Radiology, Wake Forest School of Medicine, Winston-Salem, NC, 27157, USA.', 'School of Public Health, Southwest Medical University, Luzhou, Sichuan, China.', 'Basic Medical College of Southwest Medical University, Luzhou, Sichuan, China. bt@swmu.edu.cn.']	['10.1186/s12859-019-2939-6 [doi]', '10.1186/s12859-019-2939-6 [pii]']	['Luo J', 'Chen W', 'Xue L', 'Tang B']	['ORCID: http://orcid.org/0000-0002-1199-7024']						['2019/06/15 06:00']	20190730	20190613	2019 Jun 13	2019/06/15 06:00		['Luo, Jiesi', 'Chen, Wei', 'Xue, Li', 'Tang, Bin']		['1U01CA166886/Foundation for the National Institutes of Health', 'No. 21803045/National Natural Science Foundation of China']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2939-6 [doi]	20190730	['Algorithms', 'Base Sequence', 'CRISPR-Cas Systems/*genetics', '*Deep Learning', 'Endonucleases/*metabolism', '*Neural Networks (Computer)', 'RNA, Guide/genetics']	2019/07/31 06:00		['CRISPR', 'Deep learning', 'Guide RNAs design']	['NOTNLM']	NLM	332	['2018/02/13 00:00 [received]', '2019/06/07 00:00 [accepted]', '2019/06/15 06:00 [entrez]', '2019/06/15 06:00 [pubmed]', '2019/07/31 06:00 [medline]']	England	PMC6567654		31195957	epublish	['Journal Article']		['0 (RNA, Guide)', 'EC 3.1.- (Endonucleases)']			BMC Bioinformatics. 2019 Jun 13;20(1):332. doi: 10.1186/s12859-019-2939-6.	MEDLINE	BMC Bioinformatics	Prediction of activity and specificity of CRISPR-Cpf1 using convolutional deep learning neural networks.		20	Prediction of activity and specificity of CRISPR-Cpf1 using convolutional deep learning neural networks.
PURPOSE: Machine learning-based approaches now outperform competing methods in most disciplines relevant to diagnostic radiology. Image-guided procedures, however, have not yet benefited substantially from the advent of deep learning, in particular because images for procedural guidance are not archived and thus unavailable for learning, and even if they were available, annotations would be a severe challenge due to the vast amounts of data. In silico simulation of X-ray images from 3D CT is an interesting alternative to using true clinical radiographs since labeling is comparably easy and potentially readily available. METHODS: We extend our framework for fast and realistic simulation of fluoroscopy from high-resolution CT, called DeepDRR, with tool modeling capabilities. The framework is publicly available, open source, and tightly integrated with the software platforms native to deep learning, i.e., Python, PyTorch, and PyCuda. DeepDRR relies on machine learning for material decomposition and scatter estimation in 3D and 2D, respectively, but uses analytic forward projection and noise injection to ensure acceptable computation times. On two X-ray image analysis tasks, namely (1) anatomical landmark detection and (2) segmentation and localization of robot end-effectors, we demonstrate that convolutional neural networks (ConvNets) trained on DeepDRRs generalize well to real data without re-training or domain adaptation. To this end, we use the exact same training protocol to train ConvNets on naive and DeepDRRs and compare their performance on data of cadaveric specimens acquired using a clinical C-arm X-ray system. RESULTS: Our findings are consistent across both considered tasks. All ConvNets performed similarly well when evaluated on the respective synthetic testing set. However, when applied to real radiographs of cadaveric anatomy, ConvNets trained on DeepDRRs significantly outperformed ConvNets trained on naive DRRs ([Formula: see text]). CONCLUSION: Our findings for both tasks are positive and promising. Combined with complementary approaches, such as image style transfer, the proposed framework for fast and realistic simulation of fluoroscopy from CT contributes to promoting the implementation of machine learning in X-ray-guided procedures. This paradigm shift has the potential to revolutionize intra-operative image analysis to simplify surgical workflows.	['Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA. unberath@jhu.edu.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA. unberath@jhu.edu.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA. unberath@jhu.edu.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Johns Hopkins University Applied Physics Laboratory, Laurel, MD, USA.', 'Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA.', 'Laboratory for Computational Sensing + Robotics, Johns Hopkins University, Baltimore, MD, USA.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA.']	['10.1007/s11548-019-02011-2 [doi]', '10.1007/s11548-019-02011-2 [pii]']	['Unberath M', 'Zaech JN', 'Gao C', 'Bier B', 'Goldmann F', 'Lee SC', 'Fotouhi J', 'Taylor R', 'Armand M', 'Navab N']	['ORCID: http://orcid.org/0000-0002-0055-9950']						['2019/06/13 06:00']		20190611	2019 Sep	2019/06/13 06:00		['Unberath, Mathias', 'Zaech, Jan-Nico', 'Gao, Cong', 'Bier, Bastian', 'Goldmann, Florian', 'Lee, Sing Chun', 'Fotouhi, Javad', 'Taylor, Russell', 'Armand, Mehran', 'Navab, Nassir']		['R21 EB020113/NH/NIH HHS/United States', 'R01 EB0223939/NH/NIH HHS/United States', 'Hardware Seed Grant/Nvidia', 'R01 EB016703/EB/NIBIB NIH HHS/United States', 'R21 EB020113/EB/NIBIB NIH HHS/United States', 'R01 EB023939/EB/NIBIB NIH HHS/United States']	9		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-019-02011-2 [doi]	20191023		2019/06/13 06:00		['Artificial intelligence', 'Computer assisted surgery', 'Image guidance', 'Monte Carlo simulation', 'Robotic surgery', 'Segmentation']	['NOTNLM']	NLM	1517-1528	['2019/01/28 00:00 [received]', '2019/06/03 00:00 [accepted]', '2019/06/13 06:00 [pubmed]', '2019/06/13 06:00 [medline]', '2019/06/13 06:00 [entrez]']	Germany			31187399	ppublish	['Journal Article']			IM		Int J Comput Assist Radiol Surg. 2019 Sep;14(9):1517-1528. doi: 10.1007/s11548-019-02011-2. Epub 2019 Jun 11.	In-Process	Int J Comput Assist Radiol Surg	Enabling machine learning in X-ray-based procedures via realistic simulation of image formation.		14	Enabling machine learning in X-ray-based procedures via realistic simulation of image formation.
Magnetic resonance imaging (MRI) offers the most detailed brain structure image available today; it can identify tiny lesions or cerebral cortical abnormalities. The primary purpose of the procedure is to confirm whether there is structural variation that causes epilepsy, such as hippocampal sclerotherapy, local cerebral cortical dysplasia, and cavernous hemangioma. Cerebrovascular disease, the second most common factor of death in the world, is also the fourth leading cause of death in Taiwan, with cerebrovascular disease having the highest rate of stroke. Among the most common are large vascular atherosclerotic lesions, small vascular lesions, and cardiac emboli. The purpose of this thesis is to establish a computer-aided diagnosis system based on small blood vessel lesions in MRI images, using the method of Convolutional Neural Network and deep learning to analyze brain vascular occlusion by analyzing brain MRI images. Blocks can help clinicians more quickly determine the probability and severity of stroke in patients. We analyzed MRI data from 50 patients, including 30 patients with stroke, 17 patients with occlusion but no stroke, and 3 patients with dementia. This system mainly helps doctors find out whether there are cerebral small vessel lesions in the brain MRI images, and to output the found results into labeled images. The marked contents include the position coordinates of the small blood vessel blockage, the block range, the area size, and if it may cause a stroke. Finally, all the MRI images of the patient are synthesized, showing a 3D display of the small blood vessels in the brain to assist the doctor in making a diagnosis or to provide accurate lesion location for the patient.	['Department of Electrical Engineering, National Taiwan Ocean University, Keelung 20224, Taiwan. yzhsieh@mail.ntou.edu.tw.', 'Institute of Food Safety and Risk Management, National Taiwan Ocean University, Keelung 20224, Taiwan. yzhsieh@mail.ntou.edu.tw.', 'Center of Excellence for Ocean Engineering, National Taiwan Ocean University, Keelung 20224, Taiwan. yzhsieh@mail.ntou.edu.tw.', 'Department of Electrical Engineering, National Taiwan Ocean University, Keelung 20224, Taiwan. g780455@gmail.com.', 'Department of Electrical Engineering, National Taiwan Ocean University, Keelung 20224, Taiwan. allen.chen.841202.pan@gmail.com.', 'Department of Computer Science & Information Engineering, National Central University, Taoyuan City 32001, Taiwan. muchun@csie.ncu.edu.tw.', 'Department of Radiology, Shuang Ho Hospital, New Taipei City 23561, Taiwan. 08889@s.tmu.edu.tw.', 'Department of Medical Imaging, Taipei Medical University Hospital, Taipei City 110, Taiwan. kevinh9396@gmail.com.', 'Translational Imaging Research Center, College of Medicine, Taipei Medical University, Taipei City 110, Taiwan. kevinh9396@gmail.com.', 'Department of Radiology, School of Medicine, College of Medicine, Taipei Medical University, Taipei City 110, Taiwan. kevinh9396@gmail.com.']	['s19112573 [pii]', '10.3390/s19112573 [doi]']	['Hsieh YZ', 'Luo YC', 'Pan C', 'Su MC', 'Chen CJ', 'Hsieh KL']	['ORCID: 0000-0002-5758-4516']						['2019/06/09 06:00']	20191202	20190606	2019 Jun 6	2019/06/09 06:00		['Hsieh, Yi-Zeng', 'Luo, Yu-Cin', 'Pan, Chen', 'Su, Mu-Chun', 'Chen, Chi-Jen', 'Hsieh, Kevin Li-Chun']		['MOST 107-2634-F-019-001/Ministry of Science and Technology']	11		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2573 [pii] 10.3390/s19112573 [doi]	20191202	['Biomarkers/*chemistry', '*Biosensing Techniques', 'Cerebral Small Vessel Diseases/*diagnosis/diagnostic imaging', 'Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/methods', 'Stroke/diagnosis/physiopathology']	2019/12/04 06:00		['MRI-sensor-based image', 'biomarkers detection', 'cerebral small vessel disease', 'computer-aided diagnosis system', 'convolutional neural network', 'deep learning']	['NOTNLM']	NLM		['2019/05/07 00:00 [received]', '2019/05/27 00:00 [revised]', '2019/05/30 00:00 [accepted]', '2019/06/09 06:00 [entrez]', '2019/06/09 06:00 [pubmed]', '2019/12/04 06:00 [medline]']	Switzerland	PMC6603587		31174277	epublish	['Journal Article']		['0 (Biomarkers)']	IM		Sensors (Basel). 2019 Jun 6;19(11). pii: s19112573. doi: 10.3390/s19112573.	MEDLINE	Sensors (Basel)	Cerebral Small Vessel Disease Biomarkers Detection on MRI-Sensor-Based Image and Deep Learning.		19	Cerebral Small Vessel Disease Biomarkers Detection on MRI-Sensor-Based Image and Deep Learning.
Artificial neural networks, as a specific approach towards artificial intelligence (AI), can open up a variety of new perspectives for endoscopy, such as automated lesion detection and the precise prediction of a lesion's histology by its endoscopic appearance. Whilst early experiments do suggest an enormous potential for these methods, public expectations on their application in various fields of medicine sometimes appear to be grounded on general fascination rather than detailed understanding of their inner workings. Based on a selective review of the literature, this article shall convey an intuitive understanding of the underlying methods in order to help close the gap between functioning and fascination and allow for a realistic discussion of their perspectives and limitations in endoscopy.After decades of research, the success of deep neuronal networks in image classification has provoked rising interest for AI during recent years. We quickly touch upon the developments surrounding this breakthrough and the reasons for their impact on various disciplines much beyond computer science. Through a comparison with the functioning of the human vision system, we aim to understand the mechanisms of these techniques and their success in computer vision tasks in detail. Based on these considerations, we analyse the functioning of some important AI applications in endoscopy, deduce specific limitations and perspectives, discuss the current state of their evaluation in practical endoscopy and make a plea for the need for additional and realistic tests. Moreover, we seek to give an impression of some further specific applications that can currently be foreseen and how these can shape the role that AI might finally acquire in the routine clinical practice of GI endoscopy.	['Department for Interdisciplinary Endoscopy, University Hospital Hamburg-Eppendorf.', 'Institute of Anatomy and Experimental Morphology, University Hospital Hamburg-Eppendorf.', 'DAISYlab, Forschungszentrum Medizintechnik Hamburg, Hamburg, Germany.', 'DAISYlab, Forschungszentrum Medizintechnik Hamburg, Hamburg, Germany.', 'Institute of Computational Neuroscience, University Hospital Hamburg-Eppendorf.', 'Department for Interdisciplinary Endoscopy, University Hospital Hamburg-Eppendorf.']	['10.1055/a-0891-4032 [doi]']	['Schmitz R', 'Werner R', 'Rosch T']		['(c) Georg Thieme Verlag KG Stuttgart . New York.']			['Research grant: Olympus. Grant: NVIDIA GPU Grant.']		['2019/06/07 06:00']	20190911	20190606	2019 Jun	2019/06/07 06:00		['Schmitz, Rudiger', 'Werner, Rene', 'Rosch, Thomas']			6		1439-7803 (Electronic) 0044-2771 (Linking)	0033370	Zeitschrift fur Gastroenterologie	['ger']	10.1055/a-0891-4032 [doi]	20190911	['*Artificial Intelligence', 'Deep Learning', 'Endoscopy/*trends', 'Humans', 'Image Processing, Computer-Assisted', 'Medicine/*trends', '*Neural Networks (Computer)']	2019/09/12 06:00				NLM	767-780	['2019/06/07 06:00 [entrez]', '2019/06/07 06:00 [pubmed]', '2019/09/12 06:00 [medline]']	Germany			31170744	ppublish	['Journal Article']			IM		Z Gastroenterol. 2019 Jun;57(6):767-780. doi: 10.1055/a-0891-4032. Epub 2019 Jun 6.	MEDLINE	Z Gastroenterol	[Artificial Intelligence in Endoscopy: Deep Neural Nets for Endoscopic Computer Vision - Methods & Perspectives].	Kunstliche Intelligenz in der Endoskopie: Neuronale Netze und maschinelles Sehen - Techniken und Perspektiven.	57	[Artificial Intelligence in Endoscopy: Deep Neural Nets for Endoscopic Computer Vision - Methods & Perspectives].
BACKGROUND: The limitations of traditional computer-aided detection (CAD) systems for mammography, the extreme importance of early detection of breast cancer and the high impact of the false diagnosis of patients drive researchers to investigate deep learning (DL) methods for mammograms (MGs). Recent breakthroughs in DL, in particular, convolutional neural networks (CNNs) have achieved remarkable advances in the medical fields. Specifically, CNNs are used in mammography for lesion localization and detection, risk assessment, image retrieval, and classification tasks. CNNs also help radiologists providing more accurate diagnosis by delivering precise quantitative analysis of suspicious lesions. RESULTS: In this survey, we conducted a detailed review of the strengths, limitations, and performance of the most recent CNNs applications in analyzing MG images. It summarizes 83 research studies for applying CNNs on various tasks in mammography. It focuses on finding the best practices used in these research studies to improve the diagnosis accuracy. This survey also provides a deep insight into the architecture of CNNs used for various tasks. Furthermore, it describes the most common publicly available MG repositories and highlights their main features and strengths. CONCLUSIONS: The mammography research community can utilize this survey as a basis for their current and future studies. The given comparison among common publicly available MG repositories guides the community to select the most appropriate database for their application(s). Moreover, this survey lists the best practices that improve the performance of CNNs including the pre-processing of images and the use of multi-view images. In addition, other listed techniques like transfer learning (TL), data augmentation, batch normalization, and dropout are appealing solutions to reduce overfitting and increase the generalization of the CNN models. Finally, this survey identifies the research challenges and directions that require further investigations by the community.	['Department of Computer Science and Engineering, University of Connecticut, Storrs, 06269, CT, USA. dina.abdelhafiz@uconn.edu.', 'The Informatics Research Institute (IRI), City of Scientific Research and Technological Application (SRTA-City), New Borg El-Arab, Egypt. dina.abdelhafiz@uconn.edu.', 'Department of Diagnostic Imaging, University of Connecticut Health Center, Farmington, 06030, CT, USA.', 'Department of Computer Science and Engineering, University of Connecticut, Storrs, 06269, CT, USA.', 'Department of Computer Science and Engineering, University of Connecticut, Storrs, 06269, CT, USA.']	['10.1186/s12859-019-2823-4 [doi]', '10.1186/s12859-019-2823-4 [pii]']	['Abdelhafiz D', 'Yang C', 'Ammar R', 'Nabavi S']							['2019/06/07 06:00']	20190729	20190606	2019 Jun 6	2019/06/07 06:00		['Abdelhafiz, Dina', 'Yang, Clifford', 'Ammar, Reda', 'Nabavi, Sheida']			Suppl 11		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2823-4 [doi]	20190729	['Breast Neoplasms/diagnostic imaging/pathology', 'Databases, Factual', '*Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted', 'Mammography/*methods', '*Neural Networks (Computer)', 'Publications', 'Surveys and Questionnaires']	2019/07/30 06:00		['Breast cancer', 'Classification', 'Computer-aided detection (CAD)', 'Convolutional neural networks (CNNs)', 'Deep learning (DL)', 'Feature detection', 'Machine learning (ML)', 'Mammograms (MGs)', 'Transfer learning (TL)']	['NOTNLM']	NLM	281	['2019/06/07 06:00 [entrez]', '2019/06/07 06:00 [pubmed]', '2019/07/30 06:00 [medline]']	England	PMC6551243		31167642	epublish	['Journal Article']					BMC Bioinformatics. 2019 Jun 6;20(Suppl 11):281. doi: 10.1186/s12859-019-2823-4.	MEDLINE	BMC Bioinformatics	Deep convolutional neural networks for mammography: advances, challenges and applications.		20	Deep convolutional neural networks for mammography: advances, challenges and applications.
Allergies to airborne pollen are a significant issue affecting millions of Americans. Consequently, accurately predicting the daily concentration of airborne pollen is of significant public benefit in providing timely alerts. This study presents a method for the robust estimation of the concentration of airborne Ambrosia pollen using a suite of machine learning approaches including deep learning and ensemble learners. Each of these machine learning approaches utilize data from the European Centre for Medium-Range Weather Forecasts (ECMWF) atmospheric weather and land surface reanalysis. The machine learning approaches used for developing a suite of empirical models are deep neural networks, extreme gradient boosting, random forests and Bayesian ridge regression methods for developing our predictive model. The training data included twenty-four years of daily pollen concentration measurements together with ECMWF weather and land surface reanalysis data from 1987 to 2011 is used to develop the machine learning predictive models. The last six years of the dataset from 2012 to 2017 is used to independently test the performance of the machine learning models. The correlation coefficients between the estimated and actual pollen abundance for the independent validation datasets for the deep neural networks, random forest, extreme gradient boosting and Bayesian ridge were 0.82, 0.81, 0.81 and 0.75 respectively, showing that machine learning can be used to effectively forecast the concentrations of airborne pollen.	['William B. Hanson Center for Space Sciences, The University of Texas at Dallas, Richardson, TX 75080, USA. gebreab.zewdie@utdallas.edu.', 'William B. Hanson Center for Space Sciences, The University of Texas at Dallas, Richardson, TX 75080, USA. david.lary@utdallas.edu.', 'Department of Biological Science, The University of Tulsa, Tulsa, OK 74104, USA. estelle-levetin@utulsa.edu.', 'Institute of Earth and Environmental Sciences, University of Quebec at Montreal, Montreal, QC H2L 2C4, Canada. gemechufanta@gmail.com.']	['ijerph16111992 [pii]', '10.3390/ijerph16111992 [doi]']	['Zewdie GK', 'Lary DJ', 'Levetin E', 'Garuma GF']	['ORCID: 0000-0002-0621-1584']						['2019/06/07 06:00']	20191203	20190604	2019 Jun 4	2019/06/07 06:00		['Zewdie, Gebreab K', 'Lary, David J', 'Levetin, Estelle', 'Garuma, Gemechu F']			11		1660-4601 (Electronic) 1660-4601 (Linking)	101238455	International journal of environmental research and public health	['eng']	E1992 [pii] 10.3390/ijerph16111992 [doi]	20191203	['Allergens/analysis', 'Ambrosia', '*Antigens, Plant', 'Bayes Theorem', 'Forecasting/*methods', '*Machine Learning', '*Neural Networks (Computer)', '*Plant Extracts', 'Weather']	2019/12/04 06:00		['*Ambrosia pollen', '*ECMWF', '*deep neural networks', '*extreme gradient boosting', '*machine learning', '*pollen allergy', '*random forest']	['NOTNLM']	NLM		['2019/03/24 00:00 [received]', '2019/05/27 00:00 [revised]', '2019/05/31 00:00 [accepted]', '2019/06/07 06:00 [entrez]', '2019/06/07 06:00 [pubmed]', '2019/12/04 06:00 [medline]']	Switzerland	PMC6603941		31167504	epublish	['Journal Article']		['0 (Allergens)', '0 (Antigens, Plant)', '0 (Plant Extracts)', '0 (ragweed pollen)']	IM		Int J Environ Res Public Health. 2019 Jun 4;16(11). pii: ijerph16111992. doi: 10.3390/ijerph16111992.	MEDLINE	Int J Environ Res Public Health	Applying Deep Neural Networks and Ensemble Machine Learning Methods to Forecast Airborne Ambrosia Pollen.		16	Applying Deep Neural Networks and Ensemble Machine Learning Methods to Forecast Airborne Ambrosia Pollen.
The heart muscle pumps blood to vital organs, which is indispensable for human life. Congestive heart failure (CHF) is characterized by the inability of the heart to pump blood adequately throughout the body without an increase in intracardiac pressure. The symptoms include lung and peripheral congestion, leading to breathing difficulty and swollen limbs, dizziness from reduced delivery of blood to the brain, as well as arrhythmia. Coronary artery disease, myocardial infarction, and medical co-morbidities such as kidney disease, diabetes, and high blood pressure all take a toll on the heart and can impair myocardial function. CHF prevalence is growing worldwide. It afflicts millions of people globally, and is a leading cause of death. Hence, proper diagnosis, monitoring and management are imperative. The importance of an objective CHF diagnostic tool cannot be overemphasized. Standard diagnostic tests for CHF include chest X-ray, magnetic resonance imaging (MRI), nuclear imaging, echocardiography, and invasive angiography. However, these methods are costly, time-consuming, and they can be operator-dependent. Electrocardiography (ECG) is inexpensive and widely accessible, but ECG changes are typically not specific for CHF diagnosis. A properly designed computer-aided detection (CAD) system for CHF, based on the ECG, would potentially reduce subjectivity and provide quantitative assessment for informed decision-making. Herein, we review existing CAD for automatic CHF diagnosis, and highlight the development of an ECG-based CAD diagnostic system that employs deep learning algorithms to automatically detect CHF.	"['Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore. Electronic address: e0145834@u.nus.edu.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Medicine - Cardiology, Columbia University, USA.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'National Heart Centre, Singapore.', ""Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore University of Social Sciences, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, 47500 Subang Jaya, Malaysia. Electronic address: aru@np.edu.sg.""]"	['S1120-1797(19)30111-5 [pii]', '10.1016/j.ejmp.2019.05.004 [doi]']	['Jahmunah V', 'Oh SL', 'Wei JKE', 'Ciaccio EJ', 'Chua K', 'San TR', 'Acharya UR']		['Copyright (c) 2019 Associazione Italiana di Fisica Medica. Published by Elsevier', 'Ltd. All rights reserved.']					['2019/06/03 06:00']	20191111	20190510	2019 Jun	2019/06/04 06:00		['Jahmunah, V', 'Oh, Shu Lih', 'Wei, Joel Koh En', 'Ciaccio, Edward J', 'Chua, Kuang', 'San, Tan Ru', 'Acharya, U Rajendra']					1724-191X (Electronic) 1120-1797 (Linking)	9302888	Physica medica : PM : an international journal devoted to the applications of physics to medicine and biology : official journal of the Italian Association of Biomedical Physics (AIFB)	['eng']	S1120-1797(19)30111-5 [pii] 10.1016/j.ejmp.2019.05.004 [doi]	20191111	['Deep Learning', 'Diagnosis, Computer-Assisted/*methods', '*Electrocardiography', 'Heart Failure/*diagnosis', 'Humans', 'Signal Processing, Computer-Assisted']	2019/11/12 06:00		['Computer-aided detection system', 'Congestive heart failure', 'Deep learning', 'Machine learning', 'Statistical analysis']	['NOTNLM']	NLM	95-104	['2019/03/06 00:00 [received]', '2019/05/02 00:00 [revised]', '2019/05/04 00:00 [accepted]', '2019/06/03 06:00 [entrez]', '2019/06/04 06:00 [pubmed]', '2019/11/12 06:00 [medline]']	Italy			31153403	ppublish	['Journal Article', 'Review']			IM		Phys Med. 2019 Jun;62:95-104. doi: 10.1016/j.ejmp.2019.05.004. Epub 2019 May 10.	MEDLINE	Phys Med	Computer-aided diagnosis of congestive heart failure using ECG signals - A review.		62	Computer-aided diagnosis of congestive heart failure using ECG signals - A review.
	['Department of Dermatology, Ghent University Hospital, Ghent, Belgium.', 'Cancer Research Institute Ghent (CRIG), Ghent University, Ghent, Belgium.', 'Microsoft Corporation, Seattle, WA, USA.']	['10.1111/ijd.14511 [doi]']	['Hulstaert E', 'Hulstaert L']	['ORCID: https://orcid.org/0000-0002-4610-4599']						['2019/06/01 06:00']	20191125	20190531	2019 Aug	2019/06/01 06:00		['Hulstaert, Eva', 'Hulstaert, Lars']			8		1365-4632 (Electronic) 0011-9059 (Linking)	0243704	International journal of dermatology	['eng']	10.1111/ijd.14511 [doi]	20191125	['Data Science/methods', 'Datasets as Topic', 'Deep Learning/*trends', 'Dermatology/methods/trends', 'Early Detection of Cancer/*methods/trends', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Medical Oncology/methods/trends', 'Melanoma/*diagnostic imaging/epidemiology/prevention & control', 'Skin Neoplasms/*diagnostic imaging/epidemiology/prevention & control']	2019/11/26 06:00				NLM	989-990	['2018/10/30 00:00 [received]', '2019/04/12 00:00 [revised]', '2019/04/30 00:00 [accepted]', '2019/06/01 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/06/01 06:00 [entrez]']	England			31149729	ppublish	['Journal Article']			IM		Int J Dermatol. 2019 Aug;58(8):989-990. doi: 10.1111/ijd.14511. Epub 2019 May 31.	MEDLINE	Int J Dermatol	Artificial intelligence in dermato-oncology: a joint clinical and data science perspective.		58	Artificial intelligence in dermato-oncology: a joint clinical and data science perspective.
The need for robust unsupervised anomaly detection in streaming data is increasing rapidly in the current era of smart devices, where enormous data are gathered from numerous sensors. These sensors record the internal state of a machine, the external environment, and the interaction of machines with other machines and humans. It is of prime importance to leverage this information in order to minimize downtime of machines, or even avoid downtime completely by constant monitoring. Since each device generates a different type of streaming data, it is normally the case that a specific kind of anomaly detection technique performs better than the others depending on the data type. For some types of data and use-cases, statistical anomaly detection techniques work better, whereas for others, deep learning-based techniques are preferred. In this paper, we present a novel anomaly detection technique, FuseAD, which takes advantage of both statistical and deep-learning-based approaches by fusing them together in a residual fashion. The obtained results show an increase in area under the curve (AUC) as compared to state-of-the-art anomaly detection methods when FuseAD is tested on a publicly available dataset (Yahoo Webscope benchmark). The obtained results advocate that this fusion-based technique can obtain the best of both worlds by combining their strengths and complementing their weaknesses. We also perform an ablation study to quantify the contribution of the individual components in FuseAD, i.e., the statistical ARIMA model as well as the deep-learning-based convolutional neural network (CNN) model.	['German Research Center for Artificial Intelligence (DFKI) GmbH, 67663 Kaiserslautern, Germany. mohsin.munir@dfki.de.', 'Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663 Kaiserslautern, Germany. mohsin.munir@dfki.de.', 'German Research Center for Artificial Intelligence (DFKI) GmbH, 67663 Kaiserslautern, Germany. shoaib_ahmed.siddiqui@dfki.de.', 'Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663 Kaiserslautern, Germany. shoaib_ahmed.siddiqui@dfki.de.', 'German Research Center for Artificial Intelligence (DFKI) GmbH, 67663 Kaiserslautern, Germany. muhammad_ali.chattha@dfki.de.', 'Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663 Kaiserslautern, Germany. muhammad_ali.chattha@dfki.de.', 'School of Electrical Engineering and Computer Science (SEECS), National University of Sciences and Technology (NUST), 44000 Islamabad, Pakistan. muhammad_ali.chattha@dfki.de.', 'German Research Center for Artificial Intelligence (DFKI) GmbH, 67663 Kaiserslautern, Germany. andreas.dengel@dfki.de.', 'Fachbereich Informatik, Technische Universitat Kaiserslautern, 67663 Kaiserslautern, Germany. andreas.dengel@dfki.de.', 'German Research Center for Artificial Intelligence (DFKI) GmbH, 67663 Kaiserslautern, Germany. sheraz.ahmed@dfki.de.']	['s19112451 [pii]', '10.3390/s19112451 [doi]']	['Munir M', 'Siddiqui SA', 'Chattha MA', 'Dengel A', 'Ahmed S']	['ORCID: 0000-0001-7818-0361', 'ORCID: 0000-0003-4600-7331', 'ORCID: 0000-0002-3336-5677', 'ORCID: 0000-0002-4239-6520']						['2019/06/01 06:00']		20190529	2019 May 29	2019/05/31 06:00		['Munir, Mohsin', 'Siddiqui, Shoaib Ahmed', 'Chattha, Muhammad Ali', 'Dengel, Andreas', 'Ahmed, Sheraz']			11		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2451 [pii] 10.3390/s19112451 [doi]	20191120		2019/05/31 06:01		['anomaly detection', 'deep neural networks', 'model fusion', 'sensor data', 'statistical models', 'time-series analysis']	['NOTNLM']	NLM		['2019/03/11 00:00 [received]', '2019/05/16 00:00 [revised]', '2019/05/17 00:00 [accepted]', '2019/06/01 06:00 [entrez]', '2019/05/31 06:00 [pubmed]', '2019/05/31 06:01 [medline]']	Switzerland	PMC6603659		31146357	epublish	['Journal Article']					Sensors (Basel). 2019 May 29;19(11). pii: s19112451. doi: 10.3390/s19112451.	PubMed-not-MEDLINE	Sensors (Basel)	FuseAD: Unsupervised Anomaly Detection in Streaming Sensors Data by Fusing Statistical and Deep Learning Models.		19	FuseAD: Unsupervised Anomaly Detection in Streaming Sensors Data by Fusing Statistical and Deep Learning Models.
Humans can feel, weigh and grasp diverse objects, and simultaneously infer their material properties while applying the right amount of force-a challenging set of tasks for a modern robot(1). Mechanoreceptor networks that provide sensory feedback and enable the dexterity of the human grasp(2) remain difficult to replicate in robots. Whereas computer-vision-based robot grasping strategies(3-5) have progressed substantially with the abundance of visual data and emerging machine-learning tools, there are as yet no equivalent sensing platforms and large-scale datasets with which to probe the use of the tactile information that humans rely on when grasping objects. Studying the mechanics of how humans grasp objects will complement vision-based robotic object handling. Importantly, the inability to record and analyse tactile signals currently limits our understanding of the role of tactile information in the human grasp itself-for example, how tactile maps are used to identify objects and infer their properties is unknown(6). Here we use a scalable tactile glove and deep convolutional neural networks to show that sensors uniformly distributed over the hand can be used to identify individual objects, estimate their weight and explore the typical tactile patterns that emerge while grasping objects. The sensor array (548 sensors) is assembled on a knitted glove, and consists of a piezoresistive film connected by a network of conductive thread electrodes that are passively probed. Using a low-cost (about US$10) scalable tactile glove sensor array, we record a large-scale tactile dataset with 135,000 frames, each covering the full hand, while interacting with 26 different objects. This set of interactions with different objects reveals the key correspondences between different regions of a human hand while it is manipulating objects. Insights from the tactile signatures of the human grasp-through the lens of an artificial analogue of the natural mechanoreceptor network-can thus aid the future design of prosthetics(7), robot grasping tools and human-robot interactions(1,8-10).	['Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA. subras@csail.mit.edu.', 'Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology, Cambridge, MA, USA. subras@csail.mit.edu.', 'Biological Design Center, Boston University, Boston, MA, USA. subras@csail.mit.edu.', 'Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA, USA. subras@csail.mit.edu.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Electrical Engineering and Computer Science Department, Massachusetts Institute of Technology, Cambridge, MA, USA.']	['10.1038/s41586-019-1234-z [doi]', '10.1038/s41586-019-1234-z [pii]']	['Sundaram S', 'Kellnhofer P', 'Li Y', 'Zhu JY', 'Torralba A', 'Matusik W']			['Nature. 2019 May;569(7758):638-639. PMID: 31142866']				['2019/05/31 06:00']		20190529	2019 May	2019/05/31 06:00		['Sundaram, Subramanian', 'Kellnhofer, Petr', 'Li, Yunzhu', 'Zhu, Jun-Yan', 'Torralba, Antonio', 'Matusik, Wojciech']			7758		1476-4687 (Electronic) 0028-0836 (Linking)	0410462	Nature	['eng']	10.1038/s41586-019-1234-z [doi]	20191203		2019/05/31 06:00				NLM	698-702	['2018/11/05 00:00 [received]', '2019/04/09 00:00 [accepted]', '2019/05/31 06:00 [entrez]', '2019/05/31 06:00 [pubmed]', '2019/05/31 06:00 [medline]']	England			31142856	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nature. 2019 May;569(7758):698-702. doi: 10.1038/s41586-019-1234-z. Epub 2019 May 29.	In-Process	Nature	Learning the signatures of the human grasp using a scalable tactile glove.		569	Learning the signatures of the human grasp using a scalable tactile glove.
Recently, pervasive sensing technologies have been widely applied to comprehensive patient monitoring in order to improve clinical treatment. Various types of biomedical signals collected by different sensing channels provide different aspects of patient health information. However, due to the uncertainty and variability in clinical observation, not all the channels are relevant and important to the target task. Thus, in order to extract informative representations from multi-channel biosignals, channel awareness has become a key enabler for deep learning in biosignal processing and has attracted increasing research interest in health informatics. Towards this end, we propose FusionAtt-a deep fusional attention network that can learn channel-aware representations of multi-channel biosignals, while preserving complex correlations among all the channels. FusionAtt is able to dynamically quantify the importance of each biomedical channel, and relies on more informative ones to enhance feature representation in an end-to-end manner. We empirically evaluated FusionAtt in two clinical tasks: multi-channel seizure detection and multivariate sleep stage classification. Experimental results showed that FusionAtt consistently outperformed the state-of-the-art models in four different evaluation measurements, demonstrating the effectiveness of the proposed fusional attention mechanism.	['College of Information and Communication Engineering, Beijing University of Technology, Beijing 100124, China. yuanye91@emails.bjut.edu.cn.', 'Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing University of Technology, Beijing 100124, China. yuanye91@emails.bjut.edu.cn.', 'College of Information and Communication Engineering, Beijing University of Technology, Beijing 100124, China. kebinj@bjut.edu.cn.', 'Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing University of Technology, Beijing 100124, China. kebinj@bjut.edu.cn.']	['s19112429 [pii]', '10.3390/s19112429 [doi]']	['Yuan Y', 'Jia K']							['2019/05/31 06:00']	20191122	20190528	2019 May 28	2019/05/31 06:00		['Yuan, Ye', 'Jia, Kebin']		['81871394, 61672064/National Science Foundation of China', '040000546618017/Beijing Laboratory of Advanced Information Networks']	11		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2429 [pii] 10.3390/s19112429 [doi]	20191122	['*Algorithms', '*Attention', '*Biomedical Technology', 'Databases as Topic', 'Electroencephalography', 'Humans', '*Neural Networks (Computer)', 'ROC Curve', '*Signal Processing, Computer-Assisted', 'Support Vector Machine']	2019/11/23 06:00		['attention mechanism', 'biomedical signals', 'deep learning', 'feature representation']	['NOTNLM']	NLM		['2019/04/10 00:00 [received]', '2019/05/24 00:00 [revised]', '2019/05/25 00:00 [accepted]', '2019/05/31 06:00 [entrez]', '2019/05/31 06:00 [pubmed]', '2019/11/23 06:00 [medline]']	Switzerland	PMC6603640		31141898	epublish	['Journal Article']			IM		Sensors (Basel). 2019 May 28;19(11). pii: s19112429. doi: 10.3390/s19112429.	MEDLINE	Sensors (Basel)	FusionAtt: Deep Fusional Attention Networks for Multi-Channel Biomedical Signals.		19	FusionAtt: Deep Fusional Attention Networks for Multi-Channel Biomedical Signals.
BACKGROUND: Finding biomedical named entities is one of the most essential tasks in biomedical text mining. Recently, deep learning-based approaches have been applied to biomedical named entity recognition (BioNER) and showed promising results. However, as deep learning approaches need an abundant amount of training data, a lack of data can hinder performance. BioNER datasets are scarce resources and each dataset covers only a small subset of entity types. Furthermore, many bio entities are polysemous, which is one of the major obstacles in named entity recognition. RESULTS: To address the lack of data and the entity type misclassification problem, we propose CollaboNet which utilizes a combination of multiple NER models. In CollaboNet, models trained on a different dataset are connected to each other so that a target model obtains information from other collaborator models to reduce false positives. Every model is an expert on their target entity type and takes turns serving as a target and a collaborator model during training time. The experimental results show that CollaboNet can be used to greatly reduce the number of false positives and misclassified entities including polysemous words. CollaboNet achieved state-of-the-art performance in terms of precision, recall and F1 score. CONCLUSIONS: We demonstrated the benefits of combining multiple models for BioNER. Our model has successfully reduced the number of misclassified entities and improved the performance by leveraging multiple datasets annotated for different entity types. Given the state-of-the-art performance of our model, we believe that CollaboNet can improve the accuracy of downstream biomedical text mining applications such as bio-entity relation extraction.	['Department of Computer Science and Engineering, Korea University, Seoul, 02841, Republic of Korea.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, 02841, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, 02841, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, 02841, Republic of Korea. kangj@korea.ac.kr.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, 02841, Republic of Korea. kangj@korea.ac.kr.']	['10.1186/s12859-019-2813-6 [doi]', '10.1186/s12859-019-2813-6 [pii]']	['Yoon W', 'So CH', 'Lee J', 'Kang J']							['2019/05/30 06:00']	20190719	20190529	2019 May 29	2019/05/30 06:00		['Yoon, Wonjin', 'So, Chan Ho', 'Lee, Jinhyuk', 'Kang, Jaewoo']			Suppl 10		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2813-6 [doi]	20190719	['Animals', 'Data Mining', '*Deep Learning', 'Humans', 'Mice', 'Models, Theoretical', '*Neural Networks (Computer)']	2019/07/20 06:00		['Deep learning', 'NER', 'Named entity recognition', 'Text mining']	['NOTNLM']	NLM	249	['2019/05/30 06:00 [entrez]', '2019/05/30 06:00 [pubmed]', '2019/07/20 06:00 [medline]']	England	PMC6538547		31138109	epublish	['Journal Article']			IM		BMC Bioinformatics. 2019 May 29;20(Suppl 10):249. doi: 10.1186/s12859-019-2813-6.	MEDLINE	BMC Bioinformatics	CollaboNet: collaboration of deep neural networks for biomedical named entity recognition.		20	CollaboNet: collaboration of deep neural networks for biomedical named entity recognition.
We address the challenge of detecting the contribution of noncoding mutations to disease with a deep-learning-based framework that predicts the specific regulatory effects and the deleterious impact of genetic variants. Applying this framework to 1,790 autism spectrum disorder (ASD) simplex families reveals a role in disease for noncoding mutations-ASD probands harbor both transcriptional- and post-transcriptional-regulation-disrupting de novo mutations of significantly higher functional impact than those in unaffected siblings. Further analysis suggests involvement of noncoding mutations in synaptic transmission and neuronal development and, taken together with previous studies, reveals a convergent genetic landscape of coding and noncoding mutations in ASD. We demonstrate that sequences carrying prioritized mutations identified in probands possess allele-specific regulatory activity, and we highlight a link between noncoding mutations and heterogeneity in the IQ of ASD probands. Our predictive genomics framework illuminates the role of noncoding mutations in ASD and prioritizes mutations with high impact for further study, and is broadly applicable to complex human diseases.	['Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, NJ, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Laboratory of Molecular Neuro-Oncology and Howard Hughes Medical Institute, The Rockefeller University, New York, NY, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Laboratory of Molecular Neuro-Oncology and Howard Hughes Medical Institute, The Rockefeller University, New York, NY, USA.', 'Gene Therapy Program, Department of Medicine, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.', 'Laboratory of Molecular Neuro-Oncology and Howard Hughes Medical Institute, The Rockefeller University, New York, NY, USA.', 'Institute of Neuropathology, University of Zurich, Zurich, Switzerland.', 'Laboratory of Molecular Neuro-Oncology and Howard Hughes Medical Institute, The Rockefeller University, New York, NY, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Laboratory of Molecular Neuro-Oncology and Howard Hughes Medical Institute, The Rockefeller University, New York, NY, USA.', 'Simons Foundation, New York, NY, USA.', 'Laboratory of Molecular Neuro-Oncology and Howard Hughes Medical Institute, The Rockefeller University, New York, NY, USA. darnelr@rockefeller.edu.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA. ogt@cs.princeton.edu.', 'Flatiron Institute, Simons Foundation, New York, NY, USA. ogt@cs.princeton.edu.', 'Department of Computer Science, Princeton University, Princeton, NJ, USA. ogt@cs.princeton.edu.']	['10.1038/s41588-019-0420-0 [doi]', '10.1038/s41588-019-0420-0 [pii]']	['Zhou J', 'Park CY', 'Theesfeld CL', 'Wong AK', 'Yuan Y', 'Scheckel C', 'Fak JJ', 'Funk J', 'Yao K', 'Tajima Y', 'Packer A', 'Darnell RB', 'Troyanskaya OG']	['ORCID: http://orcid.org/0000-0002-3171-8192', 'ORCID: http://orcid.org/0000-0002-5134-8088', 'ORCID: http://orcid.org/0000-0002-5676-5737']						['2019/05/29 06:00']	20190709	20190527	2019 Jun	2019/05/28 06:00		['Zhou, Jian', 'Park, Christopher Y', 'Theesfeld, Chandra L', 'Wong, Aaron K', 'Yuan, Yuan', 'Scheckel, Claudia', 'Fak, John J', 'Funk, Julien', 'Yao, Kevin', 'Tajima, Yoko', 'Packer, Alan', 'Darnell, Robert B', 'Troyanskaya, Olga G']		['R01 NS081706/NS/NINDS NIH HHS/United States', 'UM1 HG008901/HG/NHGRI NIH HHS/United States', 'R01 NS034389/NS/NINDS NIH HHS/United States', 'R35 NS097404/NS/NINDS NIH HHS/United States', 'R56 NS034389/NS/NINDS NIH HHS/United States']	6		1546-1718 (Electronic) 1061-4036 (Linking)	9216904	Nature genetics	['eng']	10.1038/s41588-019-0420-0 [doi]	20191202	['Algorithms', 'Alleles', 'Autism Spectrum Disorder/diagnosis/*genetics', 'Computational Biology/methods', '*Deep Learning', 'Gene Expression', 'Gene Expression Regulation', 'Genes, Reporter', 'Genetic Association Studies', '*Genetic Predisposition to Disease', '*Genome, Human', '*Genomics/methods', 'Humans', '*Mutation', 'Phenotype', 'RNA Processing, Post-Transcriptional', '*RNA, Untranslated', 'Transcription, Genetic']	2019/07/10 06:00	['NIHMS1050804']			NLM	973-980	['2018/08/03 00:00 [received]', '2019/04/12 00:00 [accepted]', '2019/05/28 06:00 [pubmed]', '2019/07/10 06:00 [medline]', '2019/05/29 06:00 [entrez]']	United States	PMC6758908		31133750	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA, Untranslated)']	IM		Nat Genet. 2019 Jun;51(6):973-980. doi: 10.1038/s41588-019-0420-0. Epub 2019 May 27.	MEDLINE	Nat Genet	Whole-genome deep-learning analysis identifies contribution of noncoding mutations to autism risk.		51	Whole-genome deep-learning analysis identifies contribution of noncoding mutations to autism risk.
Melanoma is the most aggressive type of skin cancer, which significantly reduces the life expectancy. Early detection of melanoma can reduce the morbidity and mortality associated with skin cancer. Dermoscopic images acquired by dermoscopic instruments are used in computational analysis for skin cancer detection. However, some image quality limitations such as noises, shadows, artefacts exist that could compromise the robustness of the skin image analysis. Hence, developing an automatic intelligent system for skin cancer diagnosis with accurate detection rate is crucial. In this paper, we evaluate the performance of several state-of-the-art convolutional neural networks in dermoscopic images of skin lesions. Our experiment is conducted on a graphics processing unit (GPU) to speed up the training and deployment process. To enhance the quality of images, we employ different pre-processing steps. We also apply data augmentation methodology such as horizontal and vertical flipping techniques to address the class skewness problem. Both pre-processing and data augmentation could help to improve the final accuracy.	['Department of Computer Science, University of Saskatchewan, Saskatchewan, Canada. Electronic address: sara.kassani@usask.ca.', 'Department of Biomedical Engineering, Tulane University, New Orleans, Louisiana, USA.']	['S0040-8166(19)30090-4 [pii]', '10.1016/j.tice.2019.04.009 [doi]']	['Hosseinzadeh Kassani S', 'Hosseinzadeh Kassani P']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/05/29 06:00']	20191121	20190422	2019 Jun	2019/05/28 06:00		['Hosseinzadeh Kassani, Sara', 'Hosseinzadeh Kassani, Peyman']					1532-3072 (Electronic) 0040-8166 (Linking)	0214745	Tissue & cell	['eng']	S0040-8166(19)30090-4 [pii] 10.1016/j.tice.2019.04.009 [doi]	20191121	['*Deep Learning', '*Dermoscopy', 'Humans', '*Image Processing, Computer-Assisted', 'Melanoma/*diagnostic imaging', 'Skin/*diagnostic imaging', 'Skin Neoplasms/*diagnostic imaging']	2019/11/22 06:00		['Cancer classification', 'Computational diagnosis', 'Convolutional neural networks', 'Deep learning', 'Melanoma detection']	['NOTNLM']	NLM	76-83	['2019/03/03 00:00 [received]', '2019/04/19 00:00 [accepted]', '2019/05/29 06:00 [entrez]', '2019/05/28 06:00 [pubmed]', '2019/11/22 06:00 [medline]']	Scotland			31133249	ppublish	['Journal Article']			IM		Tissue Cell. 2019 Jun;58:76-83. doi: 10.1016/j.tice.2019.04.009. Epub 2019 Apr 22.	MEDLINE	Tissue Cell	A comparative study of deep learning architectures on melanoma detection.		58	A comparative study of deep learning architectures on melanoma detection.
Conventional neural networks have been demonstrated to be a powerful framework for background subtraction in video acquired by static cameras. Indeed, the well-known Self-Organizing Background Subtraction (SOBS) method and its variants based on neural networks have long been the leading methods on the large-scale CDnet 2012 dataset during a long time. Convolutional neural networks, which are used in deep learning, have been recently and excessively employed for background initialization, foreground detection, and deep learned features. The top background subtraction methods currently used in CDnet 2014 are based on deep neural networks, and have demonstrated a large performance improvement in comparison to conventional unsupervised approaches based on multi-feature or multi-cue strategies. Furthermore, since the seminal work of Braham and Van Droogenbroeck in 2016, a large number of studies on convolutional neural networks applied to background subtraction have been published, and a continual gain of performance has been achieved. In this context, we provide the first review of deep neural network concepts in background subtraction for novices and experts in order to analyze this success and to provide further directions. To do so, we first surveyed the background initialization and background subtraction methods based on deep neural networks concepts, and also deep learned features. We then discuss the adequacy of deep neural networks for the task of background subtraction. Finally, experimental results are presented for the CDnet 2014 dataset.	['Lab. MIA, University La Rochelle, France. Electronic address: tbouwman@univ-lr.fr.', 'Department of Computer Science, University of Warwick, UK.', 'Department of Computer Science and Engineering, Kyungpook National University, Republic of Korea.', 'Department of Computer Science and Engineering, Kyungpook National University, Republic of Korea.']	['S0893-6080(19)30130-3 [pii]', '10.1016/j.neunet.2019.04.024 [doi]']	['Bouwmans T', 'Javed S', 'Sultana M', 'Jung SK']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/05/27 06:00']	20191108	20190515	2019 Sep	2019/05/28 06:00		['Bouwmans, Thierry', 'Javed, Sajid', 'Sultana, Maryam', 'Jung, Soon Ki']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30130-3 [pii] 10.1016/j.neunet.2019.04.024 [doi]	20191108	['Deep Learning/*standards']	2019/11/09 06:00		['Auto-encoders networks', 'Background subtraction', 'Convolutional neural networks', 'Generative adversarial networks', 'Restricted Boltzmann machines']	['NOTNLM']	NLM	8-66	['2018/11/12 00:00 [received]', '2019/02/27 00:00 [revised]', '2019/04/30 00:00 [accepted]', '2019/05/28 06:00 [pubmed]', '2019/11/09 06:00 [medline]', '2019/05/27 06:00 [entrez]']	United States			31129491	ppublish	['Comparative Study', 'Journal Article', 'Systematic Review']			IM		Neural Netw. 2019 Sep;117:8-66. doi: 10.1016/j.neunet.2019.04.024. Epub 2019 May 15.	MEDLINE	Neural Netw	Deep neural network concepts for background subtraction:A systematic review and comparative evaluation.		117	Deep neural network concepts for background subtraction:A systematic review and comparative evaluation.
Objective: The main objective of this study is to improve the classification performance of melanoma using deep learning based automatic skin lesion segmentation. It can be assist medical experts on early diagnosis of melanoma on dermoscopy images. Methods: First A Convolutional Neural Network (CNN) based U-net algorithm is used for segmentation process. Then extract color, texture and shape features from the segmented image using Local Binary Pattern ( LBP), Edge Histogram (EH), Histogram of Oriented Gradients (HOG) and Gabor method. Finally all the features extracted from these methods were fed into the Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbor (KNN) and Naive Bayes (NB) classifiers to diagnose the skin image which is either melanoma or benign lesions. Results: Experimental results show the effectiveness of the proposed method. The Dice co-efficiency value of 77.5% is achieved for image segmentation and SVM classifier produced 85.19% of accuracy. Conclusion: In deep learning environment, U-Net segmentation algorithm is found to be the best method for segmentation and it helps to improve the classification performance.	['Research Scholar, Department of Computer Science, Periyar University, Tamil Nadu, India. Email: sheejarufus.r.d@gmail.com', 'Principal, Siri PSG Arts and Science College for Women, Sankagiri, 637301, Salem, Tamil Nadu, India.']	['10.31557/APJCP.2019.20.5.1555 [doi]']	['R D S', 'A S']		['Creative Commons Attribution License']					['2019/05/26 06:00']	20191122	20190525	2019 May 25	2019/05/28 06:00		['R D, Seeja', 'A, Suresh']			5		2476-762X (Electronic) 1513-7368 (Linking)	101130625	Asian Pacific journal of cancer prevention : APJCP	['eng']		20191122	['Algorithms', 'Bayes Theorem', 'Cluster Analysis', 'Deep Learning', 'Dermoscopy/methods', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Melanoma/*pathology', 'Skin/*pathology', 'Skin Diseases/*pathology', 'Skin Neoplasms/*pathology', 'Support Vector Machine']	2019/11/23 06:00		['*Melanoma', '*deep learning', '*dermoscopy', '*segmentation', '*classification']	['NOTNLM']	NLM	1555-1561	['2019/05/26 06:00 [entrez]', '2019/05/28 06:00 [pubmed]', '2019/11/23 06:00 [medline]']	Thailand			31128062	epublish	['Journal Article']			IM		Asian Pac J Cancer Prev. 2019 May 25;20(5):1555-1561. doi: 10.31557/APJCP.2019.20.5.1555.	MEDLINE	Asian Pac J Cancer Prev	Deep Learning Based Skin Lesion Segmentation and Classification of Melanoma Using Support Vector Machine (SVM)		20	Deep Learning Based Skin Lesion Segmentation and Classification of Melanoma Using Support Vector Machine (SVM)
"A long standing open problem in the theory of neural networks is the development of quantitative methods to estimate and compare the capabilities of different architectures. Here we define the capacity of an architecture by the binary logarithm of the number of functions it can compute, as the synaptic weights are varied. The capacity provides an upperbound on the number of bits that can be extracted from the training data and stored in the architecture during learning. We study the capacity of layered, fully-connected, architectures of linear threshold neurons with L layers of size n1,n2,...,nL and show that in essence the capacity is given by a cubic polynomial in the layer sizes: C(n1,...,nL)= summation operatork=1(L-1)min(n1,...,nk)nknk+1, where layers that are smaller than all previous layers act as bottlenecks. In proving the main result, we also develop new techniques (multiplexing, enrichment, and stacking) as well as new bounds on the capacity of finite sets. We use the main result to identify architectures with maximal or minimal capacity under a number of natural constraints. This leads to the notion of structural regularization for deep architectures. While in general, everything else being equal, shallow networks compute more functions than deep networks, the functions computed by deep networks are more regular and ""interesting""."	['Department of Computer Science, University of California, Irvine, United States. Electronic address: pfbaldi@uci.edu.', 'Department of Mathematics, University of California, Irvine, United States. Electronic address: rvershyn@uci.edu.']	['S0893-6080(19)30107-8 [pii]', '10.1016/j.neunet.2019.04.009 [doi]']	['Baldi P', 'Vershynin R']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/05/25 06:00']	20190820	20190422	2019 Aug	2019/05/28 06:00		['Baldi, Pierre', 'Vershynin, Roman']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30107-8 [pii] 10.1016/j.neunet.2019.04.009 [doi]	20190820	['Algorithms', '*Deep Learning/trends', '*Neural Networks (Computer)', 'Neurons/physiology']	2019/08/21 06:00		['Capacity', 'Complexity', 'Deep learning', 'Neural networks']	['NOTNLM']	NLM	288-311	['2018/12/30 00:00 [received]', '2019/03/26 00:00 [revised]', '2019/04/03 00:00 [accepted]', '2019/05/28 06:00 [pubmed]', '2019/08/21 06:00 [medline]', '2019/05/25 06:00 [entrez]']	United States			31125915	ppublish	['Journal Article']					Neural Netw. 2019 Aug;116:288-311. doi: 10.1016/j.neunet.2019.04.009. Epub 2019 Apr 22.	MEDLINE	Neural Netw	The capacity of feedforward neural networks.		116	The capacity of feedforward neural networks.
The arterioles and venules (AV) classification of retinal vasculature is considered as the first step in the development of an automated system for analysing the vasculature biomarker association with disease prognosis. Most of the existing AV classification methods depend on the accurate segmentation of retinal blood vessels. Moreover, the unavailability of large-scale annotated data is a major hindrance in the application of deep learning techniques for AV classification. This paper presents an encoder-decoder based fully convolutional neural network for classification of retinal vasculature into arterioles and venules, without requiring the preliminary step of vessel segmentation. An optimized multiloss function is used to learn the pixel-wise and segment-wise retinal vessel labels. The proposed method is trained and evaluated on DRIVE, AVRDB, and a newly created AV classification dataset; and it attains 96%, 98%, and 97% accuracy, respectively. The new AV classification dataset is comprised of 700 annotated retinal images, which will offer the researchers a benchmark to compare their AV classification results.	['School of Electrical Engineering and Computer Science, National University of Science and Technology, Sector H-12, Islamabad, Pakistan.', 'School of Electrical Engineering and Computer Science, National University of Science and Technology, Sector H-12, Islamabad, Pakistan.', 'The Alan Turing Institute, British Library, 96 Euston Road, London NW1 2DB, UK.']	['10.1155/2019/4747230 [doi]']	['Badawi SA', 'Fraz MM']	['ORCID: 0000-0002-0859-3299']						['2019/05/22 06:00']	20191112	20190414	2019	2019/05/22 06:00		['Badawi, Sufian A', 'Fraz, Muhammad Moazam']					2314-6141 (Electronic)	101600173	BioMed research international	['eng']	10.1155/2019/4747230 [doi]	20191112	['Algorithms', '*Arterioles/diagnostic imaging', 'Biomarkers', 'Deep Learning', 'Humans', '*Neural Networks (Computer)', 'Retinal Vessels/*diagnostic imaging', '*Venules/diagnostic imaging']	2019/11/13 06:00				NLM	4747230	['2018/10/31 00:00 [received]', '2019/02/20 00:00 [revised]', '2019/03/20 00:00 [accepted]', '2019/05/22 06:00 [entrez]', '2019/05/22 06:00 [pubmed]', '2019/11/13 06:00 [medline]']	United States	PMC6487175		31111055	epublish	['Journal Article']		['0 (Biomarkers)']	IM		Biomed Res Int. 2019 Apr 14;2019:4747230. doi: 10.1155/2019/4747230. eCollection 2019.	MEDLINE	Biomed Res Int	Multiloss Function Based Deep Convolutional Neural Network for Segmentation of Retinal Vasculature into Arterioles and Venules.		2019	Multiloss Function Based Deep Convolutional Neural Network for Segmentation of Retinal Vasculature into Arterioles and Venules.
BACKGROUND: Skin cancer (SC), especially melanoma, is a growing public health burden. Experimental studies have indicated a potential diagnostic role for deep learning (DL) algorithms in identifying SC at varying sensitivities. Previously, it was demonstrated that diagnostics by dermoscopy are improved by applying an additional sonification (data to sound waves conversion) layer on DL algorithms. The aim of the study was to determine the impact of image quality on accuracy of diagnosis by sonification employing a rudimentary skin magnifier with polarized light (SMP). METHODS: Dermoscopy images acquired by SMP were processed by a first deep learning algorithm and sonified. Audio output was further analyzed by a different secondary DL. Study criteria outcomes of SMP were specificity and sensitivity, which were further processed by a F2-score, i.e. applying a twice extra weight to sensitivity over positive predictive values. FINDINGS: Patients (n=73) fulfilling inclusion criteria were referred to biopsy. SMP analysis metrics resulted in a receiver operator characteristic curve AUC's of 0.814 (95% CI, 0.798-0.831). SMP achieved a F2-score sensitivity of 91.7%, specificity of 41.8% and positive predictive value of 57.3%. Diagnosing the same set of patients' lesions by an advanced dermoscope resulted in a F2-score sensitivity of 89.5%, specificity of 57.8% and a positive predictive value of 59.9% (P=NS). INTERPRETATION: DL processing of dermoscopic images followed by sonification results in an accurate diagnostic output for SMP, implying that the quality of the dermoscope is not the major factor influencing DL diagnosis of skin cancer. Present system might assist all healthcare providers as a feasible computer-assisted detection system. FUND: Bostel Technologies. Trial Registration clinicaltrials.gov Identifier: NCT03362138.	['Department of Physiology and Pharmacology, Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel. Electronic address: dasc@tauex.tau.ac.il.', 'Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel.']	['S2352-3964(19)30294-4 [pii]', '10.1016/j.ebiom.2019.04.055 [doi]']	['Dascalu A', 'David EO']		['Copyright (c) 2019 The Authors. Published by Elsevier B.V. All rights reserved.']					['2019/05/19 06:00']	20191125	20190514	2019 May	2019/05/19 06:00		['Dascalu, A', 'David, E O']					2352-3964 (Electronic) 2352-3964 (Linking)	101647039	EBioMedicine	['eng']	S2352-3964(19)30294-4 [pii] 10.1016/j.ebiom.2019.04.055 [doi]	20191125	['Adolescent', 'Adult', 'Aged', 'Aged, 80 and over', '*Algorithms', '*Deep Learning', '*Dermoscopy/methods', 'Female', 'Humans', 'Image Processing, Computer-Assisted', 'Male', '*Medical Informatics/methods', 'Middle Aged', 'ROC Curve', 'Sensitivity and Specificity', 'Skin Neoplasms/*diagnosis', 'Young Adult']	2019/11/26 06:00		['Artificial intelligence', 'Deep learning', 'Dermoscopy', 'Melanoma', 'Skin cancer', 'Sonification', 'Telemedicine']	['NOTNLM']	NLM	107-113	['2019/03/18 00:00 [received]', '2019/04/16 00:00 [revised]', '2019/04/29 00:00 [accepted]', '2019/05/19 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/05/19 06:00 [entrez]']	Netherlands	PMC6562065		31101596	ppublish	['Journal Article']			IM	['ClinicalTrials.gov/NCT03362138']	EBioMedicine. 2019 May;43:107-113. doi: 10.1016/j.ebiom.2019.04.055. Epub 2019 May 14.	MEDLINE	EBioMedicine	Skin cancer detection by deep learning and sound analysis algorithms: A prospective clinical study of an elementary dermoscope.		43	Skin cancer detection by deep learning and sound analysis algorithms: A prospective clinical study of an elementary dermoscope.
BACKGROUND: It is clinically important to develop innovative techniques that can accurately measure blood pressures (BP) automatically. OBJECTIVES: This study aimed to present and evaluate a novel automatic BP measurement method based on deep learning method, and to confirm the effects on measured BPs of the position and contact pressure of stethoscope. METHODS: 30 healthy subjects were recruited. 9 BP measurements (from three different stethoscope contact pressures and three repeats) were performed on each subject. The convolutional neural network (CNN) was designed and trained to identify the Korotkoff sounds at a beat-by-beat level. Next, a mapping algorithm was developed to relate the identified Korotkoff beats to the corresponding cuff pressures for systolic and diastolic BP (SBP and DBP) determinations. Its performance was evaluated by investigating the effects of the position and contact pressure of stethoscope on measured BPs in comparison with reference manual auscultatory method. RESULTS: The overall measurement errors of the proposed method were 1.4 +/- 2.4 mmHg for SBP and 3.3 +/- 2.9 mmHg for DBP from all the measurements. In addition, the method demonstrated that there were small SBP differences between the 2 stethoscope positions, respectively at the 3 stethoscope contact pressures, and that DBP from the stethoscope under the cuff was significantly lower than that from outside the cuff by 2.0 mmHg (P < 0.01). CONCLUSION: Our findings suggested that the deep learning based method was an effective technique to measure BP, and could be developed further to replace the current oscillometric based automatic blood pressure measurement method.	['College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China.', 'College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China. Electronic address: hpysbsy@163.com.', 'Southern University of Science and Technology, Shenzhen 518055, China.', 'College of Electrical Engineering and Information Technology, Sichuan University, Chengdu 610064, China.', 'School of Computing, University of Leeds, Leeds, LS2 9JT, UK.', 'Faculty of Health, Education, Medicine and Social Care, Anglia Ruskin University, Chelmsford, CM1 1SQ, UK.']	['S1386-5056(19)30092-9 [pii]', '10.1016/j.ijmedinf.2019.04.023 [doi]']	['Pan F', 'He P', 'Chen F', 'Zhang J', 'Wang H', 'Zheng D']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/05/19 06:00']	20191108	20190429	2019 Aug	2019/05/19 06:00		['Pan, Fan', 'He, Peiyu', 'Chen, Fei', 'Zhang, Jing', 'Wang, He', 'Zheng, Dingchang']					1872-8243 (Electronic) 1386-5056 (Linking)	9711057	International journal of medical informatics	['eng']	S1386-5056(19)30092-9 [pii] 10.1016/j.ijmedinf.2019.04.023 [doi]	20191108	['Adult', '*Algorithms', 'Automation', '*Blood Pressure', 'Blood Pressure Determination/*methods', '*Deep Learning', 'Female', 'Humans', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'Stethoscopes/*statistics & numerical data', 'Young Adult']	2019/11/09 06:00		['*Blood pressure measurement', '*Convolutional neural network', '*Manual auscultatory method', '*Stethoscope contact pressure', '*Stethoscope position']	['NOTNLM']	NLM	71-78	['2019/01/28 00:00 [received]', '2019/04/03 00:00 [revised]', '2019/04/27 00:00 [accepted]', '2019/05/19 06:00 [pubmed]', '2019/11/09 06:00 [medline]', '2019/05/19 06:00 [entrez]']	Ireland			31101485	ppublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Int J Med Inform. 2019 Aug;128:71-78. doi: 10.1016/j.ijmedinf.2019.04.023. Epub 2019 Apr 29.	MEDLINE	Int J Med Inform	A novel deep learning based automatic auscultatory method to measure blood pressure.		128	A novel deep learning based automatic auscultatory method to measure blood pressure.
"OBJECTIVES: To develop a proof-of-concept ""interpretable"" deep learning prototype that justifies aspects of its predictions from a pre-trained hepatic lesion classifier. METHODS: A convolutional neural network (CNN) was engineered and trained to classify six hepatic tumor entities using 494 lesions on multi-phasic MRI, described in Part 1. A subset of each lesion class was labeled with up to four key imaging features per lesion. A post hoc algorithm inferred the presence of these features in a test set of 60 lesions by analyzing activation patterns of the pre-trained CNN model. Feature maps were generated that highlight regions in the original image that correspond to particular features. Additionally, relevance scores were assigned to each identified feature, denoting the relative contribution of a feature to the predicted lesion classification. RESULTS: The interpretable deep learning system achieved 76.5% positive predictive value and 82.9% sensitivity in identifying the correct radiological features present in each test lesion. The model misclassified 12% of lesions. Incorrect features were found more often in misclassified lesions than correctly identified lesions (60.4% vs. 85.6%). Feature maps were consistent with original image voxels contributing to each imaging feature. Feature relevance scores tended to reflect the most prominent imaging criteria for each class. CONCLUSIONS: This interpretable deep learning system demonstrates proof of principle for illuminating portions of a pre-trained deep neural network's decision-making, by analyzing inner layers and automatically describing features contributing to predictions. KEY POINTS: * An interpretable deep learning system prototype can explain aspects of its decision-making by identifying relevant imaging features and showing where these features are found on an image, facilitating clinical translation. * By providing feedback on the importance of various radiological features in performing differential diagnosis, interpretable deep learning systems have the potential to interface with standardized reporting systems such as LI-RADS, validating ancillary features and improving clinical practicality. * An interpretable deep learning system could potentially add quantitative data to radiologic reports and serve radiologists with evidence-based decision support."	['Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Institute of Radiology, Charite - Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin, Humboldt-Universitat, and Berlin Institute of Health, 10117, Berlin, Germany.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Institute of Radiology, Charite - Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin, Humboldt-Universitat, and Berlin Institute of Health, 10117, Berlin, Germany.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Institute of Radiology, Charite - Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin, Humboldt-Universitat, and Berlin Institute of Health, 10117, Berlin, Germany.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Biomedical Engineering, Yale School of Engineering and Applied Science, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA. j.chapiro@googlemail.com.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.']	['10.1007/s00330-019-06214-8 [doi]', '10.1007/s00330-019-06214-8 [pii]']	['Wang CJ', 'Hamm CA', 'Savic LJ', 'Ferrante M', 'Schobert I', 'Schlachter T', 'Lin M', 'Weinreb JC', 'Duncan JS', 'Chapiro J', 'Letzen B']							['2019/05/17 06:00']	20190826	20190515	2019 Jul	2019/05/17 06:00		['Wang, Clinton J', 'Hamm, Charlie A', 'Savic, Lynn J', 'Ferrante, Marc', 'Schobert, Isabel', 'Schlachter, Todd', 'Lin, MingDe', 'Weinreb, Jeffrey C', 'Duncan, James S', 'Chapiro, Julius', 'Letzen, Brian']		['R01 CA206180/CA/NCI NIH HHS/United States', 'NIH/NCI R01 CA206180/National Cancer Institute', 'RR1731/RSNA Research and Education Foundation']	7		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-019-06214-8 [doi]	20190826	['Adult', 'Aged', 'Algorithms', 'Bile Duct Neoplasms/diagnostic imaging', 'Bile Ducts, Intrahepatic', 'Carcinoma, Hepatocellular/*diagnostic imaging', 'Cholangiocarcinoma/diagnostic imaging', '*Deep Learning', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Liver Neoplasms/*diagnostic imaging', 'Machine Learning', 'Magnetic Resonance Imaging/methods', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'Predictive Value of Tests', 'Proof of Concept Study', 'Retrospective Studies']	2019/08/27 06:00		['Artificial intelligence', 'Deep learning', 'Liver cancer']	['NOTNLM']	NLM	3348-3357	['2019/02/27 00:00 [received]', '2019/04/02 00:00 [accepted]', '2019/05/17 06:00 [pubmed]', '2019/08/27 06:00 [medline]', '2019/05/17 06:00 [entrez]']	Germany			31093705	ppublish	['Journal Article']					Eur Radiol. 2019 Jul;29(7):3348-3357. doi: 10.1007/s00330-019-06214-8. Epub 2019 May 15.	MEDLINE	Eur Radiol	Deep learning for liver tumor diagnosis part II: convolutional neural network interpretation using radiologic imaging features.		29	Deep learning for liver tumor diagnosis part II: convolutional neural network interpretation using radiologic imaging features.
Neuropathologists assess vast brain areas to identify diverse and subtly-differentiated morphologies. Standard semi-quantitative scoring approaches, however, are coarse-grained and lack precise neuroanatomic localization. We report a proof-of-concept deep learning pipeline that identifies specific neuropathologies-amyloid plaques and cerebral amyloid angiopathy-in immunohistochemically-stained archival slides. Using automated segmentation of stained objects and a cloud-based interface, we annotate > 70,000 plaque candidates from 43 whole slide images (WSIs) to train and evaluate convolutional neural networks. Networks achieve strong plaque classification on a 10-WSI hold-out set (0.993 and 0.743 areas under the receiver operating characteristic and precision recall curve, respectively). Prediction confidence maps visualize morphology distributions at high resolution. Resulting network-derived amyloid beta (Abeta)-burden scores correlate well with established semi-quantitative scores on a 30-WSI blinded hold-out. Finally, saliency mapping demonstrates that networks learn patterns agreeing with accepted pathologic features. This scalable means to augment a neuropathologist's ability suggests a route to neuropathologic deep phenotyping.	['Department of Pharmaceutical Chemistry, Department of Bioengineering and Therapeutic Sciences, Institute for Neurodegenerative Diseases, and Bakar Computational Health Sciences Institute, University of California, San Francisco, 675 Nelson Rising Ln Box 0518, San Francisco, CA, 94143, USA.', 'School of Pharmaceutical Sciences, Tsinghua University, 100084, Beijing, China.', 'Department of Pharmaceutical Chemistry, Department of Bioengineering and Therapeutic Sciences, Institute for Neurodegenerative Diseases, and Bakar Computational Health Sciences Institute, University of California, San Francisco, 675 Nelson Rising Ln Box 0518, San Francisco, CA, 94143, USA.', 'Department of Neurology, University of California-Davis School of Medicine, 4860 Y Street Suite 3700, Sacramento, CA, 95817, USA.', 'Department of Pathology and Laboratory Medicine, University of California-Davis School of Medicine, 2805 50th Street, Sacramento, CA, 95817, USA.', 'Department of Public Health Sciences, University of California-Davis, Medical Science, 1C One Shields Avenue, Davis, CA, 95616, USA.', 'Department of Pharmaceutical Chemistry, Department of Bioengineering and Therapeutic Sciences, Institute for Neurodegenerative Diseases, and Bakar Computational Health Sciences Institute, University of California, San Francisco, 675 Nelson Rising Ln Box 0518, San Francisco, CA, 94143, USA. keiser@keiserlab.org.', 'Department of Pathology and Laboratory Medicine, University of California-Davis School of Medicine, 3400A Research Building III Sacramento, Davis, CA, 95817, USA. bndugger@ucdavis.edu.']	['10.1038/s41467-019-10212-1 [doi]', '10.1038/s41467-019-10212-1 [pii]']	['Tang Z', 'Chuang KV', 'DeCarli C', 'Jin LW', 'Beckett L', 'Keiser MJ', 'Dugger BN']	['ORCID: 0000-0003-0425-0173', 'ORCID: 0000-0002-0652-8071', 'ORCID: 0000-0001-9729-1032', 'ORCID: 0000-0002-2418-9843', 'ORCID: 0000-0002-1240-2192', 'ORCID: 0000-0003-2141-8855']						['2019/05/17 06:00']	20190701	20190515	2019 May 15	2019/05/17 06:00		['Tang, Ziqi', 'Chuang, Kangway V', 'DeCarli, Charles', 'Jin, Lee-Way', 'Beckett, Laurel', 'Keiser, Michael J', 'Dugger, Brittany N']		['N/A/China Scholarship Council (CSC)/International', 'P30 AG010129/U.S. Department of Health &amp; Human Services | National Institutes', 'of Health (NIH)/International', 'P30 AG010129/U.S. Department of Health &amp; Human Services | National Institutes', 'of Health (NIH)/International', 'P30 AG010129/U.S. Department of Health &amp; Human Services | National Institutes', 'of Health (NIH)/International']	1		2041-1723 (Electronic) 2041-1723 (Linking)	101528555	Nature communications	['eng']	10.1038/s41467-019-10212-1 [doi]	20190701	['Aged', 'Aged, 80 and over', 'Alzheimer Disease/*pathology', 'Brain/*pathology', 'Cohort Studies', 'Datasets as Topic', '*Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'ROC Curve']	2019/07/02 06:00				NLM	2173	['2018/10/30 00:00 [received]', '2019/04/24 00:00 [accepted]', '2019/05/17 06:00 [entrez]', '2019/05/17 06:00 [pubmed]', '2019/07/02 06:00 [medline]']	England	PMC6520374		31092819	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Commun. 2019 May 15;10(1):2173. doi: 10.1038/s41467-019-10212-1.	MEDLINE	Nat Commun	Interpretable classification of Alzheimer's disease pathologies with a convolutional neural network pipeline.		10	Interpretable classification of Alzheimer's disease pathologies with a convolutional neural network pipeline.
Chemicals interact with genes in the process of disease development and treatment. Although much biomedical research has been performed to understand relationships among genes, chemicals, and diseases, which have been reported in biomedical articles in Medline, there are few studies that extract disease-gene-chemical relationships from biomedical literature at a PubMed scale. In this study, we propose a deep learning model based on bidirectional long short-term memory to identify the evidence sentences of relationships among genes, chemicals, and diseases from Medline abstracts. Then, we develop the search engine DigChem to enable disease-gene-chemical relationship searches for 35,124 genes, 56,382 chemicals, and 5,675 diseases. We show that the identified relationships are reliable by comparing them with manual curation and existing databases. DigChem is available at http://gcancer.org/digchem.	['Gwangju Institute of Science and Technology, School of Electrical Engineering and Computer Science, Gwangju, Korea.', 'Institute for Infocomm Research, A-STAR, 138632, Singapore.', 'Gwangju Institute of Science and Technology, School of Electrical Engineering and Computer Science, Gwangju, Korea.']	['10.1371/journal.pcbi.1007022 [doi]', 'PCOMPBIOL-D-18-01377 [pii]']	['Kim J', 'Kim JJ', 'Lee H']	['ORCID: 0000-0003-2389-7183']				['The authors have declared that no competing interests exist.']		['2019/05/16 06:00']	20191108	20190515	2019 May	2019/05/16 06:00		['Kim, Jeongkyun', 'Kim, Jung-Jae', 'Lee, Hyunju']			5		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1007022 [doi]	20191108	['Abstracting and Indexing as Topic', 'Chemically-Induced Disorders/*etiology/*genetics', 'Computational Biology', 'Data Mining', 'Databases, Factual', 'Databases, Genetic', 'Deep Learning', 'Disease/*etiology/*genetics', 'Female', 'Humans', 'MEDLINE', 'Male', 'Neural Networks (Computer)', 'PubMed', '*Search Engine']	2019/11/09 06:00				NLM	e1007022	['2018/08/09 00:00 [received]', '2019/04/10 00:00 [accepted]', '2019/05/16 06:00 [entrez]', '2019/05/16 06:00 [pubmed]', '2019/11/09 06:00 [medline]']	United States	PMC6519793		31091224	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS Comput Biol. 2019 May 15;15(5):e1007022. doi: 10.1371/journal.pcbi.1007022. eCollection 2019 May.	MEDLINE	PLoS Comput Biol	DigChem: Identification of disease-gene-chemical relationships from Medline abstracts.		15	DigChem: Identification of disease-gene-chemical relationships from Medline abstracts.
Emotion recognition based on multi-channel electroencephalograph (EEG) signals is becoming increasingly attractive. However, the conventional methods ignore the spatial characteristics of EEG signals, which also contain salient information related to emotion states. In this paper, a deep learning framework based on a multiband feature matrix (MFM) and a capsule network (CapsNet) is proposed. In the framework, the frequency domain, spatial characteristics, and frequency band characteristics of the multi-channel EEG signals are combined to construct the MFM. Then, the CapsNet model is introduced to recognize emotion states according to the input MFM. Experiments conducted on the dataset for emotion analysis using EEG, physiological, and video signals (DEAP) indicate that the proposed method outperforms most of the common models. The experimental results demonstrate that the three characteristics contained in the MFM were complementary and the capsule network was more suitable for mining and utilizing the three correlation characteristics.	['School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo 454000, China. chaohao@hpu.edu.cn.', 'School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo 454000, China. 211709020013@home.hpu.edu.cn.', 'School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo 454000, China. liuyongli@hpu.edu.cn.', 'School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo 454000, China. luby@hpu.edu.cn.']	['s19092212 [pii]', '10.3390/s19092212 [doi]']	['Chao H', 'Dong L', 'Liu Y', 'Lu B']	['ORCID: 0000-0002-9708-5391']						['2019/05/16 06:00']	20190828	20190513	2019 May 13	2019/05/16 06:00		['Chao, Hao', 'Dong, Liang', 'Liu, Yongli', 'Lu, Baoyun']		['2015GGJS068/Foundation for University Key Teacher by Henan Province', 'NSFRF1616/Fundamental Research Funds for the Universities of Henan Province', '19A520004/Key Scientific Research Projects of Universities in Henan', '172102210279/Foundation for Scientific and Technological Project of Henan', 'Province', '61502150 and 61403128/National Nature Science Foundation of China']	9		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2212 [pii] 10.3390/s19092212 [doi]	20190828	['Cerebral Cortex/physiology', 'Electrodes', 'Electroencephalography/*methods', 'Emotions/classification/*physiology', 'Entropy', 'Humans', '*Machine Learning', 'Signal Processing, Computer-Assisted']	2019/08/29 06:00		['CapsNet', 'EEG signal', 'deep learning', 'emotion recognition', 'feature extraction', 'multiband feature matrix']	['NOTNLM']	NLM		['2019/03/26 00:00 [received]', '2019/05/09 00:00 [revised]', '2019/05/10 00:00 [accepted]', '2019/05/16 06:00 [entrez]', '2019/05/16 06:00 [pubmed]', '2019/08/29 06:00 [medline]']	Switzerland	PMC6540345		31086110	epublish	['Journal Article']			IM		Sensors (Basel). 2019 May 13;19(9). pii: s19092212. doi: 10.3390/s19092212.	MEDLINE	Sensors (Basel)	Emotion Recognition from Multiband EEG Signals Using CapsNet.		19	Emotion Recognition from Multiband EEG Signals Using CapsNet.
"Introduction: The radiological reading room is undergoing a paradigm shift to a symbiosis of computer science and radiology using artificial intelligence integrated with machine and deep learning with radiomics to better define tissue characteristics. The goal is to use integrated deep learning and radiomics with radiological parameters to produce a personalized diagnosis for a patient. Areas covered: This review provides an overview of historical and current deep learning and radiomics methods in the context of precision medicine in radiology. A literature search for 'Deep Learning', 'Radiomics', 'Machine learning', 'Artificial Intelligence', 'Convolutional Neural Network', 'Generative Adversarial Network', 'Autoencoders', Deep Belief Networks"", Reinforcement Learning"", and 'Multiparametric MRI' was performed in PubMed, ArXiv, Scopus, CVPR, SPIE, IEEE Xplore, and NIPS to identify articles of interest. Expert opinion: In conclusion, both deep learning and radiomics are two rapidly advancing technologies that will unite in the future to produce a single unified framework for clinical decision support with a potential to completely revolutionize the field of precision medicine."	['The Russell H. Morgan Department of Radiology and Radiological Sciences, John Hopkins University, School of Medicine, Baltimore, MD, USA.', 'Department of Computer Science, The Johns Hopkins University, Baltimore, MD, USA.', 'The Russell H. Morgan Department of Radiology and Radiological Sciences, John Hopkins University, School of Medicine, Baltimore, MD, USA.', 'Sidney Kimmel Comprehensive Cancer Center, The Johns Hopkins University School of Medicine, Baltimore, MD, USA.']	['10.1080/23808993.2019.1585805 [doi]']	['Parekh VS', 'Jacobs MA']							['2019/05/14 06:00']		20190419	2019	2019/05/14 06:00		['Parekh, Vishwa S', 'Jacobs, Michael A']		['P30 CA006973/CA/NCI NIH HHS/United States', 'R01 CA190299/CA/NCI NIH HHS/United States', 'U01 CA140204/CA/NCI NIH HHS/United States']	2		2380-8993 (Print) 2380-8993 (Linking)	101686084	Expert review of precision medicine and drug development	['eng']	10.1080/23808993.2019.1585805 [doi]	20191120		2019/05/14 06:01	['NIHMS1026617']	['Deep learning networks', 'machine learning', 'multiparametric radiomics']	['NOTNLM']	NLM	59-72	['2019/05/14 06:00 [entrez]', '2019/05/14 06:00 [pubmed]', '2019/05/14 06:01 [medline]']	England	PMC6508888		31080889	ppublish	['Journal Article']					Expert Rev Precis Med Drug Dev. 2019;4(2):59-72. doi: 10.1080/23808993.2019.1585805. Epub 2019 Apr 19.	PubMed-not-MEDLINE	Expert Rev Precis Med Drug Dev	Deep learning and radiomics in precision medicine.		4	Deep learning and radiomics in precision medicine.
Genomics data provide great opportunities for translational research and the clinical practice, for example, for predicting disease stages. However, the classification of such data is a challenging task due to their high dimensionality, noise, and heterogeneity. In recent years, deep learning classifiers generated much interest, but due to their complexity, so far, little is known about the utility of this method for genomics. In this paper, we address this problem by studying a computational diagnostics task by classification of breast cancer and inflammatory bowel disease patients based on high-dimensional gene expression data. We provide a comprehensive analysis of the classification performance of deep belief networks (DBNs) in dependence on its multiple model parameters and in comparison with support vector machines (SVMs). Furthermore, we investigate combined classifiers that integrate DBNs with SVMs. Such a classifier utilizes a DBN as representation learner forming the input for a SVM. Overall, our results provide guidelines for the complex usage of DBN for classifying gene expression data from complex diseases.	['Predictive Society and Data Analytics Lab, Faculty of Information Technology and Communication Sciences, Tampere University, Finland.', 'Turku Centre for Biotechnology, University of Turku, Finland.', 'Institute for Intelligent Production, Faculty for Management, University of Applied Sciences Upper Austria, Steyr, Austria.', 'Department of Mechatronics and Biomedical Computer Science, UMIT, Hall in Tyrol, Austria.', 'College of Computer and Control Engineering, Nankai University, Tianjin, China.', 'Predictive Society and Data Analytics Lab, Faculty of Information Technology and Communication Sciences, Tampere University, Finland.', 'Institute of Biosciences and Medical Technology, Tampere, Finland.']	['10.1002/2211-5463.12652 [doi]']	['Smolander J', 'Dehmer M', 'Emmert-Streib F']		['(c) 2019 The Authors. Published by FEBS Press and John Wiley & Sons Ltd.']					['2019/05/11 06:00']		20190607	2019 Jul	2019/05/11 06:00		['Smolander, Johannes', 'Dehmer, Matthias', 'Emmert-Streib, Frank']			7		2211-5463 (Electronic) 2211-5463 (Linking)	101580716	FEBS open bio	['eng']	10.1002/2211-5463.12652 [doi]	20191022		2019/05/11 06:00		['*artificial intelligence', '*deep belief network', '*deep learning', '*genomics', '*neural networks', '*support vector machine']	['NOTNLM']	NLM	1232-1248	['2019/02/12 00:00 [received]', '2019/04/25 00:00 [revised]', '2019/05/08 00:00 [accepted]', '2019/05/11 06:00 [pubmed]', '2019/05/11 06:00 [medline]', '2019/05/11 06:00 [entrez]']	England	PMC6609581		31074948	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		FEBS Open Bio. 2019 Jul;9(7):1232-1248. doi: 10.1002/2211-5463.12652. Epub 2019 Jun 7.	In-Process	FEBS Open Bio	Comparing deep belief networks with support vector machines for classifying gene expression data from complex disorders.		9	Comparing deep belief networks with support vector machines for classifying gene expression data from complex disorders.
Automatic modulation recognition has successfully used various machine learning methods and achieved certain results. As a subarea of machine learning, deep learning has made great progress in recent years and has made remarkable progress in the field of image and language processing. Deep learning requires a large amount of data support. As a communication field with a large amount of data, there is an inherent advantage of applying deep learning. However, the extensive application of deep learning in the field of communication has not yet been fully developed, especially in underwater acoustic communication. In this paper, we mainly discuss the modulation recognition process which is an important part of communication process by using the deep learning method. Different from the common machine learning methods that require feature extraction, the deep learning method does not require feature extraction and obtains more effects than common machine learning.	"['Department of Electrical Engineering, Ocean University of China, Qingdao 266100, China.', ""School of Physics and Electronic Engineering, Taishan University, No. 525 Dongyue Street, Tai'an City, China."", 'Department of Electrical Engineering, Ocean University of China, Qingdao 266100, China.', 'Technical Engineering Department of CRRC Qingdao Sifang Co., Ltd., Qingdao 266111, China.', 'Department of Information Science Technology, Qingdao University of Science and Technology, Qingdao 266061, China.', 'Department of Electrical Engineering, Ocean University of China, Qingdao 266100, China.', 'Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada V8W 2Y2.']"	['10.1155/2019/8039632 [doi]']	['Wang Y', 'Zhang H', 'Sang Z', 'Xu L', 'Cao C', 'Gulliver TA']	['ORCID: 0000-0001-5086-0525', 'ORCID: 0000-0002-4643-5152', 'ORCID: 0000-0002-1005-4737', 'ORCID: 0000-0002-2169-6356', 'ORCID: 0000-0003-0827-9440', 'ORCID: 0000-0001-9919-0323']						['2019/05/09 06:00']	20190829	20190401	2019	2019/05/09 06:00		['Wang, Yan', 'Zhang, Hao', 'Sang, Zhanliang', 'Xu, Lingwei', 'Cao, Conghui', 'Gulliver, T Aaron']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2019/8039632 [doi]	20190829	['Acoustics', '*Communication', '*Deep Learning', 'Humans', '*Image Processing, Computer-Assisted', 'Machine Learning', '*Neural Networks (Computer)', 'Social Networking']	2019/08/30 06:00				NLM	8039632	['2018/10/11 00:00 [received]', '2018/12/10 00:00 [accepted]', '2019/05/09 06:00 [entrez]', '2019/05/09 06:00 [pubmed]', '2019/08/30 06:00 [medline]']	United States	PMC6466928		31065254	epublish	['Journal Article']			IM		Comput Intell Neurosci. 2019 Apr 1;2019:8039632. doi: 10.1155/2019/8039632. eCollection 2019.	MEDLINE	Comput Intell Neurosci	Modulation Classification of Underwater Communication with Deep Learning Network.		2019	Modulation Classification of Underwater Communication with Deep Learning Network.
To estimate the reliability and cognitive states of operator performance in a human-machine collaborative environment, we propose a novel human mental workload (MW) recognizer based on deep learning principles and utilizing the features of the electroencephalogram (EEG). To determine personalized properties in high dimensional EEG indicators, we introduce a feature mapping layer in stacked denoising autoencoder (SDAE) that is capable of preserving the local information in EEG dynamics. The ensemble classifier is then built via the subject-specific integrated deep learning committee, and adapts to the cognitive properties of a specific human operator and alleviates inter-subject feature variations. We validate our algorithms and the ensemble SDAE classifier with local information preservation (denoted by EL-SDAE) on an EEG database collected during the execution of complex human-machine tasks. The classification performance indicates that the EL-SDAE outperforms several classical MW estimators when its optimal network architecture has been identified.	['School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, PR China; Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, PR China.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, PR China; Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, PR China. Electronic address: yinzhong@usst.edu.cn.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, PR China; Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, PR China.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, PR China; Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, PR China.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, PR China; Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, PR China.', 'OsloMet Artificial Intelligence Lab, Department of Computer Science, Oslo Metropolitan University, Oslo, N-0130, Norway.']	['S0010-4825(19)30142-8 [pii]', '10.1016/j.compbiomed.2019.04.034 [doi]']	['Yang S', 'Yin Z', 'Wang Y', 'Zhang W', 'Wang Y', 'Zhang J']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/05/07 06:00']		20190429	2019 Jun	2019/05/07 06:00		['Yang, Shuo', 'Yin, Zhong', 'Wang, Yagang', 'Zhang, Wei', 'Wang, Yongxiong', 'Zhang, Jianhua']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(19)30142-8 [pii] 10.1016/j.compbiomed.2019.04.034 [doi]	20190609		2019/05/07 06:00		['Deep learning', 'Electroencephalogram', 'Human-machine system', 'Mental workload', 'Stacked denoising autoencoder']	['NOTNLM']	NLM	159-170	['2019/01/15 00:00 [received]', '2019/04/26 00:00 [revised]', '2019/04/26 00:00 [accepted]', '2019/05/07 06:00 [pubmed]', '2019/05/07 06:00 [medline]', '2019/05/07 06:00 [entrez]']	United States			31059900	ppublish	['Journal Article']			IM		Comput Biol Med. 2019 Jun;109:159-170. doi: 10.1016/j.compbiomed.2019.04.034. Epub 2019 Apr 29.	In-Data-Review	Comput Biol Med	Assessing cognitive mental workload via EEG signals and an ensemble deep learning classifier based on denoising autoencoders.		109	Assessing cognitive mental workload via EEG signals and an ensemble deep learning classifier based on denoising autoencoders.
BACKGROUND: Identifying possible drug-target interactions (DTIs) has become an important task in drug research and development. Although high-throughput screening is becoming available, experimental methods narrow down the validation space because of extremely high cost, low success rate, and time consumption. Therefore, various computational models have been exploited to infer DTI candidates. METHODS: We introduced relevant databases and packages, mainly provided a comprehensive review of computational models for DTI identification, including network-based algorithms and machine learning-based methods. Specially, machine learning-based methods mainly include bipartite local model, matrix factorization, regularized least squares, and deep learning. RESULTS: Although computational methods have obtained significant improvement in the process of DTI prediction, these models have their limitations. We discussed potential avenues for boosting DTI prediction accuracy as well as further directions.	['School of Computer Science, Hunan University of Technology, Zhuzhou 412007, Hunan, China. zhoulq11@163.com.', 'School of Computer Science, Hunan Institute of Technology, Henyang 421002, Hunan, China. lzjfox@163.com.', 'Geneis (Beijing) Co. Ltd., Beijing 100102, China. yangjl@geneis.cn.', 'Geneis (Beijing) Co. Ltd., Beijing 100102, China. tiang@geneis.com.', 'School of Computer Science, Hunan University of Technology, Zhuzhou 412007, Hunan, China. liufxicloud@me.com.', 'School of Computer Science, Hunan University of Technology, Zhuzhou 412007, Hunan, China. wenh_hut@163.com.', 'School of Computer Science, University of Science and Technology of Hunan, Xiangtan 411201, Hunan, China. plpeng@hnu.edu.cn.', 'School of Computer Science, Hunan Institute of Technology, Henyang 421002, Hunan, China. chenmin@hnit.edu.cn.', 'School of Computer Science and Engineering, Central South University, Changsha 410083, China. xiangju@csu.edu.cn.', 'Neuroscience Research Center, Department of Basic Medical Sciences, Changsha Medical University, Changsha 410219, Hunan, China. xiangju@csu.edu.cn.', 'School of Computer Science, Hunan University of Technology, Zhuzhou 412007, Hunan, China. plhhnu@163.com.']	['molecules24091714 [pii]', '10.3390/molecules24091714 [doi]']	['Zhou L', 'Li Z', 'Yang J', 'Tian G', 'Liu F', 'Wen H', 'Peng L', 'Chen M', 'Xiang J', 'Peng L']	['ORCID: 0000-0003-4689-8672', 'ORCID: 0000-0002-2321-3901']						['2019/05/05 06:00']	20190821	20190502	2019 May 2	2019/05/06 06:00		['Zhou, Liqian', 'Li, Zejun', 'Yang, Jialiang', 'Tian, Geng', 'Liu, Fuxing', 'Wen, Hong', 'Peng, Li', 'Chen, Min', 'Xiang, Ju', 'Peng, Lihong']		['61803151/the Natural Science Foundation of China', '2018JJ3570/the Natural Science Foundation of Hunan province', '17A052/the Project of Scientific Research Fund of Hunan Provincial Education', 'Department']	9		1420-3049 (Electronic) 1420-3049 (Linking)	100964009	Molecules (Basel, Switzerland)	['eng']	E1714 [pii] 10.3390/molecules24091714 [doi]	20190821	['*Algorithms', 'Computer Simulation', 'Databases, Factual', 'Drug Discovery/*methods', 'Machine Learning', '*Molecular Docking Simulation', '*Molecular Dynamics Simulation', '*Quantitative Structure-Activity Relationship', 'Software']	2019/08/23 06:00		['computational models', 'drug repositioning', 'drug-target interaction prediction', 'machine learning-based methods', 'network-based methods']	['NOTNLM']	NLM		['2019/04/08 00:00 [received]', '2019/04/24 00:00 [revised]', '2019/04/26 00:00 [accepted]', '2019/05/05 06:00 [entrez]', '2019/05/06 06:00 [pubmed]', '2019/08/23 06:00 [medline]']	Switzerland	PMC6540161		31052598	epublish	['Journal Article', 'Review']					Molecules. 2019 May 2;24(9). pii: molecules24091714. doi: 10.3390/molecules24091714.	MEDLINE	Molecules	Revealing Drug-Target Interactions with Computational Models and Algorithms.		24	Revealing Drug-Target Interactions with Computational Models and Algorithms.
The advent of computer graphic processing units, improvement in mathematical models and availability of big data has allowed artificial intelligence (AI) using machine learning (ML) and deep learning (DL) techniques to achieve robust performance for broad applications in social-media, the internet of things, the automotive industry and healthcare. DL systems in particular provide improved capability in image, speech and motion recognition as well as in natural language processing. In medicine, significant progress of AI and DL systems has been demonstrated in image-centric specialties such as radiology, dermatology, pathology and ophthalmology. New studies, including pre-registered prospective clinical trials, have shown DL systems are accurate and effective in detecting diabetic retinopathy (DR), glaucoma, age-related macular degeneration (AMD), retinopathy of prematurity, refractive error and in identifying cardiovascular risk factors and diseases, from digital fundus photographs. There is also increasing attention on the use of AI and DL systems in identifying disease features, progression and treatment response for retinal diseases such as neovascular AMD and diabetic macular edema using optical coherence tomography (OCT). Additionally, the application of ML to visual fields may be useful in detecting glaucoma progression. There are limited studies that incorporate clinical data including electronic health records, in AL and DL algorithms, and no prospective studies to demonstrate that AI and DL algorithms can predict the development of clinical eye disease. This article describes global eye disease burden, unmet needs and common conditions of public health importance for which AI and DL systems may be applicable. Technical and clinical aspects to build a DL system to address those needs, and the potential challenges for clinical adoption are discussed. AI, ML and DL will likely play a crucial role in clinical ophthalmology practice, with implications for screening, diagnosis and follow up of the major causes of vision impairment in the setting of ageing populations globally.	['Singapore Eye Research Institute, Singapore National Eye Center, Duke-NUS Medical School, National University of Singapore, Singapore. Electronic address: daniel.ting.s.w@singhealth.com.sg.', 'Google AI Healthcare, California, USA.', 'Google AI Healthcare, California, USA.', 'Moorfields Eye Hospital, London, UK.', 'Wilmer Eye Institute, Johns Hopkins University School of Medicine, USA; Applied Physics Laboratory, Johns Hopkins University, USA; Malone Center for Engineering in Healthcare, Johns Hopkins University, USA.', 'Departments of Ophthalmology & Medical Informatics and Clinical Epidemiology, Casey Eye Institute, Oregon Health and Science University, USA.', 'Singapore Eye Research Institute, Singapore National Eye Center, Duke-NUS Medical School, National University of Singapore, Singapore; Department of Ophthalmology, Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore; Department of Clinical Pharmacology, Medical University of Vienna, Austria; Center for Medical Physics and Biomedical Engineering, Medical University of Vienna, Austria.', 'Department of Ophthalmology, Icahn School of Medicine at Mount Sinai, New York, NY, USA.', 'Wilmer Eye Institute, Johns Hopkins University School of Medicine, USA.', 'Google AI Healthcare, California, USA.', 'Department of Ophthalmology and Visual Sciences, University of Iowa Health Care, USA.', 'Singapore Eye Research Institute, Singapore National Eye Center, Duke-NUS Medical School, National University of Singapore, Singapore.']	['S1350-9462(18)30090-9 [pii]', '10.1016/j.preteyeres.2019.04.003 [doi]']	['Ting DSW', 'Peng L', 'Varadarajan AV', 'Keane PA', 'Burlina PM', 'Chiang MF', 'Schmetterer L', 'Pasquale LR', 'Bressler NM', 'Webster DR', 'Abramoff M', 'Wong TY']		['Copyright (c) 2019. Published by Elsevier Ltd.']					['2019/05/04 06:00']		20190429	2019 Sep	2019/05/03 06:00		['Ting, Daniel S W', 'Peng, Lily', 'Varadarajan, Avinash V', 'Keane, Pearse A', 'Burlina, Philippe M', 'Chiang, Michael F', 'Schmetterer, Leopold', 'Pasquale, Louis R', 'Bressler, Neil M', 'Webster, Dale R', 'Abramoff, Michael', 'Wong, Tien Y']					1873-1635 (Electronic) 1350-9462 (Linking)	9431859	Progress in retinal and eye research	['eng']	S1350-9462(18)30090-9 [pii] 10.1016/j.preteyeres.2019.04.003 [doi]	20191101		2019/05/03 06:00				NLM	100759	['2018/12/23 00:00 [received]', '2019/04/21 00:00 [revised]', '2019/04/23 00:00 [accepted]', '2019/05/03 06:00 [pubmed]', '2019/05/03 06:00 [medline]', '2019/05/04 06:00 [entrez]']	England			31048019	ppublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't""]"			IM		Prog Retin Eye Res. 2019 Sep;72:100759. doi: 10.1016/j.preteyeres.2019.04.003. Epub 2019 Apr 29.	In-Process	Prog Retin Eye Res	Deep learning in ophthalmology: The technical and clinical considerations.		72	Deep learning in ophthalmology: The technical and clinical considerations.
The etiology of cerebral palsy (CP) is complex and remains inadequately understood. Early detection of CP is an important clinical objective as this improves long term outcomes. We performed genome-wide DNA methylation analysis to identify epigenomic predictors of CP in newborns and to investigate disease pathogenesis. Methylation analysis of newborn blood DNA using an Illumina HumanMethylation450K array was performed in 23 CP cases and 21 unaffected controls. There were 230 significantly differentially-methylated CpG loci in 258 genes. Each locus had at least 2.0-fold change in methylation in CP versus controls with a FDR p-value </= 0.05. Methylation level for each CpG locus had an area under the receiver operating curve (AUC) >/= 0.75 for CP detection. Using Artificial Intelligence (AI) platforms/Machine Learning (ML) analysis, CpG methylation levels in a combination of 230 significantly differentially-methylated CpG loci in 258 genes had a 95% sensitivity and 94.4% specificity for newborn prediction of CP. Using pathway analysis, multiple canonical pathways plausibly linked to neuronal function were over-represented. Altered biological processes and functions included: neuromotor damage, malformation of major brain structures, brain growth, neuroprotection, neuronal development and de-differentiation, and cranial sensory neuron development. In conclusion, blood leucocyte epigenetic changes analyzed using AI/ML techniques appeared to accurately predict CP and provided plausible mechanistic information on CP pathogenesis.	['Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI 48073, USA. Ray.Bahado-Singh@beaumont.org.', 'Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI 48073, USA. Sangeetha.Vishweswaraiah@beaumont.org.', 'Department of Mathematics & Computer Science, Albion College, Albion, MI 49224, USA. baydas@albion.edu.', 'Dept. of Genetics, Cell Biology & Anatomy, College of Medicine, University of Nebraska Medical Center, Omaha, NE 68182, USA. nitish.mishra@unmc.edu.', 'Dept. of Genetics, Cell Biology & Anatomy, College of Medicine, University of Nebraska Medical Center, Omaha, NE 68182, USA. babu.guda@unmc.edu.', 'Department of Obstetrics and Gynecology, Oakland University William Beaumont School of Medicine, Royal Oak, MI 48073, USA. Uppala.radhakrishna@beaumont.edu.']	['ijms20092075 [pii]', '10.3390/ijms20092075 [doi]']	['Bahado-Singh RO', 'Vishweswaraiah S', 'Aydas B', 'Mishra NK', 'Guda C', 'Radhakrishna U']	['ORCID: 0000-0002-5393-9316']						['2019/05/01 06:00']	20190816	20190427	2019 Apr 27	2019/05/01 06:00		['Bahado-Singh, Ray O', 'Vishweswaraiah, Sangeetha', 'Aydas, Buket', 'Mishra, Nitish Kumar', 'Guda, Chittibabu', 'Radhakrishna, Uppala']			9		1422-0067 (Electronic) 1422-0067 (Linking)	101092791	International journal of molecular sciences	['eng']	E2075 [pii] 10.3390/ijms20092075 [doi]	20190816	['*Artificial Intelligence', 'Case-Control Studies', '*Cell-Free Nucleic Acids', 'Cerebral Palsy/blood/*genetics/metabolism', 'CpG Islands', 'DNA Methylation', '*Deep Learning', '*Epigenesis, Genetic', 'Epigenomics/methods', 'Gene Expression Profiling', 'Gene Regulatory Networks', 'Humans', 'Infant, Newborn', 'ROC Curve']	2019/08/17 06:00		['DNA methylation', 'cerebral palsy', 'epigenetics', 'neurodegenerative disorders', 'newborns']	['NOTNLM']	NLM		['2019/01/16 00:00 [received]', '2019/03/29 00:00 [revised]', '2019/04/17 00:00 [accepted]', '2019/05/01 06:00 [entrez]', '2019/05/01 06:00 [pubmed]', '2019/08/17 06:00 [medline]']	Switzerland	PMC6539236		31035542	epublish	['Journal Article']		['0 (Cell-Free Nucleic Acids)']			Int J Mol Sci. 2019 Apr 27;20(9). pii: ijms20092075. doi: 10.3390/ijms20092075.	MEDLINE	Int J Mol Sci	Deep Learning/Artificial Intelligence and Blood-Based DNA Epigenomic Prediction of Cerebral Palsy.		20	Deep Learning/Artificial Intelligence and Blood-Based DNA Epigenomic Prediction of Cerebral Palsy.
Automatic and precise segmentation and classification of tumor area in medical images is still a challenging task in medical research. Most of the conventional neural network based models usefully connected or convolutional neural networks to perform segmentation and classification. In this research, we present deep learning models using long short term memory (LSTM) and convolutional neural networks (ConvNet) for accurate brain tumor delineation from benchmark medical images. The two different models, that is, ConvNet and LSTM networks are trained using the same data set and combined to form an ensemble to improve the results. We used publicly available MICCAI BRATS 2015 brain cancer data set consisting of MRI images of four modalities T1, T2, T1c, and FLAIR. To enhance the quality of input images, multiple combinations of preprocessing methods such as noise removal, histogram equalization, and edge enhancement are formulated and best performer combination is applied. To cope with the class imbalance problem, class weighting is used in proposed models. The trained models are tested on validation data set taken from the same image set and results obtained from each model are reported. The individual score (accuracy) of ConvNet is found 75% whereas for LSTM based network produced 80% and ensemble fusion produced 82.29% accuracy.	['Department of Computer Science, Bahauddin Zakariya University, Multan, Pakistan.', 'Department of Computer Science and Engineering, University of Engineering and Technology, Lahore, Pakistan.', 'Department of Computer Science and Engineering, University of Engineering and Technology, Lahore, Pakistan.', 'College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia.', 'Department of Computer Engineering, University of Engineering and Technology, Taxila, Pakistan.', 'Department of Computer Science, COMSATS University, Islamabad, Pakistan.', 'College of Computer and Information Systems, Al Yamamah University, Riyadh, Saudi Arabia.', 'School of Computer and Technology, Anhui University, Hefei, China.']	['10.1002/jemt.23281 [doi]']	['Iqbal S', 'Ghani Khan MU', 'Saba T', 'Mehmood Z', 'Javaid N', 'Rehman A', 'Abbasi R']	['ORCID: https://orcid.org/0000-0003-1760-7653', 'ORCID: https://orcid.org/0000-0003-3138-3801']	['(c) 2019 Wiley Periodicals, Inc.']					['2019/04/30 06:00']	20191125	20190429	2019 Aug	2019/04/30 06:00		['Iqbal, Sajid', 'Ghani Khan, Muhammad U', 'Saba, Tanzila', 'Mehmood, Zahid', 'Javaid, Nadeem', 'Rehman, Amjad', 'Abbasi, Rashid']			8		1097-0029 (Electronic) 1059-910X (Linking)	9203012	Microscopy research and technique	['eng']	10.1002/jemt.23281 [doi]	20191125	['Brain/pathology', 'Brain Neoplasms/*classification/diagnosis/physiopathology', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Magnetic Resonance Imaging', 'Models, Statistical', 'Reproducibility of Results']	2019/11/26 06:00		['LSTM', 'brain tumor segmentation', 'convolutional neural networks', 'ensemble neural networks']	['NOTNLM']	NLM	1302-1315	['2019/01/21 00:00 [received]', '2019/03/24 00:00 [revised]', '2019/04/12 00:00 [accepted]', '2019/04/30 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/04/30 06:00 [entrez]']	United States			31032544	ppublish	['Journal Article']			IM		Microsc Res Tech. 2019 Aug;82(8):1302-1315. doi: 10.1002/jemt.23281. Epub 2019 Apr 29.	MEDLINE	Microsc Res Tech	Deep learning model integrating features and novel classifiers fusion for brain tumor segmentation.		82	Deep learning model integrating features and novel classifiers fusion for brain tumor segmentation.
Recent studies have shown promising results in using Deep Learning to detect malignancy in whole slide imaging, however, they were limited to just predicting a positive or negative finding for a specific neoplasm. We attempted to use Deep Learning with a convolutional neural network (CNN) algorithm to build a lymphoma diagnostic model for four diagnostic categories: (1) benign lymph node, (2) diffuse large B-cell lymphoma, (3) Burkitt lymphoma, and (4) small lymphocytic lymphoma. Our software was written in Python language. We obtained digital whole-slide images of Hematoxylin and Eosin stained slides of 128 cases including 32 cases for each diagnostic category. Four sets of 5 representative images, 40x40 pixels in dimension, were taken for each case. A total of 2,560 images were obtained from which 1,856 were used for training, 464 for validation, and 240 for testing. For each test set of 5 images, the predicted diagnosis was combined from the prediction of five images. The test results showed excellent diagnostic accuracy at 95% for image-by-image prediction and at 100% for set-by-set prediction. This preliminary study provided a proof of concept for incorporating automated lymphoma diagnostic screen into future pathology work-flow to augment the pathologists' productivity.	['Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Internal Medicine, Hematologic Oncology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Internal Medicine, Hematologic Oncology Section, University of Texas Health Science Center at Houston, Texas, TX, USA.', 'Department of Pathology and Laboratory Medicine, Hematopathology Section, University of Texas Health Science Center at Houston, Texas, TX, USA Nghia.D.Nguyen@uth.tmc.edu.']	['49/2/153 [pii]']	['Achi HE', 'Belousova T', 'Chen L', 'Wahed A', 'Wang I', 'Hu Z', 'Kanaan Z', 'Rios A', 'Nguyen AND']		['(c) 2019 by the Association of Clinical Scientists, Inc.']					['2019/04/28 06:00']	20190813		2019 Mar	2019/04/28 06:00		['Achi, Hanadi El', 'Belousova, Tatiana', 'Chen, Lei', 'Wahed, Amer', 'Wang, Iris', 'Hu, Zhihong', 'Kanaan, Zeyad', 'Rios, Adan', 'Nguyen, Andy N D']			2		1550-8080 (Electronic) 0091-7370 (Linking)	0410247	Annals of clinical and laboratory science	['eng']		20190813	['Algorithms', 'Automation', '*Deep Learning', 'Humans', '*Image Processing, Computer-Assisted', 'Lymphoma/*diagnosis/diagnostic imaging/*pathology', 'Neural Networks (Computer)']	2019/08/14 06:00		['Deep Learning', 'Lymphoma Diagnosis', 'Whole Slide Imaging']	['NOTNLM']	NLM	153-160	['2019/04/28 06:00 [entrez]', '2019/04/28 06:00 [pubmed]', '2019/08/14 06:00 [medline]']	United States			31028058	ppublish	['Journal Article']					Ann Clin Lab Sci. 2019 Mar;49(2):153-160.	MEDLINE	Ann Clin Lab Sci	Automated Diagnosis of Lymphoma with Digital Pathology Images Using Deep Learning.		49	Automated Diagnosis of Lymphoma with Digital Pathology Images Using Deep Learning.
"BACKGROUND: The rise of biomedical expert heuristic knowledge-based approaches for computational modeling and problem solving, for scientific inquiry and medical decision-making, and for consultation in the 1970's led to a major change in the paradigm that affected all of artificial intelligence (AI) research. Since then, AI has evolved, surviving several ""winters"", as it has oscillated between relying on expensive and hard-to-validate knowledge-based approaches, and the alternative of using machine learning methods for inferring classification rules from labelled datasets. In the past couple of decades, we are seeing a gradual but progressive intertwining of the two. OBJECTIVES: To give an overview of early directions in AI in medicine and threads of some subsequent developments motivated by the very different goals of scientific inquiry for biomedical research, and for computational modeling of clinical reasoning and more general healthcare problem solving from the perspective of today's ""AI-Deep Learning Boom"". To show how, from the beginning, AI was central to Biomedical and Health Informatics (BMHI), as a field investigating how to understand intelligent thinking in dealing professionally with the practice for healthcare, developing mathematical models, technology, and software tools to aid human experts in biomedicine, despite many previous bouts of ""exuberant optimism"" about the methodologies deployed. METHODS: An overview and commentary on some of the early research and publications in AI in biomedicine, emphasizing the different approaches to the modeling of problems involved in clinical practice in contrast to those of biomedical science. A concluding reflection of a few current challenges and pitfalls of AI in some biomedical applications. CONCLUSION: While biomedical knowledge-based systems played a critical role in influencing AI in its early days, 50 years later they have taken a back seat behind ""Deep Learning"" which promises to discover knowledge structures for inference and prediction, both in science and for clinical decision-support. Early work on AI for medical consultation turned out to be more useful for explanation and teaching than for clinical practice, as had been originally intended. Today, despite the many reported successes of deep learning, fundamental scientific challenges arise in drawing on models of brain science, cognition, and language, if AI is to augment and complement rather than replace human judgment and expertise in biomedicine while also incorporating these advances for translational medicine. Understanding clinical phenotypes and how they relate to precision and personalization of care requires not only scientific inquiry, but also humanistic models of treatment that respond to patient and practitioner narrative exchanges, since it is the stories and insights of human experts which encourage what Norbert Weiner termed the ethical ""human use of human beings"", so central to adherence to the Hippocratic Oath."	['Department of Computer Science, Rutgers University, USA.']	['10.1055/s-0039-1677895 [doi]']	['Kulikowski CA']		['Georg Thieme Verlag KG Stuttgart.']			['Disclosure The authors report no conflicts of interest in this work.']		['2019/04/26 06:00']		20190425	2019 Aug	2019/04/26 06:00		['Kulikowski, Casimir A']			1		2364-0502 (Electronic) 0943-4747 (Linking)	9312666	Yearbook of medical informatics	['eng']	10.1055/s-0039-1677895 [doi]	20190820		2019/04/26 06:00				NLM	249-256	['2019/04/26 06:00 [pubmed]', '2019/04/26 06:00 [medline]', '2019/04/26 06:00 [entrez]']	Germany	PMC6697545		31022744	ppublish	['Journal Article']			IM		Yearb Med Inform. 2019 Aug;28(1):249-256. doi: 10.1055/s-0039-1677895. Epub 2019 Apr 25.	In-Process	Yearb Med Inform	Beginnings of Artificial Intelligence in Medicine (AIM): Computational Artifice Assisting Scientific Inquiry and Clinical Art - with Reflections on Present AIM Challenges.		28	Beginnings of Artificial Intelligence in Medicine (AIM): Computational Artifice Assisting Scientific Inquiry and Clinical Art - with Reflections on Present AIM Challenges.
BACKGROUND: Deep learning (DL) has been widely used to solve problems with success in speech recognition, visual object recognition, and object detection for drug discovery and genomics. Natural language processing has achieved noticeable progress in artificial intelligence. This gives an opportunity to improve on the accuracy and human-computer interaction of clinical informatics. However, due to difference of vocabularies and context between a clinical environment and generic English, transplanting language models directly from up-to-date methods to real-world health care settings is not always satisfactory. Moreover, the legal restriction on using privacy-sensitive patient records hinders the progress in applying machine learning (ML) to clinical language processing. OBJECTIVE: The aim of this study was to investigate 2 ways to adapt state-of-the-art language models to extracting patient information from free-form clinical narratives to populate a handover form at a nursing shift change automatically for proofing and revising by hand: first, by using domain-specific word representations and second, by using transfer learning models to adapt knowledge from general to clinical English. We have described the practical problem, composed it as an ML task known as information extraction, proposed methods for solving the task, and evaluated their performance. METHODS: First, word representations trained from different domains served as the input of a DL system for information extraction. Second, the transfer learning model was applied as a way to adapt the knowledge learned from general text sources to the task domain. The goal was to gain improvements in the extraction performance, especially for the classes that were topically related but did not have a sufficient amount of model solutions available for ML directly from the target domain. A total of 3 independent datasets were generated for this task, and they were used as the training (101 patient reports), validation (100 patient reports), and test (100 patient reports) sets in our experiments. RESULTS: Our system is now the state-of-the-art in this task. Domain-specific word representations improved the macroaveraged F1 by 3.4%. Transferring the knowledge from general English corpora to the task-specific domain contributed a further 7.1% improvement. The best performance in populating the handover form with 37 headings was the macroaveraged F1 of 41.6% and F1 of 81.1% for filtering out irrelevant information. Performance differences between this system and its baseline were statistically significant (P<.001; Wilcoxon test). CONCLUSIONS: To our knowledge, our study is the first attempt to transfer models from general deep models to specific tasks in health care and gain a significant improvement. As transfer learning shows its advantage over other methods, especially on classes with a limited amount of training data, less experts' time is needed to annotate data for ML, which may enable good results even in resource-poor domains.	['Research School of Computer Science, College of Engineering and Computer Science, The Australian National University, Canberra, Australia.', 'Machine Learning Group, Data61, Commonwealth Scientific and Industrial Research Organisation, Canberra, Australia.', 'Research School of Computer Science, College of Engineering and Computer Science, The Australian National University, Canberra, Australia.', 'Machine Learning Group, Data61, Commonwealth Scientific and Industrial Research Organisation, Canberra, Australia.', 'Faculty of Science and Technology, University of Canberra, Canberra, Australia.', 'Department of Future Technologies, Faculty of Science and Engineering, University of Turku, Turku, Finland.', 'Research School of Computer Science, College of Engineering and Computer Science, The Australian National University, Canberra, Australia.']	['v7i2e11499 [pii]', '10.2196/11499 [doi]']	['Zhou L', 'Suominen H', 'Gedeon T']	['ORCID: http://orcid.org/0000-0001-9046-6098', 'ORCID: http://orcid.org/0000-0002-4195-1641', 'ORCID: http://orcid.org/0000-0001-8356-4909']	['(c)Liyuan Zhou, Hanna Suominen, Tom Gedeon. Originally published in JMIR Medical', 'Informatics (http://medinform.jmir.org), 25.04.2019.']					['2019/04/26 06:00']		20190425	2019 Apr 25	2019/04/26 06:00		['Zhou, Liyuan', 'Suominen, Hanna', 'Gedeon, Tom']			2		2291-9694 (Print)	101645109	JMIR medical informatics	['eng']	10.2196/11499 [doi]	20191120		2019/04/26 06:01		['artificial intelligence', 'computer systems', 'deep learning', 'information storage and retrieval', 'medical informatics', 'nursing records', 'patient handoff']	['NOTNLM']	NLM	e11499	['2018/07/06 00:00 [received]', '2019/02/17 00:00 [accepted]', '2019/02/02 00:00 [revised]', '2019/04/26 06:00 [entrez]', '2019/04/26 06:00 [pubmed]', '2019/04/26 06:01 [medline]']	Canada	PMC6658232		31021325	epublish	['Journal Article']					JMIR Med Inform. 2019 Apr 25;7(2):e11499. doi: 10.2196/11499.	PubMed-not-MEDLINE	JMIR Med Inform	Adapting State-of-the-Art Deep Language Models to Clinical Information Extraction Systems: Potentials, Challenges, and Solutions.		7	Adapting State-of-the-Art Deep Language Models to Clinical Information Extraction Systems: Potentials, Challenges, and Solutions.
We review some emerging trends in transduction, connectivity and data analytics for Point-of-Care Testing (POCT) of infectious and non-communicable diseases. The patient need for POCT is described along with developments in portable diagnostics, specifically in respect of Lab-on-chip and microfluidic systems. We describe some novel electrochemical and photonic systems and the use of mobile phones in terms of hardware components and device connectivity for POCT. Developments in data analytics that are applicable for POCT are described with an overview of data structures and recent AI/Machine learning trends. The most important methodologies of machine learning, including deep learning methods, are summarised. The potential value of trends within POCT systems for clinical diagnostics within Lower Middle Income Countries (LMICs) and the Least Developed Countries (LDCs) are highlighted.	['Department of Pathology, Faculdade de Medicina, Universidade de Sao Paulo, Sao Paulo 05508-060, Brazil. doctorshaneosullivan@gmail.com.', 'Healthcare Innovation Centre, Teesside University, Middlesbrough TS1 3BX, UK. z.ali@tees.ac.uk.', 'Faculty of Mathematics and Computer Science, University Munster, Munster 48149, Germany. xjiang@uni-muenster.de.', 'Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL 32816, USA. reza@eecs.ucf.edu.', 'Department of Electrical and Computer Engineering and Biomedical Engineering, Boston University, Boston, MA 02215, USA. selim@bu.edu.', 'IT-Instituto de Telecomunicacoes, Lisbon 1049-001, Portugal. hugoslv@gmail.com.', 'Department of Emergency Medicine, University of New Mexico School of Medicine, Albuquerque, NM 87131, USA. JTBaca@salud.unm.edu.', 'Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL 32816, USA. Brian.Kim@ucf.edu.', 'Healthcare Innovation Centre, Teesside University, Middlesbrough TS1 3BX, UK. S.M.Scott@tees.ac.uk.', 'Department of Upper GI Surgery, Wirral University Teaching Hospital, Wirral CH49 5PE, UK. misajid14@gmail.com.', 'Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL 32816, USA. moradian@knights.ucf.edu.', 'Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL 32816, USA. Hakhamanesh.Mansoorzare@UCF.EDU.', 'Institute for interactive Systems and Data Science, Graz University of Technology, Graz 8074, Austria. andreas.holzinger@medunigraz.at.', 'Institute for Medical Informatics, Statistics and Documentation, Medical University of Graz, Graz 8036, Austria. andreas.holzinger@medunigraz.at.']	['s19081917 [pii]', '10.3390/s19081917 [doi]']	"[""O'Sullivan S"", 'Ali Z', 'Jiang X', 'Abdolvand R', 'Unlu MS', 'Silva HPD', 'Baca JT', 'Kim B', 'Scott S', 'Sajid MI', 'Moradian S', 'Mansoorzare H', 'Holzinger A']"	['ORCID: 0000-0003-4287-7380', 'ORCID: 0000-0001-9884-8146', 'ORCID: 0000-0001-7678-9528', 'ORCID: 0000-0002-8594-892X', 'ORCID: 0000-0001-6764-8432', 'ORCID: 0000-0002-9335-5200']						['2019/04/26 06:00']		20190423	2019 Apr 23	2019/04/26 06:00		"[""O'Sullivan, Shane"", 'Ali, Zulfiqur', 'Jiang, Xiaoyi', 'Abdolvand, Reza', 'Unlu, M Selim', 'Silva, Hugo Placido da', 'Baca, Justin T', 'Kim, Brian', 'Scott, Simon', 'Sajid, Mohammed Imran', 'Moradian, Sina', 'Mansoorzare, Hakhamanesh', 'Holzinger, Andreas']"			8		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1917 [pii] 10.3390/s19081917 [doi]	20191120		2019/04/26 06:01		['POCT', 'artificial intelligence', 'deep learning', 'microfluidics', 'mobile phone', 'photonics']	['NOTNLM']	NLM		['2019/01/29 00:00 [received]', '2019/04/02 00:00 [revised]', '2019/04/02 00:00 [accepted]', '2019/04/26 06:00 [entrez]', '2019/04/26 06:00 [pubmed]', '2019/04/26 06:01 [medline]']	Switzerland	PMC6515310		31018573	epublish	['Journal Article']					Sensors (Basel). 2019 Apr 23;19(8). pii: s19081917. doi: 10.3390/s19081917.	PubMed-not-MEDLINE	Sensors (Basel)	Developments in Transduction, Connectivity and AI/Machine Learning for Point-of-Care Testing.		19	Developments in Transduction, Connectivity and AI/Machine Learning for Point-of-Care Testing.
The pace of population aging is growing faster worldwide. The quality of life of the aging population is mostly affected by rheumatic diseases. With the increasing rate of rheumatoid arthritis in the aging population, technological advances in the field of automatic image processing and analysis have paved way for automatic detection and diagnosis of arthritis based on how the grade of the synovial region is designed. The proposed method is based on spatial analysis using intensity-based approach to segment the skin border, thresholding and connectivity algorithm for bone region segmentation, hit-or-miss transform for bone line segmentation and distance measure with image profile to detect the joint region. After this process of localization, the synovial region is determined using the active contour technique. In arthritis condition, synovitis also occurs which is categorized into four different grades based on the fluid expansion in the synovial region. The different grades are defined and analyzed through deep learning. Convolutional neural network in a deep learning algorithm is used to diagnose the particular grade of synovitis to describe the nature of arthritis. With these results, a module to detect the nature of arthritis automatically is defined.	['1 Sathyabama University, Chennai, India.', '2 Department of Electronics and Telecommunication Engineering, Sathyabama University, Chennai, India.', '3 Department of Biomedical Engineering, Vels Institute of Science, Technology and Advanced Studies, Chennai, India.']	['10.1177/0954411919845747 [doi]']	['Hemalatha RJ', 'Vijaybaskar V', 'Thamizhvani TR']	['ORCID: https://orcid.org/0000-0003-4712-7482']						['2019/04/25 06:00']	20190620	20190424	2019 Jun	2019/04/25 06:00		['Hemalatha, R J', 'Vijaybaskar, V', 'Thamizhvani, T R']			6		2041-3033 (Electronic) 0954-4119 (Linking)	8908934	Proceedings of the Institution of Mechanical Engineers. Part H, Journal of engineering in medicine	['eng']	10.1177/0954411919845747 [doi]	20190620	['Arthritis, Rheumatoid/*diagnostic imaging/*pathology', 'Automation', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Ultrasonography']	2019/06/21 06:00		['Localization', 'active contour', 'arthritis', 'bone and joint region', 'convolutional neural network']	['NOTNLM']	NLM	657-667	['2019/04/25 06:00 [pubmed]', '2019/06/21 06:00 [medline]', '2019/04/25 06:00 [entrez]']	England			31017534	ppublish	['Journal Article']			IM		Proc Inst Mech Eng H. 2019 Jun;233(6):657-667. doi: 10.1177/0954411919845747. Epub 2019 Apr 24.	MEDLINE	Proc Inst Mech Eng H	Automatic localization of anatomical regions in medical ultrasound images of rheumatoid arthritis using deep learning.		233	Automatic localization of anatomical regions in medical ultrasound images of rheumatoid arthritis using deep learning.
OBJECTIVES: To develop and validate a proof-of-concept convolutional neural network (CNN)-based deep learning system (DLS) that classifies common hepatic lesions on multi-phasic MRI. METHODS: A custom CNN was engineered by iteratively optimizing the network architecture and training cases, finally consisting of three convolutional layers with associated rectified linear units, two maximum pooling layers, and two fully connected layers. Four hundred ninety-four hepatic lesions with typical imaging features from six categories were utilized, divided into training (n = 434) and test (n = 60) sets. Established augmentation techniques were used to generate 43,400 training samples. An Adam optimizer was used for training. Monte Carlo cross-validation was performed. After model engineering was finalized, classification accuracy for the final CNN was compared with two board-certified radiologists on an identical unseen test set. RESULTS: The DLS demonstrated a 92% accuracy, a 92% sensitivity (Sn), and a 98% specificity (Sp). Test set performance in a single run of random unseen cases showed an average 90% Sn and 98% Sp. The average Sn/Sp on these same cases for radiologists was 82.5%/96.5%. Results showed a 90% Sn for classifying hepatocellular carcinoma (HCC) compared to 60%/70% for radiologists. For HCC classification, the true positive and false positive rates were 93.5% and 1.6%, respectively, with a receiver operating characteristic area under the curve of 0.992. Computation time per lesion was 5.6 ms. CONCLUSION: This preliminary deep learning study demonstrated feasibility for classifying lesions with typical imaging features from six common hepatic lesion types, motivating future studies with larger multi-institutional datasets and more complex imaging appearances. KEY POINTS: * Deep learning demonstrates high performance in the classification of liver lesions on volumetric multi-phasic MRI, showing potential as an eventual decision-support tool for radiologists. * Demonstrating a classification runtime of a few milliseconds per lesion, a deep learning system could be incorporated into the clinical workflow in a time-efficient manner.	['Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Charite - Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin, Berlin Institute of Health, Institute of Radiology, Humboldt-Universitat, 10117, Berlin, Germany.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Charite - Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin, Berlin Institute of Health, Institute of Radiology, Humboldt-Universitat, 10117, Berlin, Germany.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Charite - Universitatsmedizin Berlin, Corporate Member of Freie Universitat Berlin, Berlin Institute of Health, Institute of Radiology, Humboldt-Universitat, 10117, Berlin, Germany.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Biomedical Engineering, Yale School of Engineering and Applied Science, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA. j.chapiro@googlemail.com.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine, 333 Cedar Street, New Haven, CT, 06520, USA.']	['10.1007/s00330-019-06205-9 [doi]', '10.1007/s00330-019-06205-9 [pii]']	['Hamm CA', 'Wang CJ', 'Savic LJ', 'Ferrante M', 'Schobert I', 'Schlachter T', 'Lin M', 'Duncan JS', 'Weinreb JC', 'Chapiro J', 'Letzen B']							['2019/04/25 06:00']	20190826	20190423	2019 Jul	2019/04/25 06:00		['Hamm, Charlie A', 'Wang, Clinton J', 'Savic, Lynn J', 'Ferrante, Marc', 'Schobert, Isabel', 'Schlachter, Todd', 'Lin, MingDe', 'Duncan, James S', 'Weinreb, Jeffrey C', 'Chapiro, Julius', 'Letzen, Brian']		['R01 CA206180/CA/NCI NIH HHS/United States', 'RR1731/RSNA Research and Education Foundation', 'NIH/NCI R01 CA206180/National Cancer Institute']	7		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-019-06205-9 [doi]	20190826	['Adult', 'Aged', 'Bile Duct Neoplasms/diagnostic imaging', 'Bile Ducts, Intrahepatic', 'Carcinoma, Hepatocellular/*diagnostic imaging', 'Cholangiocarcinoma/diagnostic imaging', '*Deep Learning', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Liver Neoplasms/*diagnostic imaging', 'Magnetic Resonance Imaging/methods', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'ROC Curve', 'Reproducibility of Results', 'Sensitivity and Specificity', 'United States']	2019/08/27 06:00		['Artificial intelligence', 'Deep learning', 'Liver cancer']	['NOTNLM']	NLM	3338-3347	['2018/12/20 00:00 [received]', '2019/03/26 00:00 [accepted]', '2019/03/06 00:00 [revised]', '2019/04/25 06:00 [pubmed]', '2019/08/27 06:00 [medline]', '2019/04/25 06:00 [entrez]']	Germany			31016442	ppublish	['Journal Article', 'Validation Studies']					Eur Radiol. 2019 Jul;29(7):3338-3347. doi: 10.1007/s00330-019-06205-9. Epub 2019 Apr 23.	MEDLINE	Eur Radiol	Deep learning for liver tumor diagnosis part I: development of a convolutional neural network classifier for multi-phasic MRI.		29	Deep learning for liver tumor diagnosis part I: development of a convolutional neural network classifier for multi-phasic MRI.
It was recently shown that architectural, regularization and rehearsal strategies can be used to train deep models sequentially on a number of disjoint tasks without forgetting previously acquired knowledge. However, these strategies are still unsatisfactory if the tasks are not disjoint but constitute a single incremental task (e.g., class-incremental learning). In this paper we point out the differences between multi-task and single-incremental-task scenarios and show that well-known approaches such as LWF, EWC and SI are not ideal for incremental task scenarios. A new approach, denoted as AR1, combining architectural and regularization strategies is then specifically proposed. AR1 overhead (in terms of memory and computation) is very small thus making it suitable for online learning. When tested on CORe50 and iCIFAR-100, AR1 outperformed existing regularization strategies by a good margin.	['Department of Computer Science and Engineering, University of Bologna, Italy. Electronic address: Davide.maltoni@unibo.it.', 'Department of Computer Science and Engineering, University of Bologna, Italy. Electronic address: vincenzo.lomonaco@unibo.it.']	['S0893-6080(19)30083-8 [pii]', '10.1016/j.neunet.2019.03.010 [doi]']	['Maltoni D', 'Lomonaco V']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/04/22 06:00']	20190820	20190405	2019 Aug	2019/04/22 06:00		['Maltoni, Davide', 'Lomonaco, Vincenzo']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30083-8 [pii] 10.1016/j.neunet.2019.03.010 [doi]	20190820	['*Deep Learning', 'Humans', 'Photic Stimulation/*methods', '*Recognition (Psychology)']	2019/08/21 06:00		['Continuous learning', 'Deep learning', 'Incremental class learning', 'Lifelong learning', 'Object recognition', 'Single-incremental-task']	['NOTNLM']	NLM	56-73	['2018/06/11 00:00 [received]', '2019/01/22 00:00 [revised]', '2019/03/12 00:00 [accepted]', '2019/04/22 06:00 [pubmed]', '2019/08/21 06:00 [medline]', '2019/04/22 06:00 [entrez]']	United States			31005851	ppublish	['Journal Article']					Neural Netw. 2019 Aug;116:56-73. doi: 10.1016/j.neunet.2019.03.010. Epub 2019 Apr 5.	MEDLINE	Neural Netw	Continuous learning in single-incremental-task scenarios.		116	Continuous learning in single-incremental-task scenarios.
This paper introduces novel deep architectures using the hybrid neural-kernel core model as the first building block. The proposed models follow a combination of a neural networks based architecture and a kernel based model enriched with pooling layers. In particular, in this context three kernel blocks with average, maxout and convolutional pooling layers are introduced and examined. We start with a simple merging layer which averages the output of the previous representation layers. The maxout layer on the other hand triggers competition among different representations of the input. Thanks to this pooling layer, not only the dimensionality of the output of multi-scale representations is reduced but also multiple sub-networks are formed within the same model. In the same context, the pointwise convolutional layer is also employed with the aim of projecting the multi-scale representations onto a new space. Experimental results show an improvement over the core deep hybrid model as well as kernel based models on several real-life datasets.	['Department of Data Science and Knowledge Engineering, Maastricht University, The Netherlands. Electronic address: siamak.mehrkanoon@maastrichtuniversity.nl.']	['S0893-6080(19)30092-9 [pii]', '10.1016/j.neunet.2019.03.011 [doi]']	['Mehrkanoon S']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/04/22 06:00']	20190820	20190328	2019 Aug	2019/04/22 06:00		['Mehrkanoon, Siamak']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30092-9 [pii] 10.1016/j.neunet.2019.03.011 [doi]	20190820	['*Deep Learning', '*Neural Networks (Computer)', '*Spatial Analysis']	2019/08/21 06:00		['Competitive learning', 'Deep learning', 'Dimensionality reduction', 'Kernel methods', 'Neural networks', 'Pooling layer']	['NOTNLM']	NLM	46-55	['2018/08/03 00:00 [received]', '2019/01/15 00:00 [revised]', '2019/03/18 00:00 [accepted]', '2019/04/22 06:00 [pubmed]', '2019/08/21 06:00 [medline]', '2019/04/22 06:00 [entrez]']	United States			31005850	ppublish	['Journal Article']					Neural Netw. 2019 Aug;116:46-55. doi: 10.1016/j.neunet.2019.03.011. Epub 2019 Mar 28.	MEDLINE	Neural Netw	Deep neural-kernel blocks.		116	Deep neural-kernel blocks.
BACKGROUND: Recent deep learning models have shown remarkable accuracy for the diagnostic classification. However, they have limitations in clinical application due to the gap between the training cohorts and real-world data. We aimed to develop a model trained only by normal brain PET data with an unsupervised manner to identify an abnormality in various disorders as imaging data of the clinical routine. METHODS: Using variational autoencoder, a type of unsupervised learning, Abnormality Score was defined as how far a given brain image is from the normal data. The model was applied to FDG PET data of Alzheimer's disease (AD) and mild cognitive impairment (MCI) and clinical routine FDG PET data for assessing behavioral abnormality and seizures. Accuracy was measured by the area under curve (AUC) of receiver-operating-characteristic (ROC) curve. We investigated whether deep learning has additional benefits with experts' visual interpretation to identify abnormal patterns. FINDINGS: The AUC of the ROC curve for differentiating AD was 0.90. The changes in cognitive scores from baseline to 2-year follow-up were significantly correlated with Abnormality Score at baseline. The AUC of the ROC curve for discriminating patients with various disorders from controls was 0.74. Experts' visual interpretation was helped by the deep learning model to identify abnormal patterns in 60% of cases initially not identified without the model. INTERPRETATION: We suggest that deep learning model trained only by normal data was applicable for identifying wide-range of abnormalities in brain diseases, even uncommon ones, proposing its possible use for interpreting real-world clinical data.	['Department of Nuclear Medicine, Seoul National University Hospital, Seoul, Republic of Korea; Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University Hospital, Seoul, Republic of Korea; Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea; Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Republic of Korea. Electronic address: dsl@plaza.snu.ac.kr.']	['S2352-3964(19)30261-0 [pii]', '10.1016/j.ebiom.2019.04.022 [doi]']	['Choi H', 'Ha S', 'Kang H', 'Lee H', 'Lee DS']		['Copyright (c) 2019. Published by Elsevier B.V.']		"[""Alzheimer's Disease Neuroimaging Initiative""]"			['2019/04/21 06:00']	20191125	20190416	2019 May	2019/04/21 06:00		['Choi, Hongyoon', 'Ha, Seunggyun', 'Kang, Hyejin', 'Lee, Hyekyoung', 'Lee, Dong Soo']		['U01 AG024904/AG/NIA NIH HHS/United States']			2352-3964 (Electronic) 2352-3964 (Linking)	101647039	EBioMedicine	['eng']	S2352-3964(19)30261-0 [pii] 10.1016/j.ebiom.2019.04.022 [doi]	20191125	['Alzheimer Disease/diagnostic imaging/pathology', 'Area Under Curve', 'Brain/*diagnostic imaging/*pathology', 'Brain Diseases/*diagnostic imaging/*pathology', 'Cognitive Dysfunction/diagnostic imaging/pathology', '*Deep Learning', 'Fluorodeoxyglucose F18', 'Humans', 'Image Processing, Computer-Assisted', 'Neuroimaging', '*Positron-Emission Tomography/methods', 'ROC Curve']	2019/11/26 06:00		['Alzheimer', 'Anomaly detection', 'Deep learning', 'PET', 'Variational autoencoder']	['NOTNLM']	NLM	447-453	['2019/01/10 00:00 [received]', '2019/03/20 00:00 [revised]', '2019/04/09 00:00 [accepted]', '2019/04/21 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/04/21 06:00 [entrez]']	Netherlands	PMC6557913		31003928	ppublish	['Journal Article']		['0Z5B2CJX4D (Fluorodeoxyglucose F18)']	IM		EBioMedicine. 2019 May;43:447-453. doi: 10.1016/j.ebiom.2019.04.022. Epub 2019 Apr 16.	MEDLINE	EBioMedicine	Deep learning only by normal brain PET identify unheralded brain anomalies.		43	Deep learning only by normal brain PET identify unheralded brain anomalies.
Automated diagnosis of tuberculosis (TB) from chest X-Rays (CXR) has been tackled with either hand-crafted algorithms or machine learning approaches such as support vector machines (SVMs) and convolutional neural networks (CNNs). Most deep neural network applied to the task of tuberculosis diagnosis have been adapted from natural image classification. These models have a large number of parameters as well as high hardware requirements, which makes them prone to overfitting and harder to deploy in mobile settings. We propose a simple convolutional neural network optimized for the problem which is faster and more efficient than previous models but preserves their accuracy. Moreover, the visualization capabilities of CNNs have not been fully investigated. We test saliency maps and grad-CAMs as tuberculosis visualization methods, and discuss them from a radiological perspective.	['Chair of Biomedical Physics, Department of Physics and Munich School of BioEngineering, Technical University of Munich, 85748, Garching, Germany. francescopasa@gmail.com.', 'Chair for Computer Vision & Artificial Intelligence, Department of Computer Science, Technical University of Munich, Boltzmannstrasse 3, 85748, Garching, Germany. francescopasa@gmail.com.', 'Chair for Computer Vision & Artificial Intelligence, Department of Computer Science, Technical University of Munich, Boltzmannstrasse 3, 85748, Garching, Germany.', 'Chair of Biomedical Physics, Department of Physics and Munich School of BioEngineering, Technical University of Munich, 85748, Garching, Germany.', 'Department of Diagnostic and Interventional Radiology, Klinikum rechts der Isar, Technical University of Munich, 81675, Munchen, Germany.', 'Chair for Computer Vision & Artificial Intelligence, Department of Computer Science, Technical University of Munich, Boltzmannstrasse 3, 85748, Garching, Germany.', 'Department of Diagnostic and Interventional Radiology, Klinikum rechts der Isar, Technical University of Munich, 81675, Munchen, Germany.']	['10.1038/s41598-019-42557-4 [doi]', '10.1038/s41598-019-42557-4 [pii]']	['Pasa F', 'Golkov V', 'Pfeiffer F', 'Cremers D', 'Pfeiffer D']							['2019/04/20 06:00']		20190418	2019 Apr 18	2019/04/20 06:00		['Pasa, F', 'Golkov, V', 'Pfeiffer, F', 'Cremers, D', 'Pfeiffer, D']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-019-42557-4 [doi]	20191120		2019/04/20 06:00				NLM	6268	['2018/08/08 00:00 [received]', '2019/03/22 00:00 [accepted]', '2019/04/20 06:00 [entrez]', '2019/04/20 06:00 [pubmed]', '2019/04/20 06:00 [medline]']	England	PMC6472370		31000728	epublish	['Journal Article']			IM		Sci Rep. 2019 Apr 18;9(1):6268. doi: 10.1038/s41598-019-42557-4.	In-Data-Review	Sci Rep	Efficient Deep Network Architectures for Fast Chest X-Ray Tuberculosis Screening and Visualization.		9	Efficient Deep Network Architectures for Fast Chest X-Ray Tuberculosis Screening and Visualization.
Brain image segmentation is of great importance not only for clinical use but also for neuroscience research. Recent developments in deep neural networks (DNNs) have led to the application of DNNs to brain image segmentation, which required extensive human annotations of whole brain images. Annotating three-dimensional brain images requires laborious efforts by expert anatomists because of the differences among images in terms of their dimensionality, noise, contrast, or ambiguous boundaries that even prevent these experts from necessarily attaining consistency. This paper proposes a semi-supervised learning framework to train a DNN based on a relatively small number of annotated (labeled) images, named atlases, but also a relatively large number of unlabeled images by leveraging image registration to attach pseudo-labels to images that were originally unlabeled. We applied our proposed method to two different datasets: open human brain images and our original marmoset brain images. When provided with the same number of atlases for training, we found our method achieved superior and more stable segmentation results than those by existing registration-based and DNN-based methods.	['Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Kyoto, 606-8501, Japan.', 'Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Kyoto, 606-8501, Japan.', 'Department of Physiology, Keio University School of Medicine, Shinjuku-ku, Tokyo, 160-8582, Japan; Laboratory for Marmoset Neural Architecture, RIKEN Center for Brain Science, Wako-shi, Saitama, 351-0198, Japan.', 'Department of Physiology, Keio University School of Medicine, Shinjuku-ku, Tokyo, 160-8582, Japan; Laboratory for Marmoset Neural Architecture, RIKEN Center for Brain Science, Wako-shi, Saitama, 351-0198, Japan.', 'Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Kyoto, 606-8501, Japan. Electronic address: ishii@i.kyoto-u.ac.jp.']	['S0893-6080(19)30095-4 [pii]', '10.1016/j.neunet.2019.03.014 [doi]']	['Ito R', 'Nakae K', 'Hata J', 'Okano H', 'Ishii S']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/04/16 06:00']	20190820	20190401	2019 Aug	2019/04/16 06:00		['Ito, Ryo', 'Nakae, Ken', 'Hata, Junichi', 'Okano, Hideyuki', 'Ishii, Shin']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30095-4 [pii] 10.1016/j.neunet.2019.03.014 [doi]	20190820	['Animals', 'Brain/*diagnostic imaging/physiology', 'Callithrix', '*Deep Learning', 'Humans', 'Imaging, Three-Dimensional/methods', '*Neural Networks (Computer)', '*Supervised Machine Learning']	2019/08/21 06:00		['Brain tissue segmentation', 'Deep neural network', 'Image registration', 'Semi-supervised learning']	['NOTNLM']	NLM	25-34	['2018/04/03 00:00 [received]', '2018/09/28 00:00 [revised]', '2019/03/22 00:00 [accepted]', '2019/04/16 06:00 [pubmed]', '2019/08/21 06:00 [medline]', '2019/04/16 06:00 [entrez]']	United States			30986724	ppublish	['Journal Article']					Neural Netw. 2019 Aug;116:25-34. doi: 10.1016/j.neunet.2019.03.014. Epub 2019 Apr 1.	MEDLINE	Neural Netw	Semi-supervised deep learning of brain tissue segmentation.		116	Semi-supervised deep learning of brain tissue segmentation.
Fine needle aspiration (FNA) is the procedure of choice for evaluating thyroid nodules. It is indicated for nodules >2 cm, even in cases of very low suspicion of malignancy. FNA has associated risks and expenses. In this study, we developed an image analysis model using a deep learning algorithm and evaluated if the algorithm could predict thyroid nodules with benign FNA results.Ultrasonographic images of thyroid nodules with cytologic or histologic results were retrospectively collected. For algorithm training, 1358 (670 benign, 688 malignant) thyroid nodule images were input into the Inception-V3 network model. The model was pretrained to classify nodules as benign or malignant using the ImageNet database. The diagnostic performance of the algorithm was tested with the prospectively collected internal (n = 55) and external test sets (n = 100).For the internal test set, 20 of the 21 FNA malignant nodules were correctly classified as malignant by the algorithm (sensitivity, 95.2%); and of the 22 nodules algorithm classified as benign, 21 were FNA benign (negative predictive value [NPV], 95.5%). For the external test set, 47 of the 50 FNA malignant nodules were correctly classified by the algorithm (sensitivity, 94.0%); and of the 31 nodules the algorithm classified as benign, 28 were FNA benign (NPV, 90.3%).The sensitivity and NPV of the deep learning algorithm shown in this study are promising. Artificial intelligence may assist clinicians to recognize nodules that are likely to be benign and avoid unnecessary FNA.	['Graduate School of Convergence Science and Technology, Seoul National University, Suwon.', 'Department of Surgery, Seoul Metropolitan Government Seoul National University Boramae Medical Center, Seoul, Korea.', 'Department of Surgery, Kuma Hospital, Kobe, Japan.', 'Department of Radiology, Seoul National University College of Medicine, Seoul Metropolitan Government Seoul National University Boramae Medical Center, Seoul.', 'Department of Surgery, Seoul National University Hospital and College of Medicine, Seoul.', 'Department of Surgery, Seoul National University Bundang Hospital, Seongnam-si, Gyeonggi-do.', 'Department of Biomedical Engineering, Chungnam National University Hospital, Chungnam National University College of Medicine, Daejeon.', 'Department of Surgery, Seoul National University Hospital and College of Medicine, Seoul.', 'Graduate School of Convergence Science and Technology, Seoul National University, Suwon.', 'Graduate School of Convergence Science and Technology, Seoul National University, Suwon.', 'Department of Internal Medicine, Seoul Metropolitan Government Seoul National University Boramae Medical Center, Seoul, Korea.', 'Department of Surgery, Kuma Hospital, Kobe, Japan.']	['10.1097/MD.0000000000015133 [doi]', '00005792-201904120-00041 [pii]']	['Song J', 'Chai YJ', 'Masuoka H', 'Park SW', 'Kim SJ', 'Choi JY', 'Kong HJ', 'Lee KE', 'Lee J', 'Kwak N', 'Yi KH', 'Miyauchi A']							['2019/04/16 06:00']	20190422		2019 Apr	2019/04/16 06:00		['Song, Junho', 'Chai, Young Jun', 'Masuoka, Hiroo', 'Park, Sun-Won', 'Kim, Su-Jin', 'Choi, June Young', 'Kong, Hyoun-Joong', 'Lee, Kyu Eun', 'Lee, Joongseek', 'Kwak, Nojun', 'Yi, Ka Hee', 'Miyauchi, Akira']			15		1536-5964 (Electronic) 0025-7974 (Linking)	2985248R	Medicine	['eng']	10.1097/MD.0000000000015133 [doi]	20190610	['Biopsy, Fine-Needle', 'Deep Learning', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Sensitivity and Specificity', 'Thyroid Gland/diagnostic imaging/pathology', 'Thyroid Nodule/*diagnostic imaging/pathology', '*Ultrasonography/methods']	2019/04/23 06:00				NLM	e15133	['2019/04/16 06:00 [entrez]', '2019/04/16 06:00 [pubmed]', '2019/04/23 06:00 [medline]']	United States	PMC6485748		30985680	ppublish	['Evaluation Studies', 'Journal Article']			AIM IM		Medicine (Baltimore). 2019 Apr;98(15):e15133. doi: 10.1097/MD.0000000000015133.	MEDLINE	Medicine (Baltimore)	Ultrasound image analysis using deep learning algorithm for the diagnosis of thyroid nodules.		98	Ultrasound image analysis using deep learning algorithm for the diagnosis of thyroid nodules.
There has been steady progress in the field of affective computing over the last two decades that has integrated artificial intelligence techniques in the construction of computational models of emotion. Having, as a purpose, the development of a system for treating phobias that would automatically determine fear levels and adapt exposure intensity based on the user's current affective state, we propose a comparative study between various machine and deep learning techniques (four deep neural network models, a stochastic configuration network, Support Vector Machine, Linear Discriminant Analysis, Random Forest and k-Nearest Neighbors), with and without feature selection, for recognizing and classifying fear levels based on the electroencephalogram (EEG) and peripheral data from the DEAP (Database for Emotion Analysis using Physiological signals) database. Fear was considered an emotion eliciting low valence, high arousal and low dominance. By dividing the ratings of valence/arousal/dominance emotion dimensions, we propose two paradigms for fear level estimation-the two-level (0-no fear and 1-fear) and the four-level (0-no fear, 1-low fear, 2-medium fear, 3-high fear) paradigms. Although all the methods provide good classification accuracies, the highest F scores have been obtained using the Random Forest Classifier-89.96% and 85.33% for the two-level and four-level fear evaluation modality.	['Department of Computer Science and Engineering, Faculty of Automatic Control and Computers, University POLITEHNICA of Bucharest, 060042 Bucharest, Romania. oana.balan@cs.pub.ro.', 'Department of Computer Science, Information Technology, Mathematics and Physics (ITIMF), Petroleum-Gas University of Ploiesti, 100680 Ploiesti, Romania. gmoise@upg-ploiesti.ro.', 'Department of Computer Science and Engineering, Faculty of Automatic Control and Computers, University POLITEHNICA of Bucharest, 060042 Bucharest, Romania. alin.moldoveanu@cs.pub.ro.', 'Department of Computer Science and Engineering, Faculty of Automatic Control and Computers, University POLITEHNICA of Bucharest, 060042 Bucharest, Romania. marius.leordeanu@cs.pub.ro.', 'Department of Computer Science and Engineering, Faculty of Automatic Control and Computers, University POLITEHNICA of Bucharest, 060042 Bucharest, Romania. florica.moldoveanu@cs.pub.ro.']	['s19071738 [pii]', '10.3390/s19071738 [doi]']	['Balan O', 'Moise G', 'Moldoveanu A', 'Leordeanu M', 'Moldoveanu F']	['ORCID: 0000-0002-6822-2684', 'ORCID: 0000-0002-1368-7249', 'ORCID: 0000-0002-8357-5840']						['2019/04/14 06:00']	20190809	20190411	2019 Apr 11	2019/04/14 06:00		['Balan, Oana', 'Moise, Gabriela', 'Moldoveanu, Alin', 'Leordeanu, Marius', 'Moldoveanu, Florica']		['1/UEFISCDI proiect 1/2018 and UPB CRC Research Grant 2017']	7		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1738 [pii] 10.3390/s19071738 [doi]	20190809	['Adult', 'Biophysical Phenomena/*physiology', '*Electroencephalography', 'Emotions/*physiology', 'Fear/classification/*physiology', 'Female', 'Humans', 'Machine Learning', 'Male', 'Young Adult']	2019/08/10 06:00		['affective computing', 'emotional assessment', 'fear classification', 'feature selection']	['NOTNLM']	NLM		['2019/03/01 00:00 [received]', '2019/04/03 00:00 [revised]', '2019/04/09 00:00 [accepted]', '2019/04/14 06:00 [entrez]', '2019/04/14 06:00 [pubmed]', '2019/08/10 06:00 [medline]']	Switzerland	PMC6479627		30978980	epublish	['Journal Article']					Sensors (Basel). 2019 Apr 11;19(7). pii: s19071738. doi: 10.3390/s19071738.	MEDLINE	Sensors (Basel)	Fear Level Classification Based on Emotional Dimensions and Machine Learning Techniques.		19	Fear Level Classification Based on Emotional Dimensions and Machine Learning Techniques.
Single-trial motor imagery classification is a crucial aspect of brain-computer applications. Therefore, it is necessary to extract and discriminate signal features involving motor imagery movements. Riemannian geometry-based feature extraction methods are effective when designing these types of motor-imagery-based brain-computer interface applications. In the field of information theory, Riemannian geometry is mainly used with covariance matrices. Accordingly, investigations showed that if the method is used after the execution of the filterbank approach, the covariance matrix preserves the frequency and spatial information of the signal. Deep-learning methods are superior when the data availability is abundant and while there is a large number of features. The purpose of this study is to a) show how to use a single deep-learning-based classifier in conjunction with BCI (brain-computer interface) applications with the CSP (common spatial features) and the Riemannian geometry feature extraction methods in BCI applications and to b) describe one of the wrapper feature-selection algorithms, referred to as the particle swarm optimization, in combination with a decision tree algorithm. In this work, the CSP method was used for a multiclass case by using only one classifier. Additionally, a combination of power spectrum density features with covariance matrices mapped onto the tangent space of a Riemannian manifold was used. Furthermore, the particle swarm optimization method was implied to ease the training by penalizing bad features, and the moving windows method was used for augmentation. After empirical study, the convolutional neural network was adopted to classify the pre-processed data. Our proposed method improved the classification accuracy for several subjects that comprised the well-known BCI competition IV 2a dataset.	['Department of Computer Science Gachon University, Sujeong-Gu, Seongnam-Si, Gyeonggi-Do 13109, Korea. ixtiyoruz312@gmail.com.', 'Department of Computer Science Gachon University, Sujeong-Gu, Seongnam-Si, Gyeonggi-Do 13109, Korea. twhangbo@gmail.com.']	['s19071736 [pii]', '10.3390/s19071736 [doi]']	['Majidov I', 'Whangbo T']							['2019/04/14 06:00']	20190809	20190411	2019 Apr 11	2019/04/14 06:00		['Majidov, Ikhtiyor', 'Whangbo, Taegkeun']			7		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1736 [pii] 10.3390/s19071736 [doi]	20190809	['Algorithms', 'Brain/*physiology', '*Brain-Computer Interfaces', 'Decision Trees', 'Deep Learning', 'Electroencephalography/*methods', 'Humans', 'Models, Theoretical', 'Movement/physiology', 'Neural Networks (Computer)', '*Signal Processing, Computer-Assisted', 'Software']	2019/08/10 06:00		['BCI', 'CSP', 'EEG', 'FBCSP (filter bank common spatial pattern)', 'Riemannian geometry', 'electro-oscillography (EOG)', 'online learning', 'particle swarm optimization (PSO)', 'tangent space']	['NOTNLM']	NLM		['2019/02/24 00:00 [received]', '2019/03/29 00:00 [revised]', '2019/04/08 00:00 [accepted]', '2019/04/14 06:00 [entrez]', '2019/04/14 06:00 [pubmed]', '2019/08/10 06:00 [medline]']	Switzerland	PMC6479542		30978978	epublish	['Journal Article']					Sensors (Basel). 2019 Apr 11;19(7). pii: s19071736. doi: 10.3390/s19071736.	MEDLINE	Sensors (Basel)	Efficient Classification of Motor Imagery Electroencephalography Signals Using Deep Learning Methods.		19	Efficient Classification of Motor Imagery Electroencephalography Signals Using Deep Learning Methods.
A large number of people suffer from certain types of osteoarthritis, such as knee, hip, and spine osteoarthritis. A correct prediction of osteoarthritis is an essential step to effectively diagnose and prevent severe osteoarthritis. Osteoarthritis is commonly diagnosed by experts through manual inspection of patients' medical images, which are usually collected in hospitals. Checking the occurrence of osteoarthritis is somewhat time-consuming for patients. In addition, the current studies are focused on automatically detecting osteoarthritis through image-based deep learning algorithms. This needs patients' medical images, which requires patients to visit the hospital. However, medical utilization and health behavior information as statistical data are easier to collect and access than medical images. Using indirect statistical data without any medical images to predict the occurrence of diverse forms of OA can have significant impacts on pro-active and preventive medical care. In this study, we used a deep neural network for detecting the occurrence of osteoarthritis using patient's statistical data of medical utilization and health behavior information. The study was based on 5749 subjects. Principal component analysis with quantile transformer scaling was employed to generate features from the patients' simple background medical records and identify the occurrence of osteoarthritis. Our experiments showed that the proposed method using deep neural network with scaled PCA resulted in 76.8% of area under the curve (AUC) and minimized the effort to generate features. Hence, this methos can be a promising tool for patients and doctors to prescreen for possible osteoarthritis to reduce health costs and patients' time in hospitals.	['Department of Healthcare Management, Youngsan University, Yangsan 626-790, Korea. limjiart@ysu.ac.kr.', 'Department of Computer Science, Kent State University, Kent, OH 44242, USA. jykim2@kent.edu.', 'Department of Physical Therapy, Youngsan University, Yangsan 626-790, Korea. 1000sh@ysu.ac.kr.']	['ijerph16071281 [pii]', '10.3390/ijerph16071281 [doi]']	['Lim J', 'Kim J', 'Cheon S']							['2019/04/13 06:00']	20190805	20190410	2019 Apr 10	2019/04/13 06:00		['Lim, Jihye', 'Kim, Jungyoon', 'Cheon, Songhee']			7		1660-4601 (Electronic) 1660-4601 (Linking)	101238455	International journal of environmental research and public health	['eng']	E1281 [pii] 10.3390/ijerph16071281 [doi]	20190805	['Algorithms', 'Area Under Curve', '*Deep Learning', 'Early Diagnosis', 'Humans', 'Middle Aged', 'Osteoarthritis/*diagnosis']	2019/08/06 06:00		['*deep learning', '*feature extraction', '*osteoarthritis', '*prediction']	['NOTNLM']	NLM		['2019/03/04 00:00 [received]', '2019/03/29 00:00 [revised]', '2019/04/07 00:00 [accepted]', '2019/04/13 06:00 [entrez]', '2019/04/13 06:00 [pubmed]', '2019/08/06 06:00 [medline]']	Switzerland	PMC6480580		30974803	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					Int J Environ Res Public Health. 2019 Apr 10;16(7). pii: ijerph16071281. doi: 10.3390/ijerph16071281.	MEDLINE	Int J Environ Res Public Health	A Deep Neural Network-Based Method for Early Detection of Osteoarthritis Using Statistical Data.		16	A Deep Neural Network-Based Method for Early Detection of Osteoarthritis Using Statistical Data.
As a data-driven science, genomics largely utilizes machine learning to capture dependencies in data and derive novel biological hypotheses. However, the ability to extract new insights from the exponentially increasing volume of genomics data requires more expressive machine learning models. By effectively leveraging large data sets, deep learning has transformed fields such as computer vision and natural language processing. Now, it is becoming the method of choice for many genomics modelling tasks, including predicting the impact of genetic variation on gene regulatory mechanisms such as DNA accessibility and splicing.	['Institute of Computational Biology, Helmholtz Zentrum Munchen, Neuherberg, Germany.', 'School of Life Sciences Weihenstephan, Technical University of Munich, Freising, Germany.', 'Department of Informatics, Technical University of Munich, Garching, Germany.', 'Department of Informatics, Technical University of Munich, Garching, Germany. gagneur@in.tum.de.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen, Neuherberg, Germany. fabian.theis@helmholtz-muenchen.de.', 'School of Life Sciences Weihenstephan, Technical University of Munich, Freising, Germany. fabian.theis@helmholtz-muenchen.de.', 'Department of Mathematics, Technical University of Munich, Garching, Germany. fabian.theis@helmholtz-muenchen.de.']	['10.1038/s41576-019-0122-6 [doi]', '10.1038/s41576-019-0122-6 [pii]']	['Eraslan G', 'Avsec Z', 'Gagneur J', 'Theis FJ']	['ORCID: http://orcid.org/0000-0001-9579-2909', 'ORCID: http://orcid.org/0000-0002-2419-1943']						['2019/04/12 06:00']	20190723		2019 Jul	2019/04/12 06:00		['Eraslan, Gokcen', 'Avsec, Ziga', 'Gagneur, Julien', 'Theis, Fabian J']			7		1471-0064 (Electronic) 1471-0056 (Linking)	100962779	Nature reviews. Genetics	['eng']	10.1038/s41576-019-0122-6 [doi]	20191029	['Base Sequence', 'Computer Simulation', '*Deep Learning', 'Genomics/*methods', 'Humans', '*Models, Genetic', '*Neural Networks (Computer)', 'Supervised Machine Learning', 'Unsupervised Machine Learning']	2019/07/25 06:00				NLM	389-403	['2019/04/12 06:00 [pubmed]', '2019/07/25 06:00 [medline]', '2019/04/12 06:00 [entrez]']	England			30971806	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"					Nat Rev Genet. 2019 Jul;20(7):389-403. doi: 10.1038/s41576-019-0122-6.	MEDLINE	Nat Rev Genet	Deep learning: new computational modelling techniques for genomics.		20	Deep learning: new computational modelling techniques for genomics.
Wild birds are monitored with the important objectives of identifying their habitats and estimating the size of their populations. Especially in the case of migratory bird, they are significantly recorded during specific periods of time to forecast any possible spread of animal disease such as avian influenza. This study led to the construction of deep-learning-based object-detection models with the aid of aerial photographs collected by an unmanned aerial vehicle (UAV). The dataset containing the aerial photographs includes diverse images of birds in various bird habitats and in the vicinity of lakes and on farmland. In addition, aerial images of bird decoys are captured to achieve various bird patterns and more accurate bird information. Bird detection models such as Faster Region-based Convolutional Neural Network (R-CNN), Region-based Fully Convolutional Network (R-FCN), Single Shot MultiBox Detector (SSD), Retinanet, and You Only Look Once (YOLO) were created and the performance of all models was estimated by comparing their computing speed and average precision. The test results show Faster R-CNN to be the most accurate and YOLO to be the fastest among the models. The combined results demonstrate that the use of deep-learning-based detection methods in combination with UAV aerial imagery is fairly suitable for bird detection in various environments.	['Department of Biosystems and Biomaterials Science and Engineering, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. hsj5596@snu.ac.kr.', 'Department of Biosystems and Biomaterials Science and Engineering, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. redstar316@snu.ac.kr.', 'Department of Biosystems and Biomaterials Science and Engineering, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. yskra@snu.ac.kr.', 'Department of Biosystems and Biomaterials Science and Engineering, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. lay117@korea.kr.', 'National Institute of Agricultural Sciences, Rural Development Administration, Jeollabuk-do 54875, Korea. lay117@korea.kr.', 'Department of Biosystems and Biomaterials Science and Engineering, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. ghiseok@snu.ac.kr.', 'Research Institute of Agriculture and Life Sciences, Seoul National University, 1 Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. ghiseok@snu.ac.kr.']	['s19071651 [pii]', '10.3390/s19071651 [doi]']	['Hong SJ', 'Han Y', 'Kim SY', 'Lee AY', 'Kim G']	['ORCID: 0000-0001-8758-8107', 'ORCID: 0000-0001-7719-9343']						['2019/04/10 06:00']	20190726	20190406	2019 Apr 6	2019/04/10 06:00		['Hong, Suk-Ju', 'Han, Yunhyeok', 'Kim, Sang-Yeon', 'Lee, Ah-Yeong', 'Kim, Ghiseok']		['317026-02/Korea Institute of Planning and Evaluation for Technology in Food,', 'Agriculture, Forestry and Fisheries']	7		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1651 [pii] 10.3390/s19071651 [doi]	20190726	['Animals', '*Birds', '*Deep Learning', 'Machine Learning', 'Neural Networks (Computer)', 'Remote Sensing Technology/*methods']	2019/07/28 06:00		['bird detection', 'convolutional neural networks', 'deep learning', 'unmanned aerial vehicle']	['NOTNLM']	NLM		['2019/02/18 00:00 [received]', '2019/03/26 00:00 [revised]', '2019/04/02 00:00 [accepted]', '2019/04/10 06:00 [entrez]', '2019/04/10 06:00 [pubmed]', '2019/07/28 06:00 [medline]']	Switzerland	PMC6479331		30959913	epublish	['Journal Article']					Sensors (Basel). 2019 Apr 6;19(7). pii: s19071651. doi: 10.3390/s19071651.	MEDLINE	Sensors (Basel)	Application of Deep-Learning Methods to Bird Detection Using Unmanned Aerial Vehicle Imagery.		19	Application of Deep-Learning Methods to Bird Detection Using Unmanned Aerial Vehicle Imagery.
Fine needle aspiration cytology (FNAC) entails using a narrow gauge (25-22G) needle to collect a sample of a lesion for microscopic examination. It allows a minimally invasive, rapid diagnosis of tissue but does not preserve its histological architecture. FNAC is commonly used for diagnosis of breast cancer, with traditional practice being based on the subjective visual assessment of the breast cytopathology cell samples under a microscope to evaluate the state of various cytological features. Therefore, there are many challenges in maintaining consistency and reproducibility of findings. However, the advent of digital imaging and computational aid in diagnosis can improve the diagnostic accuracy and reduce the effective workload of pathologists. This paper presents a comparison of various deep convolutional neural network (CNN) based fine-tuned transfer learned classification approach for the diagnosis of the cell samples. The proposed approach has been tested using VGG16, VGG19, ResNet-50 and GoogLeNet-V3 (aka Inception V3) architectures of CNN on an image dataset of 212 images (99 benign and 113 malignant), later augmented and cleansed to 2120 images (990 benign and 1130 malignant), where the network was trained using images of 80% cell samples and tested on the rest. This paper presents a comparative assessment of the models giving a new dimension to FNAC study where GoogLeNet-V3 (fine-tuned) achieved an accuracy of 96.25% which is highly satisfactory.	['The Department of Computer Science and Engineering, Assam Engineering College, Guwahati 781013, Assam, India. Electronic address: ar5saikia@gmail.com.', 'The Department of Centre for Computational and Numerical Sciences, Institute of Advanced Study in Science and Technology, Guwahati 781035, Assam, India. Electronic address: kangkana.bora89@gmail.com.', 'The Department of Centre for Computational and Numerical Sciences, Institute of Advanced Study in Science and Technology, Guwahati 781035, Assam, India.', 'Arya Wellness Center, Guwahati 781032, Assam, India. Electronic address: dranupdas@gmail.com.']	['S0040-8166(18)30439-7 [pii]', '10.1016/j.tice.2019.02.001 [doi]']	['Saikia AR', 'Bora K', 'Mahanta LB', 'Das AK']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/04/06 06:00']	20190708	20190205	2019 Apr	2019/04/06 06:00		['Saikia, Amartya Ranjan', 'Bora, Kangkana', 'Mahanta, Lipi B', 'Das, Anup Kumar']					1532-3072 (Electronic) 0040-8166 (Linking)	0214745	Tissue & cell	['eng']	S0040-8166(18)30439-7 [pii] 10.1016/j.tice.2019.02.001 [doi]	20190708	['Biopsy, Fine-Needle', 'Breast Neoplasms/*classification/*pathology', '*Deep Learning', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Male']	2019/07/10 06:00		['Breast cancer', 'Convolutional neural network', 'Deep learning', 'FNAC']	['NOTNLM']	NLM	8-14	['2018/12/13 00:00 [received]', '2019/01/30 00:00 [revised]', '2019/02/02 00:00 [accepted]', '2019/04/06 06:00 [entrez]', '2019/04/06 06:00 [pubmed]', '2019/07/10 06:00 [medline]']	Scotland			30947968	ppublish	['Comparative Study', 'Journal Article']			IM		Tissue Cell. 2019 Apr;57:8-14. doi: 10.1016/j.tice.2019.02.001. Epub 2019 Feb 5.	MEDLINE	Tissue Cell	Comparative assessment of CNN architectures for classification of breast FNAC images.		57	Comparative assessment of CNN architectures for classification of breast FNAC images.
The interaction between viral proteins and small molecule compounds is the basis of drug design. Therefore, it is a fundamental challenge to identify viral proteins according to their amino acid sequences in the field of biopharmaceuticals. The traditional prediction methods su er from the data imbalance problem and take too long computation time. To this end, this paper proposes a deep learning framework for virus protein identifying. In the framework, we employ Temporal Convolutional Network(TCN) instead of Recurrent Neural Network(RNN) for feature extraction to improve computation e ciency. We also customize the cost-sensitive loss function of TCN and introduce the misclassification cost of training samples into the weight update of Gradient Boosting Decision Tree(GBDT) to address data imbalance problem. Experiment results show that our framework not only outperforms traditional data imbalance methods but also greatly reduces the computation time with slight performance enhancement.	['Key Laboratory of Advanced Design and Intelligent Computing, Ministry of Education, Dalian University, Dalian 116622, China.', 'Key Laboratory of Advanced Design and Intelligent Computing, Ministry of Education, Dalian University, Dalian 116622, China.', 'School of Innovation and Entrepreneurship, Dalian University of Technology, Dalian, 116024, China.', 'School of Computer Science, Dalian University of Technology, Dalian 116024, China.']	['10.3934/mbe.2019081 [doi]']	['Zhao HY', 'Che C', 'Jin B', 'Wei XP']							['2019/04/06 06:00']	20190819		2019 Feb 27	2019/04/06 06:00		['Zhao, Han Yu', 'Che, Chao', 'Jin, Bo', 'Wei, Xiao Peng']			3		1551-0018 (Electronic) 1547-1063 (Linking)	101197794	Mathematical biosciences and engineering : MBE	['eng']	10.3934/mbe.2019081 [doi]	20190819	['Algorithms', 'Antiviral Agents/pharmacology', '*Biological Products', 'Computational Biology/*methods', 'Computer Simulation', 'Databases, Factual', 'Deep Learning', 'Humans', 'Internet', 'Machine Learning', 'Neural Networks (Computer)', 'Time Factors', 'Viral Proteins/*chemistry', 'Virus Diseases/therapy']	2019/08/20 06:00		['* GBDT', '* TCN', '* data imbalance', '* deep learning', '* viral protein identifying']	['NOTNLM']	NLM	1709-1717	['2019/04/06 06:00 [entrez]', '2019/04/06 06:00 [pubmed]', '2019/08/20 06:00 [medline]']	United States			30947439	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Antiviral Agents)', '0 (Biological Products)', '0 (Viral Proteins)']			Math Biosci Eng. 2019 Feb 27;16(3):1709-1717. doi: 10.3934/mbe.2019081.	MEDLINE	Math Biosci Eng	A viral protein identifying framework based on temporal convolutional network.		16	A viral protein identifying framework based on temporal convolutional network.
A Fully Convolutional Network (FCN) based deep architecture called Dual Path U-Net (DPU-Net) is proposed for automatic segmentation of the lumen and media-adventitia in IntraVascular UltraSound (IVUS) frames, which is crucial for diagnosis of many cardiovascular diseases and also for facilitating 3D reconstructions of human arteries. One of the most prevalent problems in medical image analysis is the lack of training data. To overcome this limitation, we propose a twofold solution. First, we introduce a deep architecture that is able to learn using a small number of training images and still achieves a high degree of generalization ability. Second, we strengthen the proposed DPU-Net by having a real-time augmentor control the image augmentation process. Our real-time augmentor contains specially-designed operations that simulate three types of IVUS artifacts and integrate them into the training images. We exhaustively assessed our twofold contribution over Balocco's standard publicly available IVUS 20MHz and 40MHz B-mode dataset, which contain 109 training image, 326 test images and 19 training images, 59 test images, respectively. Models are trained from scratch with the training images provided and evaluated with two commonly used metrics in the IVUS segmentation literature, namely Jaccard Measure (JM) and Hausdorff Distance (HD). Experimental results show that DPU-Net achieves 0.87 JM, 0.82mm HD and 0.86 JM, 1.07mm HD over 40MHz dataset for segmenting the lumen and the media, respectively. Also, DPU-Net achieves 0.90 JM, 0.25mm HD and 0.92 JM, 0.30mm HD over 20MHz images for segmenting the lumen and the media, respectively. In addition, DPU-Net outperforms existing methods by 8-15% in terms of HD distance. DPU-Net also shows a strong generalization property for predicting images in the test sets that contain a significant amount of major artifacts such as bifurcations, shadows, and side branches that are not common in the training set. Furthermore, DPU-Net runs within 0.03s to segment each frame with a single modern GPU (Nvidia GTX 1080). The proposed work leverages modern deep learning-based method for segmentation of lumen and the media vessel walls in both 20MHz and 40MHz IVUS B-mode images and achieves state-of-the-art results without any manual intervention. The code is available online at https://github.com/Kulbear/IVUS-Ultrasonic.	['Department of Computing Science, University of Alberta, Canada. Electronic address: jyang7@ualberta.ca.', 'Department of Computing Science, University of Alberta, Canada. Electronic address: faraji@ualberta.ca.', 'Department of Computing Science, University of Alberta, Canada. Electronic address: basu@ualberta.ca.']	['S0041-624X(18)30805-9 [pii]', '10.1016/j.ultras.2019.03.014 [doi]']	['Yang J', 'Faraji M', 'Basu A']		['Copyright (c) 2019. Published by Elsevier B.V.']					['2019/04/05 06:00']	20190621	20190323	2019 Jul	2019/04/05 06:00		['Yang, Ji', 'Faraji, Mehdi', 'Basu, Anup']					1874-9968 (Electronic) 0041-624X (Linking)	0050452	Ultrasonics	['eng']	S0041-624X(18)30805-9 [pii] 10.1016/j.ultras.2019.03.014 [doi]	20190621	['Algorithms', 'Artifacts', 'Coronary Vessels/*diagnostic imaging', '*Deep Learning', 'Humans', 'Image Enhancement/*methods', 'Image Interpretation, Computer-Assisted/*methods', 'Reproducibility of Results', 'Ultrasonography, Interventional/*methods']	2019/06/22 06:00		['DPU-Net', 'Dual Path UNet', 'IVUS', 'Intravascular', 'Real-time augmentor', 'Segmentation', 'Ultrasound']	['NOTNLM']	NLM	24-33	['2018/12/03 00:00 [received]', '2019/02/19 00:00 [revised]', '2019/03/16 00:00 [accepted]', '2019/04/05 06:00 [pubmed]', '2019/06/22 06:00 [medline]', '2019/04/05 06:00 [entrez]']	Netherlands			30947071	ppublish	['Journal Article', 'Validation Studies']			IM		Ultrasonics. 2019 Jul;96:24-33. doi: 10.1016/j.ultras.2019.03.014. Epub 2019 Mar 23.	MEDLINE	Ultrasonics	Robust segmentation of arterial walls in intravascular ultrasound images using Dual Path U-Net.		96	Robust segmentation of arterial walls in intravascular ultrasound images using Dual Path U-Net.
Mammography is successfully used as an effective screening tool for cancer diagnosis. A calcification cluster on mammography is a primary sign of cancer. Early researches have proved the diagnostic value of the calcification, yet their performance is highly dependent on handcrafted image descriptors. Characterizing the calcification mammography in an automatic and robust way remains a challenge. In this paper, the calcification was characterized by descriptors obtained from deep learning and handcrafted descriptors. We compared the performances of different image feature sets on digital mammograms. The feature sets included the deep features alone, the handcrafted features, their combination, and the filtered deep features. Experimental results have demonstrated that the deep features outperform handcrafted features, but the handcrafted features can provide complementary information for deep features. We achieved a classification precision of 89.32% and sensitivity of 86.89% using the filtered deep features, which is the best performance among all the feature sets.	['School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China.', 'Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information, South China University of Technology, Guangzhou, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China.', 'Sun Yat-sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangzhou, Guangdong 510060, China.', 'Medical Imaging Center, Shenzhen Hospital of Southern Medical University, Shenzhen, Guangdong 518101, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China.', 'Medical Imaging Center, Shenzhen Hospital of Southern Medical University, Shenzhen, Guangdong 518101, China.']	['10.1155/2019/2717454 [doi]']	['Cai H', 'Huang Q', 'Rong W', 'Song Y', 'Li J', 'Wang J', 'Chen J', 'Li L']	['ORCID: 0000-0002-2747-7234', 'ORCID: 0000-0002-4712-2692']						['2019/04/05 06:00']	20190904	20190303	2019	2019/04/05 06:00		['Cai, Hongmin', 'Huang, Qinjian', 'Rong, Wentao', 'Song, Yan', 'Li, Jiao', 'Wang, Jinhua', 'Chen, Jiazhou', 'Li, Li']					1748-6718 (Electronic) 1748-670X (Linking)	101277751	Computational and mathematical methods in medicine	['eng']	10.1155/2019/2717454 [doi]	20190904	['Adult', 'Aged', 'Algorithms', 'Biopsy', 'Breast/*diagnostic imaging', 'Breast Neoplasms/*diagnosis/diagnostic imaging', 'Calcinosis/*diagnostic imaging', 'Deep Learning', 'Early Detection of Cancer/methods', 'Female', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Mammography/*methods', 'Middle Aged', '*Neural Networks (Computer)', 'Prognosis', 'Reproducibility of Results', 'Sensitivity and Specificity', 'Software', 'Stochastic Processes', 'Young Adult']	2019/09/05 06:00				NLM	2717454	['2018/10/31 00:00 [received]', '2018/12/22 00:00 [revised]', '2019/02/04 00:00 [accepted]', '2019/04/05 06:00 [entrez]', '2019/04/05 06:00 [pubmed]', '2019/09/05 06:00 [medline]']	United States	PMC6421727		30944574	epublish	['Journal Article']			IM		Comput Math Methods Med. 2019 Mar 3;2019:2717454. doi: 10.1155/2019/2717454. eCollection 2019.	MEDLINE	Comput Math Methods Med	Breast Microcalcification Diagnosis Using Deep Convolutional Neural Network from Digital Mammograms.		2019	Breast Microcalcification Diagnosis Using Deep Convolutional Neural Network from Digital Mammograms.
BACKGROUND: Traditional methods for drug discovery are time-consuming and expensive, so efforts are being made to repurpose existing drugs. To find new ways for drug repurposing, many computational approaches have been proposed to predict drug-target interactions (DTIs). However, due to the high-dimensional nature of the data sets extracted from drugs and targets, traditional machine learning approaches, such as logistic regression analysis, cannot analyze these data sets efficiently. To overcome this issue, we propose LASSO (Least absolute shrinkage and selection operator)-based regularized linear classification models and a LASSO-DNN (Deep Neural Network) model based on LASSO feature selection to predict DTIs. These methods are demonstrated for repurposing drugs for breast cancer treatment. METHODS: We collected drug descriptors, protein sequence data from Drugbank and protein domain information from NCBI. Validated DTIs were downloaded from Drugbank. A new similarity-based approach was developed to build the negative DTIs. We proposed multiple LASSO models to integrate different combinations of feature sets to explore the prediction power and predict DTIs. Furthermore, building on the features extracted from the LASSO models with the best performance, we also introduced a LASSO-DNN model to predict DTIs. The performance of our newly proposed DNN model (LASSO-DNN) was compared with the LASSO, standard logistic (SLG) regression, support vector machine (SVM), and standard DNN models. RESULTS: Experimental results showed that the LASSO-DNN over performed the SLG, LASSO, SVM and standard DNN models. In particular, the LASSO models with protein tripeptide composition (TC) features and domain features were superior to those that contained other protein information, which may imply that TC and domain information could be better representations of proteins. Furthermore, we showed that the top ranked DTIs predicted using the LASSO-DNN model can potentially be used for repurposing existing drugs for breast cancer based on risk gene information. CONCLUSIONS: In summary, we demonstrated that the efficient representations of drug and target features are key for building learning models for predicting DTIs. The disease-associated risk genes identified from large-scale genomic studies are the potential drug targets, which can be used for drug repurposing.	['Department of Biochemistry and Medical Genetics, University of Manitoba, Winnipeg, Manitoba, Canada; Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, Manitoba, Canada; George & Fay Yee Centre for Healthcare Innovation, University of Manitoba, Winnipeg, Manitoba, Canada.', 'Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, Manitoba, Canada.', 'Department of Biochemistry and Medical Genetics, University of Manitoba, Winnipeg, Manitoba, Canada; Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, Manitoba, Canada; George & Fay Yee Centre for Healthcare Innovation, University of Manitoba, Winnipeg, Manitoba, Canada; Department of Computer Science, University of Manitoba, Winnipeg, Manitoba, Canada. Electronic address: pingzhao.hu@umanitoba.ca.']	['S1476-9271(19)30190-2 [pii]', '10.1016/j.compbiolchem.2019.03.016 [doi]']	['You J', 'McLeod RD', 'Hu P']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/04/03 06:00']	20190729	20190325	2019 Jun	2019/04/03 06:00		['You, Jiaying', 'McLeod, Robert D', 'Hu, Pingzhao']					1476-928X (Electronic) 1476-9271 (Linking)	101157394	Computational biology and chemistry	['eng']	S1476-9271(19)30190-2 [pii] 10.1016/j.compbiolchem.2019.03.016 [doi]	20190729	['Amino Acid Sequence', 'Antineoplastic Agents/chemistry/*metabolism', 'Breast Neoplasms/genetics', 'Computational Biology/methods', 'Databases, Chemical/statistics & numerical data', 'Databases, Protein/statistics & numerical data', '*Deep Learning', 'Drug Repositioning', 'Genes, Neoplasm/drug effects', '*Models, Chemical', 'Molecular Structure', 'Protein Binding', 'Protein Domains', 'Proteins/chemistry/*metabolism', 'Support Vector Machine']	2019/07/30 06:00		['Deep learning', 'Drug repurposing', 'Drug-target interaction', 'Feature integration', 'LASSO models']	['NOTNLM']	NLM	90-101	['2019/03/07 00:00 [received]', '2019/03/23 00:00 [accepted]', '2019/04/03 06:00 [pubmed]', '2019/07/30 06:00 [medline]', '2019/04/03 06:00 [entrez]']	England			30939415	ppublish	['Journal Article']		['0 (Antineoplastic Agents)', '0 (Proteins)']			Comput Biol Chem. 2019 Jun;80:90-101. doi: 10.1016/j.compbiolchem.2019.03.016. Epub 2019 Mar 25.	MEDLINE	Comput Biol Chem	Predicting drug-target interaction network using deep learning model.		80	Predicting drug-target interaction network using deep learning model.
Model-free reinforcement learning is a powerful and efficient machine-learning paradigm which has been generally used in the robotic control domain. In the reinforcement learning setting, the value function method learns policies by maximizing the state-action value (Q value), but it suffers from inaccurate Q estimation and results in poor performance in a stochastic environment. To mitigate this issue, we present an approach based on the actor-critic framework, and in the critic branch we modify the manner of estimating Q-value by introducing the advantage function, such as dueling network, which can estimate the action-advantage value. The action-advantage value is independent of state and environment noise, we use it as a fine-tuning factor to the estimated Q value. We refer to this approach as the actor-dueling-critic (ADC) network since the frame is inspired by the dueling network. Furthermore, we redesign the dueling network part in the critic branch to make it adapt to the continuous action space. The method was tested on gym classic control environments and an obstacle avoidance environment, and we design a noise environment to test the training stability. The results indicate the ADC approach is more stable and converges faster than the DDPG method in noise environments.	['College of Automation, Harbin Engineering University, Harbin 150001, China. wumenghao@hrbeu.edu.cn.', 'Department of Computer Science, Aalto University, 02150 Espoo, Finland. wumenghao@hrbeu.edu.cn.', 'College of Automation, Harbin Engineering University, Harbin 150001, China. gaoyanbin@hrbeu.edu.cn.', 'Department of Computer Science, Aalto University, 02150 Espoo, Finland. alexander.jung@aalto.fi.', 'College of Automation, Harbin Engineering University, Harbin 150001, China. 18846425693@hrbeu.edu.cn.', 'College of Automation, Harbin Engineering University, Harbin 150001, China. dushitong@hrbeu.edu.cn.']	['s19071547 [pii]', '10.3390/s19071547 [doi]']	['Wu M', 'Gao Y', 'Jung A', 'Zhang Q', 'Du S']							['2019/04/03 06:00']	20190719	20190330	2019 Mar 30	2019/04/03 06:00		['Wu, Menghao', 'Gao, Yanbin', 'Jung, Alexander', 'Zhang, Qiang', 'Du, Shitong']		['201706680063/China Scholarship Council', '61803118/National Natural Science Foundation of China']	7		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1547 [pii] 10.3390/s19071547 [doi]	20190719	['*Algorithms', 'Deep Learning', 'Markov Chains', 'Robotics']	2019/07/20 06:00		['DDPG', 'advantage', 'continuous control', 'dueling network', 'reinforcement learning']	['NOTNLM']	NLM		['2019/02/25 00:00 [received]', '2019/03/23 00:00 [revised]', '2019/03/25 00:00 [accepted]', '2019/04/03 06:00 [entrez]', '2019/04/03 06:00 [pubmed]', '2019/07/20 06:00 [medline]']	Switzerland	PMC6479875		30935035	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Mar 30;19(7). pii: s19071547. doi: 10.3390/s19071547.	MEDLINE	Sensors (Basel)	The Actor-Dueling-Critic Method for Reinforcement Learning.		19	The Actor-Dueling-Critic Method for Reinforcement Learning.
The ability to evaluate empirical diffusion MRI acquisitions for quality and to correct the resulting imaging metrics allows for improved inference and increased replicability. Previous work has shown promise for estimation of bias and variance of generalized fractional anisotropy (GFA) but comes at the price of computational complexity. This paper aims to provide methods for estimating GFA, bias of GFA and standard deviation of GFA quickly and accurately. In order to provide a method for bias and variance estimation that can return results faster than the previously studied statistical techniques, three deep, fully-connected neural networks are developed for GFA, bias of GFA, and standard deviation of GFA. The results of these networks are compared to the observed values of the metrics as well as those fit from the statistical techniques (i.e. Simulation Extrapolation (SIMEX) for bias estimation and wild bootstrap for variance estimation). Our GFA network provides predictions that are closer to the true GFA values than a Q-ball fit of the observed data (root-mean-square error (RMSE) 0.0077 vs 0.0082, p<.001). The bias network also shows statistically significant improvement in comparison to the SIMEX-estimated error of GFA (RMSE 0.0071 vs. 0.01, p<.001).	['Biostatistics, Vanderbilt University Medical Center, Nashville, TN, USA.', 'Computer Science, Vanderbilt University, Nashville, TN, USA.', 'Electrical Engineering, Vanderbilt University, Nashville, TN, USA.', 'Vanderbilt University Institute of Imaging Science, Vanderbilt University Medical Center, Nashville, TN, USA.', 'Computer Science, Vanderbilt University, Nashville, TN, USA.', 'Vanderbilt University Institute of Imaging Science, Vanderbilt University Medical Center, Nashville, TN, USA.', 'Biostatistics, Vanderbilt University Medical Center, Nashville, TN, USA; Center for Quantitative Sciences, Vanderbilt University Medical Center, Nashville, TN, USA. Electronic address: h.kang@vumc.org.', 'Electrical Engineering, Vanderbilt University, Nashville, TN, USA; Vanderbilt University Institute of Imaging Science, Vanderbilt University Medical Center, Nashville, TN, USA; Department of Psychiatry and Behavioral Sciences, Vanderbilt University School of Medicine, TN, USA.']	['S0730-725X(18)30436-3 [pii]', '10.1016/j.mri.2019.03.021 [doi]']	['Hainline AE', 'Nath V', 'Parvathaneni P', 'Schilling KG', 'Blaber JA', 'Anderson AW', 'Kang H', 'Landman BA']		['Copyright (c) 2019 Elsevier Inc. All rights reserved.']					['2019/03/31 06:00']	20190904	20190326	2019 Jun	2019/03/31 06:00		['Hainline, Allison E', 'Nath, Vishwesh', 'Parvathaneni, Prasanna', 'Schilling, Kurt G', 'Blaber, Justin A', 'Anderson, Adam W', 'Kang, Hakmook', 'Landman, Bennett A']		['R01 EB017230/EB/NIBIB NIH HHS/United States', 'UL1 RR024975/RR/NCRR NIH HHS/United States', 'UL1 TR000445/TR/NCATS NIH HHS/United States']			1873-5894 (Electronic) 0730-725X (Linking)	8214883	Magnetic resonance imaging	['eng']	S0730-725X(18)30436-3 [pii] 10.1016/j.mri.2019.03.021 [doi]	20191101	['Algorithms', '*Anisotropy', 'Bias', 'Brain/*diagnostic imaging', '*Deep Learning', '*Diffusion Magnetic Resonance Imaging', '*Diffusion Tensor Imaging', 'Humans', 'Models, Statistical', 'Monte Carlo Method', 'Nerve Net', 'Reproducibility of Results', 'Signal-To-Noise Ratio']	2019/09/05 06:00	['NIHMS1525831']	['*Bias correction', '*GFA', '*HARDI', '*Measurement error', '*Neural network', '*Q-ball']	['NOTNLM']	NLM	130-136	['2018/09/13 00:00 [received]', '2019/03/23 00:00 [revised]', '2019/03/23 00:00 [accepted]', '2020/06/01 00:00 [pmc-release]', '2019/03/31 06:00 [pubmed]', '2019/09/05 06:00 [medline]', '2019/03/31 06:00 [entrez]']	Netherlands	PMC6818965	['2020/06/01 00:00']	30926560	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Magn Reson Imaging. 2019 Jun;59:130-136. doi: 10.1016/j.mri.2019.03.021. Epub 2019 Mar 26.	MEDLINE	Magn Reson Imaging	A deep learning approach to estimation of subject-level bias and variance in high angular resolution diffusion imaging.		59	A deep learning approach to estimation of subject-level bias and variance in high angular resolution diffusion imaging.
Congestive heart failure (CHF) refers to the inadequate blood filling function of the ventricular pump and it may cause an insufficient heart discharge volume that fails to meet the needs of body metabolism. Heart rate variability (HRV) based on the RR interval is a proven effective predictor of CHF. Short-term HRV has been used widely in many healthcare applications to monitor patients' health, especially in combination with mobile phones and smart watches. Inspired by the inception module from GoogLeNet, we combined long short-term memory (LSTM) and an Inception module for CHF detection. Five open-source databases were used for training and testing, and three RR segment length types (N = 500, 1000 and 2000) were used for the comparison with other studies. With blindfold validation, the proposed method achieved 99.22%, 98.85% and 98.92% accuracy using the Beth Israel Deaconess Medical Center (BIDMC) CHF, normal sinus rhythm (NSR) and the Fantasia database (FD) databases and 82.51%, 86.68% and 87.55% accuracy using the NSR-RR and CHF-RR databases, with N = 500, 1000 and 2000 length RR interval segments, respectively. Our end-to-end system can help clinicians to detect CHF using short-term assessment of the heartbeat. It can be installed in healthcare applications to monitor the status of human heart.	['Automation School, Beijing University of Posts and Telecommunications, No. 10 Xitucheng Road, Beijing 100876, China. wld@bupt.edu.cn.', 'Automation School, Beijing University of Posts and Telecommunications, No. 10 Xitucheng Road, Beijing 100876, China. zxg@bupt.edu.cn.']	['s19071502 [pii]', '10.3390/s19071502 [doi]']	['Wang L', 'Zhou X']	['ORCID: 0000-0002-9346-6250']						['2019/03/31 06:00']	20190719	20190328	2019 Mar 28	2019/03/31 06:00		['Wang, Ludi', 'Zhou, Xiaoguang']		['00/BUPT Excellent Ph.D. Students Foundation', '6170204/National Natural Science Foundation of China']	7		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1502 [pii] 10.3390/s19071502 [doi]	20190719	['Adult', 'Aged', 'Databases, Factual', 'Deep Learning', 'Electrocardiography/*methods', 'Female', 'Heart Failure/*diagnosis', 'Heart Rate/*physiology', 'Humans', 'Male', 'Middle Aged', 'Neural Networks (Computer)', 'Young Adult']	2019/07/20 06:00		['congestive heart failure', 'deep learning', 'inception module', 'short-term RR intervals']	['NOTNLM']	NLM		['2019/02/26 00:00 [received]', '2019/03/22 00:00 [revised]', '2019/03/22 00:00 [accepted]', '2019/03/31 06:00 [entrez]', '2019/03/31 06:00 [pubmed]', '2019/07/20 06:00 [medline]']	Switzerland	PMC6480269		30925693	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Mar 28;19(7). pii: s19071502. doi: 10.3390/s19071502.	MEDLINE	Sensors (Basel)	Detection of Congestive Heart Failure Based on LSTM-Based Deep Network via Short-Term RR Intervals.		19	Detection of Congestive Heart Failure Based on LSTM-Based Deep Network via Short-Term RR Intervals.
"The World Health Organization defines Smart Healthcare as ""Information and Communication Technology applications in the medical and health fields, including medical care, disease management, public health monitoring, education, and research."" In addition, many scholars believe that ""Smart Healthcare"" refers also to the integration of medical informatics, public health, and business applications mainly through the Internet and related artificial intelligence and data mining technologies in order to provide more accurate personal healthcare services and health information. The concept of deep learning has gained ground rapidly in recent years. While deep learning is usually applied to the studies of image/object recognition such as board game notations, paintings, people/things/objects in pictures, and so on, it is also often applied to the extraction of features. However, researchers have rarely used deep learning methods to predict outcomes in the medical and healthcare fields, preferring instead to make these predictions using algorithms based in traditional statistical methods and regression analysis. This paper introduces and investigates deep learning methods in the context of predicting outcomes in the medical and healthcare fields."	['MA, Deputy Engineer, Computer and Information Network Center, National Chung Hsing University, Taiwan, ROC.', 'PhD, Professor, Department of Information Management, National Taichung University of Science and Technology, Taiwan, ROC. mychen@nutc.edu.tw.']	['10.6224/JN.201904_66(2).02 [doi]']	['Lin SH', 'Chen MY']							['2019/03/30 06:00']	20190819		2019 Apr	2019/03/30 06:00		['Lin, Shu-Hung', 'Chen, Mu-Yen']			2		0047-262X (Print)	0073267	Hu li za zhi The journal of nursing	['chi']	JN.201904_66(2).02 [pii] 10.6224/JN.201904_66(2).02 [doi]	20190819	['Algorithms', '*Artificial Intelligence', '*Delivery of Health Care', 'Humans', 'Information Technology', 'Medical Informatics']	2019/08/20 06:00		['artificial intelligence', 'deep learning', 'machine learning', 'smart healthcare']	['NOTNLM']	NLM	7-13	['2019/03/30 06:00 [entrez]', '2019/03/30 06:00 [pubmed]', '2019/08/20 06:00 [medline]']	China (Republic : 1949- )			30924509	ppublish	['Journal Article']					Hu Li Za Zhi. 2019 Apr;66(2):7-13. doi: 10.6224/JN.201904_66(2).02.	MEDLINE	Hu Li Za Zhi	[Artificial Intelligence in Smart Health: Investigation of Theory and Practice].		66	[Artificial Intelligence in Smart Health: Investigation of Theory and Practice].
To enable the application of deep learning in biology, we present Selene (https://selene.flatironinstitute.org/), a PyTorch-based deep learning library for fast and easy development, training, and application of deep learning model architectures for any biological sequence data. We demonstrate on DNA sequences how Selene allows researchers to easily train a published architecture on new data, develop and evaluate a new architecture, and use a trained model to answer biological questions of interest.	['Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, NJ, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA. ogt@cs.princeton.edu.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA. ogt@cs.princeton.edu.', 'Department of Computer Science, Princeton University, Princeton, NJ, USA. ogt@cs.princeton.edu.']	['10.1038/s41592-019-0360-8 [doi]', '10.1038/s41592-019-0360-8 [pii]']	['Chen KM', 'Cofer EM', 'Zhou J', 'Troyanskaya OG']	['ORCID: 0000-0002-7461-9530', 'ORCID: 0000-0003-3877-0433', 'ORCID: 0000-0002-3721-4550', 'ORCID: 0000-0002-5676-5737']						['2019/03/30 06:00']	20190529	20190328	2019 Apr	2019/03/30 06:00		['Chen, Kathleen M', 'Cofer, Evan M', 'Zhou, Jian', 'Troyanskaya, Olga G']		['HHSN272201000054C/AI/NIAID NIH HHS/United States', 'R01 HG005998/HG/NHGRI NIH HHS/United States', 'T32 HG003284/HG/NHGRI NIH HHS/United States', 'U54 HL117798/HL/NHLBI NIH HHS/United States']	4		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/s41592-019-0360-8 [doi]	20191008	['Algorithms', 'Alzheimer Disease/metabolism', 'Area Under Curve', 'Computational Biology/*methods', '*Deep Learning', 'Gene Library', 'Genomics', 'Humans', 'Models, Statistical', 'Mutagenesis', 'Mutation', '*Neural Networks (Computer)', 'Normal Distribution', 'Programming Languages', '*Sequence Analysis, DNA', 'Software']	2019/05/30 06:00				NLM	315-318	['2018/10/08 00:00 [received]', '2019/02/20 00:00 [accepted]', '2019/03/30 06:00 [entrez]', '2019/03/30 06:00 [pubmed]', '2019/05/30 06:00 [medline]']	United States			30923381	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Methods. 2019 Apr;16(4):315-318. doi: 10.1038/s41592-019-0360-8. Epub 2019 Mar 28.	MEDLINE	Nat Methods	Selene: a PyTorch-based deep learning library for sequence data.		16	Selene: a PyTorch-based deep learning library for sequence data.
In this paper, a preliminary baseball player behavior classification system is proposed. By using multiple IoT sensors and cameras, the proposed method accurately recognizes many of baseball players' behaviors by analyzing signals from heterogeneous sensors. The contribution of this paper is threefold: (i) signals from a depth camera and from multiple inertial sensors are obtained and segmented, (ii) the time-variant skeleton vector projection from the depth camera and the statistical features extracted from the inertial sensors are used as features, and (iii) a deep learning-based scheme is proposed for training behavior classifiers. The experimental results demonstrate that the proposed deep learning behavior system achieves an accuracy of greater than 95% compared to the proposed dataset.	['Department of New Media Art, Taipei National University of the Arts, Taipei 112, Taiwan. swsun@newmedia.tnua.edu.tw.', 'Computer Center, Taipei National University of the Arts, Taipei 112, Taiwan. swsun@newmedia.tnua.edu.tw.', 'Department of Communication Engineering, National Central University, Taoyuan 320, Taiwan. tcmou.vaplab@gmail.com.', 'Graduate Institute of Dance Theory, Taipei National University of the Arts, Taipei 112, Taiwan. m10446017@dance.tnua.edu.tw.', 'Department of Communication Engineering, National Central University, Taoyuan 320, Taiwan. pcchang@ce.ncu.edu.tw.', 'Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei 106, Taiwan. hua@mail.ntust.edu.tw.', 'Center for Cyber-Physical System Innovation, National Taiwan University of Science and Technology, Taipei 106, Taiwan. hua@mail.ntust.edu.tw.', 'Department of Electrical Engineering, Yuan Ze University, Taoyuan 320, Taiwan. hcshih@saturn.yzu.edu.tw.']	['s19061425 [pii]', '10.3390/s19061425 [doi]']	['Sun SW', 'Mou TC', 'Fang CC', 'Chang PC', 'Hua KL', 'Shih HC']	['ORCID: 0000-0003-2761-7484', 'ORCID: 0000-0002-7735-243X', 'ORCID: 0000-0001-9241-6633']						['2019/03/27 06:00']	20190528	20190322	2019 Mar 22	2019/03/27 06:00		['Sun, Shih-Wei', 'Mou, Ting-Chen', 'Fang, Chih-Chieh', 'Chang, Pao-Chi', 'Hua, Kai-Lung', 'Shih, Huang-Chia']		['MOST 106-2221-E-119-002, MOST 107-2221-E-119 -001-MY2, MOST 107-2627-H-155-001,', 'MOST 107-2218-E-011-014/Ministry of Science and Technology, Taiwan']	6		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1425 [pii] 10.3390/s19061425 [doi]	20190528	['Accelerometry/instrumentation/*methods', 'Baseball', 'Behavior/*physiology', '*Deep Learning', 'Humans', 'Joints/physiology', 'Memory, Long-Term', 'Memory, Short-Term', 'Photography', 'Wearable Electronic Devices']	2019/05/29 06:00		['LSTM network', 'behavior recognition', 'deep learning', 'depth camera', 'inertial sensor', 'machine learning', 'multimodal']	['NOTNLM']	NLM		['2019/02/14 00:00 [received]', '2019/03/12 00:00 [revised]', '2019/03/20 00:00 [accepted]', '2019/03/27 06:00 [entrez]', '2019/03/27 06:00 [pubmed]', '2019/05/29 06:00 [medline]']	Switzerland	PMC6471259		30909503	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Mar 22;19(6). pii: s19061425. doi: 10.3390/s19061425.	MEDLINE	Sensors (Basel)	Baseball Player Behavior Classification System Using Long Short-Term Memory with Multimodal Features.		19	Baseball Player Behavior Classification System Using Long Short-Term Memory with Multimodal Features.
The success of deep machine learning in processing of large amounts of data, for example, in image or voice recognition and generation, raises the possibilities that these tools can also be applied for solving complex problems in materials science. In this forum article, we focus on molecular design that aims to answer the question on how we can predict and synthesize molecules with tailored physical, chemical, or biological properties. A potential answer to this question could be found by using intelligent systems that integrate physical models and computational machine learning techniques with automated synthesis and characterization tools. Such systems learn through every single experiment in an analogy to a human scientific expert. While the general idea of an autonomous system for molecular synthesis and characterization has been around for a while, its implementations for the materials sciences are sparse. Here we provide an overview of the developments in chemistry automation and the applications of machine learning techniques in the chemical and pharmaceutical industries with a focus on the novel capabilities that deep learning brings in.	['Kebotix, Inc. , 501 Massachusetts Avenue , Cambridge , Massachusetts 02139 , United States.', 'Kebotix, Inc. , 501 Massachusetts Avenue , Cambridge , Massachusetts 02139 , United States.', 'Department of Chemistry and Chemical Biology , Harvard University , Cambridge , Massachusetts 02138 , United States.', 'Kebotix, Inc. , 501 Massachusetts Avenue , Cambridge , Massachusetts 02139 , United States.', 'Kebotix, Inc. , 501 Massachusetts Avenue , Cambridge , Massachusetts 02139 , United States.', 'Department of Chemistry and Department of Computer Science , University of Toronto , Toronto , Ontario M5S 3H6 , Canada.', 'Kebotix, Inc. , 501 Massachusetts Avenue , Cambridge , Massachusetts 02139 , United States.', 'Department of Chemistry and Chemical Biology , Harvard University , Cambridge , Massachusetts 02138 , United States.']	['10.1021/acsami.9b01226 [doi]']	['Dimitrov T', 'Kreisbeck C', 'Becker JS', 'Aspuru-Guzik A', 'Saikin SK']	['ORCID: http://orcid.org/0000-0002-5675-7825', 'ORCID: http://orcid.org/0000-0002-8277-4434', 'ORCID: http://orcid.org/0000-0003-1924-3961']						['2019/03/26 06:00']		20190325	2019 Jul 17	2019/03/26 06:00		['Dimitrov, Tanja', 'Kreisbeck, Christoph', 'Becker, Jill S', 'Aspuru-Guzik, Alan', 'Saikin, Semion K']			28		1944-8252 (Electronic) 1944-8244 (Linking)	101504991	ACS applied materials & interfaces	['eng']	10.1021/acsami.9b01226 [doi]	20190717		2019/03/26 06:00		['artificial intelligence', 'autonomous synthesis', 'deep learning', 'inverse design', 'machine learning', 'neural networks']	['NOTNLM']	NLM	24825-24836	['2019/03/26 06:00 [pubmed]', '2019/03/26 06:00 [medline]', '2019/03/26 06:00 [entrez]']	United States			30908004	ppublish	['Journal Article']			IM		ACS Appl Mater Interfaces. 2019 Jul 17;11(28):24825-24836. doi: 10.1021/acsami.9b01226. Epub 2019 Mar 25.	In-Process	ACS Appl Mater Interfaces	Autonomous Molecular Design: Then and Now.		11	Autonomous Molecular Design: Then and Now.
PURPOSE: Optical imaging is evolving as a key technique for advanced sensing in the operating room. Recent research has shown that machine learning algorithms can be used to address the inverse problem of converting pixel-wise multispectral reflectance measurements to underlying tissue parameters, such as oxygenation. Assessment of the specific hardware used in conjunction with such algorithms, however, has not properly addressed the possibility that the problem may be ill-posed. METHODS: We present a novel approach to the assessment of optical imaging modalities, which is sensitive to the different types of uncertainties that may occur when inferring tissue parameters. Based on the concept of invertible neural networks, our framework goes beyond point estimates and maps each multispectral measurement to a full posterior probability distribution which is capable of representing ambiguity in the solution via multiple modes. Performance metrics for a hardware setup can then be computed from the characteristics of the posteriors. RESULTS: Application of the assessment framework to the specific use case of camera selection for physiological parameter estimation yields the following insights: (1) estimation of tissue oxygenation from multispectral images is a well-posed problem, while (2) blood volume fraction may not be recovered without ambiguity. (3) In general, ambiguity may be reduced by increasing the number of spectral bands in the camera. CONCLUSION: Our method could help to optimize optical camera design in an application-specific manner.	['Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany. t.adler@dkfz-heidelberg.de.', 'Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany. t.adler@dkfz-heidelberg.de.', 'Visual Learning Lab, Heidelberg University, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany.', 'Medical Faculty, Heidelberg University, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany.', 'Faculty of Physics and Astronomy, Heidelberg University, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany.', 'Visual Learning Lab, Heidelberg University, Heidelberg, Germany.', 'Visual Learning Lab, Heidelberg University, Heidelberg, Germany.', 'Visual Learning Lab, Heidelberg University, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, Deutsches Krebsforschungszentrum, Im Neuenheimer Feld 223, 69120, Heidelberg, Germany.']	['10.1007/s11548-019-01939-9 [doi]', '10.1007/s11548-019-01939-9 [pii]']	['Adler TJ', 'Ardizzone L', 'Vemuri A', 'Ayala L', 'Grohl J', 'Kirchner T', 'Wirkert S', 'Kruse J', 'Rother C', 'Kothe U', 'Maier-Hein L']	['ORCID: http://orcid.org/0000-0002-3424-6629', 'ORCID: http://orcid.org/0000-0002-5332-4856']						['2019/03/24 06:00']	20190902	20190322	2019 Jun	2019/03/25 06:00		['Adler, Tim J', 'Ardizzone, Lynton', 'Vemuri, Anant', 'Ayala, Leonardo', 'Grohl, Janek', 'Kirchner, Thomas', 'Wirkert, Sebastian', 'Kruse, Jakob', 'Rother, Carsten', 'Kothe, Ullrich', 'Maier-Hein, Lena']		['ERC-2015-StG-37960/Horizon 2020 Framework Programme']	6		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-019-01939-9 [doi]	20190902	['Algorithms', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', 'Optical Imaging/*methods', 'Uncertainty']	2019/09/03 06:00		['Ambiguity', 'Deep learning', 'Error analysis', 'Invertible neural networks', 'Multispectral imaging', 'Optical imaging', 'Surgical data science', 'Uncertainty estimation']	['NOTNLM']	NLM	997-1007	['2019/02/05 00:00 [received]', '2019/03/07 00:00 [accepted]', '2019/03/25 06:00 [pubmed]', '2019/09/03 06:00 [medline]', '2019/03/24 06:00 [entrez]']	Germany			30903566	ppublish	['Journal Article']			IM		Int J Comput Assist Radiol Surg. 2019 Jun;14(6):997-1007. doi: 10.1007/s11548-019-01939-9. Epub 2019 Mar 22.	MEDLINE	Int J Comput Assist Radiol Surg	Uncertainty-aware performance assessment of optical imaging modalities with invertible neural networks.		14	Uncertainty-aware performance assessment of optical imaging modalities with invertible neural networks.
BACKGROUND AND OBJECTIVES: The calcaneus is the most fracture-prone tarsal bone and injuries to the surrounding tissue are some of the most difficult to treat. Currently there is a lack of consensus on treatment or interpretation of computed tomography (CT) images for calcaneus fractures. This study proposes a novel computer-assisted method for automated classification and detection of fracture locations in calcaneus CT images using a deep learning algorithm. METHODS: Two types of Convolutional Neural Network (CNN) architectures with different network depths, a Residual network (ResNet) and a Visual geometry group (VGG), were evaluated and compared for the classification performance of CT scans into fracture and non-fracture categories based on coronal, sagittal, and transverse views. The bone fracture detection algorithm incorporated fracture area matching using the speeded-up robust features (SURF) method, Canny edge detection, and contour tracing. RESULTS: Results showed that ResNet was comparable in accuracy (98%) to the VGG network for bone fracture classification but achieved better performance for involving a deeper neural network architecture. ResNet classification results were used as the input for detecting the location and type of bone fracture using SURF algorithm. CONCLUSIONS: Results from real patient fracture data sets demonstrate the feasibility using deep CNN and SURF for computer-aided classification and detection of the location of calcaneus fractures in CT images.	['Department of Computer Science and Information Engineering, National Central University, Jhongli County, Taoyuan City, Taiwan.', 'Department of Computer Science and Information Engineering, National Central University, Jhongli County, Taoyuan City, Taiwan.', 'Department of Computer Science and Information Engineering, National Central University, Jhongli County, Taoyuan City, Taiwan. Electronic address: jcw@csie.ncu.edu.tw.', 'Department of Mechanical Engineering, National Central University, Jhongli County, Taoyuan City, Taiwan.', 'Department of Mechanical Engineering, National Central University, Jhongli County, Taoyuan City, Taiwan.', 'Institute of Cognitive Neuroscience, National Central University, Jhongli County, Taoyuan City, Taiwan.', 'Institute of Cognitive Neuroscience, National Central University, Jhongli County, Taoyuan City, Taiwan. Electronic address: ihsieh@cc.ncu.edu.tw.']	['S0169-2607(18)31465-2 [pii]', '10.1016/j.cmpb.2019.02.006 [doi]']	['Pranata YD', 'Wang KC', 'Wang JC', 'Idram I', 'Lai JY', 'Liu JW', 'Hsieh IH']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/03/24 06:00']	20190809	20190212	2019 Apr	2019/03/25 06:00		['Pranata, Yoga Dwi', 'Wang, Kuan-Chung', 'Wang, Jia-Ching', 'Idram, Irwansyah', 'Lai, Jiing-Yih', 'Liu, Jia-Wei', 'Hsieh, I-Hui']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)31465-2 [pii] 10.1016/j.cmpb.2019.02.006 [doi]	20190809	['Algorithms', 'Calcaneus/*diagnostic imaging/*injuries', '*Deep Learning', 'Fractures, Bone/*diagnosis/*diagnostic imaging', 'Humans', 'Neural Networks (Computer)', 'Tomography, X-Ray Computed/*methods']	2019/08/10 06:00		['Calcaneus fracture', 'Computed tomography image', 'Convolutional neural networks', 'Residual network', 'Visual geometry group']	['NOTNLM']	NLM	27-37	['2018/10/11 00:00 [received]', '2019/01/29 00:00 [revised]', '2019/02/11 00:00 [accepted]', '2019/03/24 06:00 [entrez]', '2019/03/25 06:00 [pubmed]', '2019/08/10 06:00 [medline]']	Ireland			30902248	ppublish	['Journal Article']					Comput Methods Programs Biomed. 2019 Apr;171:27-37. doi: 10.1016/j.cmpb.2019.02.006. Epub 2019 Feb 12.	MEDLINE	Comput Methods Programs Biomed	Deep learning and SURF for automated classification and detection of calcaneus fractures in CT images.		171	Deep learning and SURF for automated classification and detection of calcaneus fractures in CT images.
The combination of big data and deep learning is a world-shattering technology that can make a great impact on any industry if used in a proper way. With the availability of large volume of health care datasets and progressions in deep learning techniques, systems are now well equipped in diagnosing many health problems. Utilizing the intensity of substantial historical information in electronic health record (EHR), we built up, a conventional predictive temporal model utilizing recurrent neural systems (RNN) like LSTM and connected to longitudinal time stepped EHR. Experience records were contribution to RNN to anticipate the analysis and prescription classes for a resulting visit during heart disappointment (e.g. diagnosis codes, drug codes or method codes). In this paper, we also investigated whether use of deep learning to model temporal relations among events in electronic health records (EHRs) would enhance the model performance in predicting initial diagnosis of heart failure (HF) compared to some of the traditional methods that disregard temporality. By examining these time stamped EHRs, we could recognize the associations between various diagnosis occasions and finally predicate when a patient is being analyzed for a disease. In any case, it is hard to access the current EHR data straightforwardly, since almost all data are sparse and not standardized. Along these lines, we proposed a robust model for prediction of heart failure. The fundamental commitment of this paper is to predict the failure of heart by means of a neural network model based on patient's electronic medicinal information. In order to, demonstrate the diagnosis events and prediction of heart failure, we used the medical concept vectors and the essential standards of a long short-term memory (LSTM) deep network model. The proposed LSTM model uses SiLU and tanh as activation function in the hidden layers and Softmax in output layer in the network. Bridgeout is used as a regularization technique for weight optimization throughout the network. Assessments subject to the real-time data exhibit the favorable effectiveness and feasibility of recommended model in the risk of heart failure prediction. The results showed improved accuracy in heart failure detection and the model performance is compared using the existing deep learning models. Enhanced prior detection could expose novel chances for deferring or anticipating movement to analysis of heart failure and diminish cost.	['Department of Information & Technology, SRM Institute of Science and Technology, Chennai, India. maragathamhaarish@gmail.com.', 'Department of Information & Technology, SRM Institute of Science and Technology, Chennai, India.']	['10.1007/s10916-019-1243-3 [doi]', '10.1007/s10916-019-1243-3 [pii]']	['Maragatham G', 'Devi S']							['2019/03/20 06:00']	20190805	20190319	2019 Mar 19	2019/03/20 06:00		['Maragatham, G', 'Devi, Shobana']			5		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-019-1243-3 [doi]	20190805	['*Big Data', 'Deep Learning', 'Electronic Health Records/*organization & administration', 'Heart Failure/*diagnosis/diagnostic imaging', 'Humans', '*Neural Networks (Computer)']	2019/08/06 06:00		['Electronic health record', 'LSTM Model', 'Long short-term memory', 'Recurrent neural systems']	['NOTNLM']	NLM	111	['2019/01/30 00:00 [received]', '2019/03/06 00:00 [accepted]', '2019/03/20 06:00 [entrez]', '2019/03/20 06:00 [pubmed]', '2019/08/06 06:00 [medline]']	United States			30888519	epublish	['Journal Article']					J Med Syst. 2019 Mar 19;43(5):111. doi: 10.1007/s10916-019-1243-3.	MEDLINE	J Med Syst	LSTM Model for Prediction of Heart Failure in Big Data.		43	LSTM Model for Prediction of Heart Failure in Big Data.
Recent advances in large-scale single-cell RNA-seq enable fine-grained characterization of phenotypically distinct cellular states in heterogeneous tissues. We present scScope, a scalable deep-learning-based approach that can accurately and rapidly identify cell-type composition from millions of noisy single-cell gene-expression profiles.	['Department of Pharmaceutical Chemistry, University of California, San Francisco, San Francisco, CA, USA.', 'Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China.', 'Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China.', 'Department of Pharmaceutical Chemistry, University of California, San Francisco, San Francisco, CA, USA. lani.wu@ucsf.edu.', 'Department of Pharmaceutical Chemistry, University of California, San Francisco, San Francisco, CA, USA. steven.altschuler@ucsf.edu.']	['10.1038/s41592-019-0353-7 [doi]', '10.1038/s41592-019-0353-7 [pii]']	['Deng Y', 'Bao F', 'Dai Q', 'Wu LF', 'Altschuler SJ']	['ORCID: 0000-0002-0052-7537', 'ORCID: 0000-0001-9142-0796']						['2019/03/20 06:00']	20190529	20190318	2019 Apr	2019/03/20 06:00		['Deng, Yue', 'Bao, Feng', 'Dai, Qionghai', 'Wu, Lani F', 'Altschuler, Steven J']		['RO1 CA185404 /NH/NIH HHS/United States', 'CA184984 /NH/NIH HHS/United States', 'R01 EY028205/EY/NEI NIH HHS/United States', 'R01 CA185404/CA/NCI NIH HHS/United States', 'GM112690/NH/NIH HHS/United States', 'R01 EY028205 /NH/NIH HHS/United States', 'R01 CA184984/CA/NCI NIH HHS/United States', 'R01 GM112690/GM/NIGMS NIH HHS/United States']	4		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/s41592-019-0353-7 [doi]	20191023	['Algorithms', 'Animals', 'Brain Mapping', 'Cluster Analysis', 'Computational Biology/methods', 'Computer Simulation', '*Databases, Genetic', '*Deep Learning', '*Gene Expression Profiling', 'Inflammation', 'Intestines/cytology', 'Leukocytes, Mononuclear/cytology', 'Mice', 'Phenotype', 'Principal Component Analysis', 'RNA/analysis/*genetics', 'Reproducibility of Results', 'Retina/metabolism', 'Sequence Analysis, RNA', '*Single-Cell Analysis', 'Software', '*Transcriptome']	2019/05/30 06:00	['NIHMS1052036']			NLM	311-314	['2018/10/11 00:00 [received]', '2019/02/12 00:00 [accepted]', '2019/03/20 06:00 [pubmed]', '2019/05/30 06:00 [medline]', '2019/03/20 06:00 [entrez]']	United States	PMC6774994		30886411	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['63231-63-0 (RNA)']	IM		Nat Methods. 2019 Apr;16(4):311-314. doi: 10.1038/s41592-019-0353-7. Epub 2019 Mar 18.	MEDLINE	Nat Methods	Scalable analysis of cell-type composition from single-cell transcriptomics using deep recurrent learning.		16	Scalable analysis of cell-type composition from single-cell transcriptomics using deep recurrent learning.
This paper outlines typical terminology for modeling and highlights key historical and forthcoming aspects of mathematical modeling. Mathematical models (MM) are mental conceptualizations, enclosed in a virtual domain, whose purpose is to translate real-life situations into mathematical formulations to describe existing patterns or forecast future behaviors in real-life situations. The appropriateness of the virtual representation of real-life situations through MM depends on the modeler's ability to synthesize essential concepts and associate their interrelationships with measured data. The development of MM paralleled the evolution of digital computing. The scientific community has only slightly accepted and used MM, in part because scientists are trained in experimental research and not systems thinking. The scientific advancements in ruminant production have been tangible but incipient because we are still learning how to connect experimental research data and concepts through MM, a process that is still obscure to many scientists. Our inability to ask the right questions and to define the boundaries of our problem when developing models might have limited the breadth and depth of MM in agriculture. Artificial intelligence (AI) has been developed in tandem with the need to analyze big data using high-performance computing. However, the emergence of AI, a computational technology that is data-intensive and requires less systems thinking of how things are interrelated, may further reduce the interest in mechanistic, conceptual MM. Artificial intelligence might provide, however, a paradigm shift in MM, including nutrition modeling, by creating novel opportunities to understand the underlying mechanisms when integrating large amounts of quantifiable data. Associating AI with mechanistic models may eventually lead to the development of hybrid mechanistic machine-learning modeling. Modelers must learn how to integrate powerful data-driven tools and knowledge-driven approaches into functional models that are sustainable and resilient. The successful future of MM might rely on the development of redesigned models that can integrate existing technological advancements in data analytics to take advantage of accumulated scientific knowledge. However, the next evolution may require the creation of novel technologies for data gathering and analyses and the rethinking of innovative MM concepts rather than spending resources in collecting futile data or amending old technologies.	['Department of Animal Science, Texas A&M University, College Station, TX.']	['5382308 [pii]', '10.1093/jas/skz092 [doi]']	['Tedeschi LO']		['(c) The Author(s) 2019. Published by Oxford University Press on behalf of the', 'American Society of Animal Science.']					['2019/03/19 06:00']	20190828		2019 Apr 29	2019/03/19 06:00		['Tedeschi, Luis O']			5		1525-3163 (Electronic) 0021-8812 (Linking)	8003002	Journal of animal science	['eng']	10.1093/jas/skz092 [doi]	20190828	['Animal Nutritional Physiological Phenomena', 'Animals', '*Artificial Intelligence', 'Computer Simulation', '*Data Science', '*Machine Learning', '*Models, Theoretical', 'Ruminants/*physiology', '*Systems Analysis']	2019/08/29 06:00		['artificial intelligence', 'computer program', 'deep learning', 'machine learning', 'mathematical modeling and simulation', 'prediction']	['NOTNLM']	NLM	1921-1944	['2019/01/03 00:00 [received]', '2019/03/17 00:00 [accepted]', '2019/03/19 06:00 [pubmed]', '2019/08/29 06:00 [medline]', '2019/03/19 06:00 [entrez]']	United States	PMC6488328		30882142	ppublish	['Journal Article']			IM		J Anim Sci. 2019 Apr 29;97(5):1921-1944. doi: 10.1093/jas/skz092.	MEDLINE	J Anim Sci	ASN-ASAS SYMPOSIUM: FUTURE OF DATA ANALYTICS IN NUTRITION: Mathematical modeling in ruminant nutrition: approaches and paradigms, extant models, and thoughts for upcoming predictive analytics1,2.		97	ASN-ASAS SYMPOSIUM: FUTURE OF DATA ANALYTICS IN NUTRITION: Mathematical modeling in ruminant nutrition: approaches and paradigms, extant models, and thoughts for upcoming predictive analytics1,2.
Urban areas feature complex and heterogeneous land covers which create challenging issues for tree species classification. The increased availability of high spatial resolution multispectral satellite imagery and LiDAR datasets combined with the recent evolution of deep learning within remote sensing for object detection and scene classification, provide promising opportunities to map individual tree species with greater accuracy and resolution. However, there are knowledge gaps that are related to the contribution of Worldview-3 SWIR bands, very high resolution PAN band and LiDAR data in detailed tree species mapping. Additionally, contemporary deep learning methods are hampered by lack of training samples and difficulties of preparing training data. The objective of this study was to examine the potential of a novel deep learning method, Dense Convolutional Network (DenseNet), to identify dominant individual tree species in a complex urban environment within a fused image of WorldView-2 VNIR, Worldview-3 SWIR and LiDAR datasets. DenseNet results were compared against two popular machine classifiers in remote sensing image analysis, Random Forest (RF) and Support Vector Machine (SVM). Our results demonstrated that: (1) utilizing a data fusion approach beginning with VNIR and adding SWIR, LiDAR, and panchromatic (PAN) bands increased the overall accuracy of the DenseNet classifier from 75.9% to 76.8%, 81.1% and 82.6%, respectively. (2) DenseNet significantly outperformed RF and SVM for the classification of eight dominant tree species with an overall accuracy of 82.6%, compared to 51.8% and 52% for SVM and RF classifiers, respectively. (3) DenseNet maintained superior performance over RF and SVM classifiers under restricted training sample quantities which is a major limiting factor for deep learning techniques. Overall, the study reveals that DenseNet is more effective for urban tree species classification as it outperforms the popular RF and SVM techniques when working with highly complex image scenes regardless of training sample size.	['Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO 63108, USA. sean.hartling@slu.edu.', 'Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO 63108, USA. vasit.sagan@slu.edu.', 'Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO 63108, USA. sidike.paheding@slu.edu.', 'Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO 63108, USA. mason.maimaitijiang@slu.edu.', 'Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO 63108, USA. Joshua.Carron@slu.edu.']	['s19061284 [pii]', '10.3390/s19061284 [doi]']	['Hartling S', 'Sagan V', 'Sidike P', 'Maimaitijiang M', 'Carron J']	['ORCID: 0000-0003-4375-2096', 'ORCID: 0000-0003-4712-9672']						['2019/03/17 06:00']	20190415	20190314	2019 Mar 14	2019/03/17 06:00		['Hartling, Sean', 'Sagan, Vasit', 'Sidike, Paheding', 'Maimaitijiang, Maitiniyazi', 'Carron, Joshua']		['IIA1355406/National Science Foundation']	6		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1284 [pii] 10.3390/s19061284 [doi]	20190428	['*Deep Learning', 'Humans', 'Neural Networks (Computer)', '*Support Vector Machine']	2019/04/16 06:00		['convolutional neural network (CNN)', 'data fusion', 'deep learning', 'dense convolutional network (DenseNet)', 'random forest (RF)', 'support vector machine (SVM)', 'tree species classification']	['NOTNLM']	NLM		['2019/01/11 00:00 [received]', '2019/03/06 00:00 [revised]', '2019/03/09 00:00 [accepted]', '2019/03/17 06:00 [entrez]', '2019/03/17 06:00 [pubmed]', '2019/04/16 06:00 [medline]']	Switzerland	PMC6471063		30875732	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Mar 14;19(6). pii: s19061284. doi: 10.3390/s19061284.	MEDLINE	Sensors (Basel)	Urban Tree Species Classification Using a WorldView-2/3 and LiDAR Data Fusion Approach and Deep Learning.		19	Urban Tree Species Classification Using a WorldView-2/3 and LiDAR Data Fusion Approach and Deep Learning.
BACKGROUND: The ability to predict which pairs of amino acid residues in a protein are in contact with each other offers many advantages for various areas of research that focus on proteins. For example, contact prediction can be used to reduce the computational complexity of predicting the structure of proteins and even to help identify functionally important regions of proteins. These predictions are becoming especially important given the relatively low number of experimentally determined protein structures compared to the amount of available protein sequence data. RESULTS: Here we have developed and benchmarked a set of machine learning methods for performing residue-residue contact prediction, including random forests, direct-coupling analysis, support vector machines, and deep networks (stacked denoising autoencoders). These methods are able to predict contacting residue pairs given only the amino acid sequence of a protein. According to our own evaluations performed at a resolution of +/- two residues, the predictors we trained with the random forest algorithm were our top performing methods with average top 10 prediction accuracy scores of 85.13% (short range), 74.49% (medium range), and 54.49% (long range). Our ensemble models (stacked denoising autoencoders combined with support vector machines) were our best performing deep network predictors and achieved top 10 prediction accuracy scores of 75.51% (short range), 60.26% (medium range), and 43.85% (long range) using the same evaluation. These tests were blindly performed on targets from the CASP11 dataset; and the results suggested that our models achieved comparable performance to contact predictors developed by groups that participated in CASP11. CONCLUSIONS: Due to the challenging nature of contact prediction, it is beneficial to develop and benchmark a variety of different prediction methods. Our work has produced useful tools with a simple interface that can provide contact predictions to users without requiring a lengthy installation process. In addition to this, we have released our C++ implementation of the direct-coupling analysis method as a standalone software package. Both this tool and our RFcon web server are freely available to the public at http://dna.cs.miami.edu/RFcon /.	['School of Computing Sciences and Computer Engineering, University of Southern Mississippi, 118 College Drive, Hattiesburg, MS, 39406, USA.', 'Department of Computer Science, University of Miami, 1365 Memorial Drive, Coral Gables, FL, 33124, USA.', 'School of Computing Sciences and Computer Engineering, University of Southern Mississippi, 118 College Drive, Hattiesburg, MS, 39406, USA.', 'Department of Computer Science, University of Miami, 1365 Memorial Drive, Coral Gables, FL, 33124, USA. zheng.wang@miami.edu.']	['10.1186/s12859-019-2627-6 [doi]', '10.1186/s12859-019-2627-6 [pii]']	['Luttrell J 4th', 'Liu T', 'Zhang C', 'Wang Z']							['2019/03/16 06:00']	20190502	20190314	2019 Mar 14	2019/03/16 06:00		['Luttrell, Joseph 4th', 'Liu, Tong', 'Zhang, Chaoyang', 'Wang, Zheng']		['R15 GM120650/GM/NIGMS NIH HHS/United States']	Suppl 2		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2627-6 [doi]	20190502	['Amino Acid Sequence', 'Computational Biology/*methods', 'Machine Learning/*standards', 'Proteins/*metabolism']	2019/05/03 06:00		['Direct coupling analysis', 'Protein', 'Random forest', 'Residue-residue contact prediction', 'Web server']	['NOTNLM']	NLM	100	['2019/03/16 06:00 [entrez]', '2019/03/16 06:00 [pubmed]', '2019/05/03 06:00 [medline]']	England	PMC6419322		30871477	epublish	['Journal Article']		['0 (Proteins)']	IM		BMC Bioinformatics. 2019 Mar 14;20(Suppl 2):100. doi: 10.1186/s12859-019-2627-6.	MEDLINE	BMC Bioinformatics	Predicting protein residue-residue contacts using random forests and deep networks.		20	Predicting protein residue-residue contacts using random forests and deep networks.
Detection of abnormalities in wireless capsule endoscopy (WCE) images is a challenging task. Typically, these images suffer from low contrast, complex background, variations in lesion shape and color, which affect the accuracy of their segmentation and subsequent classification. This research proposes an automated system for detection and classification of ulcers in WCE images, based on state-of-the-art deep learning networks. Deep learning techniques, and in particular, convolutional neural networks (CNNs), have recently become popular in the analysis and recognition of medical images. The medical image datasets used in this study were obtained from WCE video frames. In this work, two milestone CNN architectures, namely the AlexNet and the GoogLeNet are extensively evaluated in object classification into ulcer or non-ulcer. Furthermore, we examine and analyze the images identified as containing ulcer objects to evaluate the efficiency of the utilized CNNs. Extensive experiments show that CNNs deliver superior performance, surpassing traditional machine learning methods by large margins, which supports their effectiveness as automated diagnosis tools.	['Department of Computer Science, College of Computer Engineering and Sciences Prince Sattam Bin Abdulaziz University, Alkharj 11942, Saudi Arabia. h.alaskar@psau.edu.sa.', 'Department of Computer Science, Liverpool John Moores University, Liverpool L3 3AF, UK. a.hussain@ljmu.ac.uk.', 'Department of Computer Science, College of Computer Engineering and Sciences Prince Sattam Bin Abdulaziz University, Alkharj 11942, Saudi Arabia. N.alaseem@psau.edu.sa.', 'Department of Computer Science, Khalifa University of Science and Technology, Abu Dhabi 127788, UAE. panos.liatsis@ku.ac.ae.', 'Department of Computer Science, Liverpool John Moores University, Liverpool L3 3AF, UK. D.AlJumeily@ljmu.ac.uk.']	['s19061265 [pii]', '10.3390/s19061265 [doi]']	['Alaskar H', 'Hussain A', 'Al-Aseem N', 'Liatsis P', 'Al-Jumeily D']	['ORCID: 0000-0002-1688-0669', 'ORCID: 0000-0002-5490-6030']						['2019/03/16 06:00']	20190415	20190313	2019 Mar 13	2019/03/16 06:00		['Alaskar, Haya', 'Hussain, Abir', 'Al-Aseem, Nourah', 'Liatsis, Panos', 'Al-Jumeily, Dhiya']			6		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1265 [pii] 10.3390/s19061265 [doi]	20190428	['Capsule Endoscopy/*methods', 'Deep Learning', 'Humans', 'Image Interpretation, Computer-Assisted', 'Image Processing, Computer-Assisted', 'Machine Learning', '*Neural Networks (Computer)', 'Ulcer/*diagnostic imaging']	2019/04/16 06:00		['AlexNet', 'GoogLeNet', 'convolutional neural networks', 'deep learning networks', 'ulcer detection', 'wireless capsule endoscopy']	['NOTNLM']	NLM		['2019/01/24 00:00 [received]', '2019/02/24 00:00 [revised]', '2019/03/08 00:00 [accepted]', '2019/03/16 06:00 [entrez]', '2019/03/16 06:00 [pubmed]', '2019/04/16 06:00 [medline]']	Switzerland	PMC6471286		30871162	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Mar 13;19(6). pii: s19061265. doi: 10.3390/s19061265.	MEDLINE	Sensors (Basel)	Application of Convolutional Neural Networks for Automated Ulcer Detection in Wireless Capsule Endoscopy Images.		19	Application of Convolutional Neural Networks for Automated Ulcer Detection in Wireless Capsule Endoscopy Images.
PURPOSE: To develop a deep learning method for prediction of three-dimensional (3D) voxel-by-voxel dose distributions of helical tomotherapy (HT). METHODS: Using previously treated HT plans as training data, a deep learning model named U-ResNet-D was trained to predict a 3D dose distribution. First, the contoured structures and dose volumes were converted from plan database to 3D matrix with a program based on a developed visualization toolkit (VTK), then transferred to U-ResNet-D for correlating anatomical features and dose distributions at voxel-level. One hundred and ninety nasopharyngeal cancer (NPC) patients treated by HT with multiple planning target volumes (PTVs) in different prescription patterns were studied. The model was typically trained from scratch with weights randomly initialized rather than using transfer-learning method, and used to predict new patient's 3D dose distributions. The predictive accuracy was evaluated with three methods: (a) The dose difference at the position r, delta(r, r) = Dc (r) - Dp (r), was calculated for each voxel. The mean (mudelta(r,r) ) and standard deviation (sigmadelta(r,r) ) of delta(r, r) were calculated to assess the prediction bias and precision; (b) The mean absolute differences of dosimetric indexes (DIs) including maximum and mean dose, homogeneity index, conformity index, and dose spillage for PTVs and organ at risks (OARs) were calculated and statistically analyzed with the paired-samples t test; (c) Dice similarity coefficients (DSC) between predicted and clinical isodose volumes were calculated. RESULTS: The U-ResNet-D model predicted 3D dose distribution accurately. For twenty tested patients, the prediction bias ranged from -2.0% to 2.3% and prediction error varied from 1.5% to 4.5% (relative to prescription) for 3D dose differences. The mean absolute dose differences for PTVs and OARs are within 2.0% and 4.2%, and nearly all the DIs for PTVs and OARs had no significant differences. The averaged DSC ranged from 0.95 to 1 for different isodose volumes. CONCLUSIONS: The study developed a new deep learning method for 3D voxel-by-voxel dose prediction, and shown to be able to produce accurately dose predictions for nasopharyngeal patients treated by HT. The predicted 3D dose map can be useful for improving radiotherapy planning design, ensuring plan quality and consistency, making clinical technique comparison, and guiding automatic treatment planning.	['National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, 17 Panjiayuannanli, Chaoyang District, Beijing, 100021, China.']	['10.1002/mp.13490 [doi]']	['Liu Z', 'Fan J', 'Li M', 'Yan H', 'Hu Z', 'Huang P', 'Tian Y', 'Miao J', 'Dai J']		['(c) 2019 American Association of Physicists in Medicine.']					['2019/03/15 06:00']	20190912	20190330	2019 May	2019/03/15 06:00		['Liu, Zhiqiang', 'Fan, Jiawei', 'Li, Minghui', 'Yan, Hui', 'Hu, Zhihui', 'Huang, Peng', 'Tian, Yuan', 'Miao, Junjie', 'Dai, Jianrong']		['LC2018B07/Beijing Hope Run Special Fund of Cancer Foundation of China', '11875320/National Natural Science Foundation of China', '11805039/National Natural Science Foundation of China', '2016YFC0904600/National Key Projects of Research and Development of China']	5		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13490 [doi]	20190912	['*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Nasopharyngeal Neoplasms/diagnostic imaging/*radiotherapy', 'Organs at Risk/radiation effects', 'Radiotherapy Dosage', 'Radiotherapy Planning, Computer-Assisted/*methods', 'Radiotherapy, Intensity-Modulated/methods', 'Tomography, X-Ray Computed/methods']	2019/09/13 06:00		['3D dose prediction', 'deep learning', 'helical tomotherapy', 'nasopharyngeal cancers']	['NOTNLM']	NLM	1972-1983	['2018/11/29 00:00 [received]', '2019/02/14 00:00 [revised]', '2019/03/04 00:00 [accepted]', '2019/03/15 06:00 [pubmed]', '2019/09/13 06:00 [medline]', '2019/03/15 06:00 [entrez]']	United States			30870586	ppublish	['Journal Article']			IM		Med Phys. 2019 May;46(5):1972-1983. doi: 10.1002/mp.13490. Epub 2019 Mar 30.	MEDLINE	Med Phys	A deep learning method for prediction of three-dimensional dose distribution of helical tomotherapy.		46	A deep learning method for prediction of three-dimensional dose distribution of helical tomotherapy.
BACKGROUND: Plant pests mainly refers to insects and mites that harm crops and products. There are a wide variety of plant pests, with wide distribution, fast reproduction and large quantity, which directly causes serious losses to crops. Therefore, pest recognition is very important for crops to grow healthily, and this in turn affects crop yields and quality. At present, it is a great challenge to realize accurate and reliable pest identification. RESULTS: In this study, we put forward a diagnostic system based on transfer learning for pest detection and recognition. This method is able to train and test ten types of pests and achieves an accuracy of 93.84%. We compared this transfer learning method with human experts and a traditional neural network model. Experimental results show that the performance of the proposed method is comparable to human experts and the traditional neural network. To verify the general adaptability of this model, we used our model to recognize two types of weeds: Sisymbrium sophia and Procumbent Speedwell, and achieved an accuracy of 98.92%. CONCLUSION: The proposed method can provide evidence for the control of pests and weeds and the precise spraying of pesticides. Thus, it provides reliable technical support for precision agriculture. (c) 2019 Society of Chemical Industry.	['Department of electronic information, Science and Information College, Qingdao Agriculture University, Qingdao, China.', 'Department of electronic information, Science and Information College, Qingdao Agriculture University, Qingdao, China.', 'Department of electronic information, Science and Information College, Qingdao Agriculture University, Qingdao, China.', 'Department of electronic information, Science and Information College, Qingdao Agriculture University, Qingdao, China.', 'Department of electronic information, Science and Information College, Qingdao Agriculture University, Qingdao, China.', 'Department of electronic information, Science and Information College, Qingdao Agriculture University, Qingdao, China.']	['10.1002/jsfa.9689 [doi]']	['Dawei W', 'Limiao D', 'Jiangong N', 'Jiyue G', 'Hongfei Z', 'Zhongzhi H']	['ORCID: https://orcid.org/0000-0003-1878-3034', 'ORCID: https://orcid.org/0000-0002-5662-319X']	['(c) 2019 Society of Chemical Industry.']					['2019/03/15 06:00']	20190806	20190422	2019 Aug 15	2019/03/15 06:00		['Dawei, Wang', 'Limiao, Deng', 'Jiangong, Ni', 'Jiyue, Gao', 'Hongfei, Zhu', 'Zhongzhi, Han']		['ZR2017MC041/Natural Science Foundation of Shandong Province', '31872849/National Natural Science Foundation of China']	10		1097-0010 (Electronic) 0022-5142 (Linking)	0376334	Journal of the science of food and agriculture	['eng']	10.1002/jsfa.9689 [doi]	20190806	['Animals', 'Crops, Agricultural/*parasitology', 'Humans', 'Image Processing, Computer-Assisted', 'Insecta/*physiology', '*Machine Learning', 'Neural Networks (Computer)', 'Pest Control/instrumentation/*methods', 'Plant Diseases/parasitology', 'Plant Weeds/physiology', 'Weed Control/instrumentation/*methods']	2019/08/07 06:00		['deep learning', 'model universal', 'pest recognition', 'transfer learning']	['NOTNLM']	NLM	4524-4531	['2018/12/09 00:00 [received]', '2019/03/02 00:00 [revised]', '2019/03/07 00:00 [accepted]', '2019/03/15 06:00 [pubmed]', '2019/08/07 06:00 [medline]', '2019/03/15 06:00 [entrez]']	England			30868598	ppublish	['Evaluation Studies', 'Journal Article']					J Sci Food Agric. 2019 Aug 15;99(10):4524-4531. doi: 10.1002/jsfa.9689. Epub 2019 Apr 22.	MEDLINE	J Sci Food Agric	Recognition pest by image-based transfer learning.		99	Recognition pest by image-based transfer learning.
Molecular recognition features (MoRFs) are key functional regions of intrinsically disordered proteins (IDPs), which play important roles in the molecular interaction network of cells and are implicated in many serious human diseases. Identifying MoRFs is essential for both functional studies of IDPs and drug design. This study adopts the cutting-edge machine learning method of artificial intelligence to develop a powerful model for improving MoRFs prediction. We proposed a method, named as en_DCNNMoRF (ensemble deep convolutional neural network-based MoRF predictor). It combines the outcomes of two independent deep convolutional neural network (DCNN) classifiers that take advantage of different features. The first, DCNNMoRF1, employs position-specific scoring matrix (PSSM) and 22 types of amino acid-related factors to describe protein sequences. The second, DCNNMoRF2, employs PSSM and 13 types of amino acid indexes to describe protein sequences. For both single classifiers, DCNN with a novel two-dimensional attention mechanism was adopted, and an average strategy was added to further process the output probabilities of each DCNN model. Finally, en_DCNNMoRF combined the two models by averaging their final scores. When compared with other well-known tools applied to the same datasets, the accuracy of the novel proposed method was comparable with that of state-of-the-art methods. The related web server can be accessed freely via http://vivace.bi.a.u-tokyo.ac.jp:8008/fang/en_MoRFs.php .	['* Department of Computer Science and Engineering, Shandong University of Technology, Shandong 255049, P. R. China.', 'dagger Graduate School of Agricultural and Life Sciences, The University of Tokyo, Tokyo 113-8657, Japan.', '* Department of Computer Science and Engineering, Shandong University of Technology, Shandong 255049, P. R. China.', '* Department of Computer Science and Engineering, Shandong University of Technology, Shandong 255049, P. R. China.', 'dagger Graduate School of Agricultural and Life Sciences, The University of Tokyo, Tokyo 113-8657, Japan.']	['10.1142/S0219720019500045 [doi]']	['Fang C', 'Moriwaki Y', 'Tian A', 'Li C', 'Shimizu K']	['ORCID: 0000-0002-3245-0052']						['2019/03/15 06:00']			2019 Feb	2019/03/15 06:00		['Fang, Chun', 'Moriwaki, Yoshitaka', 'Tian, Aikui', 'Li, Caihong', 'Shimizu, Kentaro']			1		1757-6334 (Electronic) 0219-7200 (Linking)	101187344	Journal of bioinformatics and computational biology	['eng']	10.1142/S0219720019500045 [doi]	20191120		2019/03/15 06:00		['*Disordered proteins', '*deep learning', '*molecular recognition features', '*prediction']	['NOTNLM']	NLM	1950004	['2019/03/15 06:00 [entrez]', '2019/03/15 06:00 [pubmed]', '2019/03/15 06:00 [medline]']	Singapore			30866736	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Bioinform Comput Biol. 2019 Feb;17(1):1950004. doi: 10.1142/S0219720019500045.	In-Process	J Bioinform Comput Biol	Identifying short disorder-to-order binding regions in disordered proteins with a deep convolutional neural network method.		17	Identifying short disorder-to-order binding regions in disordered proteins with a deep convolutional neural network method.
Gentrification is multidimensional and complex, but there is general agreement that visible changes to neighbourhoods are a clear manifestation of the process. Recent advances in computer vision and deep learning provide a unique opportunity to support automated mapping or 'deep mapping' of perceptual environmental attributes. We present a Siamese convolutional neural network (SCNN) that automatically detects gentrification-like visual changes in temporal sequences of Google Street View (GSV) images. Our SCNN achieves 95.6% test accuracy and is subsequently applied to GSV sequences at 86110 individual properties over a 9-year period in Ottawa, Canada. We use Kernel Density Estimation (KDE) to produce maps that illustrate where the spatial concentration of visual property improvements was highest within the study area at different times from 2007-2016. We find strong concordance between the mapped SCNN results and the spatial distribution of building permits in the City of Ottawa from 2011 to 2016. Our mapped results confirm those urban areas that are known to be undergoing gentrification as well as revealing areas undergoing gentrification that were previously unknown. Our approach differs from previous works because we examine the atomic unit of gentrification, namely, the individual property, for visual property improvements over time and we rely on KDE to describe regions of high spatial intensity that are indicative of gentrification processes.	"['Laboratory for Applied Geomatics and GIS Science (LAGGISS), Department of Geography, Environment and Geomatics, University of Ottawa, Ottawa, Canada.', 'Laboratory for Applied Geomatics and GIS Science (LAGGISS), Department of Geography, Environment and Geomatics, University of Ottawa, Ottawa, Canada.', 'Laboratory for Applied Geomatics and GIS Science (LAGGISS), Department of Geography, Environment and Geomatics, University of Ottawa, Ottawa, Canada.', ""l'Ecole nationale des sciences geographiques (ENSG-Geomatique), Paris, Champs-sur-Marne, France.""]"	['10.1371/journal.pone.0212814 [doi]', 'PONE-D-18-32613 [pii]']	['Ilic L', 'Sawada M', 'Zarzelli A']	['ORCID: 0000-0001-5180-5325', 'ORCID: 0000-0002-4221-0589']				['The authors have declared that no competing interests exist.']		['2019/03/14 06:00']	20191127	20190313	2019	2019/03/14 06:00		['Ilic, Lazar', 'Sawada, M', 'Zarzelli, Amaury']			3		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0212814 [doi]	20191127	['Canada', 'Cities/statistics & numerical data', 'Deep Learning', 'Geographic Mapping', 'Humans', '*Residence Characteristics', '*Social Change', 'Spatial Analysis']	2019/11/28 06:00				NLM	e0212814	['2018/11/13 00:00 [received]', '2019/02/08 00:00 [accepted]', '2019/03/14 06:00 [entrez]', '2019/03/14 06:00 [pubmed]', '2019/11/28 06:00 [medline]']	United States	PMC6415887		30865701	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2019 Mar 13;14(3):e0212814. doi: 10.1371/journal.pone.0212814. eCollection 2019.	MEDLINE	PLoS One	Deep mapping gentrification in a large Canadian city using deep learning and Google Street View.		14	Deep mapping gentrification in a large Canadian city using deep learning and Google Street View.
Noncoding single nucleotide polymorphisms (SNPs) and their target genes are important components of the heritability of diseases and other polygenic traits. Identifying these SNPs and target genes could potentially reveal new molecular mechanisms and advance precision medicine. For polygenic traits, genome-wide association studies (GWAS) are preferred tools for identifying trait-associated regions. However, identifying causal noncoding SNPs within such regions is a difficult problem in computational biology. The DNA sequence context of a noncoding SNP is well-established as an important source of information that is beneficial for discriminating functional from nonfunctional noncoding SNPs. We describe the use of a deep residual network (ResNet)-based model-entitled Res2s2aM-that fuses anking DNA sequence information with additional SNP annotation information to discriminate functional from nonfunctional noncoding SNPs. On a ground-truth set of disease-associated SNPs compiled from the Genome-wide Repository of Associations between SNPs and Phenotypes (GRASP) database, Res2s2aM improves the prediction accuracy of functional SNPs significantly in comparison to models based only on sequence information as well as a leading tool for post-GWAS noncoding SNP prioritization (RegulomeDB).	['School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, 97330, USA2Department of Biomedical Sciences, Oregon State University, Corvallis, OR, 97330, USA.']	['9789813279827_0008 [pii]']	['Liu Z', 'Yao Y', 'Wei Q', 'Weeder B', 'Ramsey SA']							['2019/03/14 06:00']	20190823		2019	2019/03/14 06:00		['Liu, Zheng', 'Yao, Yao', 'Wei, Qi', 'Weeder, Benjamin', 'Ramsey, Stephen A']					2335-6936 (Electronic) 2335-6928 (Linking)	9711271	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	['eng']		20190823	['Algorithms', 'Computational Biology', 'Databases, Nucleic Acid/statistics & numerical data', '*Deep Learning', 'Genome-Wide Association Study/statistics & numerical data', 'Humans', 'Models, Genetic', 'Molecular Sequence Annotation', '*Neural Networks (Computer)', '*Polymorphism, Single Nucleotide', 'Sequence Analysis, DNA']	2019/08/24 06:00				NLM	76-87	['2019/03/14 06:00 [entrez]', '2019/03/14 06:00 [pubmed]', '2019/08/24 06:00 [medline]']	United States			30864312	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"					Pac Symp Biocomput. 2019;24:76-87.	MEDLINE	Pac Symp Biocomput	Res2s2aM: Deep residual network-based model for identifying functional noncoding SNPs in trait-associated regions.		24	Res2s2aM: Deep residual network-based model for identifying functional noncoding SNPs in trait-associated regions.
Protein domain boundary prediction is usually an early step to understand protein function and structure. Most of the current computational domain boundary prediction methods suffer from low accuracy and limitation in handling multi-domain types, or even cannot be applied on certain targets such as proteins with discontinuous domain. We developed an ab-initio protein domain predictor using a stacked bidirectional LSTM model in deep learning. Our model is trained by a large amount of protein sequences without using feature engineering such as sequence profiles. Hence, the predictions using our method is much faster than others, and the trained model can be applied to any type of target proteins without constraint. We evaluated DeepDom by a 10-fold cross validation and also by applying it on targets in different categories from CASP 8 and CASP 9. The comparison with other methods has shown that DeepDom outperforms most of the current ab-initio methods and even achieves better results than the top-level template-based method in certain cases. The code of DeepDom and the test data we used in CASP 8, 9 can be accessed through GitHub at https://github.com/yuexujiang/DeepDom.	['Department of Electrical Engineering and Computer Science, Bond Life Sciences Center, University of Missouri, Columbia, Missouri 65211, USA.']	['9789813279827_0007 [pii]']	['Jiang Y', 'Wang D', 'Xu D']							['2019/03/14 06:00']	20190823		2019	2019/03/14 06:00		['Jiang, Yuexu', 'Wang, Duolin', 'Xu, Dong']		['R35 GM126985/GM/NIGMS NIH HHS/United States']			2335-6936 (Electronic) 2335-6928 (Linking)	9711271	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	['eng']		20190823	['Algorithms', 'Amino Acid Sequence', 'Computational Biology', 'Databases, Protein', '*Deep Learning', 'Neural Networks (Computer)', '*Protein Domains']	2019/08/24 06:00	['NIHMS999768']			NLM	66-75	['2019/03/14 06:00 [entrez]', '2019/03/14 06:00 [pubmed]', '2019/08/24 06:00 [medline]']	United States	PMC6417825		30864311	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']					Pac Symp Biocomput. 2019;24:66-75.	MEDLINE	Pac Symp Biocomput	DeepDom: Predicting protein domain boundary from sequence alone using stacked bidirectional LSTM.		24	DeepDom: Predicting protein domain boundary from sequence alone using stacked bidirectional LSTM.
"The proliferation of healthcare data has brought the opportunities of applying data-driven approaches, such as machine learning methods, to assist diagnosis. Recently, many deep learning methods have been shown with impressive successes in predicting disease status with raw input data. However, the ""black-box"" nature of deep learning and the highreliability requirement of biomedical applications have created new challenges regarding the existence of confounding factors. In this paper, with a brief argument that inappropriate handling of confounding factors will lead to models' sub-optimal performance in real-world applications, we present an efficient method that can remove the inuences of confounding factors such as age or gender to improve the across-cohort prediction accuracy of neural networks. One distinct advantage of our method is that it only requires minimal changes of the baseline model's architecture so that it can be plugged into most of the existing neural networks. We conduct experiments across CT-scan, MRA, and EEG brain wave with convolutional neural networks and LSTM to verify the efficiency of our method."	['School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA, haohanw@cs.cmu.edu.']	['9789813279827_0006 [pii]']	['Wang H', 'Wu Z', 'Xing EP']							['2019/03/14 06:00']	20190823		2019	2019/03/14 06:00		['Wang, Haohan', 'Wu, Zhenglin', 'Xing, Eric P']		['P30 DA035778/DA/NIDA NIH HHS/United States', 'R01 GM093156/GM/NIGMS NIH HHS/United States']			2335-6936 (Electronic) 2335-6928 (Linking)	9711271	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	['eng']		20190823	['Computational Biology', '*Deep Learning', 'Diagnosis, Computer-Assisted', 'Humans', 'Machine Learning', '*Medical Informatics', 'Medical Informatics Applications', 'Medical Informatics Computing', '*Neural Networks (Computer)']	2019/08/24 06:00	['NIHMS999766']			NLM	54-65	['2019/03/14 06:00 [entrez]', '2019/03/14 06:00 [pubmed]', '2019/08/24 06:00 [medline]']	United States	PMC6417810		30864310	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"					Pac Symp Biocomput. 2019;24:54-65.	MEDLINE	Pac Symp Biocomput	Removing Confounding Factors Associated Weights in Deep Neural Networks Improves the Prediction Accuracy for Healthcare Applications.		24	Removing Confounding Factors Associated Weights in Deep Neural Networks Improves the Prediction Accuracy for Healthcare Applications.
Remaining useful life (RUL) estimation is one of the most important component in prognostic health management (PHM) system in modern industry. It defined as the length from the current time to the end of the useful life. With the rapid development of the smart manufacturing, the data-driven RUL approaches have been widely investigated in both academic and engineering fields. Deep learning, which is a new paradigm in machine learning, has been applied in the RUL related fields, and has achieved remarkable results. However, classical deep learning algorithms also encounter the vanishing/exploding gradient problem found in artificial neural network with gradient-based learning methods and backpropagation. In this research, a new residual convolutional neural network (ResCNN) is proposed. ResCNN applies the residual block which skips several blocks of convolutional layers by using shortcut connections, and can help to overcome vanishing/exploding gradient problem. What's more, the ResCNN is enhanced by using the k-fold ensemble method. The proposed ensemble ResCNN is conducted on the C-MAPSS data provided by NASA. The results show that the proposed ensemble ResCNN has achieved significant improvement in both the mean and the standard deviation of the prediction RUL values. The proposed ensemble ResCNN has also compared with other famous machine learning and deep learning methods, including Multilayer Perceptron, Support Vector Machines, Deep Belief Networks, Long Short-Term Memory Model, Convolutional Neural Network and many other methods in literatures. The comparison results show that ensemble ResCNN achieved the start-of-the-art results, and outperform almost all of them.	['The State Key Laboratory of Digital Manufacturing Equipment & Technology, School of Mechanical Science & Engineering, Huazhong University of Science & Technology, Wuhan, 430074, China.']	['10.3934/mbe.2019040 [doi]']	['Wen L', 'Dong Y', 'Gao L']							['2019/03/14 06:00']	20190822		2019 Jan 28	2019/03/14 06:00		['Wen, Long', 'Dong, Yan', 'Gao, Liang']			2		1551-0018 (Electronic) 1547-1063 (Linking)	101197794	Mathematical biosciences and engineering : MBE	['eng']	10.3934/mbe.2019040 [doi]	20190822	['Algorithms', 'Computer Simulation', 'Deep Learning', 'Fuzzy Logic', 'Internet', 'Learning', 'Linear Models', 'Longevity', '*Neural Networks (Computer)', '*Prognosis', '*Support Vector Machine', 'Time Factors']	2019/08/23 06:00		['* convolutional neural network', '* ensemble learning', '* prognostic health management', '* remaining useful life estimation', '* residual network']	['NOTNLM']	NLM	862-880	['2019/03/14 06:00 [entrez]', '2019/03/14 06:00 [pubmed]', '2019/08/23 06:00 [medline]']	United States			30861669	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					Math Biosci Eng. 2019 Jan 28;16(2):862-880. doi: 10.3934/mbe.2019040.	MEDLINE	Math Biosci Eng	A new ensemble residual convolutional neural network for remaining useful life estimation.		16	A new ensemble residual convolutional neural network for remaining useful life estimation.
Hubel and Wiesel's study about low areas of the visual cortex (VC) inspired deep models for invariant pattern recognition. In such models, simple and complex layers alternate local feature extraction with subsampling to add invariance to distortion or transformations. However, it was shown that to tolerate large changes between examples of the same category, the subsampling operation has to discard so much information that the model loses the capability to discriminate between categories. So, in practice, small changes are tolerated by these layers and, afterwards, a powerful classifier is introduced to do the rest. By incorporating insights from higher areas of the VC, we add to the already used retinotopic step an object-centered step which increases invariance capabilities without losing so much information. By doing so, we reduce the need for a powerful, data hungry classification layer and, thus, are able to introduce a simple classification mechanism which is based on selective attention. The resulting model is tested with an invariant pattern recognition task in the MNIST and ETL-1 datasets. We verify that the model is able to achieve better accuracies with less training examples. More specifically, on the MNIST test set, the model achieves a 100% accuracy when trained with little more than 10% of the training set.	['Department of Computer Science and Engineering, INESC-ID & Instituto Superior Tecnico, University of Lisbon, Av. Prof. Dr. Anibal Cavaco Silva, 2744-016 Porto Salvo, Portugal. Electronic address: luis.sa.couto@tecnico.ulisboa.pt.', 'Department of Computer Science and Engineering, INESC-ID & Instituto Superior Tecnico, University of Lisbon, Av. Prof. Dr. Anibal Cavaco Silva, 2744-016 Porto Salvo, Portugal. Electronic address: andreas.wichert@tecnico.ulisboa.pt.']	['S0893-6080(19)30040-1 [pii]', '10.1016/j.neunet.2019.01.018 [doi]']	['Sa-Couto L', 'Wichert A']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/03/12 06:00']	20190705	20190226	2019 Jun	2019/03/12 06:00		['Sa-Couto, Luis', 'Wichert, Andreas']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30040-1 [pii] 10.1016/j.neunet.2019.01.018 [doi]	20190705	['*Machine Learning', 'Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods']	2019/07/06 06:00		"['Deep learning', ""Hubel Wiesel's hypothesis"", 'Invariant pattern recognition', 'Selective attention', 'Steep learning']"	['NOTNLM']	NLM	38-46	['2018/03/18 00:00 [received]', '2019/01/10 00:00 [revised]', '2019/01/31 00:00 [accepted]', '2019/03/12 06:00 [pubmed]', '2019/07/06 06:00 [medline]', '2019/03/12 06:00 [entrez]']	United States			30856532	ppublish	['Journal Article']			IM		Neural Netw. 2019 Jun;114:38-46. doi: 10.1016/j.neunet.2019.01.018. Epub 2019 Feb 26.	MEDLINE	Neural Netw	Attention Inspired Network: Steep learning curve in an invariant pattern recognition model.		114	Attention Inspired Network: Steep learning curve in an invariant pattern recognition model.
Importance: Proper evaluation of the performance of artificial intelligence techniques in the analysis of digitized medical images is paramount for the adoption of such techniques by the medical community and regulatory agencies. Objectives: To compare several cross-validation (CV) approaches to evaluate the performance of a classifier for automatic grading of prostate cancer in digitized histopathologic images and compare the performance of the classifier when trained using data from 1 expert and multiple experts. Design, Setting, and Participants: This quality improvement study used tissue microarray data (333 cores) from 231 patients who underwent radical prostatectomy at the Vancouver General Hospital between June 27, 1997, and June 7, 2011. Digitized images of tissue cores were annotated by 6 pathologists for 4 classes (benign and Gleason grades 3, 4, and 5) between December 12, 2016, and October 5, 2017. Patches of 192 microm2 were extracted from these images. There was no overlap between patches. A deep learning classifier based on convolutional neural networks was trained to predict a class label from among the 4 classes (benign and Gleason grades 3, 4, and 5) for each image patch. The classification performance was evaluated in leave-patches-out CV, leave-cores-out CV, and leave-patients-out 20-fold CV. The analysis was performed between November 15, 2018, and January 1, 2019. Main Outcomes and Measures: The classifier performance was evaluated by its accuracy, sensitivity, and specificity in detection of cancer (benign vs cancer) and in low-grade vs high-grade differentiation (Gleason grade 3 vs grades 4-5). The statistical significance analysis was performed using the McNemar test. The agreement level between pathologists and the classifier was quantified using a quadratic-weighted kappa statistic. Results: On 333 tissue microarray cores from 231 participants with prostate cancer (mean [SD] age, 63.2 [6.3] years), 20-fold leave-patches-out CV resulted in mean (SD) accuracy of 97.8% (1.2%), sensitivity of 98.5% (1.0%), and specificity of 97.5% (1.2%) for classifying benign patches vs cancerous patches. By contrast, 20-fold leave-patients-out CV resulted in mean (SD) accuracy of 85.8% (4.3%), sensitivity of 86.3% (4.1%), and specificity of 85.5% (7.2%). Similarly, 20-fold leave-cores-out CV resulted in mean (SD) accuracy of 86.7% (3.7%), sensitivity of 87.2% (4.0%), and specificity of 87.7% (5.5%). Results of McNemar tests showed that the leave-patches-out CV accuracy, sensitivity, and specificity were significantly higher than those for both leave-patients-out CV and leave-cores-out CV. Similar results were observed for classifying low-grade cancer vs high-grade cancer. When trained on a single expert, the overall agreement in grading between pathologists and the classifier ranged from 0.38 to 0.58; when trained using the majority vote among all experts, it was 0.60. Conclusions and Relevance: Results of this study suggest that in prostate cancer classification from histopathologic images, patch-wise CV and single-expert training and evaluation may lead to a biased estimation of classifier's performance. To allow reproducibility and facilitate comparison between automatic classification methods, studies in the field should evaluate their performance using patient-based CV and multiexpert data. Some of these conclusions may be generalizable to other histopathologic applications and to other applications of machine learning in medicine.	['Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Urologic Sciences, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Urologic Sciences, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Urologic Sciences, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Pathology and Laboratory Medicine, Vancouver General Hospital, Vancouver, British Columbia, Canada.', 'British Columbia Cancer Agency, Vancouver, British Columbia, Canada.', 'Department of Urologic Sciences, University of British Columbia, Vancouver, British Columbia, Canada.', 'Richmond Hospital, Vancouver Coastal Health, Richmond, British Columbia, Canada.', 'Department of Pathology and Laboratory Medicine, Vancouver General Hospital, Vancouver, British Columbia, Canada.', 'British Columbia Cancer Agency, Vancouver, British Columbia, Canada.', 'British Columbia Cancer Agency, Vancouver, British Columbia, Canada.', 'Emmes Canada, Burnaby, British Columbia, Canada.', 'Department of Statistics and Actuarial Science, Simon Fraser University, Burnaby, British Columbia, Canada.', 'Department of Urologic Sciences, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, British Columbia, Canada.', 'Department of Urologic Sciences, University of British Columbia, Vancouver, British Columbia, Canada.']	['2727273 [pii]', '10.1001/jamanetworkopen.2019.0442 [doi]']	['Nir G', 'Karimi D', 'Goldenberg SL', 'Fazli L', 'Skinnider BF', 'Tavassoli P', 'Turbin D', 'Villamil CF', 'Wang G', 'Thompson DJS', 'Black PC', 'Salcudean SE']							['2019/03/09 06:00']	20191125	20190301	2019 Mar 1	2019/03/09 06:00		['Nir, Guy', 'Karimi, Davood', 'Goldenberg, S Larry', 'Fazli, Ladan', 'Skinnider, Brian F', 'Tavassoli, Peyman', 'Turbin, Dmitry', 'Villamil, Carlos F', 'Wang, Gang', 'Thompson, Darby J S', 'Black, Peter C', 'Salcudean, Septimiu E']			3		2574-3805 (Electronic) 2574-3805 (Linking)	101729235	JAMA network open	['eng']	10.1001/jamanetworkopen.2019.0442 [doi]	20191125	['Algorithms', '*Artificial Intelligence', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Male', 'Middle Aged', 'Neoplasm Grading', '*Prostate/diagnostic imaging/pathology', '*Prostatic Neoplasms/diagnostic imaging/pathology', 'Tissue Array Analysis']	2019/11/26 06:00				NLM	e190442	['2019/03/09 06:00 [entrez]', '2019/03/09 06:00 [pubmed]', '2019/11/26 06:00 [medline]']	United States	PMC6484626		30848813	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		JAMA Netw Open. 2019 Mar 1;2(3):e190442. doi: 10.1001/jamanetworkopen.2019.0442.	MEDLINE	JAMA Netw Open	Comparison of Artificial Intelligence Techniques to Evaluate Performance of a Classifier for Automatic Grading of Prostate Cancer From Digitized Histopathologic Images.		2	Comparison of Artificial Intelligence Techniques to Evaluate Performance of a Classifier for Automatic Grading of Prostate Cancer From Digitized Histopathologic Images.
PURPOSE: In radiation therapy, a key step for a successful cancer treatment is image-based treatment planning. One objective of the planning phase is the fast and accurate segmentation of organs at risk and target structures from medical images. However, manual delineation of organs, which is still the gold standard in many clinical environments, is time-consuming and prone to inter-observer variations. Consequently, many automated segmentation methods have been developed. METHODS: In this work, we train two hierarchical 3D neural networks to segment multiple organs at risk in the head and neck area. First, we train a coarse network on size-reduced medical images to locate the organs of interest. Second, a subsequent fine network on full-resolution images is trained for a final accurate segmentation. The proposed method is purely deep learning based; accordingly, no pre-registration or post-processing is required. RESULTS: The approach has been applied on a publicly available computed tomography dataset, created for the MICCAI 2015 Auto-Segmentation challenge. In an extensive evaluation process, the best configurations for the trained networks have been determined. Compared to the existing methods, the presented approach shows state-of-the-art performance for the segmentation of seven different structures in the head and neck area. CONCLUSION: We conclude that 3D neural networks outperform the most existing model- and atlas-based methods for the segmentation of organs at risk in the head and neck area. The ease of use, high accuracy and the test time efficiency of the method make it promising for image-based treatment planning in clinical practice.	['Department of Biomedical Computer Science and Mechatronics, University for Health Sciences, Medical Informatics and Technology, 6060, Hall, Tyrol, Austria. elias.tappeiner@umit.at.', 'Department of Biomedical Computer Science and Mechatronics, University for Health Sciences, Medical Informatics and Technology, 6060, Hall, Tyrol, Austria.', 'Department of Biomedical Computer Science and Mechatronics, University for Health Sciences, Medical Informatics and Technology, 6060, Hall, Tyrol, Austria.', 'Department of Biomedical Computer Science and Mechatronics, University for Health Sciences, Medical Informatics and Technology, 6060, Hall, Tyrol, Austria.', 'Department of Experimental and Clinical Medicine, Magna Graecia University of Catanzaro, 88100, Catanzaro, Italy.', 'Department of Experimental and Clinical Medicine, Magna Graecia University of Catanzaro, 88100, Catanzaro, Italy.', 'Department of Radiation Oncology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, 02114, USA.', 'Department of Biomedical Computer Science and Mechatronics, University for Health Sciences, Medical Informatics and Technology, 6060, Hall, Tyrol, Austria.', 'Department of Biomedical Computer Science and Mechatronics, University for Health Sciences, Medical Informatics and Technology, 6060, Hall, Tyrol, Austria.']	['10.1007/s11548-019-01922-4 [doi]', '10.1007/s11548-019-01922-4 [pii]']	['Tappeiner E', 'Proll S', 'Honig M', 'Raudaschl PF', 'Zaffino P', 'Spadea MF', 'Sharp GC', 'Schubert R', 'Fritscher K']							['2019/03/09 06:00']	20190617	20190307	2019 May	2019/03/09 06:00		['Tappeiner, Elias', 'Proll, Samuel', 'Honig, Markus', 'Raudaschl, Patrick F', 'Zaffino, Paolo', 'Spadea, Maria F', 'Sharp, Gregory C', 'Schubert, Rainer', 'Fritscher, Karl']			5		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-019-01922-4 [doi]	20190617	['*Deep Learning', 'Head and Neck Neoplasms/*diagnosis', 'Humans', 'Imaging, Three-Dimensional/*methods', '*Neural Networks (Computer)', 'Observer Variation', 'Tomography, X-Ray Computed/methods']	2019/06/18 06:00		['Head and neck', 'Multi-organ segmentation', 'Neural network', 'Radiotherapy']	['NOTNLM']	NLM	745-754	['2018/08/17 00:00 [received]', '2019/02/04 00:00 [accepted]', '2019/03/09 06:00 [pubmed]', '2019/06/18 06:00 [medline]', '2019/03/09 06:00 [entrez]']	Germany			30847761	ppublish	['Journal Article']			IM		Int J Comput Assist Radiol Surg. 2019 May;14(5):745-754. doi: 10.1007/s11548-019-01922-4. Epub 2019 Mar 7.	MEDLINE	Int J Comput Assist Radiol Surg	Multi-organ segmentation of the head and neck area: an efficient hierarchical neural networks approach.		14	Multi-organ segmentation of the head and neck area: an efficient hierarchical neural networks approach.
We present an approach for fully automatic urinary bladder segmentation in CT images with artificial neural networks in this study. Automatic medical image analysis has become an invaluable tool in the different treatment stages of diseases. Especially medical image segmentation plays a vital role, since segmentation is often the initial step in an image analysis pipeline. Since deep neural networks have made a large impact on the field of image processing in the past years, we use two different deep learning architectures to segment the urinary bladder. Both of these architectures are based on pre-trained classification networks that are adapted to perform semantic segmentation. Since deep neural networks require a large amount of training data, specifically images and corresponding ground truth labels, we furthermore propose a method to generate such a suitable training data set from Positron Emission Tomography/Computed Tomography image data. This is done by applying thresholding to the Positron Emission Tomography data for obtaining a ground truth and by utilizing data augmentation to enlarge the dataset. In this study, we discuss the influence of data augmentation on the segmentation results, and compare and evaluate the proposed architectures in terms of qualitative and quantitative segmentation performance. The results presented in this study allow concluding that deep neural networks can be considered a promising approach to segment the urinary bladder in CT images.	['Institute for Computer Graphics and Vision, Faculty of Computer Science and Biomedical Engineering, Graz University of Technology, Graz, Austria.', 'Computer Algorithms for Medicine Laboratory, Graz, Austria.', 'Department of Oral & Maxillofacial Surgery, Medical University of Graz, Auenbruggerplatz, Styria, Austria.', 'Institute for Computer Graphics and Vision, Faculty of Computer Science and Biomedical Engineering, Graz University of Technology, Graz, Austria.', 'Computer Algorithms for Medicine Laboratory, Graz, Austria.', 'Department of Oral & Maxillofacial Surgery, Medical University of Graz, Auenbruggerplatz, Styria, Austria.', 'Institute for Computer Graphics and Vision, Faculty of Computer Science and Biomedical Engineering, Graz University of Technology, Graz, Austria.', 'Computer Algorithms for Medicine Laboratory, Graz, Austria.', 'Department of Oral & Maxillofacial Surgery, Medical University of Graz, Auenbruggerplatz, Styria, Austria.']	['10.1371/journal.pone.0212550 [doi]', 'PONE-D-18-14204 [pii]']	['Gsaxner C', 'Roth PM', 'Wallner J', 'Egger J']	['ORCID: 0000-0002-5225-1982']				['The authors have declared that no competing interests exist.']		['2019/03/06 06:00']	20191126	20190305	2019	2019/03/06 06:00		['Gsaxner, Christina', 'Roth, Peter M', 'Wallner, Jurgen', 'Egger, Jan']			3		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0212550 [doi]	20191126	['*Deep Learning', 'Humans', '*Image Processing, Computer-Assisted', '*Positron-Emission Tomography', '*Tomography, X-Ray Computed', 'Urinary Bladder/*diagnostic imaging']	2019/11/27 06:00				NLM	e0212550	['2018/05/11 00:00 [received]', '2019/02/05 00:00 [accepted]', '2019/03/06 06:00 [entrez]', '2019/03/06 06:00 [pubmed]', '2019/11/27 06:00 [medline]']	United States	PMC6400332		30835746	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2019 Mar 5;14(3):e0212550. doi: 10.1371/journal.pone.0212550. eCollection 2019.	MEDLINE	PLoS One	Exploit fully automatic low-level segmented PET data for training high-level deep learning algorithms for the corresponding CT data.		14	Exploit fully automatic low-level segmented PET data for training high-level deep learning algorithms for the corresponding CT data.
Intelligence has been considered as the major challenge in promoting economic potential and production efficiency of precision agriculture. In order to apply advanced deep-learning technology to complete various agricultural tasks in online and offline ways, a large number of crop vision datasets with domain-specific annotation are urgently needed. To encourage further progress in challenging realistic agricultural conditions, we present the CropDeep species classification and detection dataset, consisting of 31,147 images with over 49,000 annotated instances from 31 different classes. In contrast to existing vision datasets, images were collected with different cameras and equipment in greenhouses, captured in a wide variety of situations. It features visually similar species and periodic changes with more representative annotations, which have supported a stronger benchmark for deep-learning-based classification and detection. To further verify the application prospect, we provide extensive baseline experiments using state-of-the-art deep-learning classification and detection models. Results show that current deep-learning-based methods achieve well performance in classification accuracy over 99%. While current deep-learning methods achieve only 92% detection accuracy, illustrating the difficulty of the dataset and improvement room of state-of-the-art deep-learning models when applied to crops production and management. Specifically, we suggest that the YOLOv3 network has good potential application in agricultural detection tasks.	['School of Computer and Information Engineering, Beijing Technology and Business University, Beijing 100048, China. zhengyangyang@st.btbu.edu.cn.', 'School of Computer and Information Engineering, Beijing Technology and Business University, Beijing 100048, China. kongjianlei@btbu.edu.cn.', 'Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing 100048, China. kongjianlei@btbu.edu.cn.', 'School of Computer and Information Engineering, Beijing Technology and Business University, Beijing 100048, China. jinxuebo@btbu.edu.cn.', 'Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing 100048, China. jinxuebo@btbu.edu.cn.', 'School of Computer and Information Engineering, Beijing Technology and Business University, Beijing 100048, China. sdwangxy@163.com.', 'Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing 100048, China. sdwangxy@163.com.', 'School of Computer and Information Engineering, Beijing Technology and Business University, Beijing 100048, China. zuomin@btbu.edu.cn.', 'Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing 100048, China. zuomin@btbu.edu.cn.']	['s19051058 [pii]', '10.3390/s19051058 [doi]']	['Zheng YY', 'Kong JL', 'Jin XB', 'Wang XY', 'Zuo M']					['The authors declare no conflict of interest.']		['2019/03/06 06:00']	20190429	20190301	2019 Mar 1	2019/03/06 06:00		['Zheng, Yang-Yang', 'Kong, Jian-Lei', 'Jin, Xue-Bo', 'Wang, Xiao-Yi', 'Zuo, Min']		['No. 2017YFC1600605/National Key Research and Development Program of China', 'No. KM201910011010/Beijing Municipal Education Commission', 'No. 61673002/National Natural Science Foundation of China']	5		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1058 [pii] 10.3390/s19051058 [doi]	20190429	['Agriculture/*methods', 'Algorithms', '*Deep Learning', 'Machine Learning', 'Neural Networks (Computer)']	2019/04/30 06:00		['Internet of Things', 'agricultural autonomous robots', 'deep convolutional neural networks', 'greenhouse', 'real-time online processing']	['NOTNLM']	NLM		['2019/02/11 00:00 [received]', '2019/02/25 00:00 [revised]', '2019/02/26 00:00 [accepted]', '2019/03/06 06:00 [entrez]', '2019/03/06 06:00 [pubmed]', '2019/04/30 06:00 [medline]']	Switzerland	PMC6427818		30832283	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Mar 1;19(5). pii: s19051058. doi: 10.3390/s19051058.	MEDLINE	Sensors (Basel)	CropDeep: The Crop Vision Dataset for Deep-Learning-Based Classification and Detection in Precision Agriculture.		19	CropDeep: The Crop Vision Dataset for Deep-Learning-Based Classification and Detection in Precision Agriculture.
Non-coding RNAs (ncRNAs) play crucial roles in multiple fundamental biological processes, such as post-transcriptional gene regulation, and are implicated in many complex human diseases. Mostly ncRNAs function by interacting with corresponding RNA-binding proteins. The research on ncRNA(-)protein interaction is the key to understanding the function of ncRNA. However, the biological experiment techniques for identifying RNA(-)protein interactions (RPIs) are currently still expensive and time-consuming. Due to the complex molecular mechanism of ncRNA(-)protein interaction and the lack of conservation for ncRNA, especially for long ncRNA (lncRNA), the prediction of ncRNA(-)protein interaction is still a challenge. Deep learning-based models have become the state-of-the-art in a range of biological sequence analysis problems due to their strong power of feature learning. In this study, we proposed a hierarchical deep learning framework RPITER to predict RNA(-)protein interaction. For sequence coding, we improved the conjoint triad feature (CTF) coding method by complementing more primary sequence information and adding sequence structure information. For model design, RPITER employed two basic neural network architectures of convolution neural network (CNN) and stacked auto-encoder (SAE). Comprehensive experiments were performed on five benchmark datasets from PDB and NPInter databases to analyze and compare the performances of different sequence coding methods and prediction models. We found that CNN and SAE deep learning architectures have powerful fitting abilities for the k-mer features of RNA and protein sequence. The improved CTF coding method showed performance gain compared with the original CTF method. Moreover, our designed RPITER performed well in predicting RNA(-)protein interaction (RPI) and could outperform most of the previous methods. On five widely used RPI datasets, RPI369, RPI488, RPI1807, RPI2241 and NPInter, RPITER obtained A U C of 0.821, 0.911, 0.990, 0.957 and 0.985, respectively. The proposed RPITER could be a complementary method for predicting RPI and constructing RPI network, which would help push forward the related biological research on ncRNAs and lncRNAs.	['College of Computer Science and Technology, Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun 130012, China. pengcheng2114@mails.jlu.edu.cn.', 'College of Computer Science and Technology, Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun 130012, China. hansy15@mails.jlu.edu.cn.', 'College of Computer Science and Technology, Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun 130012, China. huizhang16@mails.jlu.edu.cn.', 'College of Computer Science and Technology, Key Laboratory of Symbol Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun 130012, China. liying@jlu.edu.cn.']	['ijms20051070 [pii]', '10.3390/ijms20051070 [doi]']	['Peng C', 'Han S', 'Zhang H', 'Li Y']	['ORCID: 0000-0002-7804-149X']						['2019/03/06 06:00']	20190604	20190301	2019 Mar 1	2019/03/06 06:00		['Peng, Cheng', 'Han, Siyu', 'Zhang, Hui', 'Li, Ying']		['71774154, 61472158 and 61402194/National Natural Science Foundation of China', '20180101331JC and 20180101050JC/Natural Science Foundation of Jilin Province']	5		1422-0067 (Electronic) 1422-0067 (Linking)	101092791	International journal of molecular sciences	['eng']	E1070 [pii] 10.3390/ijms20051070 [doi]	20190604	['Animals', 'Humans', '*Machine Learning', 'Protein Binding', 'RNA, Long Noncoding/*chemistry/metabolism', 'Sequence Analysis, Protein/*methods', 'Sequence Analysis, RNA/*methods', '*Software']	2019/06/05 06:00		['CNN', 'deep learning', 'ncRNA', 'ncRNA-protein interaction prediction']	['NOTNLM']	NLM		['2019/01/28 00:00 [received]', '2019/02/23 00:00 [revised]', '2019/02/25 00:00 [accepted]', '2019/03/06 06:00 [entrez]', '2019/03/06 06:00 [pubmed]', '2019/06/05 06:00 [medline]']	Switzerland	PMC6429152		30832218	epublish	['Journal Article']		['0 (RNA, Long Noncoding)']	IM		Int J Mol Sci. 2019 Mar 1;20(5). pii: ijms20051070. doi: 10.3390/ijms20051070.	MEDLINE	Int J Mol Sci	RPITER: A Hierarchical Deep Learning Framework for ncRNA(-)Protein Interaction Prediction.		20	RPITER: A Hierarchical Deep Learning Framework for ncRNA(-)Protein Interaction Prediction.
PURPOSE: Tumor-stroma ratio (TSR) serves as an independent prognostic factor in colorectal cancer and other solid malignancies. The recent introduction of digital pathology in routine tissue diagnostics holds opportunities for automated TSR analysis. We investigated the potential of computer-aided quantification of intratumoral stroma in rectal cancer whole-slide images. METHODS: Histological slides from 129 rectal adenocarcinoma patients were analyzed by two experts who selected a suitable stroma hot-spot and visually assessed TSR. A semi-automatic method based on deep learning was trained to segment all relevant tissue types in rectal cancer histology and subsequently applied to the hot-spots provided by the experts. Patients were assigned to a 'stroma-high' or 'stroma-low' group by both TSR methods (visual and automated). This allowed for prognostic comparison between the two methods in terms of disease-specific and disease-free survival times. RESULTS: With stroma-low as baseline, automated TSR was found to be prognostic independent of age, gender, pT-stage, lymph node status, tumor grade, and whether adjuvant therapy was given, both for disease-specific survival (hazard ratio = 2.48 (95% confidence interval 1.29-4.78)) and for disease-free survival (hazard ratio = 2.05 (95% confidence interval 1.11-3.78)). Visually assessed TSR did not serve as an independent prognostic factor in multivariate analysis. CONCLUSIONS: This work shows that TSR is an independent prognosticator in rectal cancer when assessed automatically in user-provided stroma hot-spots. The deep learning-based technology presented here may be a significant aid to pathologists in routine diagnostics.	['Department of Pathology, Radboud Institute for Health Sciences, Radboud University Medical Center, P.O.Box 9101, 6500 HB, Nijmegen, The Netherlands.', 'Diagnostic Image Analysis Group (DIAG), Radboud University Medical Center, Nijmegen, The Netherlands.', 'Laboratory for Pathology East Netherlands (LabPON), Hengelo, The Netherlands.', 'Laboratory for Pathology East Netherlands (LabPON), Hengelo, The Netherlands.', 'Department of Surgery, Medisch Spectrum Twente, Enschede, The Netherlands.', 'Diagnostic Image Analysis Group (DIAG), Radboud University Medical Center, Nijmegen, The Netherlands.', 'Department of Pathology, Radboud Institute for Health Sciences, Radboud University Medical Center, P.O.Box 9101, 6500 HB, Nijmegen, The Netherlands.', 'Diagnostic Image Analysis Group (DIAG), Radboud University Medical Center, Nijmegen, The Netherlands.', 'Department of Surgery, Leiden University Medical Center, Leiden, The Netherlands.', 'Department of Surgery, Leiden University Medical Center, Leiden, The Netherlands.', 'Department of Pathology, Radboud Institute for Health Sciences, Radboud University Medical Center, P.O.Box 9101, 6500 HB, Nijmegen, The Netherlands.', 'Department of Pathology, Radboud Institute for Health Sciences, Radboud University Medical Center, P.O.Box 9101, 6500 HB, Nijmegen, The Netherlands.', 'Diagnostic Image Analysis Group (DIAG), Radboud University Medical Center, Nijmegen, The Netherlands.', 'Department of Pathology, Radboud Institute for Health Sciences, Radboud University Medical Center, P.O.Box 9101, 6500 HB, Nijmegen, The Netherlands. Jeroen.vanderlaak@radboudumc.nl.', 'Diagnostic Image Analysis Group (DIAG), Radboud University Medical Center, Nijmegen, The Netherlands. Jeroen.vanderlaak@radboudumc.nl.', 'Center for Medical Image Science and Visualization, Linkoping University, Linkoping, Sweden. Jeroen.vanderlaak@radboudumc.nl.']	['10.1007/s13402-019-00429-z [doi]', '10.1007/s13402-019-00429-z [pii]']	['Geessink OGF', 'Baidoshvili A', 'Klaase JM', 'Ehteshami Bejnordi B', 'Litjens GJS', 'van Pelt GW', 'Mesker WE', 'Nagtegaal ID', 'Ciompi F', 'van der Laak JAWM']							['2019/03/03 06:00']	20191125	20190301	2019 Jun	2019/03/03 06:00		['Geessink, Oscar G F', 'Baidoshvili, Alexi', 'Klaase, Joost M', 'Ehteshami Bejnordi, Babak', 'Litjens, Geert J S', 'van Pelt, Gabi W', 'Mesker, Wilma E', 'Nagtegaal, Iris D', 'Ciompi, Francesco', 'van der Laak, Jeroen A W M']		['KUN 2014-7032/KWF Kankerbestrijding', 'KUN 2014-7032/KWF Kankerbestrijding']	3		2211-3436 (Electronic) 2211-3428 (Linking)	101552938	Cellular oncology (Dordrecht)	['eng']	10.1007/s13402-019-00429-z [doi]	20191125	['Aged', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Female', 'Humans', 'Kaplan-Meier Estimate', 'Male', 'Middle Aged', 'Multivariate Analysis', 'Neoplasm Staging', 'Pathology, Clinical/methods', 'Prognosis', 'Rectal Neoplasms/*diagnosis', 'Stromal Cells/*pathology']	2019/11/26 06:00		['Automated analysis', 'Computational pathology', 'Deep learning', 'Prognosis', 'Rectal carcinoma', 'Tumor-stroma ratio']	['NOTNLM']	NLM	331-341	['2019/02/07 00:00 [accepted]', '2019/03/03 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/03/03 06:00 [entrez]']	Netherlands			30825182	ppublish	['Journal Article']			IM		Cell Oncol (Dordr). 2019 Jun;42(3):331-341. doi: 10.1007/s13402-019-00429-z. Epub 2019 Mar 1.	MEDLINE	Cell Oncol (Dordr)	Computer aided quantification of intratumoral stroma yields an independent prognosticator in rectal cancer.		42	Computer aided quantification of intratumoral stroma yields an independent prognosticator in rectal cancer.
"Humans and wildlife inhabit a world with panoply of natural and synthetic chemicals. Alarmingly, only a limited number of chemicals have undergone comprehensive toxicological evaluation due to limitations of traditional toxicity testing. High-throughput screening assays provide a higher-speed alternative for conventional toxicity testing. Advancement of high-throughput bioassay technology has greatly increased chemical toxicity data volumes in the past decade, pushing toxicology research into a ""big data"" era. However, traditional data analysis methods fail to effectively process large data volumes, presenting both a challenge and an opportunity for toxicologists. Deep learning, a machine learning method leveraging deep neural networks (DNNs), is a proven useful tool for building quantitative structure-activity relationship (QSAR) models for toxicity prediction utilizing these new large datasets. In this mini review, a brief technical background on DNNs is provided, and the current state of chemical toxicity prediction models built with DNNs is reviewed. In addition, relevant toxicity data sources are summarized, possible limitations are discussed, and perspectives on DNN utilization in chemical toxicity prediction are given."	['a Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology , Dalian University of Technology , Dalian , China.', 'a Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology , Dalian University of Technology , Dalian , China.', 'a Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology , Dalian University of Technology , Dalian , China.', 'a Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology , Dalian University of Technology , Dalian , China.', 'b National Center for Toxicological Research , U.S. Food and Drug Administration , Jefferson , Arkansas , USA.']	['10.1080/10590501.2018.1537563 [doi]']	['Tang W', 'Chen J', 'Wang Z', 'Xie H', 'Hong H']							['2019/03/02 06:00']	20190416	20190301	2018	2019/03/02 06:00		['Tang, Weihao', 'Chen, Jingwen', 'Wang, Zhongyu', 'Xie, Hongbin', 'Hong, Huixiao']			4		1532-4095 (Electronic) 1059-0501 (Linking)	9317093	Journal of environmental science and health. Part C, Environmental carcinogenesis & ecotoxicology reviews	['eng']	10.1080/10590501.2018.1537563 [doi]	20190416	['*Deep Learning', 'Environmental Pollutants/*toxicity', 'High-Throughput Screening Assays', 'Humans', 'Machine Learning', '*Models, Chemical', 'Neural Networks (Computer)', 'Quantitative Structure-Activity Relationship', 'Toxicity Tests/*methods']	2019/04/17 06:00		['*Chemicals toxicity', '*QSAR', '*deep learning', '*deep neural networks', '*high-throughput screening assays']	['NOTNLM']	NLM	252-271	['2019/03/02 06:00 [pubmed]', '2019/04/17 06:00 [medline]', '2019/03/02 06:00 [entrez]']	United States			30821199	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"		['0 (Environmental Pollutants)']	IM		J Environ Sci Health C Environ Carcinog Ecotoxicol Rev. 2018;36(4):252-271. doi: 10.1080/10590501.2018.1537563. Epub 2019 Mar 1.	MEDLINE	J Environ Sci Health C Environ Carcinog Ecotoxicol Rev	Deep learning for predicting toxicity of chemicals: a mini review.		36	Deep learning for predicting toxicity of chemicals: a mini review.
Deep learning (DL) is a branch of machine learning (ML) showing increasing promise in medicine, to assist in data classification, novel disease phenotyping and complex decision making. Deep learning is a form of ML typically implemented via multi-layered neural networks. Deep learning has accelerated by recent advances in computer hardware and algorithms and is increasingly applied in e-commerce, finance, and voice and image recognition to learn and classify complex datasets. The current medical literature shows both strengths and limitations of DL. Strengths of DL include its ability to automate medical image interpretation, enhance clinical decision-making, identify novel phenotypes, and select better treatment pathways in complex diseases. Deep learning may be well-suited to cardiovascular medicine in which haemodynamic and electrophysiological indices are increasingly captured on a continuous basis by wearable devices as well as image segmentation in cardiac imaging. However, DL also has significant weaknesses including difficulties in interpreting its models (the 'black-box' criticism), its need for extensive adjudicated ('labelled') data in training, lack of standardization in design, lack of data-efficiency in training, limited applicability to clinical trials, and other factors. Thus, the optimal clinical application of DL requires careful formulation of solvable problems, selection of most appropriate DL algorithms and data, and balanced interpretation of results. This review synthesizes the current state of DL for cardiovascular clinicians and investigators, and provides technical context to appreciate the promise, pitfalls, near-term challenges, and opportunities for this exciting new area.	['Department of Internal Medicine, Icahn School of Medicine at Mount Sinai, 1 Gustave L. Levy Pl, New York, NY, USA.', 'Department of Cardiovascular Diseases, Icahn School of Medicine at Mount Sinai, Mount Sinai Hospital, Mount Sinai Heart, New York, NY, USA.', 'Department of Genetics and Genomic Sciences, Institute for Next Generation Healthcare, Icahn School of Medicine at Mount Sinai, New York, NY, USA.', 'Department of Cardiovascular Diseases, Icahn School of Medicine at Mount Sinai, Mount Sinai Hospital, Mount Sinai Heart, New York, NY, USA.', 'Robert D. and Patricia E. Kern Center for the Science of Health Care Delivery, Mayo Clinic, Rochester, MN, USA.', 'Division of Health Care Policy and Research, Department of Health Sciences Research, Mayo Clinic, Rochester, MN, USA.', 'Department of Computer Science, Kent State University, Kent, OH, USA.', 'Department of Cardiovascular Diseases, Icahn School of Medicine at Mount Sinai, Mount Sinai Hospital, Mount Sinai Heart, New York, NY, USA.', 'Department of Radiology, New York-Presbyterian Hospital and Weill Cornell Medicine, New York, NY, USA.', 'Department of Cardiovascular Medicine, Heart and Vascular Institute, Cleveland Clinic, OH, USA.', 'Department of Cellular and Molecular Medicine, Lerner Research Institute, Cleveland, OH, USA.', 'Center for Clinical Genomics, Cleveland Clinic, Cleveland, OH, USA.', 'Department of Cardiovascular Diseases, Icahn School of Medicine at Mount Sinai, Mount Sinai Hospital, Mount Sinai Heart, New York, NY, USA.', 'Cardiovascular Institute and Department of Cardiovascular Medicine, Stanford University Medical Center, Stanford, CA, USA.']	['5366208 [pii]', '10.1093/eurheartj/ehz056 [doi]']	['Krittanawong C', 'Johnson KW', 'Rosenson RS', 'Wang Z', 'Aydar M', 'Baber U', 'Min JK', 'Tang WHW', 'Halperin JL', 'Narayan SM']		['Published on behalf of the European Society of Cardiology. All rights reserved.', '(c) The Author(s) 2019. For permissions, please email:', 'journals.permissions@oup.com.']					['2019/03/01 06:00']			2019 Jul 1	2019/03/01 06:00		['Krittanawong, Chayakrit', 'Johnson, Kipp W', 'Rosenson, Robert S', 'Wang, Zhen', 'Aydar, Mehmet', 'Baber, Usman', 'Min, James K', 'Tang, W H Wilson', 'Halperin, Jonathan L', 'Narayan, Sanjiv M']		['K24 HL103800/HL/NHLBI NIH HHS/United States', 'R01 HL083359/HL/NHLBI NIH HHS/United States']	25		1522-9645 (Electronic) 0195-668X (Linking)	8006263	European heart journal	['eng']	10.1093/eurheartj/ehz056 [doi]	20191008		2019/03/01 06:00		['Artificial intelligence', 'Big data', 'Cardiovascular medicine', 'Deep learning', 'Precision medicine']	['NOTNLM']	NLM	2058-2073	['2018/09/29 00:00 [received]', '2018/11/02 00:00 [revised]', '2019/01/22 00:00 [accepted]', '2020/07/01 00:00 [pmc-release]', '2019/03/01 06:00 [pubmed]', '2019/03/01 06:00 [medline]', '2019/03/01 06:00 [entrez]']	England	PMC6600129	['2020/07/01 00:00']	30815669	ppublish	['Journal Article']			IM		Eur Heart J. 2019 Jul 1;40(25):2058-2073. doi: 10.1093/eurheartj/ehz056.	In-Data-Review	Eur Heart J	Deep learning for cardiovascular medicine: a practical primer.		40	Deep learning for cardiovascular medicine: a practical primer.
Parkinson's Disease (PD) is one of the most prevalent neurodegenerative diseases that affects tens of millions of Americans. PD is highly progressive and heterogeneous. Quite a few studies have been conducted in recent years on predictive or disease progression modeling of PD using clinical and biomarkers data. Neuroimaging, as another important information source for neurodegenerative disease, has also arisen considerable interests from the PD community. In this paper, we propose a deep learning method based on Graph Convolutional Networks (GCN) for fusing multiple modalities of brain images in relationship prediction which is useful for distinguishing PD cases from controls. On Parkinson's Progression Markers Initiative (PPMI) cohort, our approach achieved 0.9537+/-0.0587 AUC, compared with 0.6443+/-0.0223 AUC achieved by traditional approaches such as PCA.	['Department of Healthcare Policy and Research, Weill Cornell Medical College, Cornell University, NY.', 'Equal Contribution. Corresponding author, email: few2001@med.cornell.edu.', 'Department of Healthcare Policy and Research, Weill Cornell Medical College, Cornell University, NY.', 'Equal Contribution. Corresponding author, email: few2001@med.cornell.edu.', 'Department of Statistics, University of Connecticut, CT.', 'Department of Preventive Medicine, Feinberg School of Medicine, Northwestern University, IL.', 'Department of Computer Science and Engineering, Michigan State University, MI.', 'Department of Healthcare Policy and Research, Weill Cornell Medical College, Cornell University, NY.', 'Equal Contribution. Corresponding author, email: few2001@med.cornell.edu.']		['Zhang X', 'He L', 'Chen K', 'Luo Y', 'Zhou J', 'Wang F']							['2019/03/01 06:00']	20191111	20181205	2018	2019/03/01 06:00		['Zhang, Xi', 'He, Lifang', 'Chen, Kun', 'Luo, Yuan', 'Zhou, Jiayu', 'Wang, Fei']					1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20191111	['Biomarkers', 'Brain/*diagnostic imaging', 'Cohort Studies', '*Deep Learning', 'Disease Progression', 'Humans', '*Models, Neurological', '*Neuroimaging', 'Parkinson Disease/*diagnostic imaging']	2019/11/12 06:00				NLM	1147-1156	['2019/03/01 06:00 [entrez]', '2019/03/01 06:00 [pubmed]', '2019/11/12 06:00 [medline]']	United States	PMC6371363		30815157	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Biomarkers)']	IM		AMIA Annu Symp Proc. 2018 Dec 5;2018:1147-1156. eCollection 2018.	MEDLINE	AMIA Annu Symp Proc	Multi-View Graph Convolutional Network and Its Applications on Neuroimage Analysis for Parkinson's Disease.		2018	Multi-View Graph Convolutional Network and Its Applications on Neuroimage Analysis for Parkinson's Disease.
There has been an increasing interest in developing deep learning methods to recognize clinical concepts from narrative clinical text. Recently, several studies have reported that Recurrent Neural Networks (RNNs) outperformed traditional machine learning methods such as Conditional Random Fields (CRFs). Deep learning-based Named Entity Recognition (NER) systems often use statistical language models to learn word embeddings from unlabeled corpora. However, current word embedding methods have limitations to learn decent representations for low-frequency words. Medicine is a knowledge-extensive domain; existing medical knowledge has the potential to improve feature representations for less frequent yet important words. However, it is still not clear how existing medical knowledge can help deep learning models in clinical NER tasks. In this study, we integrated medical knowledge from the Unified Medical Language System with word embeddings trained from an unlabeled clinical corpus in RNNs for detection of problems, treatments and lab tests. We examined three different ways to generate medical knowledge features, including a dictionary lookup program, the KnowledgeMap system, and the MedLEE system. We also compared representing medical knowledge as one-hot vectors versus representing medical knowledge as embedding layers. The evaluation results showed that the RNN with medical knowledge as embedding layers achieved new state-of-the-art performance (a strict F1 score of 86.21% and a relaxed F1 score of 92.80%) on the 2010 i2b2 corpus, outperforming an RNN with only word embeddings and RNNs with medical knowledge as one-hot vectors. This study demonstrated an efficient way of integrating medical knowledge with distributed word representations for clinical NER.	['Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, Florida, USA.', 'Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, Florida, USA.', 'Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, Florida, USA.', 'Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, Florida, USA.', 'School of Biomedical Informatics, the University of Texas Health Science Center at Houston, Houston, Texas, USA.', 'Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, Florida, USA.']		['Wu Y', 'Yang X', 'Bian J', 'Guo Y', 'Xu H', 'Hogan W']							['2019/03/01 06:00']	20191111	20181205	2018	2019/03/01 06:00		['Wu, Yonghui', 'Yang, Xi', 'Bian, Jiang', 'Guo, Yi', 'Xu, Hua', 'Hogan, William']		['R01 LM010681/LM/NLM NIH HHS/United States', 'U24 CA194215/CA/NCI NIH HHS/United States', 'UL1 TR001427/TR/NCATS NIH HHS/United States']			1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20191111	['*Deep Learning', 'Humans', 'Natural Language Processing', '*Neural Networks (Computer)', 'Unified Medical Language System']	2019/11/12 06:00				NLM	1110-1117	['2019/03/01 06:00 [entrez]', '2019/03/01 06:00 [pubmed]', '2019/11/12 06:00 [medline]']	United States	PMC6371322		30815153	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		AMIA Annu Symp Proc. 2018 Dec 5;2018:1110-1117. eCollection 2018.	MEDLINE	AMIA Annu Symp Proc	Combine Factual Medical Knowledge and Distributed Word Representation to Improve Clinical Named Entity Recognition.		2018	Combine Factual Medical Knowledge and Distributed Word Representation to Improve Clinical Named Entity Recognition.
Deep Learning can significantly benefit cancer proteomics and genomics. In this study, we attempted to determine a set of critical proteins that were associated with the FLT3-ITD mutation in newly-diagnosed acute myeloid leukemia patients. A Deep Learning network consisting of autoencoders formed a hierarchical model from which high-level features were extracted without labeled training data. Dimensional reduction reduced the number of critical proteins from 231 to 20. Deep Learning found an excellent correlation between FLT3-ITD mutation with the levels of these 20 critical proteins (accuracy 97%, sensitivity 90%, and specificity 100%). Our Deep Learning network could hone in on 20 proteins with the strongest association with FLT3-ITD. The results of this study allow for a novel approach to determine critical protein pathways in the FLT3-ITD mutation, and provide proof-of-concept for an accurate approach to model big data in cancer proteomics and genomics.	['Department of Pathology and Laboratory Medicine, The University of Texas Health Science Center McGovern Medical School, Houston, TX, USA.', 'Department of Pathology and Laboratory Medicine, The University of Texas Health Science Center McGovern Medical School, Houston, TX, USA.', 'Department of Pathology and Laboratory Medicine, The University of Texas Health Science Center McGovern Medical School, Houston, TX, USA.', 'Department of Pathology and Laboratory Medicine, The University of Texas Health Science Center McGovern Medical School, Houston, TX, USA Nghia.D.Nguyen@uth.tmc.edu.']	['49/1/119 [pii]']	['Liang CA', 'Chen L', 'Wahed A', 'Nguyen AND']		['(c) 2019 by the Association of Clinical Scientists, Inc.']					['2019/03/01 06:00']	20190716		2019 Jan	2019/03/01 06:00		['Liang, Christine A', 'Chen, Lei', 'Wahed, Amer', 'Nguyen, Andy N D']			1		1550-8080 (Electronic) 0091-7370 (Linking)	0410247	Annals of clinical and laboratory science	['eng']		20190716	['Blood Proteins/analysis', '*Deep Learning', 'Humans', 'Leukemia, Myeloid, Acute/*genetics/*metabolism/pathology', '*Mutation', '*Neural Networks (Computer)', 'Proteome/*analysis', 'Proteomics/methods', 'Tandem Repeat Sequences', 'fms-Like Tyrosine Kinase 3/*genetics']	2019/07/17 06:00		['AML', 'Deep Learning', 'FLT3-ITD', 'Neural Network', 'Proteomics']	['NOTNLM']	NLM	119-126	['2019/03/01 06:00 [entrez]', '2019/03/01 06:00 [pubmed]', '2019/07/17 06:00 [medline]']	United States			30814087	ppublish	['Journal Article']		['0 (Blood Proteins)', '0 (Proteome)', 'EC 2.7.10.1 (FLT3 protein, human)', 'EC 2.7.10.1 (fms-Like Tyrosine Kinase 3)']	IM		Ann Clin Lab Sci. 2019 Jan;49(1):119-126.	MEDLINE	Ann Clin Lab Sci	Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using Deep Learning Neural Network.		49	Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using Deep Learning Neural Network.
BACKGROUND: Ligand-binding proteins play key roles in many biological processes. Identification of protein-ligand binding residues is important in understanding the biological functions of proteins. Existing computational methods can be roughly categorized as sequence-based or 3D-structure-based methods. All these methods are based on traditional machine learning. In a series of binding residue prediction tasks, 3D-structure-based methods are widely superior to sequence-based methods. However, due to the great number of proteins with known amino acid sequences, sequence-based methods have considerable room for improvement with the development of deep learning. Therefore, prediction of protein-ligand binding residues with deep learning requires study. RESULTS: In this study, we propose a new sequence-based approach called DeepCSeqSite for ab initio protein-ligand binding residue prediction. DeepCSeqSite includes a standard edition and an enhanced edition. The classifier of DeepCSeqSite is based on a deep convolutional neural network. Several convolutional layers are stacked on top of each other to extract hierarchical features. The size of the effective context scope is expanded as the number of convolutional layers increases. The long-distance dependencies between residues can be captured by the large effective context scope, and stacking several layers enables the maximum length of dependencies to be precisely controlled. The extracted features are ultimately combined through one-by-one convolution kernels and softmax to predict whether the residues are binding residues. The state-of-the-art ligand-binding method COACH and some of its submethods are selected as baselines. The methods are tested on a set of 151 nonredundant proteins and three extended test sets. Experiments show that the improvement of the Matthews correlation coefficient (MCC) is no less than 0.05. In addition, a training data augmentation method that slightly improves the performance is discussed in this study. CONCLUSIONS: Without using any templates that include 3D-structure data, DeepCSeqSite significantlyoutperforms existing sequence-based and 3D-structure-based methods, including COACH. Augmentation of the training sets slightly improves the performance. The model, code and datasets are available at https://github.com/yfCuiFaith/DeepCSeqSite .	['Faculty of Education, East China Normal University, 3663 N. Zhongshan Rd., Shanghai, 200062, China.', 'School of Data Science & Engineering, East China Normal University, Shanghai, 3663 N. Zhongshan Rd., Shanghai, 200062, China.', 'Faculty of Education, East China Normal University, 3663 N. Zhongshan Rd., Shanghai, 200062, China. qwdong@dase.ecnu.edu.cn.', 'School of Data Science & Engineering, East China Normal University, Shanghai, 3663 N. Zhongshan Rd., Shanghai, 200062, China. qwdong@dase.ecnu.edu.cn.', 'School of Data Science & Engineering, East China Normal University, Shanghai, 3663 N. Zhongshan Rd., Shanghai, 200062, China.', 'The High School Affiliated of Liaoning Normal University, Dalian, China.']	['10.1186/s12859-019-2672-1 [doi]', '10.1186/s12859-019-2672-1 [pii]']	['Cui Y', 'Dong Q', 'Hong D', 'Wang X']							['2019/02/28 06:00']	20190401	20190226	2019 Feb 26	2019/02/28 06:00		['Cui, Yifeng', 'Dong, Qiwen', 'Hong, Daocheng', 'Wang, Xikun']		['61672234, U1401256, U1711262, 61402177/National Natural Science Foundation of', 'China (CN)', '2016YFB1000905/National Key Research and Development Program of China']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2672-1 [doi]	20190401	['Algorithms', 'Amino Acid Sequence', 'Databases, Protein', '*Deep Learning', 'Ligands', '*Neural Networks (Computer)', 'Protein Binding', 'Proteins/*metabolism']	2019/04/02 06:00		['3D-structure-based methods', 'Binding residues', 'Deep convolutional networks', 'Protein', 'Sequence-based methods']	['NOTNLM']	NLM	93	['2018/11/12 00:00 [received]', '2019/02/07 00:00 [accepted]', '2019/02/28 06:00 [entrez]', '2019/02/28 06:00 [pubmed]', '2019/04/02 06:00 [medline]']	England	PMC6390579		30808287	epublish	['Journal Article']		['0 (Ligands)', '0 (Proteins)']	IM		BMC Bioinformatics. 2019 Feb 26;20(1):93. doi: 10.1186/s12859-019-2672-1.	MEDLINE	BMC Bioinformatics	Predicting protein-ligand binding residues with deep convolutional neural networks.		20	Predicting protein-ligand binding residues with deep convolutional neural networks.
Background: In this study, we propose a method for automatically predicting atrial fibrillation (AF) based on convolutional neural network (CNN) using a short-term normal electrocardiogram (ECG) signal. Methods: We designed a CNN model and optimized it by dropout and normalization. One-dimensional convolution, max-pooling, and fully-connected multiple perceptron were used to analyze the short-term normal ECG. The ECG signal was preprocessed and segmented to train and evaluate the proposed CNN model. The training and test sets consisted of the two AF and one normal dataset from the MIT-BIH database. Results: The proposed CNN model for the automatic prediction of AF achieved a high performance with a sensitivity of 98.6%, a specificity of 98.7%, and an accuracy of 98.7%. Conclusion: The results show the possibility of automatically predicting AF based on the CNN model using a short-term normal ECG signal. The proposed CNN model for the automatic prediction of AF can be a helpful tool for the early diagnosis of AF in healthcare fields.	['Department of Biomedical Engineering, Yonsei University College of Health Science, Wonju, Korea.', 'CHANGEUI TECH Co., Ltd., Wonju, Korea.', 'Department of Biomedical Engineering, Yonsei University College of Health Science, Wonju, Korea.', 'Department of Biomedical Engineering, Yonsei University College of Health Science, Wonju, Korea.', 'MEDIANA Co., Ltd., Wonju, Korea.', 'Department of Biomedical Engineering, Yonsei University College of Health Science, Wonju, Korea.']	['10.3346/jkms.2019.34.e64 [doi]']	['Erdenebayar U', 'Kim H', 'Park JU', 'Kang D', 'Lee KJ']	['ORCID: https://orcid.org/0000-0002-3493-9724', 'ORCID: https://orcid.org/0000-0002-1707-7771', 'ORCID: https://orcid.org/0000-0002-6358-5777', 'ORCID: https://orcid.org/0000-0003-2753-1824', 'ORCID: https://orcid.org/0000-0002-2704-456X']				['Disclosure: The authors have no potential conflicts of interest to disclose.']		['2019/02/27 06:00']	20190531	20190215	2019 Feb 25	2019/02/26 06:00		['Erdenebayar, Urtnasan', 'Kim, Hyeonggon', 'Park, Jong-Uk', 'Kang, Dongwon', 'Lee, Kyoung-Joung']			7		1598-6357 (Electronic) 1011-8934 (Linking)	8703518	Journal of Korean medical science	['eng']	10.3346/jkms.2019.34.e64 [doi]	20190531	['Atrial Fibrillation/*diagnosis', 'Automation', 'Deep Learning', 'Electrocardiography', 'Humans', '*Neural Networks (Computer)', 'Sensitivity and Specificity']	2019/06/01 06:00		['Atrial Fibrillation', 'Convolutional Neural Network', 'Deep Learning', 'Electrocardiogram']	['NOTNLM']	NLM	e64	['2018/10/27 00:00 [received]', '2019/01/20 00:00 [accepted]', '2019/02/27 06:00 [entrez]', '2019/02/26 06:00 [pubmed]', '2019/06/01 06:00 [medline]']	Korea (South)	PMC6384436		30804732	epublish	['Journal Article']			IM		J Korean Med Sci. 2019 Feb 15;34(7):e64. doi: 10.3346/jkms.2019.34.e64. eCollection 2019 Feb 25.	MEDLINE	J Korean Med Sci	Automatic Prediction of Atrial Fibrillation Based on Convolutional Neural Network Using a Short-term Normal Electrocardiogram Signal.		34	Automatic Prediction of Atrial Fibrillation Based on Convolutional Neural Network Using a Short-term Normal Electrocardiogram Signal.
A promising direction in deep learning research consists in learning representations and simultaneously discovering cluster structure in unlabeled data by optimizing a discriminative loss function. As opposed to supervised deep learning, this line of research is in its infancy, and how to design and optimize suitable loss functions to train deep neural networks for clustering is still an open question. Our contribution to this emerging field is a new deep clustering network that leverages the discriminative power of information-theoretic divergence measures, which have been shown to be effective in traditional clustering. We propose a novel loss function that incorporates geometric regularization constraints, thus avoiding degenerate structures of the resulting clustering partition. Experiments on synthetic benchmarks and real datasets show that the proposed network achieves competitive performance with respect to other state-of-the-art methods, scales well to large datasets, and does not require pre-training steps.	['Machine Learning Group, UiT the Arctic University of Norway, Norway (1). Electronic address: michael.c.kampffmeyer@uit.no.', 'Machine Learning Group, UiT the Arctic University of Norway, Norway (1).', 'Machine Learning Group, UiT the Arctic University of Norway, Norway (1).', 'Department of Computer Science, University of Exeter, UK; Departments of Computer Science and Mathematics, University of Manitoba, Canada.', 'Norwegian Computing Center, Oslo, Norway.', 'Machine Learning Group, UiT the Arctic University of Norway, Norway (1); Norwegian Computing Center, Oslo, Norway.']	['S0893-6080(19)30029-2 [pii]', '10.1016/j.neunet.2019.01.015 [doi]']	['Kampffmeyer M', 'Lokse S', 'Bianchi FM', 'Livi L', 'Salberg AB', 'Jenssen R']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/02/25 06:00']	20190514	20190208	2019 May	2019/02/25 06:00		['Kampffmeyer, Michael', 'Lokse, Sigurd', 'Bianchi, Filippo M', 'Livi, Lorenzo', 'Salberg, Arnt-Borre', 'Jenssen, Robert']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30029-2 [pii] 10.1016/j.neunet.2019.01.015 [doi]	20190514	['Cluster Analysis', 'Deep Learning/*trends', 'Discriminant Analysis', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/methods/*trends']	2019/05/15 06:00		['Clustering', 'Deep learning', 'Divergence', 'Information-theoretic learning', 'Unsupervised learning']	['NOTNLM']	NLM	91-101	['2018/06/08 00:00 [received]', '2019/01/14 00:00 [revised]', '2019/01/29 00:00 [accepted]', '2019/02/25 06:00 [pubmed]', '2019/05/15 06:00 [medline]', '2019/02/25 06:00 [entrez]']	United States			30798048	ppublish	['Journal Article']			IM		Neural Netw. 2019 May;113:91-101. doi: 10.1016/j.neunet.2019.01.015. Epub 2019 Feb 8.	MEDLINE	Neural Netw	Deep divergence-based approach to clustering.		113	Deep divergence-based approach to clustering.
It is evident through biology research that, biological neural network could be implemented through two means: by congenital heredity, or by posteriority learning. However, traditionally, artificial neural network, especially the Deep learning Neural Networks (DNNs) are implemented only through exhaustive training and learning. Fixed structure is built, and then parameters are trained through huge amount of data. In this way, there are a lot of redundancies in the implemented artificial neural network. This redundancy not only requires more effort to train the network, but also costs more computing resources when used. In this paper, we proposed a bionic way to implement artificial neural network through construction rather than training and learning. The hierarchy of the neural network is designed according to analysis of the required functionality, and then module design is carried out to form each hierarchy. We choose the Drosophila's visual neural network as a test case to verify our method's validation. The results show that the bionic artificial neural network built through our method could work as a bionic compound eye, which can achieve the detection of the object and their movement, and the results are better on some properties, compared with the Drosophila's biological compound eyes.	['Institute of Microelectronics, Tsinghua University, Beijing, China.', 'School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.', 'Institute of Microelectronics, Tsinghua University, Beijing, China.', 'Institute of Microelectronics, Tsinghua University, Beijing, China.', 'Institute of Microelectronics, Tsinghua University, Beijing, China.', 'School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.', 'School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.', 'School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.', 'School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.', 'Institute of Microelectronics, Tsinghua University, Beijing, China.']	['10.1371/journal.pone.0212368 [doi]', 'PONE-D-18-32204 [pii]']	['He H', 'Yang X', 'Xu Z', 'Deng N', 'Shang Y', 'Liu G', 'Ji M', 'Zheng W', 'Zhao J', 'Dong L']	['ORCID: 0000-0001-7983-6473']				['The authors have declared that no competing interests exist.']		['2019/02/23 06:00']	20191118	20190222	2019	2019/02/23 06:00		['He, Hu', 'Yang, Xu', 'Xu, Zhiheng', 'Deng, Ning', 'Shang, Yingjie', 'Liu, Guo', 'Ji, Mengyao', 'Zheng, Wenhao', 'Zhao, Jinfeng', 'Dong, Liya']			2		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0212368 [doi]	20191118	['Algorithms', 'Animals', '*Artificial Intelligence', '*Bionics', 'Color', 'Drosophila melanogaster/*physiology', 'Machine Learning', 'Movement', 'Nerve Net/*physiology', '*Neural Networks (Computer)', 'Pattern Recognition, Automated', 'Visual Pathways/*physiology', 'Visual Perception/*physiology']	2019/11/19 06:00				NLM	e0212368	['2018/11/08 00:00 [received]', '2019/01/31 00:00 [accepted]', '2019/02/23 06:00 [entrez]', '2019/02/23 06:00 [pubmed]', '2019/11/19 06:00 [medline]']	United States	PMC6386347		30794587	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2019 Feb 22;14(2):e0212368. doi: 10.1371/journal.pone.0212368. eCollection 2019.	MEDLINE	PLoS One	Implementing artificial neural networks through bionic construction.		14	Implementing artificial neural networks through bionic construction.
In this paper, a multipath convolutional neural network (MP-CNN) is proposed for rehabilitation exercise recognition using sensor data. It consists of two novel components: a dynamic convolutional neural network (D-CNN) and a state transition probability CNN (S-CNN). In the D-CNN, Gaussian mixture models (GMMs) are exploited to capture the distribution of sensor data for the body movements of the physical rehabilitation exercises. Then, the input signals and the GMMs are screened into different segments. These form multiple paths in the CNN. The S-CNN uses a modified Lempel(-)Ziv(-)Welch (LZW) algorithm to extract the transition probabilities of hidden states as discriminate features of different movements. Then, the D-CNN and the S-CNN are combined to build the MP-CNN. To evaluate the rehabilitation exercise, a special evaluation matrix is proposed along with the deep learning classifier to learn the general feature representation for each class of rehabilitation exercise at different levels. Then, for any rehabilitation exercise, it can be classified by the deep learning model and compared to the learned best features. The distance to the best feature is used as the score for the evaluation. We demonstrate our method with our collected dataset and several activity recognition datasets. The classification results are superior when compared to those obtained using other deep learning models, and the evaluation scores are effective for practical applications.	['Advanced Institute of Manufacturing with High-tech Innovations, Center for Innovative Research on Aging Society (CIRAS) and Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi 62102, Taiwan. cca104m@cs.ccu.edu.tw.']	['s19040887 [pii]', '10.3390/s19040887 [doi]']	['Zhu ZA', 'Lu YC', 'You CH', 'Chiang CK']					['The authors declare no conflict of interest.']		['2019/02/23 06:00']	20190313	20190220	2019 Feb 20	2019/02/23 06:00		['Zhu, Zheng-An', 'Lu, Yun-Chung', 'You, Chih-Hsiang', 'Chiang, Chen-Kuo']			4		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E887 [pii] 10.3390/s19040887 [doi]	20190404	['Algorithms', '*Deep Learning', 'Exercise Therapy/*methods', 'Humans', 'Movement/*physiology', 'Pattern Recognition, Automated']	2019/03/14 06:00		['deep learning', 'evaluation', 'recognition', 'rehabilitation exercises', 'sensor data']	['NOTNLM']	NLM		['2018/12/19 00:00 [received]', '2019/02/16 00:00 [revised]', '2019/02/16 00:00 [accepted]', '2019/02/23 06:00 [entrez]', '2019/02/23 06:00 [pubmed]', '2019/03/14 06:00 [medline]']	Switzerland	PMC6412882		30791648	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Feb 20;19(4). pii: s19040887. doi: 10.3390/s19040887.	MEDLINE	Sensors (Basel)	Deep Learning for Sensor-Based Rehabilitation Exercise Recognition and Evaluation.		19	Deep Learning for Sensor-Based Rehabilitation Exercise Recognition and Evaluation.
Sleep disorder is a symptom of many neurological diseases that may significantly affect the quality of daily life. Traditional methods are time-consuming and involve the manual scoring of polysomnogram (PSG) signals obtained in a laboratory environment. However, the automated monitoring of sleep stages can help detect neurological disorders accurately as well. In this study, a flexible deep learning model is proposed using raw PSG signals. A one-dimensional convolutional neural network (1D-CNN) is developed using electroencephalogram (EEG) and electrooculogram (EOG) signals for the classification of sleep stages. The performance of the system is evaluated using two public databases (sleep-edf and sleep-edfx). The developed model yielded the highest accuracies of 98.06%, 94.64%, 92.36%, 91.22%, and 91.00% for two to six sleep classes, respectively, using the sleep-edf database. Further, the proposed model obtained the highest accuracies of 97.62%, 94.34%, 92.33%, 90.98%, and 89.54%, respectively for the same two to six sleep classes using the sleep-edfx dataset. The developed deep learning model is ready for clinical usage, and can be tested with big PSG data.	"['Department of Computer Engineering, Munzur University, Tunceli 62000, Turkey. oyildirim@munzur.edu.tr.', 'Department of Computer Engineering, Munzur University, Tunceli 62000, Turkey. baloglu@munzur.edu.tr.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore 599489, Singapore. aru@np.edu.sg.', 'Department of Biomedical Engineering, School of Science and Technology, Singapore School of Social Sciences, Singapore 599489, Singapore. aru@np.edu.sg.', ""School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, Subang Jaya 47500, Malaysia. aru@np.edu.sg.""]"	['ijerph16040599 [pii]', '10.3390/ijerph16040599 [doi]']	['Yildirim O', 'Baloglu UB', 'Acharya UR']	['ORCID: 0000-0001-5375-3012', 'ORCID: 0000-0003-2689-8552']						['2019/02/23 06:00']	20190624	20190219	2019 Feb 19	2019/02/23 06:00		['Yildirim, Ozal', 'Baloglu, Ulas Baran', 'Acharya, U Rajendra']			4		1660-4601 (Electronic) 1660-4601 (Linking)	101238455	International journal of environmental research and public health	['eng']	E599 [pii] 10.3390/ijerph16040599 [doi]	20190624	['Automation', '*Deep Learning', 'Electroencephalography', 'Electrooculography', 'Humans', 'Neural Networks (Computer)', 'Polysomnography/*methods', '*Sleep Stages', 'Sleep Wake Disorders/*physiopathology']	2019/06/25 06:00		['*CNNs', '*classification', '*deep learning', '*polysomnography (PSG)', '*sleep stages']	['NOTNLM']	NLM		['2018/12/01 00:00 [received]', '2019/01/23 00:00 [revised]', '2019/02/16 00:00 [accepted]', '2019/02/23 06:00 [entrez]', '2019/02/23 06:00 [pubmed]', '2019/06/25 06:00 [medline]']	Switzerland	PMC6406978		30791379	epublish	['Journal Article']			IM		Int J Environ Res Public Health. 2019 Feb 19;16(4). pii: ijerph16040599. doi: 10.3390/ijerph16040599.	MEDLINE	Int J Environ Res Public Health	A Deep Learning Model for Automated Sleep Stages Classification Using PSG Signals.		16	A Deep Learning Model for Automated Sleep Stages Classification Using PSG Signals.
Chronic Obstructive Pulmonary Disease (COPD) is a prevalent chronic pulmonary condition that affects hundreds of millions of people all over the world. Many COPD patients got readmitted to hospital within 30 days after discharge due to various reasons. Such readmission can usually be avoided if additional attention is paid to patients with high readmission risk and appropriate actions are taken. This makes early prediction of the hospital readmission risk an important problem. The goal of this paper is to conduct a systematic study on developing different types of machine learning models, including both deep and non-deep ones, for predicting the readmission risk of COPD patients. We evaluate those different approaches on a real world database containing the medical claims of 111,992 patients from the Geisinger Health System from January 2004 to September 2015. The patient features we build the machine learning models upon include both knowledge-driven ones, which are the features extracted according to clinical knowledge potentially related to COPD readmission, and data-driven features, which are extracted from the patient data themselves. Our analysis showed that the prediction performance in terms of Area Under the receiver operating characteristic (ROC) Curve (AUC) can be improved from around 0.60 using knowledge-driven features, to 0.653 by combining both knowledge-driven and data-driven features, based on the one-year claims history before discharge. Moreover, we also demonstrate that the complex deep learning models in this case cannot really improve the prediction performance, with the best AUC around 0.65.	['Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, NY, USA.', 'Department of Computer Science and Technology, Institute for Artificial Intelligence, Tsinghua-Fuzhou Institute for Data Technology, and Bioinformatics Division, BNRist, Tsinghua University, Beijing, China.', 'American Air Liquide, Newark, DE, USA.', 'Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, NY, USA. few2001@med.cornell.edu.']	['10.1038/s41598-019-39071-y [doi]', '10.1038/s41598-019-39071-y [pii]']	['Min X', 'Yu B', 'Wang F']							['2019/02/22 06:00']		20190220	2019 Feb 20	2019/02/23 06:00		['Min, Xu', 'Yu, Bin', 'Wang, Fei']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-019-39071-y [doi]	20191120		2019/02/23 06:00				NLM	2362	['2018/07/25 00:00 [received]', '2019/01/15 00:00 [accepted]', '2019/02/22 06:00 [entrez]', '2019/02/23 06:00 [pubmed]', '2019/02/23 06:00 [medline]']	England	PMC6382784		30787351	epublish	['Journal Article']			IM		Sci Rep. 2019 Feb 20;9(1):2362. doi: 10.1038/s41598-019-39071-y.	In-Data-Review	Sci Rep	Predictive Modeling of the Hospital Readmission Risk from Patients' Claims Data Using Machine Learning: A Case Study on COPD.		9	Predictive Modeling of the Hospital Readmission Risk from Patients' Claims Data Using Machine Learning: A Case Study on COPD.
Objective: To establish automatic liver fibrosis classification models by using traditional machine learning and deep learning methods and preliminaryly evaluate the efficiency. Methods: Gray scale ultrasound images and corresponding elastic images of 354 patients, 247 males and 107 females, mean age (54+/-12) years undergoing partial hepatectomy in Zhongshan Hospital of Fudan University from November 2014 to January 2016 were enrolled in this study. By using traditional machine learning and deep learning methods, an automatic classification model of liver fibrosis stages (S0 to S4) were established through feature extraction and classification of ultrasound image data sets and the accuracy in different classification categories of each model were calculated, by using liver biopsy as the reference standard. Results: Pathological examination showed 73 cases in pathological stage S0, 40 cases in S1, 49 cases in S2, 41 cases in S3, and 151 cases in S4. The traditional machine classification model based on support vector machine (SVM) classifier and sparse representation classifier and the deep learning classification model based on LeNet-5 neural network, their accuracy rates in the two categories (S0/S1/S2 and S3/S4) were 89.8%, 91.8% and 90.7% respectively; the accuracy rates in the three categories (S0/S1 and S2/S3 and S4) were 75.3%, 79.4% and 82.8% respectively; the accuracy in the three categories (S0 and S1/S2/S3 and S4) were 79.3%, 82.7% and 87.2% respectively. Conclusions: Computer-aided assessment of liver fibrosis progression in patients with chronic hepatitis B has a high accuracy, and can achieve a more detailed classification. This method is expected to be applied in the non-invasive evaluation of liver fibrosis in patients with hepatitis B in clinical work in the future.	['Department of Ultrasound, Zhongshan Hospital, Fudan University, Shanghai Institute of Medical Imaging, Fudan University, Shanghai 200032, China.', 'Department of Electronic Engineering, Fudan University, Shanghai 200433, China.', 'Department of Ultrasound, Zhongshan Hospital, Fudan University, Shanghai Institute of Medical Imaging, Fudan University, Shanghai 200032, China.', 'Department of Ultrasound, Zhongshan Hospital, Fudan University, Shanghai Institute of Medical Imaging, Fudan University, Shanghai 200032, China.', 'Department of Electronic Engineering, Fudan University, Shanghai 200433, China.', 'Department of Electronic Engineering, Fudan University, Shanghai 200433, China.', 'Department of Ultrasound, Zhongshan Hospital, Fudan University, Shanghai Institute of Medical Imaging, Fudan University, Shanghai 200032, China.']	['10.3760/cma.j.issn.0376-2491.2019.07.003 [doi]']	['Fu TT', 'Yao Z', 'Ding H', 'Xu ZT', 'Yang MR', 'Yu JH', 'Wang WP']							['2019/02/21 06:00']	20190410		2019 Feb 19	2019/02/21 06:00		['Fu, T T', 'Yao, Z', 'Ding, H', 'Xu, Z T', 'Yang, M R', 'Yu, J H', 'Wang, W P']		['81571675, 61471125/National Natural Science Foundation of China']	7		0376-2491 (Print) 0376-2491 (Linking)	7511141	Zhonghua yi xue za zhi	['chi']	10.3760/cma.j.issn.0376-2491.2019.07.003 [doi]	20190410	['Adult', 'Aged', 'Disease Progression', 'Female', 'Fibrosis', '*Hepatitis B, Chronic/complications', 'Humans', 'Liver', '*Liver Cirrhosis/etiology', 'Male', 'Middle Aged', 'Ultrasonography']	2019/04/11 06:00		['Artificial intelligence', 'Elasticity imaging techniques', 'Liver cirrhosis', 'Ultrasonography']	['NOTNLM']	NLM	491-495	['2019/02/21 06:00 [entrez]', '2019/02/21 06:00 [pubmed]', '2019/04/11 06:00 [medline]']	China			30786344	ppublish	['Journal Article']			IM		Zhonghua Yi Xue Za Zhi. 2019 Feb 19;99(7):491-495. doi: 10.3760/cma.j.issn.0376-2491.2019.07.003.	MEDLINE	Zhonghua Yi Xue Za Zhi	[Computer-aided assessment of liver fibrosis progression in patients with chronic hepatitis B: an exploratory research].		99	[Computer-aided assessment of liver fibrosis progression in patients with chronic hepatitis B: an exploratory research].
Motivated by the recent progress of deep spiking neural networks (SNNs), we propose a structure-time parallel strategy based on layered structure and one-time computation over a time window to speed up the prominent spike-based deep learning algorithm named broadcast alignment. Furthermore, a well-designed deep hierarchical model based on the parallel broadcast alignment is proposed for object recognition. The parallel broadcast alignment achieves a significant 137x speedup compared to its original implementation on MNIST dataset. The object recognition model achieves higher accuracy than that of the latest spiking deep convolutional neural networks on the ETH-80 dataset. The proposed parallel strategy and the object recognition model will facilitate both the simulation of deep SNNs for studying spiking neural dynamics and also the applications of spike-based deep learning in real-world problems.	['Neuromorphic Computing Research Center, College of Computer Science, Sichuan University, Chengdu, 610065, China.', 'Neuromorphic Computing Research Center, College of Computer Science, Sichuan University, Chengdu, 610065, China.', 'Neuromorphic Computing Research Center, College of Computer Science, Sichuan University, Chengdu, 610065, China.', 'Neuromorphic Computing Research Center, College of Computer Science, Sichuan University, Chengdu, 610065, China. Electronic address: ryan@scu.edu.cn.']	['S0893-6080(19)30021-8 [pii]', '10.1016/j.neunet.2019.01.010 [doi]']	['Wu X', 'Wang Y', 'Tang H', 'Yan R']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2019/02/21 06:00']	20190514	20190204	2019 May	2019/02/21 06:00		['Wu, Xi', 'Wang, Yixuan', 'Tang, Huajin', 'Yan, Rui']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30021-8 [pii] 10.1016/j.neunet.2019.01.010 [doi]	20190514	['Algorithms', 'Animals', 'Deep Learning/*trends', 'Humans', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/methods/*trends', 'Time Factors', 'Visual Perception']	2019/05/15 06:00		['Deep spiking neural networks', 'Neuromorphic computing', 'Parallel implementation', 'Spike-based deep learning']	['NOTNLM']	NLM	72-78	['2018/07/03 00:00 [received]', '2019/01/08 00:00 [revised]', '2019/01/22 00:00 [accepted]', '2019/02/21 06:00 [pubmed]', '2019/05/15 06:00 [medline]', '2019/02/21 06:00 [entrez]']	United States			30785011	ppublish	['Journal Article']			IM		Neural Netw. 2019 May;113:72-78. doi: 10.1016/j.neunet.2019.01.010. Epub 2019 Feb 4.	MEDLINE	Neural Netw	A structure-time parallel implementation of spike-based deep learning.		113	A structure-time parallel implementation of spike-based deep learning.
Artificial intelligence (AI), particularly deep learning algorithms, is gaining extensive attention for its excellent performance in image-recognition tasks. They can automatically make a quantitative assessment of complex medical image characteristics and achieve an increased accuracy for diagnosis with higher efficiency. AI is widely used and getting increasingly popular in the medical imaging of the liver, including radiology, ultrasound, and nuclear medicine. AI can assist physicians to make more accurate and reproductive imaging diagnosis and also reduce the physicians' workload. This article illustrates basic technical knowledge about AI, including traditional machine learning and deep learning algorithms, especially convolutional neural networks, and their clinical application in the medical imaging of liver diseases, such as detecting and evaluating focal liver lesions, facilitating treatment, and predicting liver treatment response. We conclude that machine-assisted medical services will be a promising solution for future liver medical care. Lastly, we discuss the challenges and future directions of clinical application of deep learning techniques.	['Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China.', 'Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China.', 'Department of Ultrasound, Tianyou Hospital Affiliated to Wuhan University of Technology, Wuhan 430030, Hubei Province, China.', 'Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China.', 'Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China.', 'Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China.', 'School of Mathematics and Computer Science, Wuhan Textitle University, Wuhan 430200, Hubei Province, China.', 'Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China. cuixinwu@live.cn.', 'Sino-German Tongji-Caritas Research Center of Ultrasound in Medicine, Department of Medical Ultrasound, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, Hubei Province, China.']	['10.3748/wjg.v25.i6.672 [doi]']	['Zhou LQ', 'Wang JY', 'Yu SY', 'Wu GG', 'Wei Q', 'Deng YB', 'Wu XL', 'Cui XW', 'Dietrich CF']					['Conflict-of-interest statement: There is no conflict of interest associated with', 'any of the senior author or other coauthors who contributed their efforts in this', 'manuscript.']		['2019/02/21 06:00']	20190313		2019 Feb 14	2019/02/21 06:00		['Zhou, Li-Qiang', 'Wang, Jia-Yu', 'Yu, Song-Yuan', 'Wu, Ge-Ge', 'Wei, Qi', 'Deng, You-Bin', 'Wu, Xing-Long', 'Cui, Xin-Wu', 'Dietrich, Christoph F']			6		2219-2840 (Electronic) 1007-9327 (Linking)	100883448	World journal of gastroenterology	['eng']	10.3748/wjg.v25.i6.672 [doi]	20190313	['Algorithms', '*Artificial Intelligence', 'Deep Learning', 'Diagnostic Imaging/*methods', 'Humans', 'Liver/*diagnostic imaging', 'Liver Diseases/*diagnostic imaging', 'Machine Learning', 'Neural Networks (Computer)']	2019/03/14 06:00		['Artificial intelligence', 'Deep learning', 'Imaging', 'Liver', 'Machine learning', 'Ultrasound']	['NOTNLM']	NLM	672-682	['2018/11/25 00:00 [received]', '2018/12/24 00:00 [revised]', '2019/01/09 00:00 [accepted]', '2019/02/21 06:00 [entrez]', '2019/02/21 06:00 [pubmed]', '2019/03/14 06:00 [medline]']	United States	PMC6378542		30783371	ppublish	['Journal Article', 'Review']			IM		World J Gastroenterol. 2019 Feb 14;25(6):672-682. doi: 10.3748/wjg.v25.i6.672.	MEDLINE	World J Gastroenterol	Artificial intelligence in medical imaging of the liver.		25	Artificial intelligence in medical imaging of the liver.
Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for computational learning systems and autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. Although significant advances have been made in domain-specific learning with neural networks, extensive research efforts are required for the development of robust lifelong learning on autonomous agents and robots. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.	['Knowledge Technology, Department of Informatics, Universitat Hamburg, Germany. Electronic address: parisi@informatik.uni-hamburg.de.', 'Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, NY, USA.', 'Department of Computer Science, Heriot-Watt University, Edinburgh Centre for Robotics, Scotland, UK.', 'Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, NY, USA.', 'Knowledge Technology, Department of Informatics, Universitat Hamburg, Germany.']	['S0893-6080(19)30023-1 [pii]', '10.1016/j.neunet.2019.01.012 [doi]']	['Parisi GI', 'Kemker R', 'Part JL', 'Kanan C', 'Wermter S']		['Copyright (c) 2019 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2019/02/20 06:00']	20190514	20190206	2019 May	2019/02/20 06:00		['Parisi, German I', 'Kemker, Ronald', 'Part, Jose L', 'Kanan, Christopher', 'Wermter, Stefan']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(19)30023-1 [pii] 10.1016/j.neunet.2019.01.012 [doi]	20190514	['Animals', 'Humans', 'Machine Learning/*trends', 'Memory', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/methods/*trends']	2019/05/15 06:00		['Catastrophic forgetting', 'Continual learning', 'Developmental systems', 'Lifelong learning', 'Memory consolidation']	['NOTNLM']	NLM	54-71	['2018/07/06 00:00 [received]', '2019/01/18 00:00 [revised]', '2019/01/22 00:00 [accepted]', '2019/02/20 06:00 [pubmed]', '2019/05/15 06:00 [medline]', '2019/02/20 06:00 [entrez]']	United States			30780045	ppublish	['Journal Article', 'Review']			IM		Neural Netw. 2019 May;113:54-71. doi: 10.1016/j.neunet.2019.01.012. Epub 2019 Feb 6.	MEDLINE	Neural Netw	Continual lifelong learning with neural networks: A review.		113	Continual lifelong learning with neural networks: A review.
BACKGROUND: Protein ubiquitination occurs when the ubiquitin protein binds to a target protein residue of lysine (K), and it is an important regulator of many cellular functions, such as signal transduction, cell division, and immune reactions, in eukaryotes. Experimental and clinical studies have shown that ubiquitination plays a key role in several human diseases, and recent advances in proteomic technology have spurred interest in identifying ubiquitination sites. However, most current computing tools for predicting target sites are based on small-scale data and shallow machine learning algorithms. RESULTS: As more experimentally validated ubiquitination sites emerge, we need to design a predictor that can identify lysine ubiquitination sites in large-scale proteome data. In this work, we propose a deep learning predictor, DeepUbi, based on convolutional neural networks. Four different features are adopted from the sequences and physicochemical properties. In a 10-fold cross validation, DeepUbi obtains an AUC (area under the Receiver Operating Characteristic curve) of 0.9, and the accuracy, sensitivity and specificity exceeded 85%. The more comprehensive indicator, MCC, reaches 0.78. We also develop a software package that can be freely downloaded from https://github.com/Sunmile/DeepUbi . CONCLUSION: Our results show that DeepUbi has excellent performance in predicting ubiquitination based on large data.	['Department of Information and Computing Science, University of Science and Technology Beijing, Beijing, 100083, China.', 'Department of Information and Computing Science, University of Science and Technology Beijing, Beijing, 100083, China.', 'Department of Information and Computing Science, University of Science and Technology Beijing, Beijing, 100083, China.', 'Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China.', 'Department of Information and Computing Science, University of Science and Technology Beijing, Beijing, 100083, China. xuyan@ustb.edu.cn.', 'Beijing Key Laboratory for Magneto-photoelectrical Composite and Interface Science, University of Science and Technology Beijing, Beijing, 100083, China. xuyan@ustb.edu.cn.']	['10.1186/s12859-019-2677-9 [doi]', '10.1186/s12859-019-2677-9 [pii]']	['Fu H', 'Yang Y', 'Wang X', 'Wang H', 'Xu Y']	['ORCID: http://orcid.org/0000-0001-9462-580X']						['2019/02/20 06:00']	20190307	20190218	2019 Feb 18	2019/02/20 06:00		['Fu, Hongli', 'Yang, Yingxi', 'Wang, Xiaobo', 'Wang, Hui', 'Xu, Yan']		['11671032/National Natural Science Foundation of China', 'FRF-TP-17-024A2/Fundamental Research Funds for the Central Universities']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2677-9 [doi]	20190307	['*Deep Learning', 'Humans', 'Lysine/metabolism', 'Neural Networks (Computer)', 'Proteome/metabolism', 'Proteomics/*methods', 'Software', 'Ubiquitinated Proteins/*chemistry', '*Ubiquitination']	2019/03/08 06:00		['Convolutional neural networks', 'Deep learning', 'Ubiquitination']	['NOTNLM']	NLM	86	['2018/11/08 00:00 [received]', '2019/02/12 00:00 [accepted]', '2019/02/20 06:00 [entrez]', '2019/02/20 06:00 [pubmed]', '2019/03/08 06:00 [medline]']	England	PMC6379983		30777029	epublish	['Journal Article']		['0 (Proteome)', '0 (Ubiquitinated Proteins)', 'K3Z4F929H6 (Lysine)']	IM		BMC Bioinformatics. 2019 Feb 18;20(1):86. doi: 10.1186/s12859-019-2677-9.	MEDLINE	BMC Bioinformatics	DeepUbi: a deep learning framework for prediction of ubiquitination sites in proteins.		20	DeepUbi: a deep learning framework for prediction of ubiquitination sites in proteins.
Quantitative susceptibility mapping (QSM) reveals pathological changes in widespread diseases such as Parkinson's disease, Multiple Sclerosis, or hepatic iron overload. QSM requires multiple processing steps after the acquisition of magnetic resonance imaging (MRI) phase measurements such as unwrapping, background field removal and the solution of an ill-posed field-to-source-inversion. Current techniques utilize iterative optimization procedures to solve the inversion and background field correction, which are computationally expensive and lead to suboptimal or over-regularized solutions requiring a careful choice of parameters that make a clinical application of QSM challenging. We have previously demonstrated that a deep convolutional neural network can invert the magnetic dipole kernel with a very efficient feed forward multiplication not requiring iterative optimization or the choice of regularization parameters. In this work, we extended this approach to remove background fields in QSM. The prototype method, called SHARQnet, was trained on simulated background fields and tested on 3T and 7T brain datasets. We show that SHARQnet outperforms current background field removal procedures and generalizes to a wide range of input data without requiring any parameter adjustments. In summary, we demonstrate that the solution of ill-posed problems in QSM can be achieved by learning the underlying physics causing the artifacts and removing them in an efficient and reliable manner and thereby will help to bring QSM towards clinical applications.	['Centre for Advanced Imaging, The University of Queensland, Building 57 of University Dr, St Lucia, QLD 4072, Brisbane, Australia. Electronic address: steffen.bollmann@cai.uq.edu.au.', 'Department of Health Science and Technology, Aalborg University, Fredrik Bajers Vej 7, 9000 Aalborg, Denmark.', 'Department of Health Science and Technology, Aalborg University, Fredrik Bajers Vej 7, 9000 Aalborg, Denmark.', 'Department of Health Science and Technology, Aalborg University, Fredrik Bajers Vej 7, 9000 Aalborg, Denmark.', 'Department of Health Science and Technology, Aalborg University, Fredrik Bajers Vej 7, 9000 Aalborg, Denmark.', 'Department of Health Science and Technology, Aalborg University, Fredrik Bajers Vej 7, 9000 Aalborg, Denmark.', 'Centre for Advanced Imaging, The University of Queensland, Building 57 of University Dr, St Lucia, QLD 4072, Brisbane, Australia; Siemens Healthcare Pty Ltd, Brisbane, Australia.', 'Department of Neurology, Medical University of Graz, Auenbruggerplatz 22, 8036 Graz, Austria.', 'CSIRO Health and Biosecurity Flagship, The Australian eHealth Research Centre, Australia.', 'Centre for Advanced Imaging, The University of Queensland, Building 57 of University Dr, St Lucia, QLD 4072, Brisbane, Australia.']	['S0939-3889(18)30167-3 [pii]', '10.1016/j.zemedi.2019.01.001 [doi]']	"['Bollmann S', 'Kristensen MH', 'Larsen MS', 'Olsen MV', 'Pedersen MJ', 'Ostergaard LR', ""O'Brien K"", 'Langkammer C', 'Fazlollahi A', 'Barth M']"		['Copyright (c) 2019. Published by Elsevier GmbH.']					['2019/02/19 06:00']	20191125	20190214	2019 May	2019/02/19 06:00		"['Bollmann, Steffen', 'Kristensen, Matilde Holm', 'Larsen, Morten Skaarup', 'Olsen, Mathias Vassard', 'Pedersen, Mads Jozwiak', 'Ostergaard, Lasse Riis', ""O'Brien, Kieran"", 'Langkammer, Christian', 'Fazlollahi, Amir', 'Barth, Markus']"			2		1876-4436 (Electronic) 0939-3889 (Linking)	100886455	Zeitschrift fur medizinische Physik	['eng']	S0939-3889(18)30167-3 [pii] 10.1016/j.zemedi.2019.01.001 [doi]	20191125	['*Artifacts', 'Brain/diagnostic imaging', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Magnetic Resonance Imaging']	2019/11/26 06:00		['Background field correction', 'Deep learning', 'Quantitative susceptibility mapping']	['NOTNLM']	NLM	139-149	['2018/12/19 00:00 [received]', '2019/01/16 00:00 [revised]', '2019/01/18 00:00 [accepted]', '2019/02/19 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/02/19 06:00 [entrez]']	Germany			30773331	ppublish	['Journal Article']			IM		Z Med Phys. 2019 May;29(2):139-149. doi: 10.1016/j.zemedi.2019.01.001. Epub 2019 Feb 14.	MEDLINE	Z Med Phys	SHARQnet - Sophisticated harmonic artifact reduction in quantitative susceptibility mapping using a deep convolutional neural network.		29	SHARQnet - Sophisticated harmonic artifact reduction in quantitative susceptibility mapping using a deep convolutional neural network.
OBJECTIVES: The aim of this study was to develop a fully automated deep learning approach for identification of the pectoral muscle on mediolateral oblique (MLO) view mammograms and evaluate its performance in comparison to our previously developed texture-field orientation (TFO) method using conventional image feature analysis. Pectoral muscle segmentation is an important step for automated image analyses such as breast density or parenchymal pattern classification, lesion detection, and multiview correlation. MATERIALS AND METHODS: Institutional Review Board (IRB) approval was obtained before data collection. A dataset of 729 MLO-view mammograms including 637 digitized film mammograms (DFM) and 92 digital mammograms (DM) from our previous study was used for the training and validation of our deep convolutional neural network (DCNN) segmentation method. In addition, we collected an independent set of 203 DMs from 131 patients for testing. The film mammograms were digitized at a pixel size of 50 mum x 50 mum with a Lumiscan digitizer. All DMs were acquired with GE systems at a pixel size of 100 mum x 100 mum. An experienced MQSA radiologist manually drew the pectoral muscle boundary on each mammogram as the reference standard. We trained the DCNN to estimate a probability map of the pectoral muscle region on mammograms. The DCNN consisted of a contracting path to capture multiresolution image context and a symmetric expanding path for prediction of the pectoral muscle region. Three DCNN structures were compared for automated identification of pectoral muscles. Tenfold cross-validation was used in training of the DCNNs. After training, we applied the ten trained models during cross-validation to the independent DM test set. The predicted pectoral muscle region of each test DM was obtained as the mean probability map by averaging the ensemble of probability maps from the ten models. The DCNN-segmented pectoral muscle was evaluated by three performance measures relative to the reference standard: (a) the percent overlap area (POA) of the pectoral muscle regions, (b) the Hausdorff distance (Hdist), and (c) the average Euclidean distance (AvgDist) between the boundaries. The results were compared to those obtained with the TFO method, used as our baseline. A two-tailed paired t test was performed to examine the significance in the differences between the DCNN and the baseline. RESULTS: In the ten test partitions of the cross-validation set, the DCNN achieved a mean POA of 96.5 +/- 2.9%, a mean Hdist of 2.26 +/- 1.31 mm, and a mean AvgDist of 0.78 +/- 0.58 mm, while the corresponding measures by the baseline method were 94.2 +/- 4.8%, 3.69 +/- 2.48 mm, and 1.30 +/- 1.22 mm, respectively. For the independent DM test set, the DCNN achieved a mean POA of 93.7% +/- 6.9%, a mean Hdist of 3.80 +/- 3.21 mm, and a mean AvgDist of 1.49 +/- 1.62 mm comparing to 86.9% +/- 16.0%, 7.18 +/- 14.22 mm, and 3.98 +/- 14.13 mm, respectively, by the baseline method. CONCLUSION: In comparison to the TFO method, DCNN significantly improved the accuracy of pectoral muscle identification on mammograms (P < 0.05).	['Department of Radiology, University of Michigan, Ann Arbor, MI, USA.', 'School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.', 'Guangdong Province Key Laboratory Computational Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, USA.', 'School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.', 'Guangdong Province Key Laboratory Computational Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.']	['10.1002/mp.13451 [doi]']	['Ma X', 'Wei J', 'Zhou C', 'Helvie MA', 'Chan HP', 'Hadjiiski LM', 'Lu Y']		['(c) 2019 American Association of Physicists in Medicine.']					['2019/02/17 06:00']	20190912	20190312	2019 May	2019/02/17 06:00		['Ma, Xiangyuan', 'Wei, Jun', 'Zhou, Chuan', 'Helvie, Mark A', 'Chan, Heang-Ping', 'Hadjiiski, Lubomir M', 'Lu, Yao']		['2016B030307003/Science and Technology Innovative Project of Guangdong Province', '2015B020233008/Science and Technology Innovative Project of Guangdong Province', 'U01 CA195599/National Institutes of Health', '2015B010110003/Science and Technology Innovative Project of Guangdong Province', '2016YFB0200602/China Department of Science and Technology', 'U01 CA195599/CA/NCI NIH HHS/United States', '2017B020210001/Guangdong Provincial Science and Technology', '201604020003/Guangzhou Science and Technology Creative Key Grant', '81830052/NSFC', '11401601/NSFC']	5		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13451 [doi]	20190912	['Algorithms', 'Breast Neoplasms/*diagnostic imaging', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Mammography/*methods', '*Neural Networks (Computer)', 'Observer Variation', 'Pectoralis Muscles/*diagnostic imaging', 'Radiologists']	2019/09/13 06:00	['NIHMS1012241']	['deep convolutional neural network (DCNN)', 'mammogram', 'mediolateral oblique (MLO) view', 'pectoral muscle']	['NOTNLM']	NLM	2103-2114	['2018/06/04 00:00 [received]', '2018/12/20 00:00 [revised]', '2019/02/02 00:00 [accepted]', '2020/05/01 00:00 [pmc-release]', '2019/02/17 06:00 [pubmed]', '2019/09/13 06:00 [medline]', '2019/02/17 06:00 [entrez]']	United States	PMC6510623	['2020/05/01 00:00']	30771257	ppublish	['Comparative Study', 'Journal Article']			IM		Med Phys. 2019 May;46(5):2103-2114. doi: 10.1002/mp.13451. Epub 2019 Mar 12.	MEDLINE	Med Phys	Automated pectoral muscle identification on MLO-view mammograms: Comparison of deep neural network to conventional computer vision.		46	Automated pectoral muscle identification on MLO-view mammograms: Comparison of deep neural network to conventional computer vision.
Place cells in the mammalian hippocampus signal self-location with sparse spatially stable firing fields. Based on observation of place cell activity it is possible to accurately decode an animal's location. The precision of this decoding sets a lower bound for the amount of information that the hippocampal population conveys about the location of the animal. In this work we use a novel recurrent neural network (RNN) decoder to infer the location of freely moving rats from single unit hippocampal recordings. RNNs are biologically plausible models of neural circuits that learn to incorporate relevant temporal context without the need to make complicated assumptions about the use of prior information to predict the current state. When decoding animal position from spike counts in 1D and 2D-environments, we show that the RNN consistently outperforms a standard Bayesian approach with either flat priors or with memory. In addition, we also conducted a set of sensitivity analysis on the RNN decoder to determine which neurons and sections of firing fields were the most influential. We found that the application of RNNs to neural data allowed flexible integration of temporal context, yielding improved accuracy relative to the more commonly used Bayesian approaches and opens new avenues for exploration of the neural code.	['Computational Neuroscience Lab, Institute of Computer Science, University of Tartu, Tartu, Estonia.', 'Computational Neuroscience Lab, Institute of Computer Science, University of Tartu, Tartu, Estonia.', 'Department of Cell and Developmental Biology, University College London, London, United Kingdom.', 'Department of Cell and Developmental Biology, University College London, London, United Kingdom.', 'Computational Neuroscience Lab, Institute of Computer Science, University of Tartu, Tartu, Estonia.']	['10.1371/journal.pcbi.1006822 [doi]', 'PCOMPBIOL-D-18-00017 [pii]']	['Tampuu A', 'Matiisen T', 'Olafsdottir HF', 'Barry C', 'Vicente R']	['ORCID: 0000-0002-2497-0007']				['The authors have declared that no competing interests exist.']		['2019/02/16 06:00']	20190328	20190215	2019 Feb	2019/02/16 06:00		['Tampuu, Ardi', 'Matiisen, Tambet', 'Olafsdottir, H Freyja', 'Barry, Caswell', 'Vicente, Raul']			2		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1006822 [doi]	20190329	['Action Potentials', 'Animals', 'Bayes Theorem', 'Forecasting/*methods', 'Hippocampus/*physiology', 'Machine Learning', 'Male', 'Memory', 'Models, Neurological', 'Neural Networks (Computer)', 'Neurons', 'Place Cells/*physiology', 'Rats', 'Rats, Inbred Strains/physiology', 'Spatial Processing/physiology']	2019/03/29 06:00				NLM	e1006822	['2018/01/04 00:00 [received]', '2019/01/28 00:00 [accepted]', '2019/03/08 00:00 [revised]', '2019/02/16 06:00 [pubmed]', '2019/03/29 06:00 [medline]', '2019/02/16 06:00 [entrez]']	United States	PMC6407788		30768590	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS Comput Biol. 2019 Feb 15;15(2):e1006822. doi: 10.1371/journal.pcbi.1006822. eCollection 2019 Feb.	MEDLINE	PLoS Comput Biol	Efficient neural decoding of self-location with a deep recurrent network.		15	Efficient neural decoding of self-location with a deep recurrent network.
Current pharmaceutical formulation development still strongly relies on the traditional trial-and-error methods of pharmaceutical scientists. This approach is laborious, time-consuming and costly. Recently, deep learning has been widely applied in many challenging domains because of its important capability of automatic feature extraction. The aim of the present research is to apply deep learning methods to predict pharmaceutical formulations. In this paper, two types of dosage forms were chosen as model systems. Evaluation criteria suitable for pharmaceutics were applied to assess the performance of the models. Moreover, an automatic dataset selection algorithm was developed for selecting the representative data as validation and test datasets. Six machine learning methods were compared with deep learning. Results showed that the accuracies of both two deep neural networks were above 80% and higher than other machine learning models; the latter showed good prediction of pharmaceutical formulations. In summary, deep learning employing an automatic data splitting algorithm and the evaluation criteria suitable for pharmaceutical formulation data was developed for the prediction of pharmaceutical formulations for the first time. The cross-disciplinary integration of pharmaceutics and artificial intelligence may shift the paradigm of pharmaceutical research from experience-dependent studies to data-driven methodologies.	['State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, China.', 'Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, China.', 'State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, China.', 'State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, China.', 'State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, China.', 'Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, China.', 'State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, China.']	['10.1016/j.apsb.2018.09.010 [doi]', 'S2211-3835(18)30282-X [pii]']	['Yang Y', 'Ye Z', 'Su Y', 'Zhao Q', 'Li X', 'Ouyang D']							['2019/02/16 06:00']		20180928	2019 Jan	2019/02/16 06:00		['Yang, Yilong', 'Ye, Zhuyifan', 'Su, Yan', 'Zhao, Qianqian', 'Li, Xiaoshan', 'Ouyang, Defang']			1		2211-3835 (Print) 2211-3835 (Linking)	101600560	Acta pharmaceutica Sinica. B	['eng']	10.1016/j.apsb.2018.09.010 [doi]	20191120		2019/02/16 06:01		['ANNs, artificial neural networks', 'APIs, active pharmaceutical ingredients', 'Automatic dataset selection algorithm', 'DNNs, deep neural networks', 'Deep learning', 'ESs, expert systems', 'FDA, U.S. Food and Drug Administration', 'HPMC, hydroxypropyl methylene cellulose', 'MAE, mean absolute error', 'MD-FIS, the Maximum Dissimilarity algorithm with the small group filter and', 'representative initial set selection', 'MLR, multiple linear regression', 'OFDF, oral fast disintegrating films', 'Oral fast disintegrating films', 'Oral sustained release matrix tablets', 'PLSR, partial least squared regression', 'Pharmaceutical formulation', 'QSAR, quantitative structure activity relationships', 'QbD, quality by design', 'RF, random forest', 'RMSE, root mean squared error', 'SRMT, sustained release matrix tablets', 'SVM, support vector machine', 'Small data', 'k-NN, k-nearest neighbors']	['NOTNLM']	NLM	177-185	['2018/07/28 00:00 [received]', '2018/09/05 00:00 [revised]', '2018/09/05 00:00 [accepted]', '2019/02/16 06:00 [entrez]', '2019/02/16 06:00 [pubmed]', '2019/02/16 06:01 [medline]']	Netherlands	PMC6362259		30766789	ppublish	['Journal Article']					Acta Pharm Sin B. 2019 Jan;9(1):177-185. doi: 10.1016/j.apsb.2018.09.010. Epub 2018 Sep 28.	PubMed-not-MEDLINE	Acta Pharm Sin B	Deep learning for in vitro prediction of pharmaceutical formulations.		9	Deep learning for in vitro prediction of pharmaceutical formulations.
	['Department of Computer Science, Weizmann, Institute of Science, Rehovot, Israel. shimon.ullman@weizmann.ac.il.']	['363/6428/692 [pii]', '10.1126/science.aau6595 [doi]']	['Ullman S']							['2019/02/16 06:00']	20190801		2019 Feb 15	2019/02/16 06:00		['Ullman, Shimon']			6428		1095-9203 (Electronic) 0036-8075 (Linking)	0404511	Science (New York, N.Y.)	['eng']	10.1126/science.aau6595 [doi]	20190801	['*Artificial Intelligence', 'Brain/ultrastructure', 'Deep Learning', 'Humans', 'Learning/physiology', '*Neural Networks (Computer)', 'Neurosciences/*methods']	2019/08/02 06:00				NLM	692-693	['2019/02/16 06:00 [entrez]', '2019/02/16 06:00 [pubmed]', '2019/08/02 06:00 [medline]']	United States			30765552	ppublish	['Journal Article']					Science. 2019 Feb 15;363(6428):692-693. doi: 10.1126/science.aau6595.	MEDLINE	Science	Using neuroscience to develop artificial intelligence.		363	Using neuroscience to develop artificial intelligence.
Machine learning approaches are increasingly used to extract patterns and insights from the ever-increasing stream of geospatial data, but current approaches may not be optimal when system behaviour is dominated by spatial or temporal context. Here, rather than amending classical machine learning, we argue that these contextual cues should be used as part of deep learning (an approach that is able to extract spatio-temporal features automatically) to gain further process understanding of Earth system science problems, improving the predictive ability of seasonal forecasting and modelling of long-range spatial connections across multiple timescales, for example. The next step will be a hybrid modelling approach, coupling physical process models with the versatility of data-driven machine learning.	['Department of Biogeochemical Integration, Max Planck Institute for Biogeochemistry, Jena, Germany. mreichstein@bgc-jena.mpg.de.', 'Michael-Stifel-Center Jena for Data-driven and Simulation Science, Jena, Germany. mreichstein@bgc-jena.mpg.de.', 'Image Processing Laboratory (IPL), University of Valencia, Valencia, Spain.', 'Max Planck Institute for Meteorology, Hamburg, Germany.', 'Department of Biogeochemical Integration, Max Planck Institute for Biogeochemistry, Jena, Germany.', 'Michael-Stifel-Center Jena for Data-driven and Simulation Science, Jena, Germany.', 'Computer Vision Group, Computer Science, Friedrich Schiller University, Jena, Germany.', 'Department of Biogeochemical Integration, Max Planck Institute for Biogeochemistry, Jena, Germany.', 'CENSE, Departamento de Ciencias e Engenharia do Ambiente, Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Lisbon, Portugal.', 'National Energy Research Supercomputing Center, Lawrence Berkeley National Laboratory, Berkeley, CA, USA.']	['10.1038/s41586-019-0912-1 [doi]', '10.1038/s41586-019-0912-1 [pii]']	['Reichstein M', 'Camps-Valls G', 'Stevens B', 'Jung M', 'Denzler J', 'Carvalhais N', 'Prabhat']			['Nature. 2019 Feb;566(7743):153. PMID: 30867602']				['2019/02/15 06:00']	20190711	20190213	2019 Feb	2019/02/15 06:00		['Reichstein, Markus', 'Camps-Valls, Gustau', 'Stevens, Bjorn', 'Jung, Martin', 'Denzler, Joachim', 'Carvalhais, Nuno', 'Prabhat']			7743		1476-4687 (Electronic) 0028-0836 (Linking)	0410462	Nature	['eng']	10.1038/s41586-019-0912-1 [doi]	20190711	['*Big Data', '*Computer Simulation', '*Deep Learning', 'Earth Sciences/*methods', 'Facial Recognition', 'Female', 'Forecasting/*methods', 'Geographic Mapping', 'Humans', 'Knowledge', 'Pattern Recognition, Automated/*methods', 'Regression (Psychology)', 'Reproducibility of Results', 'Seasons', 'Spatio-Temporal Analysis', 'Time Factors', 'Translating', 'Uncertainty', 'Weather']	2019/07/12 06:00				NLM	195-204	['2017/07/28 00:00 [received]', '2018/12/05 00:00 [accepted]', '2019/02/15 06:00 [entrez]', '2019/02/15 06:00 [pubmed]', '2019/07/12 06:00 [medline]']	England			30760912	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Nature. 2019 Feb;566(7743):195-204. doi: 10.1038/s41586-019-0912-1. Epub 2019 Feb 13.	MEDLINE	Nature	Deep learning and process understanding for data-driven Earth system science.		566	Deep learning and process understanding for data-driven Earth system science.
Tracking scientific research publications on the evaluation, utility and implementation of genomic applications is critical for the translation of basic research to impact clinical and population health. In this work, we utilize state-of-the-art machine learning approaches to identify translational research in genomics beyond bench to bedside from the biomedical literature. We apply the convolutional neural networks (CNNs) and support vector machines (SVMs) to the bench/bedside article classification on the weekly manual annotation data of the Public Health Genomics Knowledge Base database. Both classifiers employ salient features to determine the probability of curation-eligible publications, which can effectively reduce the workload of manual triage and curation process. We applied the CNNs and SVMs to an independent test set (n = 400), and the models achieved the F-measure of 0.80 and 0.74, respectively. We further tested the CNNs, which perform better results, on the routine annotation pipeline for 2 weeks and significantly reduced the effort and retrieved more appropriate research articles. Our approaches provide direct insight into the automated curation of genomic translational research beyond bench to bedside. The machine learning classifiers are found to be helpful for annotators to enhance the efficiency of manual curation.	['National Center for Biotechnology Information, National Library of Medicine, Bethesda, MD, USA.', 'Implementation Science Team, Division of Cancer Control and Population Sciences, National Cancer Institute, Bethesda, MD, USA.', 'National Center for Biotechnology Information, National Library of Medicine, Bethesda, MD, USA.', 'Office of Public Health Genomics, Centers for Disease Control and Prevention, Atlanta, GA, USA.', 'National Center for Biotechnology Information, National Library of Medicine, Bethesda, MD, USA.']	['5309020 [pii]', '10.1093/database/baz010 [doi]']	['Hsu YY', 'Clyne M', 'Wei CH', 'Khoury MJ', 'Lu Z']							['2019/02/13 06:00']	20190724	20190101	2019 Jan 1	2019/02/13 06:00		['Hsu, Yi-Yu', 'Clyne, Mindy', 'Wei, Chih-Hsuan', 'Khoury, Muin J', 'Lu, Zhiyong']					1758-0463 (Electronic) 1758-0463 (Linking)	101517697	Database : the journal of biological databases and curation	['eng']	10.1093/database/baz010 [doi]	20190724	['*Deep Learning', '*Genomics', 'Neural Networks (Computer)', 'ROC Curve', 'Reproducibility of Results', 'Statistics as Topic', 'Support Vector Machine', 'Task Performance and Analysis', '*Translational Medical Research']	2019/07/25 06:00				NLM		['2018/10/18 00:00 [received]', '2019/01/15 00:00 [accepted]', '2019/02/13 06:00 [entrez]', '2019/02/13 06:00 [pubmed]', '2019/07/25 06:00 [medline]']	England	PMC6367517		30753477	epublish	['Journal Article', 'Research Support, N.I.H., Intramural']					Database (Oxford). 2019 Jan 1;2019. pii: 5309020. doi: 10.1093/database/baz010.	MEDLINE	Database (Oxford)	Using deep learning to identify translational research in genomic medicine beyond bench to bedside.		2019	Using deep learning to identify translational research in genomic medicine beyond bench to bedside.
OBJECTIVES: To develop a U-Net-based deep learning approach (U-DL) for bladder segmentation in computed tomography urography (CTU) as a part of a computer-assisted bladder cancer detection and treatment response assessment pipeline. MATERIALS AND METHODS: A dataset of 173 cases including 81 cases in the training/validation set (42 masses, 21 with wall thickening, 18 normal bladders), and 92 cases in the test set (43 masses, 36 with wall thickening, 13 normal bladders) were used with Institutional Review Board approval. An experienced radiologist provided three-dimensional (3D) hand outlines for all cases as the reference standard. We previously developed a bladder segmentation method that used a deep learning convolution neural network and level sets (DCNN-LS) within a user-input bounding box. However, some cases with poor image quality or with advanced bladder cancer spreading into the neighboring organs caused inaccurate segmentation. We have newly developed an automated U-DL method to estimate a likelihood map of the bladder in CTU. The U-DL did not require a user-input box and the level sets for postprocessing. To identify the best model for this task, we compared the following models: (a) two-dimensional (2D) U-DL and 3D U-DL using 2D CT slices and 3D CT volumes, respectively, as input, (b) U-DLs using CT images of different resolutions as input, and (c) U-DLs with and without automated cropping of the bladder as an image preprocessing step. The segmentation accuracy relative to the reference standard was quantified by six measures: average volume intersection ratio (AVI), average percent volume error (AVE), average absolute volume error (AAVE), average minimum distance (AMD), average Hausdorff distance (AHD), and the average Jaccard index (AJI). As a baseline, the results from our previous DCNN-LS method were used. RESULTS: In the test set, the best 2D U-DL model achieved AVI, AVE, AAVE, AMD, AHD, and AJI values of 93.4 +/- 9.5%, -4.2 +/- 14.2%, 9.2 +/- 11.5%, 2.7 +/- 2.5 mm, 9.7 +/- 7.6 mm, 85.0 +/- 11.3%, respectively, while the corresponding measures by the best 3D U-DL were 90.6 +/- 11.9%, -2.3 +/- 21.7%, 11.5 +/- 18.5%, 3.1 +/- 3.2 mm, 11.4 +/- 10.0 mm, and 82.6 +/- 14.2%, respectively. For comparison, the corresponding values obtained with the baseline method were 81.9 +/- 12.1%, 10.2 +/- 16.2%, 14.0 +/- 13.0%, 3.6 +/- 2.0 mm, 12.8 +/- 6.1 mm, and 76.2 +/- 11.8%, respectively, for the same test set. The improvement for all measures between the best U-DL and the DCNN-LS were statistically significant (P < 0.001). CONCLUSION: Compared to a previous DCNN-LS method, which depended on a user-input bounding box, the U-DL provided more accurate bladder segmentation and was more automated than the previous approach.	['Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.', 'Guangdong Province Key Laboratory Computational Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'Department of Radiology, University of Michigan, Ann Arbor, MI, 48109, USA.', 'School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.', 'Guangdong Province Key Laboratory Computational Science, Sun Yat-Sen University, Guangzhou, 510275, P.R. China.']	['10.1002/mp.13438 [doi]']	['Ma X', 'Hadjiiski LM', 'Wei J', 'Chan HP', 'Cha KH', 'Cohan RH', 'Caoili EM', 'Samala R', 'Zhou C', 'Lu Y']		['(c) 2019 American Association of Physicists in Medicine.']					['2019/02/09 06:00']	20190830	20190228	2019 Apr	2019/02/09 06:00		['Ma, Xiangyuan', 'Hadjiiski, Lubomir M', 'Wei, Jun', 'Chan, Heang-Ping', 'Cha, Kenny H', 'Cohan, Richard H', 'Caoili, Elaine M', 'Samala, Ravi', 'Zhou, Chuan', 'Lu, Yao']		['U01CA179106/GF/NIH HHS/United States', '201604020003/Guangdong Provincial Science and Technology', '2016YFB0200602/China Department of Science and Technology', '2017B020210001/Guangdong Provincial Science and Technology', '2015B020233008/Science and Technology Innovative Project', 'U01 CA179106/CA/NCI NIH HHS/United States', '81830052/NSFC', '2015B010110003/Science and Technology Innovative Project', '2016B030307003/Science and Technology Innovative Project', '11401601/NSFC']	4		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13438 [doi]	20190830	['Algorithms', 'Case-Control Studies', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Neural Networks (Computer)', 'Tomography, X-Ray Computed/*methods', 'Urinary Bladder/*diagnostic imaging', 'Urinary Bladder Neoplasms/*diagnostic imaging', 'Urography/methods']	2019/08/31 06:00	['NIHMS1011265']	['CT urography', 'bladder', 'computer-aided detection', 'deep learning', 'segmentation']	['NOTNLM']	NLM	1752-1765	['2018/09/05 00:00 [received]', '2018/12/26 00:00 [revised]', '2019/01/31 00:00 [accepted]', '2020/04/01 00:00 [pmc-release]', '2019/02/09 06:00 [pubmed]', '2019/08/31 06:00 [medline]', '2019/02/09 06:00 [entrez]']	United States	PMC6453730	['2020/04/01 00:00']	30734932	ppublish	['Journal Article']			IM		Med Phys. 2019 Apr;46(4):1752-1765. doi: 10.1002/mp.13438. Epub 2019 Feb 28.	MEDLINE	Med Phys	U-Net based deep learning bladder segmentation in CT urography.		46	U-Net based deep learning bladder segmentation in CT urography.
BACKGROUND: Prioritization of variants in personal genomic data is a major challenge. Recently, computational methods that rely on comparing phenotype similarity have shown to be useful to identify causative variants. In these methods, pathogenicity prediction is combined with a semantic similarity measure to prioritize not only variants that are likely to be dysfunctional but those that are likely involved in the pathogenesis of a patient's phenotype. RESULTS: We have developed DeepPVP, a variant prioritization method that combined automated inference with deep neural networks to identify the likely causative variants in whole exome or whole genome sequence data. We demonstrate that DeepPVP performs significantly better than existing methods, including phenotype-based methods that use similar features. DeepPVP is freely available at https://github.com/bio-ontology-research-group/phenomenet-vp . CONCLUSIONS: DeepPVP further improves on existing variant prioritization methods both in terms of speed as well as accuracy.	['Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology, 4700 KAUST, Thuwal, 23955-6900, Kingdom of Saudi Arabia.', 'Computer, Electrical and Mathematical Sciences & Engineering Division (CEMSE), King Abdullah University of Science and Technology, 4700 KAUST, PO Box 2882, Thuwal, 23955-6900, Kingdom of Saudi Arabia.', 'Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology, 4700 KAUST, Thuwal, 23955-6900, Kingdom of Saudi Arabia.', 'Computer, Electrical and Mathematical Sciences & Engineering Division (CEMSE), King Abdullah University of Science and Technology, 4700 KAUST, PO Box 2882, Thuwal, 23955-6900, Kingdom of Saudi Arabia.', 'Department of Physiology, Development & Neuroscience, University of Cambridge, Downing Street, Cambridge, CB2 3EG, UK.', 'College of Medical and Dental Sciences, Institute of Cancer and Genomic Sciences, Centre for Computational Biology, University of Birmingham, Birmingham, B15 2TT, UK.', 'Institute of Translational Medicine, University Hospitals Birmingham, NHS Foundation Trust, Birmingham, B15 2TT, UK.', 'NIHR Experimental Cancer Medicine Centre, Birmingham, B15 2TT, UK.', 'NIHR Surgical Reconstruction and Microbiology, Birmingham, B15 2TT, UK.', 'NIHR Biomedical Research Centre, Birmingham, B15 2TT, UK.', 'MRC Health Data Research UK, Birmingham, B15 2TT, UK.', 'Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology, 4700 KAUST, Thuwal, 23955-6900, Kingdom of Saudi Arabia. robert.hoehndorf@kaust.edu.sa.', 'Computer, Electrical and Mathematical Sciences & Engineering Division (CEMSE), King Abdullah University of Science and Technology, 4700 KAUST, PO Box 2882, Thuwal, 23955-6900, Kingdom of Saudi Arabia. robert.hoehndorf@kaust.edu.sa.']	['10.1186/s12859-019-2633-8 [doi]', '10.1186/s12859-019-2633-8 [pii]']	['Boudellioua I', 'Kulmanov M', 'Schofield PN', 'Gkoutos GV', 'Hoehndorf R']	['ORCID: http://orcid.org/0000-0001-8149-5890']						['2019/02/08 06:00']	20190304	20190206	2019 Feb 6	2019/02/08 06:00		['Boudellioua, Imane', 'Kulmanov, Maxat', 'Schofield, Paul N', 'Gkoutos, Georgios V', 'Hoehndorf, Robert']		['URF/1/3454-01-01/King Abdullah University of Science and Technology', 'FCC/1/1976-08-01/King Abdullah University of Science and Technology', '731075/Horizon 2020', 'IOS:1340112/National Science Foundation', 'FCS/1/3657-02-01/King Abdullah University of Science and Technology']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2633-8 [doi]	20190304	['*Deep Learning', 'Exome/genetics', 'Gene Frequency/genetics', '*Genetic Variation', 'Humans', 'Neural Networks (Computer)', 'Phenotype', '*Software', 'Whole Exome Sequencing']	2019/03/05 06:00		['Machine learning', 'Ontology', 'Phenotype', 'Variant prioritization']	['NOTNLM']	NLM	65	['2018/03/29 00:00 [received]', '2019/01/17 00:00 [accepted]', '2019/02/08 06:00 [entrez]', '2019/02/08 06:00 [pubmed]', '2019/03/05 06:00 [medline]']	England	PMC6364462		30727941	epublish	['Journal Article']			IM		BMC Bioinformatics. 2019 Feb 6;20(1):65. doi: 10.1186/s12859-019-2633-8.	MEDLINE	BMC Bioinformatics	DeepPVP: phenotype-based prioritization of causative variants using deep learning.		20	DeepPVP: phenotype-based prioritization of causative variants using deep learning.
Segmentation and detection of mitotic nuclei is a challenging task. To address this problem, a Transfer Learning based fast and accurate system is proposed. To give the classifier a balanced dataset, this work exploits the concept of Transfer Learning by first using a pre-trained convolutional neural network (CNN) for segmentation, and then another Hybrid-CNN (with Weights Transfer and custom layers) for classification of mitoses. First, mitotic nuclei are automatically annotated, based on the ground truth centroids. The segmentation module then segments mitotic nuclei and also produces some false positives. Finally, the detection module is trained on the patches from the segmentation module and performs the final detection. Fine-tuning based Transfer Learning reduced training time, provided good initial weights, and improved the detection rate with F-measure of 0.713 and 76% area under the precision-recall curve for the challenging task of mitosis detection.	['Pattern Recognition Lab, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad.', 'Pattern Recognition Lab, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad.', 'Deep Learning Lab, Centre for Mathematical Sciences, Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad.', 'Department of Biomedical Engineering, College of Medical Science, Catholic University of Daegu, Gyoungsangbuk-do, Republic of Korea.']	['5306632 [pii]', '10.1093/jmicro/dfz002 [doi]']	['Wahab N', 'Khan A', 'Lee YS']		['(c) The Author(s) 2019. Published by Oxford University Press on behalf of The', 'Japanese Society of Microscopy. All rights reserved. For permissions, please', 'e-mail: journals.permissions@oup.com.']					['2019/02/06 06:00']	20190814		2019 Jun 1	2019/02/06 06:00		['Wahab, Noorul', 'Khan, Asifullah', 'Lee, Yeon Soo']			3		2050-5701 (Electronic) 2050-5698 (Linking)	101595834	Microscopy (Oxford, England)	['eng']	10.1093/jmicro/dfz002 [doi]	20190814	['Artificial Intelligence', 'Automation, Laboratory/*methods', 'Breast Neoplasms/*diagnosis/pathology', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', 'Mitosis/*physiology', '*Neural Networks (Computer)']	2019/08/15 06:00		['breast cancer', 'convolutional neural networks', 'mitosis count', 'nuclei segmentation', 'transfer learning']	['NOTNLM']	NLM	216-233	['2018/09/16 00:00 [received]', '2018/12/21 00:00 [revised]', '2019/01/11 00:00 [accepted]', '2019/02/06 06:00 [pubmed]', '2019/08/15 06:00 [medline]', '2019/02/06 06:00 [entrez]']	England			30722018	ppublish	['Journal Article']					Microscopy (Oxf). 2019 Jun 1;68(3):216-233. doi: 10.1093/jmicro/dfz002.	MEDLINE	Microscopy (Oxf)	Transfer learning based deep CNN for segmentation and detection of mitoses in breast cancer histopathological images.		68	Transfer learning based deep CNN for segmentation and detection of mitoses in breast cancer histopathological images.
Analogy-the ability to find and apply deep structural patterns across domains-has been fundamental to human innovation in science and technology. Today there is a growing opportunity to accelerate innovation by moving analogy out of a single person's mind and distributing it across many information processors, both human and machine. Doing so has the potential to overcome cognitive fixation, scale to large idea repositories, and support complex problems with multiple constraints. Here we lay out a perspective on the future of scalable analogical innovation and first steps using crowds and artificial intelligence (AI) to augment creativity that quantitatively demonstrate the promise of the approach, as well as core challenges critical to realizing this vision.	['Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA 15213; nkittur@cs.cmu.edu.', 'Robert Bosch, Research and Technology Center, Division 3, Pittsburgh, PA 15222.', 'School of Computer Science and Engineering, The Hebrew University of Jerusalem, 9190401 Jerusalem, Israel.', 'College of Information Studies, University of Maryland, College Park, MD 20742.', 'Department of Information, Operations and Management Sciences, Leonard N. Stern School of Business, New York University, New York, NY 10012.', 'School of Computer Science and Engineering, The Hebrew University of Jerusalem, 9190401 Jerusalem, Israel.', 'Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA 15213.', 'Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA 15213.', 'School of Computer Science and Engineering, The Hebrew University of Jerusalem, 9190401 Jerusalem, Israel.']	['1807185116 [pii]', '10.1073/pnas.1807185116 [doi]']	['Kittur A', 'Yu L', 'Hope T', 'Chan J', 'Lifshitz-Assaf H', 'Gilon K', 'Ng F', 'Kraut RE', 'Shahaf D']	['ORCID: 0000-0002-8554-2137']				['The authors declare no conflict of interest.']		['2019/02/06 06:00']	20190404		2019 Feb 5	2019/02/06 06:00	['Proc Natl Acad Sci U S A. 2019 Aug 13;116(33):16654. PMID: 31405965']	['Kittur, Aniket', 'Yu, Lixiu', 'Hope, Tom', 'Chan, Joel', 'Lifshitz-Assaf, Hila', 'Gilon, Karni', 'Ng, Felicia', 'Kraut, Robert E', 'Shahaf, Dafna']			6		1091-6490 (Electronic) 0027-8424 (Linking)	7505876	Proceedings of the National Academy of Sciences of the United States of America	['eng']	10.1073/pnas.1807185116 [doi]	20190404		2019/02/06 06:01		['*AI', '*analogy', '*crowdsourcing', '*innovation', '*machine learning']	['NOTNLM']	NLM	1870-1877	['2019/02/06 06:00 [pubmed]', '2019/02/06 06:01 [medline]', '2019/02/06 06:00 [entrez]']	United States	PMC6369801		30718420	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S."", ""Research Support, Non-U.S. Gov't""]"					Proc Natl Acad Sci U S A. 2019 Feb 5;116(6):1870-1877. doi: 10.1073/pnas.1807185116.	PubMed-not-MEDLINE	Proc Natl Acad Sci U S A	Scaling up analogical innovation with crowds and AI.		116	Scaling up analogical innovation with crowds and AI.
Comprehensive characterization of ligand-binding sites is invaluable to infer molecular functions of hypothetical proteins, trace evolutionary relationships between proteins, engineer enzymes to achieve a desired substrate specificity, and develop drugs with improved selectivity profiles. These research efforts pose significant challenges owing to the fact that similar pockets are commonly observed across different folds, leading to the high degree of promiscuity of ligand-protein interactions at the system-level. On that account, novel algorithms to accurately classify binding sites are needed. Deep learning is attracting a significant attention due to its successful applications in a wide range of disciplines. In this communication, we present DeepDrug3D, a new approach to characterize and classify binding pockets in proteins with deep learning. It employs a state-of-the-art convolutional neural network in which biomolecular structures are represented as voxels assigned interaction energy-based attributes. The current implementation of DeepDrug3D, trained to detect and classify nucleotide- and heme-binding sites, not only achieves a high accuracy of 95%, but also has the ability to generalize to unseen data as demonstrated for steroid-binding proteins and peptidase enzymes. Interestingly, the analysis of strongly discriminative regions of binding pockets reveals that this high classification accuracy arises from learning the patterns of specific molecular interactions, such as hydrogen bonds, aromatic and hydrophobic contacts. DeepDrug3D is available as an open-source program at https://github.com/pulimeng/DeepDrug3D with the accompanying TOUGH-C1 benchmarking dataset accessible from https://osf.io/enz69/.	['Division of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, United States of America.', 'Department of Biological Sciences, Louisiana State University, Baton Rouge, LA, United States of America.', 'Department of Biological Sciences, Louisiana State University, Baton Rouge, LA, United States of America.', 'Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, LA, United States of America.', 'Division of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, United States of America.', 'Department of Biological Sciences, Louisiana State University, Baton Rouge, LA, United States of America.', 'Center for Computation & Technology, Louisiana State University, Baton Rouge, LA, United States of America.']	['10.1371/journal.pcbi.1006718 [doi]', 'PCOMPBIOL-D-18-01397 [pii]']	['Pu L', 'Govindaraj RG', 'Lemoine JM', 'Wu HC', 'Brylinski M']	['ORCID: 0000-0002-9632-8419', 'ORCID: 0000-0002-6204-2869']				['The authors have declared that no competing interests exist.']		['2019/02/05 06:00']	20190312	20190204	2019 Feb	2019/02/05 06:00		['Pu, Limeng', 'Govindaraj, Rajiv Gandhi', 'Lemoine, Jeffrey Mitchell', 'Wu, Hsiao-Chun', 'Brylinski, Michal']		['R35 GM119524/GM/NIGMS NIH HHS/United States']	2		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1006718 [doi]	20190312	['Algorithms', 'Binding Sites/*physiology', 'Computational Biology/*methods', 'Databases, Protein', 'Deep Learning', 'Ligands', 'Models, Molecular', 'Neural Networks (Computer)', 'Protein Binding/physiology', 'Proteins/chemistry']	2019/03/13 06:00				NLM	e1006718	['2018/08/13 00:00 [received]', '2018/12/16 00:00 [accepted]', '2019/02/14 00:00 [revised]', '2019/02/05 06:00 [pubmed]', '2019/03/13 06:00 [medline]', '2019/02/05 06:00 [entrez]']	United States	PMC6375647		30716081	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']		['0 (Ligands)', '0 (Proteins)']	IM		PLoS Comput Biol. 2019 Feb 4;15(2):e1006718. doi: 10.1371/journal.pcbi.1006718. eCollection 2019 Feb.	MEDLINE	PLoS Comput Biol	DeepDrug3D: Classification of ligand-binding pockets in proteins with a convolutional neural network.		15	DeepDrug3D: Classification of ligand-binding pockets in proteins with a convolutional neural network.
BACKGROUND AND OBJECTIVE: Prostate segmentation on Magnetic Resonance (MR) imaging is problematic because disease changes the shape and boundaries of the gland and it can be difficult to separate the prostate from surrounding tissues. We propose an automated model that extracts and combines multi-level features in a deep neural network to segment prostate on MR images. METHODS: Our proposed model, the Propagation Deep Neural Network (P-DNN), incorporates the optimal combination of multi-level feature extraction as a single model. High level features from the convolved data using DNN are extracted for prostate localization and shape recognition, while labeling propagation, by low level cues, is embedded into a deep layer to delineate the prostate boundary. RESULTS: A well-recognized benchmarking dataset (50 training data and 30 testing data from patients) was used to evaluate the P-DNN. When compared it to existing DNN methods, the P-DNN statistically outperformed the baseline DNN models with an average improvement in the DSC of 3.19%. When compared to the state-of-the-art non-DNN prostate segmentation methods, P-DNN was competitive by achieving 89.9 +/- 2.8% DSC and 6.84 +/- 2.5 mm HD on training sets and 84.13 +/- 5.18% DSC and 9.74 +/- 4.21 mm HD on testing sets. CONCLUSION: Our results show that P-DNN maximizes multi-level feature extraction for prostate segmentation of MR images.	['Biomedical and Multimedia Information Technology Research Group, School of Computer Science, University of Sydney, Sydney, Australia.', 'Biomedical and Multimedia Information Technology Research Group, School of Computer Science, University of Sydney, Sydney, Australia. Electronic address: xiu.wang@sydney.edu.au.', 'Biomedical and Multimedia Information Technology Research Group, School of Computer Science, University of Sydney, Sydney, Australia.', 'Department of Urology, Nepean Hospital, Kingswood, Australia.', 'Department of Molecular Imaging, Royal Prince Alfred Hospital, Sydney, Australia.', 'Biomedical and Multimedia Information Technology Research Group, School of Computer Science, University of Sydney, Sydney, Australia.']	['S0169-2607(18)31099-X [pii]', '10.1016/j.cmpb.2018.12.031 [doi]']	['Yan K', 'Wang X', 'Kim J', 'Khadra M', 'Fulham M', 'Feng D']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2019/02/05 06:00']	20190515	20181229	2019 Mar	2019/02/05 06:00		['Yan, Ke', 'Wang, Xiuying', 'Kim, Jinman', 'Khadra, Mohamed', 'Fulham, Michael', 'Feng, Dagan']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)31099-X [pii] 10.1016/j.cmpb.2018.12.031 [doi]	20190515	['Algorithms', '*Deep Learning', 'Humans', 'Magnetic Resonance Imaging/*methods', 'Male', 'Neural Networks (Computer)', 'Prostate/*physiopathology']	2019/05/16 06:00		['Deep neural network', 'Multi-level features', 'Prostate segmentation']	['NOTNLM']	NLM	11-21	['2018/07/31 00:00 [received]', '2018/12/13 00:00 [revised]', '2018/12/28 00:00 [accepted]', '2019/02/05 06:00 [entrez]', '2019/02/05 06:00 [pubmed]', '2019/05/16 06:00 [medline]']	Ireland			30712600	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2019 Mar;170:11-21. doi: 10.1016/j.cmpb.2018.12.031. Epub 2018 Dec 29.	MEDLINE	Comput Methods Programs Biomed	A propagation-DNN: Deep combination learning of multi-level features for MR prostate segmentation.		170	A propagation-DNN: Deep combination learning of multi-level features for MR prostate segmentation.
Effort-aware just-in-time (JIT) defect prediction is to rank source code changes based on the likelihood of detects as well as the effort to inspect such changes. Accurate defect prediction algorithms help to find more defects with limited effort. To improve the accuracy of defect prediction, in this paper, we propose a deep learning based approach for effort-aware just-in-time defect prediction. The key idea of the proposed approach is that neural network and deep learning could be exploited to select useful features for defect prediction because they have been proved excellent at selecting useful features for classification and regression. First, we preprocess ten numerical metrics of code changes, and then feed them to a neural network whose output indicates how likely the code change under test contains bugs. Second, we compute the benefit cost ratio for each code change by dividing the likelihood by its size. Finally, we rank code changes according to their benefit cost ratio. Evaluation results on a well-known data set suggest that the proposed approach outperforms the state-of-the-art approaches on each of the subject projects. It improves the average recall and popt by 15.6% and 8.1%, respectively.	['School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.', 'School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China.']	['10.1371/journal.pone.0211359 [doi]', 'PONE-D-18-31860 [pii]']	['Qiao L', 'Wang Y']	['ORCID: 0000-0002-8221-3741']				['The authors have declared that no competing interests exist.']		['2019/02/02 06:00']	20191101	20190201	2019	2019/02/02 06:00		['Qiao, Lei', 'Wang, Yan']			2		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0211359 [doi]	20191101	['Deep Learning', '*Neural Networks (Computer)', 'Software']	2019/11/02 06:00				NLM	e0211359	['2018/11/08 00:00 [received]', '2019/01/13 00:00 [accepted]', '2019/02/02 06:00 [entrez]', '2019/02/02 06:00 [pubmed]', '2019/11/02 06:00 [medline]']	United States	PMC6358090		30707738	epublish	['Journal Article']			IM		PLoS One. 2019 Feb 1;14(2):e0211359. doi: 10.1371/journal.pone.0211359. eCollection 2019.	MEDLINE	PLoS One	Effort-aware and just-in-time defect prediction with neural network.		14	Effort-aware and just-in-time defect prediction with neural network.
Deep learning has caused a third boom of artificial intelligence and great changes of diagnostic medical imaging systems such as radiology, pathology, retinal imaging, dermatology inspection, and endoscopic diagnosis will be expected in the near future. However, various attempts and new methods of deep learning have been proposed in recent years, and their progress is extremely fast. Therefore, at the initial stage when medical artificial intelligence papers were published, the artificial intelligence technology itself may be old technology or well-known general-purpose common technology. Therefore, the author has reviewed state-of-the-art computer vision papers and presentations of 2018 using deep learning technologies, which will have future clinical potentials selected from the point of view of a radiologist such as generative adversarial network, knowledge distillation, and general image data sets for supervised learning.	['Department of Radiology, The Jikei University, School of Medicine, 3-25-8, Nishi-shimbashi, Minato-ku, Tokyo, 1058461, Japan. nakata@jikei.ac.jp.']	['10.1007/s11604-018-0804-6 [doi]', '10.1007/s11604-018-0804-6 [pii]']	['Nakata N']							['2019/02/02 06:00']	20190501	20190131	2019 Feb	2019/02/02 06:00		['Nakata, Norio']		['18065754/Japan Agency for Medical Research and Development', '17K10374/Japan Society for the Promotion of Science']	2		1867-108X (Electronic) 1867-1071 (Linking)	101490689	Japanese journal of radiology	['eng']	10.1007/s11604-018-0804-6 [doi]	20190501	['*Artificial Intelligence', 'Deep Learning', 'Diagnostic Imaging/*methods', 'Humans']	2019/05/02 06:00		['Artificial intelligence', 'Computer vision', 'Deep learning']	['NOTNLM']	NLM	103-108	['2018/11/08 00:00 [received]', '2018/12/14 00:00 [accepted]', '2019/02/02 06:00 [pubmed]', '2019/05/02 06:00 [medline]', '2019/02/02 06:00 [entrez]']	Japan			30706381	ppublish	['Journal Article', 'Review']			IM		Jpn J Radiol. 2019 Feb;37(2):103-108. doi: 10.1007/s11604-018-0804-6. Epub 2019 Jan 31.	MEDLINE	Jpn J Radiol	Recent technical development of artificial intelligence for diagnostic medical imaging.		37	Recent technical development of artificial intelligence for diagnostic medical imaging.
High-grade gliomas are the most aggressive malignant brain tumors. Accurate pre-operative prognosis for this cohort can lead to better treatment planning. Conventional survival prediction based on clinical information is subjective and could be inaccurate. Recent radiomics studies have shown better prognosis by using carefully-engineered image features from magnetic resonance images (MRI). However, feature engineering is usually time consuming, laborious and subjective. Most importantly, the engineered features cannot effectively encode other predictive but implicit information provided by multi-modal neuroimages. We propose a two-stage learning-based method to predict the overall survival (OS) time of high-grade gliomas patient. At the first stage, we adopt deep learning, a recently dominant technique of artificial intelligence, to automatically extract implicit and high-level features from multi-modal, multi-channel preoperative MRI such that the features are competent of predicting survival time. Specifically, we utilize not only contrast-enhanced T1 MRI, but also diffusion tensor imaging (DTI) and resting-state functional MRI (rs-fMRI), for computing multiple metric maps (including various diffusivity metric maps derived from DTI, and also the frequency-specific brain fluctuation amplitude maps and local functional connectivity anisotropy-related metric maps derived from rs-fMRI) from 68 high-grade glioma patients with different survival time. We propose a multi-channel architecture of 3D convolutional neural networks (CNNs) for deep learning upon those metric maps, from which high-level predictive features are extracted for each individual patch of these maps. At the second stage, those deeply learned features along with the pivotal limited demographic and tumor-related features (such as age, tumor size and histological type) are fed into a support vector machine (SVM) to generate the final prediction result (i.e., long or short overall survival time). The experimental results demonstrate that this multi-model, multi-channel deep survival prediction framework achieves an accuracy of 90.66%, outperforming all the competing methods. This study indicates highly demanded effectiveness on prognosis of deep learning technique in neuro-oncological applications for better individualized treatment planning towards precision medicine.	['Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27514, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27514, USA.', 'Department of Neurosurgery, Huashan Hospital, Fudan University, Shanghai, 200040, China.', 'Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai, 200040, China.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27514, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27514, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27514, USA.', 'Department of Neurosurgery, Huashan Hospital, Fudan University, Shanghai, 200040, China.', 'Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai, 200040, China.', 'Med-X Research Institute, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200030, China.', 'Med-X Research Institute, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200030, China. wang.qian@sjtu.edu.cn.', 'Department of Neurosurgery, Huashan Hospital, Fudan University, Shanghai, 200040, China. wjsongc@126.com.', 'Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai, 200040, China. wjsongc@126.com.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, 27514, USA. dgshen@med.unc.edu.', 'Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, Republic of Korea. dgshen@med.unc.edu.']	['10.1038/s41598-018-37387-9 [doi]', '10.1038/s41598-018-37387-9 [pii]']	['Nie D', 'Lu J', 'Zhang H', 'Adeli E', 'Wang J', 'Yu Z', 'Liu L', 'Wang Q', 'Wu J', 'Shen D']	['ORCID: http://orcid.org/0000-0003-0385-8988', 'ORCID: http://orcid.org/0000-0002-0579-7763', 'ORCID: http://orcid.org/0000-0001-9548-0411']						['2019/02/02 06:00']		20190131	2019 Jan 31	2019/02/02 06:00		['Nie, Dong', 'Lu, Junfeng', 'Zhang, Han', 'Adeli, Ehsan', 'Wang, Jun', 'Yu, Zhengda', 'Liu, LuYan', 'Wang, Qian', 'Wu, Jinsong', 'Shen, Dinggang']		['R01 EB008374/EB/NIBIB NIH HHS/United States', 'R01 EB006733/EB/NIBIB NIH HHS/United States', 'R01 EB022880/EB/NIBIB NIH HHS/United States', 'R01 AG041721/AG/NIA NIH HHS/United States', 'EB006733/U.S. Department of Health &amp; Human Services | NIH | NIH Clinical', 'Center (Clinical Center)', 'R01 AG049371/AG/NIA NIH HHS/United States', 'R21 MH108914/MH/NIMH NIH HHS/United States', 'R01 AG042599/AG/NIA NIH HHS/United States', 'RF1 AG053867/AG/NIA NIH HHS/United States', 'R01 MH100217/MH/NIMH NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-37387-9 [doi]	20191120		2019/02/02 06:00				NLM	1103	['2018/03/19 00:00 [received]', '2018/11/13 00:00 [accepted]', '2019/02/02 06:00 [entrez]', '2019/02/02 06:00 [pubmed]', '2019/02/02 06:00 [medline]']	England	PMC6355868		30705340	epublish	['Journal Article']			IM		Sci Rep. 2019 Jan 31;9(1):1103. doi: 10.1038/s41598-018-37387-9.	In-Data-Review	Sci Rep	Multi-Channel 3D Deep Feature Learning for Survival Time Prediction of Brain Tumor Patients Using Multi-Modal Neuroimages.		9	Multi-Channel 3D Deep Feature Learning for Survival Time Prediction of Brain Tumor Patients Using Multi-Modal Neuroimages.
Objective: To investigate the clinical significance of high definition (HD) MRI rectal lymph node aided diagnostic system based on deep neural network. Methods: The research selected 301 patients with rectal cancer who underwent pelvic HD MRI and reported pelvic lymph node metastasis from July 2016 to December 2017 in Affiliated Hospital of Qingdao University. According to the chronological order, the first 201 cases were used as learning group. The remaining 100 cases were used as verification group. There were 149 males (74.1%) and 52 females in the study group, with an average age of 58.8 years. There were 76 males (76.0%) and 24 females in the validation group, with an average age of 60.2 years. Firstly, Using deep learning technique, researchers trained the 12 060 HD MRI lymph nodes images data of learning group with convolution neural network to simulate the judgment process of radiologists, and established an artificial intelligence automatic recognition system for metastatic lymph nodes of rectal cancer. Then, 6 030 images of the validation group were clinically validated. Artificial intelligence and radiologists simultaneously diagnosed all cases of HD MRI images and made the diagnosis results of metastatic lymph node. Receiver operating characteristic (ROC) curve and area under curve (AUC) were used to compare the diagnostic level of them. Results: After continuous iteration training of the learning group data, the loss function value of artificial intelligence decreased continuously, and the diagnostic error decreased continuously. Among the 6 030 images of verification group, 912 images were considered to exist metastatic lymph nodes in radiologists' diagnosis and 987 in artificial intelligence diagnosis. There were 772 images having identical diagnostic results of lymph node location and number of metastases with the two methods. Compared with manual diagnosis, the AUC of the intelligent platform was 0.886 2, the diagnostic time of a single case was 10 s, but the average diagnostic time of doctors was 600 s. Conclusion: The HD MRI lymph node automatic recognition system based on deep neural network has high accuracy and high efficiency, and has the clinical significance of auxiliary diagnosis.	['Department of Gastrointestinal Surgery, Affiliated Hospital of Qingdao University, Qingdao 266000, China.', 'Department of Gastrointestinal Surgery, Affiliated Hospital of Qingdao University, Qingdao 266000, China.', 'Department of Gastrointestinal Surgery, Affiliated Hospital of Qingdao University, Qingdao 266000, China.', 'Beihang University Qingdao Research Institute, Qingdao 266000, China.', 'Department of Gastrointestinal Surgery, Affiliated Hospital of Qingdao University, Qingdao 266000, China.', 'Department of Gastrointestinal Surgery, Affiliated Hospital of Qingdao University, Qingdao 266000, China.', 'Department of Gastrointestinal Surgery, Affiliated Hospital of Qingdao University, Qingdao 266000, China.']	['10.3760/cma.j.issn.0529-5815.2019.02.007 [doi]']	['Zhou YP', 'Li S', 'Zhang XX', 'Zhang ZD', 'Gao YX', 'Ding L', 'Lu Y']							['2019/02/02 06:00']	20190618		2019 Feb 1	2019/02/02 06:00		['Zhou, Y P', 'Li, S', 'Zhang, X X', 'Zhang, Z D', 'Gao, Y X', 'Ding, L', 'Lu, Y']		['81802473/National Natural Science Foundation of China']	2		0529-5815 (Print) 0529-5815 (Linking)	0153611	Zhonghua wai ke za zhi [Chinese journal of surgery]	['chi']	10.3760/cma.j.issn.0529-5815.2019.02.007 [doi]	20190618	['Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted', 'Lymph Nodes/*diagnostic imaging/pathology', 'Lymphatic Metastasis', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', 'Pelvis', 'Rectal Neoplasms/*diagnostic imaging/pathology']	2019/06/19 06:00		['Artificial intelligence', 'Lymphatic metastasis', 'Magnetic resonance imaging', 'Rectal neoplasms']	['NOTNLM']	NLM	108-113	['2019/02/02 06:00 [entrez]', '2019/02/02 06:00 [pubmed]', '2019/06/19 06:00 [medline]']	China			30704213	ppublish	['Journal Article']			IM		Zhonghua Wai Ke Za Zhi. 2019 Feb 1;57(2):108-113. doi: 10.3760/cma.j.issn.0529-5815.2019.02.007.	MEDLINE	Zhonghua Wai Ke Za Zhi	[High definition MRI rectal lymph node aided diagnostic system based on deep neural network].		57	[High definition MRI rectal lymph node aided diagnostic system based on deep neural network].
BACKGROUND: The goal of temporal indexing is to select an occurred time or time interval for each medical entity in clinical notes, so that all medical entities can be indexed on a united timeline, which could assist the understanding of clinical notes and the further application of medical entities. Some temporal relation shared tasks for the medical entity in English clinical notes have been organized in the past few years, such as the 2012 i2b2 NLP challenge, 2015 and 2016 clinical TempEval challenges. In these tasks, many heuristics rule-based and machine learning-based systems have been developed. In recent years, the deep neural network models have shown great potential on many problems including the relation classification. METHODS: In this paper, we propose a recurrent convolutional neural network (RNN-CNN) model for the temporal indexing task, which consists of four layers: input layer - generates representation for each context word of medical entities or temporal expressions; LSTM (long-short term memory) layer - learns the context information of each word in a sentence and outputs a new word representation sequence; CNN layer - extracts meaningful features from a sentence and outputs a new representation for medical entity or temporal expression; Output layer - takes the representations of medical entity, temporal expression and relation features as input and classifies the temporal relation. Finally, the time or time interval for each medical entity can be directly selected according to the probability of each temporal relation predicted by above model. RESULTS: To investigate the performance of our RNN-CNN model for the temporal indexing task, several baseline methods were also employed, such as the rule-based, support vector machine (SVM), convolutional neural network (CNN) and recurrent neural network (RNN) methods. Experiments conducted on a manually annotated corpus (including 563 clinical notes with 12,611 medical entities and 4006 temporal expressions) show that RNN-CNN model achieves the best F1-score of 75.97% for temporal relation classification and the best accuracy of 71.96% for temporal indexing. CONCLUSIONS: Neural network methods perform much better than the traditional rule-based and SVM-based method, which can capture more semantic information from the context of medical entities and temporal expressions. Besides, all our methods perform much better for the accurate time indexing than the time interval indexing, so how to improve the performance for time interval indexing will be the main focus in our future work.	['Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Shenzhen, 518055, China.', 'Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Shenzhen, 518055, China.', 'Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Shenzhen, 518055, China.', 'Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Shenzhen, 518055, China. tangbuzhou@gmail.com.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.']	['10.1186/s12911-019-0735-x [doi]', '10.1186/s12911-019-0735-x [pii]']	['Liu Z', 'Wang X', 'Chen Q', 'Tang B', 'Xu H']							['2019/02/01 06:00']	20190703	20190131	2019 Jan 31	2019/02/01 06:00		['Liu, Zengjian', 'Wang, Xiaolong', 'Chen, Qingcai', 'Tang, Buzhou', 'Xu, Hua']			Suppl 1		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-019-0735-x [doi]	20190703	['China', '*Data Mining', '*Electronic Health Records', 'Humans', '*Medical Informatics Applications', '*Neural Networks (Computer)', 'Time Factors']	2019/07/04 06:00		['*Clinical notes', '*Convolutional neural network', '*Medical entity', '*Recurrent neural network', '*Temporal indexing']	['NOTNLM']	NLM	17	['2019/02/01 06:00 [entrez]', '2019/02/01 06:00 [pubmed]', '2019/07/04 06:00 [medline]']	England	PMC6354334		30700331	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Inform Decis Mak. 2019 Jan 31;19(Suppl 1):17. doi: 10.1186/s12911-019-0735-x.	MEDLINE	BMC Med Inform Decis Mak	Temporal indexing of medical entity in Chinese clinical notes.		19	Temporal indexing of medical entity in Chinese clinical notes.
BACKGROUND: Extracting relations between important clinical entities is critical but very challenging for natural language processing (NLP) in the medical domain. Researchers have applied deep learning-based approaches to clinical relation extraction; but most of them consider sentence sequence only, without modeling syntactic structures. The aim of this study was to utilize a deep neural network to capture the syntactic features and further improve the performances of relation extraction in clinical notes. METHODS: We propose a novel neural approach to model shortest dependency path (SDP) between target entities together with the sentence sequence for clinical relation extraction. Our neural network architecture consists of three modules: (1) sentence sequence representation module using bidirectional long short-term memory network (Bi-LSTM) to capture the features in the sentence sequence; (2) SDP representation module implementing the convolutional neural network (CNN) and Bi-LSTM network to capture the syntactic context for target entities using SDP information; and (3) classification module utilizing a fully-connected layer with Softmax function to classify the relation type between target entities. RESULTS: Using the 2010 i2b2/VA relation extraction dataset, we compared our approach with other baseline methods. Our experimental results show that the proposed approach achieved significant improvements over comparable existing methods, demonstrating the effectiveness of utilizing syntactic structures in deep learning-based relation extraction. The F-measure of our method reaches 74.34% which is 2.5% higher than the method without using syntactic features. CONCLUSIONS: We propose a new neural network architecture by modeling SDP along with sentence sequence to extract multi-relations from clinical text. Our experimental results show that the proposed approach significantly improve the performances on clinical notes, demonstrating the effectiveness of syntactic structures in deep learning-based relation extraction.	['School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, 77030, USA.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, 77030, USA.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, 77030, USA. hua.xu@uth.tmc.edu.']	['10.1186/s12911-019-0736-9 [doi]', '10.1186/s12911-019-0736-9 [pii]']	['Li Z', 'Yang Z', 'Shen C', 'Xu J', 'Zhang Y', 'Xu H']							['2019/02/01 06:00']	20190703	20190131	2019 Jan 31	2019/02/01 06:00		['Li, Zhiheng', 'Yang, Zhihao', 'Shen, Chen', 'Xu, Jun', 'Zhang, Yaoyun', 'Xu, Hua']		['U24 CA194215/CA/NCI NIH HHS/United States']	Suppl 1		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-019-0736-9 [doi]	20190703	['*Deep Learning', '*Electronic Health Records', 'Humans', '*Medical Informatics Applications', '*Natural Language Processing']	2019/07/04 06:00		['*Relation extraction - deep learning', '*Shortest dependency path']	['NOTNLM']	NLM	22	['2019/02/01 06:00 [entrez]', '2019/02/01 06:00 [pubmed]', '2019/07/04 06:00 [medline]']	England	PMC6354333		30700301	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Inform Decis Mak. 2019 Jan 31;19(Suppl 1):22. doi: 10.1186/s12911-019-0736-9.	MEDLINE	BMC Med Inform Decis Mak	Integrating shortest dependency path and sentence sequence into a deep learning framework for relation extraction in clinical text.		19	Integrating shortest dependency path and sentence sequence into a deep learning framework for relation extraction in clinical text.
This paper tries to give a gentle introduction to deep learning in medical image processing, proceeding from theoretical foundations to applications. We first discuss general reasons for the popularity of deep learning, including several major breakthroughs in computer science. Next, we start reviewing the fundamental basics of the perceptron and neural networks, along with some fundamental theory that is often omitted. Doing so allows us to understand the reasons for the rise of deep learning in many application domains. Obviously medical image processing is one of these areas which has been largely affected by this rapid progress, in particular in image detection and recognition, image segmentation, image registration, and computer-aided diagnosis. There are also recent trends in physical simulation, modeling, and reconstruction that have led to astonishing results. Yet, some of these approaches neglect prior knowledge and hence bear the risk of producing implausible results. These apparent weaknesses highlight current limitations of deep ()learning. However, we also briefly discuss promising approaches that might be able to resolve these problems in the future.	['Friedrich-Alexander-University Erlangen-Nuremberg, Germany. Electronic address: andreas.maier@fau.de.', 'Friedrich-Alexander-University Erlangen-Nuremberg, Germany.', 'Technical University of Munich, Germany.', 'Friedrich-Alexander-University Erlangen-Nuremberg, Germany.']	['S0939-3889(18)30120-X [pii]', '10.1016/j.zemedi.2018.12.003 [doi]']	['Maier A', 'Syben C', 'Lasser T', 'Riess C']		['Copyright (c) 2019. Published by Elsevier GmbH.']					['2019/01/29 06:00']	20191125	20190125	2019 May	2019/01/29 06:00		['Maier, Andreas', 'Syben, Christopher', 'Lasser, Tobias', 'Riess, Christian']			2		1876-4436 (Electronic) 0939-3889 (Linking)	100886455	Zeitschrift fur medizinische Physik	['eng']	S0939-3889(18)30120-X [pii] 10.1016/j.zemedi.2018.12.003 [doi]	20191125	['*Deep Learning', '*Diagnostic Imaging', 'Humans', 'Image Processing, Computer-Assisted/*methods']	2019/11/26 06:00		['Computer-aided diagnosis', 'Deep learning', 'Image reconstruction', 'Image registration', 'Image segmentation', 'Introduction', 'Machine learning', 'Physical simulation']	['NOTNLM']	NLM	86-101	['2018/10/04 00:00 [received]', '2018/12/20 00:00 [revised]', '2018/12/21 00:00 [accepted]', '2019/01/29 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/01/29 06:00 [entrez]']	Germany			30686613	ppublish	['Journal Article', 'Review']			IM		Z Med Phys. 2019 May;29(2):86-101. doi: 10.1016/j.zemedi.2018.12.003. Epub 2019 Jan 25.	MEDLINE	Z Med Phys	A gentle introduction to deep learning in medical image processing.		29	A gentle introduction to deep learning in medical image processing.
BACKGROUND: tRNAscan-SE is the leading tool for transfer RNA (tRNA) annotation, which has been widely used in the field. However, tRNAscan-SE can return a significant number of false positives when applied to large sequences. Recently, conventional machine learning methods have been proposed to address this issue, but their efficiency can be still limited due to their dependency on handcrafted features. With the growing availability of large-scale genomic data-sets, deep learning methods, especially convolutional neural networks, have demonstrated excellent power in characterizing sequence patterns in genomic sequences. Thus, we hypothesize that deep learning may bring further improvement for tRNA prediction. METHODS: We proposed a new computational approach based on deep neural networks to predict tRNA gene sequences. We designed and investigated various deep neural network architectures. We used the tRNA sequences as positive samples, and the false-positive tRNA sequences predicted by tRNAscan-SE in coding sequences as negative samples, to train and evaluate the proposed models by comparison with the conventional machine learning methods and popular tRNA prediction tools. RESULTS: Using the one-hot encoding method, our proposed models can extract features without involving extensive manual feature engineering. Our proposed best model outperformed the existing methods under different performance metrics. CONCLUSION: The proposed deep learning methods can substantially reduce the false positive output by the state-of-the-art tool tRNAscan-SE. Coupled with tRNAscan-SE, it can serve as a useful complementary tool for tRNA annotation. The application to tRNA prediction demonstrates the superiority of deep learning in automatic feature generation for characterizing sequence patterns.	"['Department of Computer Science, New Jersey Institute of Technology, Newark, New Jersey, USA.', 'Department of Computer Science, New Jersey Institute of Technology, Newark, New Jersey, USA, zhiwei@njit.edu.', ""The Center for Applied Genomics, The Children's Hospital of Philadelphia, Philadelphia, Pennsylvania, USA."", 'Department of Pediatrics, University of Pennsylvania School of Medicine, Philadelphia, Pennsylvania, USA.']"	['000493215 [pii]', '10.1159/000493215 [doi]']	['Gao X', 'Wei Z', 'Hakonarson H']		['(c) 2019 S. Karger AG, Basel.']					['2019/01/28 06:00']	20190607	20190125	2018	2019/01/28 06:00		['Gao, Xin', 'Wei, Zhi', 'Hakonarson, Hakon']			3		1423-0062 (Electronic) 0001-5652 (Linking)	0200525	Human heredity	['eng']	10.1159/000493215 [doi]	20190607	['*Algorithms', 'Area Under Curve', '*Deep Learning', 'Humans', 'Models, Theoretical', 'Neural Networks (Computer)', 'RNA, Transfer/*genetics', 'ROC Curve', 'Software']	2019/06/08 06:00		['*Deep learning', '*Genomics', '*Machine learning', '*Multilayer neural network', '*tRNA prediction', '*tRNAscan-SE improvement']	['NOTNLM']	NLM	163-172	['2019/01/28 06:00 [pubmed]', '2019/06/08 06:00 [medline]', '2019/01/28 06:00 [entrez]']	Switzerland			30685762	ppublish	['Journal Article']		['9014-25-9 (RNA, Transfer)']	IM		Hum Hered. 2018;83(3):163-172. doi: 10.1159/000493215. Epub 2019 Jan 25.	MEDLINE	Hum Hered	tRNA-DL: A Deep Learning Approach to Improve tRNAscan-SE Prediction Results.		83	tRNA-DL: A Deep Learning Approach to Improve tRNAscan-SE Prediction Results.
BACKGROUND AND OBJECTIVE: Deep learning provides an automatic and robust solution to depression severity evaluation. However, despite it is powerful, there is a trade-off between robust performance and the cost of manual annotation. METHODS: Motivated by knowledge evolution and domain adaptation, we propose a deep evaluation network using skew-robust adversarial discriminative domain adaptation (SRADDA), which adaptively shifts its domain from a large-scale Twitter dataset to a small-scale depression interview dataset for evaluating the severity of depression. RESULTS: Without top-down selection, SRADDA-based severity evaluation network achieves regression errors of 6.38 (Root Mean Square Error,RMSE) and 4.93 (Mean Absolute Error,MAE), which outperforms baselines provided by the Audio/Visual Emotion Challenge and Workshop(AVEC 2017). However, with top-down selection, the network achieves comparable results (RMSE = 5.13, MAE = 4.08). CONCLUSIONS: Results show that SRADDA not only represents features robustly, but also performs comparably to state-of-the-art results on small-scale dataset, DAIC-WOZ.	['The Intelligent Computing and Software Research Center, Information Science and Technology College, Beijing Normal University, 19 xinjiekou street, Beijing 100875, China.', 'The Intelligent Computing and Software Research Center, Information Science and Technology College, Beijing Normal University, 19 xinjiekou street, Beijing 100875, China; Smart financial research and development center, Hebei Finance University, China.', 'The Intelligent Computing and Software Research Center, Information Science and Technology College, Beijing Normal University, 19 xinjiekou street, Beijing 100875, China. Electronic address: hejun@bnu.edu.cn.', 'The Intelligent Computing and Software Research Center, Information Science and Technology College, Beijing Normal University, 19 xinjiekou street, Beijing 100875, China.', 'The Intelligent Computing and Software Research Center, Information Science and Technology College, Beijing Normal University, 19 xinjiekou street, Beijing 100875, China.']	['S0169-2607(18)30450-4 [pii]', '10.1016/j.cmpb.2019.01.006 [doi]']	['Sun B', 'Zhang Y', 'He J', 'Xiao Y', 'Xiao R']		['Copyright (c) 2019 Elsevier B.V. All rights reserved.']					['2019/01/27 06:00']	20191125	20190117	2019 May	2019/01/27 06:00		['Sun, Bo', 'Zhang, Yinghui', 'He, Jun', 'Xiao, Yongkang', 'Xiao, Rong']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30450-4 [pii] 10.1016/j.cmpb.2019.01.006 [doi]	20191125	['Algorithms', 'Brain/*pathology', 'Costs and Cost Analysis', 'Databases, Factual', 'Deep Learning', 'Depression/*diagnosis', 'Diagnosis, Computer-Assisted/*methods', 'Discriminant Analysis', 'Humans', 'Medical Informatics', '*Pattern Recognition, Automated', 'Reproducibility of Results', '*Severity of Illness Index', 'Social Media']	2019/11/26 06:00		['Adversarial learning', 'Deep learning', 'Domain adaptation', 'Knowledge evolution', 'Skew-robustness']	['NOTNLM']	NLM	185-195	['2018/03/31 00:00 [received]', '2018/11/01 00:00 [revised]', '2019/01/15 00:00 [accepted]', '2019/01/27 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2019/01/27 06:00 [entrez]']	Ireland			30683543	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2019 May;173:185-195. doi: 10.1016/j.cmpb.2019.01.006. Epub 2019 Jan 17.	MEDLINE	Comput Methods Programs Biomed	An automatic diagnostic network using skew-robust adversarial discriminative domain adaptation to evaluate the severity of depression.		173	An automatic diagnostic network using skew-robust adversarial discriminative domain adaptation to evaluate the severity of depression.
In recent years, deep learning has revolutionized the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained, most often in a supervised manner using backpropagation. Vast amounts of labeled training examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and are arguably the only viable option if one wants to understand how the brain computes at the neuronal description level. The spikes of biological neurons are sparse in time and space, and event-driven. Combined with bio-plausible local learning rules, this makes it easier to build low-power, neuromorphic hardware for SNNs. However, training deep SNNs remains a challenge. Spiking neurons' transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy and computational cost. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while SNNs typically require many fewer operations and are the better candidates to process spatio-temporal data.	['School of Computing and Informatics, University of Louisiana at Lafayette, Lafayette, LA 70504, USA. Electronic address: tavanaei@louisiana.edu.', 'Department of Physiology, Monash University, Clayton, VIC, Australia.', 'Department of Computer Science, Faculty of Mathematical Sciences and Computer, Kharazmi University, Tehran, Iran.', 'CERCO UMR 5549, CNRS-Universite de Toulouse 3, F-31300, France.', 'School of Computing and Informatics, University of Louisiana at Lafayette, Lafayette, LA 70504, USA.']	['S0893-6080(18)30333-2 [pii]', '10.1016/j.neunet.2018.12.002 [doi]']	['Tavanaei A', 'Ghodrati M', 'Kheradpisheh SR', 'Masquelier T', 'Maida A']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2019/01/26 06:00']	20190403	20181218	2019 Mar	2019/01/27 06:00		['Tavanaei, Amirhossein', 'Ghodrati, Masoud', 'Kheradpisheh, Saeed Reza', 'Masquelier, Timothee', 'Maida, Anthony']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30333-2 [pii] 10.1016/j.neunet.2018.12.002 [doi]	20190403	['*Action Potentials/physiology', 'Algorithms', 'Brain/physiology', '*Deep Learning/trends', 'Humans', 'Machine Learning/trends', '*Models, Neurological', '*Neural Networks (Computer)', 'Neurons/physiology']	2019/04/04 06:00		['Biological plausibility', 'Deep learning', 'Machine learning', 'Power-efficient architecture', 'Spiking neural network']	['NOTNLM']	NLM	47-63	['2018/06/07 00:00 [received]', '2018/12/02 00:00 [revised]', '2018/12/03 00:00 [accepted]', '2019/01/27 06:00 [pubmed]', '2019/04/04 06:00 [medline]', '2019/01/26 06:00 [entrez]']	United States			30682710	ppublish	['Journal Article', 'Review']			IM		Neural Netw. 2019 Mar;111:47-63. doi: 10.1016/j.neunet.2018.12.002. Epub 2018 Dec 18.	MEDLINE	Neural Netw	Deep learning in spiking neural networks.		111	Deep learning in spiking neural networks.
A recurrent criticism concerning the use of online social media data in political science research is the lack of demographic information about social media users. By employing a face-recognition algorithm to the profile pictures of Facebook users, the paper derives two fundamental demographic characteristics (age and gender) of a sample of Facebook users who interacted with the most relevant British parties in the two weeks before the Brexit referendum of 23 June 2016. The article achieves the goals of (i) testing the precision of the algorithm, (ii) testing its validity, (iii) inferring new evidence on digital mobilisation, and (iv) tracing the path for future developments and application of the algorithm. The findings show that the algorithm is reliable and that it can be fruitfully used in political and social sciences both to confirm the validity of survey data and to obtain information from populations that are generally unavailable within traditional surveys.	['Collegio Carlo Alberto, Turin, Italy.', 'Collegio Carlo Alberto, Turin, Italy.', 'Department of Cultures, Politics and Society, University of Turin, Turin, Italy.']	['10.1371/journal.pone.0211013 [doi]', 'PONE-D-17-36538 [pii]']	['Mancosu M', 'Bobba G']	['ORCID: 0000-0002-3017-4066']				['The authors have declared that no competing interests exist.']		['2019/01/26 06:00']	20191022	20190125	2019	2019/01/27 06:00		['Mancosu, Moreno', 'Bobba, Giuliano']			1		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0211013 [doi]	20191022	['Adult', '*Deep Learning', '*European Union', 'Female', 'Humans', '*Image Processing, Computer-Assisted', 'Male', '*Social Media', 'United Kingdom']	2019/10/23 06:00				NLM	e0211013	['2017/10/11 00:00 [received]', '2018/11/27 00:00 [accepted]', '2019/01/26 06:00 [entrez]', '2019/01/27 06:00 [pubmed]', '2019/10/23 06:00 [medline]']	United States	PMC6347201		30682111	epublish	['Journal Article']			IM		PLoS One. 2019 Jan 25;14(1):e0211013. doi: 10.1371/journal.pone.0211013. eCollection 2019.	MEDLINE	PLoS One	Using deep-learning algorithms to derive basic characteristics of social media users: The Brexit campaign as a case study.		14	Using deep-learning algorithms to derive basic characteristics of social media users: The Brexit campaign as a case study.
BACKGROUND: Early diagnosis of skin cancer lesions by dermoscopy, the gold standard in dermatological imaging, calls for a diagnostic upscale. The aim of the study was to improve the accuracy of dermoscopic skin cancer diagnosis through use of novel deep learning (DL) algorithms. An additional sonification-derived diagnostic layer was added to the visual classification to increase sensitivity. METHODS: Two parallel studies were conducted: a laboratory retrospective study (LABS, n=482 biopsies) and a non-interventional prospective observational study (OBS, n=63 biopsies). A training data set of biopsy-verified reports, normal and cancerous skin lesions (n=3954), were used to develop a DL classifier exploring visual features (System A). The outputs of the classifier were sonified, i.e. data conversion into sound (System B). Derived sound files were analyzed by a second machine learning classifier, either as raw audio (LABS, OBS) or following conversion into spectrograms (LABS) and by image analysis and human heuristics (OBS). The OBS criteria outcomes were System A specificity and System B sensitivity as raw sounds, spectrogram areas or heuristics. FINDINGS: LABS employed dermoscopies, half benign half malignant, and compared the accuracy of Systems A and B. System A algorithm resulted in a ROC AUC of 0.976 (95% CI, 0.965-0.987). Secondary machine learning analysis of raw sound, FFT and Spectrogram ROC curves resulted in AUC's of 0.931 (95% CI 0.881-0.981), 0.90 (95% CI 0.838-0.963) and 0.988 (CI 95% 0.973-1.001), respectively. OBS analysis of raw sound dermoscopies by the secondary machine learning resulted in a ROC AUC of 0.819 (95% CI, 0.7956 to 0.8406). OBS image analysis of AUC for spectrograms displayed a ROC AUC of 0.808 (CI 95% 0.6945 To 0.9208). By applying a heuristic analysis of Systems A and B a sensitivity of 86% and specificity of 91% were derived in the clinical study. INTERPRETATION: Adding a second stage of processing, which includes a deep learning algorithm of sonification and heuristic inspection with machine learning, significantly improves diagnostic accuracy. A combined two-stage system is expected to assist clinical decisions and de-escalate the current trend of over-diagnosis of skin cancer lesions as pathological. FUND: Bostel Technologies. Trial Registration clinicaltrials.gov Identifier: NCT03362138.	['Sonification Lab, School of Psychology, School of Interactive Computing, Georgia Institute of Technology (Walker BN), Georgia.', 'School of Interactive Computing, Georgia Institute of Technology, Atlanta, Georgia.', 'Hoplabs, Atlanta, Georgia.', 'Institute of GT Sonification Lab, Georgia Technology, Atlanta, Georgia.', 'Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, Georgia.', 'Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel.', 'Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel.', 'Department of Physiology and Pharmacology, Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel. Electronic address: dasc@post.tau.ac.il.']	['S2352-3964(19)30033-7 [pii]', '10.1016/j.ebiom.2019.01.028 [doi]']	['Walker BN', 'Rehg JM', 'Kalra A', 'Winters RM', 'Drews P', 'Dascalu J', 'David EO', 'Dascalu A']		['Copyright (c) 2019 The Author(s). Published by Elsevier B.V. All rights reserved.']					['2019/01/25 06:00']	20190625	20190120	2019 Feb	2019/01/25 06:00		['Walker, B N', 'Rehg, J M', 'Kalra, A', 'Winters, R M', 'Drews, P', 'Dascalu, J', 'David, E O', 'Dascalu, A']					2352-3964 (Electronic) 2352-3964 (Linking)	101647039	EBioMedicine	['eng']	S2352-3964(19)30033-7 [pii] 10.1016/j.ebiom.2019.01.028 [doi]	20190625	['Adolescent', 'Adult', 'Aged', 'Aged, 80 and over', '*Algorithms', 'Artificial Intelligence', '*Deep Learning', 'Dermoscopy/*methods', 'Female', 'Humans', 'Male', 'Middle Aged', 'ROC Curve', 'Retrospective Studies', 'Skin/pathology', 'Skin Neoplasms/*diagnosis', '*Sound', 'Telemedicine', 'Young Adult']	2019/06/27 06:00		['Artificial intelligence', 'Deep learning', 'Dermoscopy', 'Melanoma', 'Skin cancer', 'Sonification', 'Telemedicine']	['NOTNLM']	NLM	176-183	['2018/12/04 00:00 [received]', '2018/12/23 00:00 [revised]', '2019/01/11 00:00 [accepted]', '2019/01/25 06:00 [pubmed]', '2019/06/27 06:00 [medline]', '2019/01/25 06:00 [entrez]']	Netherlands	PMC6413349		30674442	ppublish	['Journal Article', 'Observational Study']			IM	['ClinicalTrials.gov/NCT03362138']	EBioMedicine. 2019 Feb;40:176-183. doi: 10.1016/j.ebiom.2019.01.028. Epub 2019 Jan 20.	MEDLINE	EBioMedicine	Dermoscopy diagnosis of cancerous lesions utilizing dual deep learning algorithms via visual and audio (sonification) outputs: Laboratory and prospective observational studies.		40	Dermoscopy diagnosis of cancerous lesions utilizing dual deep learning algorithms via visual and audio (sonification) outputs: Laboratory and prospective observational studies.
BACKGROUND: Lysine acetylation in protein is one of the most important post-translational modifications (PTMs). It plays an important role in essential biological processes and is related to various diseases. To obtain a comprehensive understanding of regulatory mechanism of lysine acetylation, the key is to identify lysine acetylation sites. Previously, several shallow machine learning algorithms had been applied to predict lysine modification sites in proteins. However, shallow machine learning has some disadvantages. For instance, it is not as effective as deep learning for processing big data. RESULTS: In this work, a novel predictor named DeepAcet was developed to predict acetylation sites. Six encoding schemes were adopted, including a one-hot, BLOSUM62 matrix, a composition of K-space amino acid pairs, information gain, physicochemical properties, and a position specific scoring matrix to represent the modified residues. A multilayer perceptron (MLP) was utilized to construct a model to predict lysine acetylation sites in proteins with many different features. We also integrated all features and implemented the feature selection method to select a feature set that contained 2199 features. As a result, the best prediction achieved 84.95% accuracy, 83.45% specificity, 86.44% sensitivity, 0.8540 AUC, and 0.6993 MCC in a 10-fold cross-validation. For an independent test set, the prediction achieved 84.87% accuracy, 83.46% specificity, 86.28% sensitivity, 0.8407 AUC, and 0.6977 MCC. CONCLUSION: The predictive performance of our DeepAcet is better than that of other existing methods. DeepAcet can be freely downloaded from https://github.com/Sunmile/DeepAcet .	['Department of Information and Computer Science, University of Science and Technology Beijing, Beijing, 100083, China.', 'Department of Information and Computer Science, University of Science and Technology Beijing, Beijing, 100083, China.', 'Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China.', 'Department of Information and Computer Science, University of Science and Technology Beijing, Beijing, 100083, China. xuyan@ustb.edu.cn.', 'Beijing Key Laboratory for Magneto-photoelectrical Composite and Interface Science, University of Science and Technology Beijing, Beijing, 100083, China. xuyan@ustb.edu.cn.']	['10.1186/s12859-019-2632-9 [doi]', '10.1186/s12859-019-2632-9 [pii]']	['Wu M', 'Yang Y', 'Wang H', 'Xu Y']	['ORCID: http://orcid.org/0000-0001-9462-580X']						['2019/01/25 06:00']	20190304	20190123	2019 Jan 23	2019/01/25 06:00		['Wu, Meiqi', 'Yang, Yingxi', 'Wang, Hui', 'Xu, Yan']		['11671032/National Natural Science Foundation of China', 'FRF-TP-17-024A2/Fundamental Research Funds for the Central Universities']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-019-2632-9 [doi]	20190304	['Acetylation', 'Deep Learning/*standards', 'Lysine/*chemistry', 'Protein Processing, Post-Translational/*genetics']	2019/03/05 06:00		['Deep learning', 'Lysine acetylation', 'PTMs']	['NOTNLM']	NLM	49	['2018/09/17 00:00 [received]', '2019/01/16 00:00 [accepted]', '2019/01/25 06:00 [entrez]', '2019/01/25 06:00 [pubmed]', '2019/03/05 06:00 [medline]']	England	PMC6343287		30674277	epublish	['Journal Article']		['K3Z4F929H6 (Lysine)']	IM		BMC Bioinformatics. 2019 Jan 23;20(1):49. doi: 10.1186/s12859-019-2632-9.	MEDLINE	BMC Bioinformatics	A deep learning method to more accurately recall known lysine acetylation sites.		20	A deep learning method to more accurately recall known lysine acetylation sites.
BACKGROUND: A deep learning computer artificial intelligence system is helpful for early identification of ground glass opacities (GGOs). METHODS: Images from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database were used in AlexNet and GoogLeNet to detect pulmonary nodules, and 221 GGO images provided by Xinhua Hospital were used in ResNet50 for detecting GGOs. We used computed tomography image radial reorganization to create the input image of the three-dimensional features, and used the extracted features for deep learning, network training, testing, and analysis. RESULTS: In the final evaluation results, we found that the accuracy of identification of lung nodule could reach 88.0%, with an F-score of 0.891. In terms of performance and accuracy, our method was better than the existing solutions. The GGO nodule classification achieved the best F-score of 0.87805. We propose a preprocessing method of red, green, and blue (RGB) superposition in the region of interest to effectively increase the differentiation between nodules and normal tissues, and that is the innovation of our research. CONCLUSIONS: The method of deep learning proposed in this study is more sensitive than other systems in recent years, and the average false positive is lower than that of others.	['Department of Respiratory Medicine, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China.', 'Department of Respiratory Medicine, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China.', 'Department of Respiratory Medicine, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China. guoxuejun@xinhuamed.com.cn.', 'School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China. yiping@sjtu.edu.cn.', 'School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China.', 'Department of Respiratory Medicine, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China.', 'Department of Radiology, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China.', 'Department of Respiratory Medicine, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China.', 'Department of Respiratory Medicine, Xinhua Hospital, School of Medicine, Shanghai Jiao Tong University, Shanghai, 200092, China.', 'Shanghai Jiaotong University School of Medicine, Shanghai, 200092, China.']	['10.1186/s12938-019-0627-4 [doi]', '10.1186/s12938-019-0627-4 [pii]']	['Ye W', 'Gu W', 'Guo X', 'Yi P', 'Meng Y', 'Han F', 'Yu L', 'Chen Y', 'Zhang G', 'Wang X']							['2019/01/24 06:00']	20190701	20190122	2019 Jan 22	2019/01/24 06:00		['Ye, Wenjing', 'Gu, Wen', 'Guo, Xuejun', 'Yi, Ping', 'Meng, Yishuang', 'Han, Fengfeng', 'Yu, Lingwei', 'Chen, Yi', 'Zhang, Guorui', 'Wang, Xueting']		['81770023/National Natural Science Foundation of China', '17ZR1418400/Natural Science Foundation of Shanghai', '16CR2042B/Clinical Research Plan of SHDC']	1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-019-0627-4 [doi]	20190701	['Algorithms', 'Databases, Factual', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'False Positive Reactions', 'Humans', 'Image Processing, Computer-Assisted', 'Lung/*diagnostic imaging', 'Lung Neoplasms/diagnostic imaging', 'Radiographic Image Interpretation, Computer-Assisted/methods', 'Radiology', 'Reproducibility of Results', 'Sensitivity and Specificity', 'Solitary Pulmonary Nodule/*diagnostic imaging', 'Tomography, X-Ray Computed']	2019/07/02 06:00		['Artificial intelligence', 'Computer-aided diagnosis', 'Deep learning', 'Ground-glass opacity', 'Pulmonary nodule']	['NOTNLM']	NLM	6	['2018/11/20 00:00 [received]', '2019/01/16 00:00 [accepted]', '2019/01/24 06:00 [entrez]', '2019/01/24 06:00 [pubmed]', '2019/07/02 06:00 [medline]']	England	PMC6343356		30670024	epublish	['Journal Article']			IM		Biomed Eng Online. 2019 Jan 22;18(1):6. doi: 10.1186/s12938-019-0627-4.	MEDLINE	Biomed Eng Online	Detection of pulmonary ground-glass opacity based on deep learning computer artificial intelligence.		18	Detection of pulmonary ground-glass opacity based on deep learning computer artificial intelligence.
PURPOSE: This study aims to adapt and evaluate the performance of different state-of-the-art deep learning object detection methods to automatically identify esophageal adenocarcinoma (EAC) regions from high-definition white light endoscopy (HD-WLE) images. METHOD: Several state-of-the-art object detection methods using Convolutional Neural Networks (CNNs) were adapted to automatically detect abnormal regions in the esophagus HD-WLE images, utilizing VGG'16 as the backbone architecture for feature extraction. Those methods are Regional-based Convolutional Neural Network (R-CNN), Fast R-CNN, Faster R-CNN and Single-Shot Multibox Detector (SSD). For the evaluation of the different methods, 100 images from 39 patients that have been manually annotated by five experienced clinicians as ground truth have been tested. RESULTS: Experimental results illustrate that the SSD and Faster R-CNN networks show promising results, and the SSD outperforms other methods achieving a sensitivity of 0.96, specificity of 0.92 and F-measure of 0.94. Additionally, the Average Recall Rate of the Faster R-CNN in locating the EAC region accurately is 0.83. CONCLUSION: In this paper, recent deep learning object detection methods are adapted to detect esophageal abnormalities automatically. The evaluation of the methods proved its ability to locate abnormal regions in the esophagus from endoscopic images. The automatic detection is a crucial step that may help early detection and treatment of EAC and also can improve automatic tumor segmentation to monitor its growth and treatment outcome.	['University of Lincoln, Lincoln, UK. nghatwary@lincoln.ac.uk.', 'Arab Academy for Science and Technology, Alexandria, Egypt. nghatwary@lincoln.ac.uk.', 'University of Lincoln, Lincoln, UK.', 'University of Lincoln, Lincoln, UK.']	['10.1007/s11548-019-01914-4 [doi]', '10.1007/s11548-019-01914-4 [pii]']	['Ghatwary N', 'Zolgharni M', 'Ye X']	['ORCID: http://orcid.org/0000-0002-4019-479X', 'ORCID: http://orcid.org/0000-0003-0904-2904', 'ORCID: http://orcid.org/0000-0003-0115-0724']						['2019/01/23 06:00']	20190513	20190122	2019 Apr	2019/01/23 06:00		['Ghatwary, Noha', 'Zolgharni, Massoud', 'Ye, Xujiong']			4		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-019-01914-4 [doi]	20190513	['Adenocarcinoma/*diagnosis', '*Deep Learning', '*Early Diagnosis', 'Esophageal Neoplasms/*diagnosis', 'Humans', '*Neural Networks (Computer)', 'Reproducibility of Results']	2019/05/14 06:00		"[""Barrett's esophagus"", 'Deep learning', 'Esophageal adenocarcinoma detection', 'HD-WLE']"	['NOTNLM']	NLM	611-621	['2018/01/11 00:00 [received]', '2019/01/07 00:00 [accepted]', '2019/01/23 06:00 [pubmed]', '2019/05/14 06:00 [medline]', '2019/01/23 06:00 [entrez]']	Germany	PMC6420905		30666547	ppublish	['Journal Article']		['Adenocarcinoma Of Esophagus']	IM		Int J Comput Assist Radiol Surg. 2019 Apr;14(4):611-621. doi: 10.1007/s11548-019-01914-4. Epub 2019 Jan 22.	MEDLINE	Int J Comput Assist Radiol Surg	Early esophageal adenocarcinoma detection using deep learning methods.		14	Early esophageal adenocarcinoma detection using deep learning methods.
INTRODUCTION AND AIM: The technology, named 'deep learning' is the promising result of the last two decades of development in computer science. It poses an unavoidable challenge for medicine, how to understand, apply and adopt the - today not fully explored - possibilities that have become available by these new methods. METHOD: It is a gift and a mission, since the exponentially growing volume of raw data (from imaging, laboratory, therapy diagnostics or therapy interactions, etc.) did not solve until now our wished and aimed goal to treat patients according to their personal status and setting or specific to their tumor and disease. RESULTS: Currently, as a responsible health care provider and financier, we face the problem of supporting suboptimal procedures and protocols either at individual or at community level. The problem roots in the overwhelming amount of data and, at the same time, the lack of targeted information for treatment. We expect from the deep learning technology an aid which helps to reinforce and extend the human-human cooperations in patient-doctor visits. We expect that computers take over the tedious work allowing to revive the core of healing medicine: the insightful meeting and discussion between patients and medical experts. CONCLUSION: We should learn the revelational possibilities of deep learning techniques that can help to overcome our recognized finite capacities in data processing and integration. If we, doctors and health care providers or decision makers, are able to abandon our fears and prejudices, then we can utilize this new tool not only in imaging diagnostics but also for daily therapies (e.g., immune therapy). The paper aims to make a great mind to do this. Orv Hetil. 2019; 160(4): 138-143.	['Komplex Rendszerek Fizikaja Tanszek, Eotvos Lorand Tudomanyegyetem Budapest.', 'Radiologiai Klinika, Semmelweis Egyetem, Altalanos Orvostudomanyi Kar Budapest.', 'MTA-ELTE Statisztikus es Biologiai Fizika Kutatocsoport, Budapest, Pazmany P. setany 1/A, 1117.', 'III. Belgyogyaszati Klinika, Semmelweis Egyetem, Altalanos Orvostudomanyi Kar Budapest.', 'Radiologiai Klinika, Semmelweis Egyetem, Altalanos Orvostudomanyi Kar Budapest.', 'Komplex Rendszerek Fizikaja Tanszek, Eotvos Lorand Tudomanyegyetem Budapest.', 'Radiologiai Klinika, Semmelweis Egyetem, Altalanos Orvostudomanyi Kar Budapest.', 'Radiologiai Klinika, Semmelweis Egyetem, Altalanos Orvostudomanyi Kar Budapest.']	['10.1556/650.2019.31263 [doi]']	['Ribli D', 'Zsuppan R', 'Pollner P', 'Horvath A', 'Bansaghi Z', 'Csabai I', 'Berczi V', 'Unger Z']							['2019/01/22 06:00']	20191016		2019 Jan	2019/01/22 06:00		['Ribli, Dezso', 'Zsuppan, Richard', 'Pollner, Peter', 'Horvath, Anna', 'Bansaghi, Zoltan', 'Csabai, Istvan', 'Berczi, Viktor', 'Unger, Zsuzsa']			4		1788-6120 (Electronic) 0030-6002 (Linking)	0376412	Orvosi hetilap	['hun']	10.1556/650.2019.31263 [doi]	20191016	['*Artificial Intelligence', '*Deep Learning', 'Humans', 'Hungary', '*Mammography', 'Motivation', 'Physician-Patient Relations', '*User-Computer Interface']	2019/10/17 06:00		['artificial intelligence', 'gepi tanulas', 'machine learning', 'mammography', 'mammografia', 'mesterseges intelligencia', 'szamitogep es felhasznalo egyuttmukodese', 'user-computer interface']	['NOTNLM']	NLM	138-143	['2019/01/22 06:00 [entrez]', '2019/01/22 06:00 [pubmed]', '2019/10/17 06:00 [medline]']	Hungary			30661383	ppublish	['Journal Article']			IM		Orv Hetil. 2019 Jan;160(4):138-143. doi: 10.1556/650.2019.31263.	MEDLINE	Orv Hetil	[Potential applications of deep learning-based technologies in Hungarian mammography].	A szamitogepes melytanulasi technologia varhato megjelenese a hazai mammografiaban.	160	[Potential applications of deep learning-based technologies in Hungarian mammography].
The sonogram is currently an effective cancer screening and diagnosis way due to the convenience and harmlessness in humans. Traditionally, lesion boundary segmentation is first adopted and then classification is conducted, to reach the judgment of benign or malignant tumor. In addition, sonograms often contain much speckle noise and intensity inhomogeneity. This study proposes a novel benign or malignant tumor classification system, which comprises intensity inhomogeneity correction and stacked denoising autoencoder (SDAE), and it is suitable for small-size dataset. A classifier is established by extracting features in the multilayer training of SDAE; automatic analysis of imaging features by the deep learning algorithm is applied on image classification, thus allowing the system to have high efficiency and robust distinguishing. In this study, two kinds of dataset (private data and public data) are used for deep learning models training. For each dataset, two groups of test images are compared: the original images and the images after intensity inhomogeneity correction, respectively. The results show that when deep learning algorithm is applied on the sonograms after intensity inhomogeneity correction, there is a significant increase of the tumor distinguishing accuracy. This study demonstrated that it is important to use preprocessing to highlight the image features and further give these features for deep learning models. In this way, the classification accuracy will be better to just use the original images for deep learning.	['Department of Electrical Engineering, National United University, Miaoli, Taiwan.', 'Department of Electrical Engineering, National United University, Miaoli, Taiwan.', 'Department of Electrical Engineering, National United University, Miaoli, Taiwan.', 'Department of Radiology, Taipei Veterans General Hospital and National Yang Ming University, Taipei, Taiwan.', 'Department of Management Information Systems, National Pingtung University of Science and Technology, Neipu, Taiwan.']	['10.1155/2018/8413403 [doi]']	['Lee CY', 'Chen GL', 'Zhang ZX', 'Chou YH', 'Hsu CC']	['ORCID: 0000-0002-7477-782X', 'ORCID: 0000-0002-2083-4438']						['2019/01/18 06:00']	20191122	20181204	2018	2019/01/18 06:00		['Lee, Chia-Yen', 'Chen, Guan-Lin', 'Zhang, Zhong-Xuan', 'Chou, Yi-Hong', 'Hsu, Chih-Chung']					2040-2295 (Print) 2040-2295 (Linking)	101528166	Journal of healthcare engineering	['eng']	10.1155/2018/8413403 [doi]	20191122	['Algorithms', 'Breast/diagnostic imaging', 'Breast Neoplasms/*diagnostic imaging', '*Deep Learning', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Ultrasonography, Mammary/*methods']	2019/11/23 06:00				NLM	8413403	['2018/06/29 00:00 [received]', '2018/10/25 00:00 [revised]', '2018/11/18 00:00 [accepted]', '2019/01/18 06:00 [entrez]', '2019/01/18 06:00 [pubmed]', '2019/11/23 06:00 [medline]']	England	PMC6311841		30651947	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Healthc Eng. 2018 Dec 4;2018:8413403. doi: 10.1155/2018/8413403. eCollection 2018.	MEDLINE	J Healthc Eng	Is Intensity Inhomogeneity Correction Useful for Classification of Breast Cancer in Sonograms Using Deep Neural Network?		2018	Is Intensity Inhomogeneity Correction Useful for Classification of Breast Cancer in Sonograms Using Deep Neural Network?
Fusing multichannel neurophysiological signals to recognize human emotion states becomes increasingly attractive. The conventional methods ignore the complementarity between time domain characteristics, frequency domain characteristics, and time-frequency characteristics of electroencephalogram (EEG) signals and cannot fully capture the correlation information between different channels. In this paper, an integrated deep learning framework based on improved deep belief networks with glia chains (DBN-GCs) is proposed. In the framework, the member DBN-GCs are employed for extracting intermediate representations of EEG raw features from multiple domains separately, as well as mining interchannel correlation information by glia chains. Then, the higher level features describing time domain characteristics, frequency domain characteristics, and time-frequency characteristics are fused by a discriminative restricted Boltzmann machine (RBM) to implement emotion recognition task. Experiments conducted on the DEAP benchmarking dataset achieve averaged accuracy of 75.92% and 76.83% for arousal and valence states classification, respectively. The results show that the proposed framework outperforms most of the above deep classifiers. Thus, potential of the proposed framework is demonstrated.	['School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China.', 'School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China.', 'School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China.', 'School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China.']	['10.1155/2018/9750904 [doi]']	['Chao H', 'Zhi H', 'Dong L', 'Liu Y']	['ORCID: 0000-0001-6700-9446', 'ORCID: 0000-0002-3598-9053', 'ORCID: 0000-0002-9708-5391', 'ORCID: 0000-0002-0540-865X']						['2019/01/17 06:00']	20190412	20181213	2018	2019/01/17 06:00		['Chao, Hao', 'Zhi, Huilai', 'Dong, Liang', 'Liu, Yongli']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2018/9750904 [doi]	20190412	['*Algorithms', 'Arousal/physiology', '*Deep Learning', '*Electroencephalography/methods', 'Emotions/*physiology', 'Humans', 'Support Vector Machine']	2019/04/13 06:00				NLM	9750904	['2018/09/14 00:00 [received]', '2018/11/14 00:00 [revised]', '2018/11/25 00:00 [accepted]', '2019/01/17 06:00 [entrez]', '2019/01/17 06:00 [pubmed]', '2019/04/13 06:00 [medline]']	United States	PMC6311795		30647727	epublish	['Journal Article']			IM		Comput Intell Neurosci. 2018 Dec 13;2018:9750904. doi: 10.1155/2018/9750904. eCollection 2018.	MEDLINE	Comput Intell Neurosci	Recognition of Emotions Using Multichannel EEG Data and DBN-GC-Based Ensemble Deep Learning Framework.		2018	Recognition of Emotions Using Multichannel EEG Data and DBN-GC-Based Ensemble Deep Learning Framework.
The field of natural language processing (NLP) has seen rapid advances in the past several years since the introduction of deep learning techniques. A variety of NLP tasks including syntactic parsing, machine translation, and summarization can now be performed by relatively simple combinations of general neural network models such as recurrent neural networks and attention mechanisms. This manuscript gives a brief introduction to deep learning and an overview of the current deep learning-based NLP technology.	['Department of Information and Communication Engineering, Graduate School of Information Science and Technology, The University of Tokyo.']	['1416201215 [pii]', '10.11477/mf.1416201215 [doi]']	['Tsuruoka Y']							['2019/01/11 06:00']	20190514		2019 Jan	2019/01/11 06:00		['Tsuruoka, Yoshimasa']			1		1881-6096 (Print) 1881-6096 (Linking)	101299709	Brain and nerve = Shinkei kenkyu no shinpo	['jpn']	10.11477/mf.1416201215 [doi]	20190514	['*Deep Learning', '*Natural Language Processing', '*Neural Networks (Computer)']	2019/05/15 06:00				NLM	45-55	['2019/01/11 06:00 [entrez]', '2019/01/11 06:00 [pubmed]', '2019/05/15 06:00 [medline]']	Japan			30630129	ppublish	['Journal Article', 'Review']			IM		Brain Nerve. 2019 Jan;71(1):45-55. doi: 10.11477/mf.1416201215.	MEDLINE	Brain Nerve	[Deep Learning and Natural Language Processing].		71	[Deep Learning and Natural Language Processing].
BACKGROUND: Glaucoma is the leading cause of irreversible blindness worldwide. It is a heterogeneous group of conditions with a common optic neuropathy and associated loss of peripheral vision. Both over and under-diagnosis carry high costs in terms of healthcare spending and preventable blindness. The characteristic clinical feature of glaucoma is asymmetrical optic nerve rim narrowing, which is difficult for humans to quantify reliably. Strategies to improve and automate optic disc assessment are therefore needed to prevent sight loss. METHODS: We developed a novel glaucoma detection algorithm that segments and analyses colour photographs to quantify optic nerve rim consistency around the whole disc at 15-degree intervals. This provides a profile of the cup/disc ratio, in contrast to the vertical cup/disc ratio in common use. We introduce a spatial probabilistic model, to account for the optic nerve shape, we then use this model to derive a disc deformation index and a decision rule for glaucoma. We tested our algorithm on two separate image datasets (ORIGA and RIM-ONE). RESULTS: The spatial algorithm accurately distinguished glaucomatous and healthy discs on internal and external validation (AUROC 99.6% and 91.0% respectively). It achieves this using a dataset 100-times smaller than that required for deep learning algorithms, is flexible to the type of cup and disc segmentation (automated or semi-automated), utilises images with missing data, and is correlated with the disc size (p = 0.02) and the rim-to-disc at the narrowest rim (p<0.001, in external validation). DISCUSSION: The spatial probabilistic algorithm is highly accurate, highly data efficient and it extends to any imaging hardware in which the boundaries of cup and disc can be segmented, thus making the algorithm particularly applicable to research into disease mechanisms, and also glaucoma screening in low resource settings.	"['Department of Eye & Vision Science, Institute of Ageing and Chronic Disease, University of Liverpool, Liverpool, United Kingdom.', ""Centre for Clinical Brain Sciences, University of Edinburgh, Chancellor's Building, Edinburgh, United Kingdom."", 'Department of Eye & Vision Science, Institute of Ageing and Chronic Disease, University of Liverpool, Liverpool, United Kingdom.', 'Department of Eye & Vision Science, Institute of Ageing and Chronic Disease, University of Liverpool, Liverpool, United Kingdom.', ""St Paul's Eye Unit, Royal Liverpool University Hospitals NHS Trust, Liverpool, United Kingdom."", 'Medical Information Engineering Department, Taishan Medical School, TaiAn City, ShanDong Province, China.', 'Department of Electrical Engineering and Electronics, University of Liverpool, Brownlow Hill, Liverpool, United Kingdom.', 'School of Computing, Mathematics and Digital Technology, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, Manchester, United Kingdom.', ""St Paul's Eye Unit, Royal Liverpool University Hospitals NHS Trust, Liverpool, United Kingdom."", 'Biomedical Sciences Research Institute, Faculty of Life & Health Sciences, Ulster University, Coleraine, Northern Ireland.', 'Department of Ophthalmology, Royal Victoria Hospital, Belfast, Northern Ireland.', 'Institute for Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, Massachusetts, United States of America.', 'Glaucoma Research Center, Wills Eye Hospital, Philadelphia, Pennsylvania, United States of America.', 'Department of Eye & Vision Science, Institute of Ageing and Chronic Disease, University of Liverpool, Liverpool, United Kingdom.', ""St Paul's Eye Unit, Royal Liverpool University Hospitals NHS Trust, Liverpool, United Kingdom."", 'Department of Applied Mathematics, Faculty of Engineering and Technology, Liverpool John Moores University, Liverpool, United Kingdom.']"	['10.1371/journal.pone.0209409 [doi]', 'PONE-D-18-23605 [pii]']	['MacCormick IJC', 'Williams BM', 'Zheng Y', 'Li K', 'Al-Bander B', 'Czanner S', 'Cheeseman R', 'Willoughby CE', 'Brown EN', 'Spaeth GL', 'Czanner G']	['ORCID: 0000-0002-1246-4166', 'ORCID: 0000-0002-1157-2093']				['The authors have declared that no competing interests exist.']		['2019/01/11 06:00']	20190924	20190110	2019	2019/01/11 06:00	['PLoS One. 2019 Apr 3;14(4):e0215056. PMID: 30943257']	['MacCormick, Ian J C', 'Williams, Bryan M', 'Zheng, Yalin', 'Li, Kun', 'Al-Bander, Baidaa', 'Czanner, Silvester', 'Cheeseman, Rob', 'Willoughby, Colin E', 'Brown, Emery N', 'Spaeth, George L', 'Czanner, Gabriela']			1		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0209409 [doi]	20190925	['*Algorithms', 'Diagnosis, Computer-Assisted/*methods/statistics & numerical data', 'Diagnostic Techniques, Ophthalmological/*statistics & numerical data', 'Glaucoma/diagnosis/*diagnostic imaging', 'Humans', 'Models, Statistical', 'Optic Disk/diagnostic imaging', 'Optic Nerve/diagnostic imaging', 'Spatial Analysis', 'Support Vector Machine']	2019/09/26 06:00				NLM	e0209409	['2018/08/10 00:00 [received]', '2018/12/05 00:00 [accepted]', '2019/01/11 06:00 [entrez]', '2019/01/11 06:00 [pubmed]', '2019/09/26 06:00 [medline]']	United States	PMC6328156		30629635	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			IM		PLoS One. 2019 Jan 10;14(1):e0209409. doi: 10.1371/journal.pone.0209409. eCollection 2019.	MEDLINE	PLoS One	Accurate, fast, data efficient and interpretable glaucoma diagnosis with automated spatial analysis of the whole cup to disc profile.		14	Accurate, fast, data efficient and interpretable glaucoma diagnosis with automated spatial analysis of the whole cup to disc profile.
The precision-based revolution in medicine continues to demand stratification of patients into smaller and more personalized subgroups. While genomic technologies have largely led this movement, diagnostic results can take days to weeks to generate. Management at, or closer to, the point of care still heavily relies on the subjective qualitative interpretation of clinical and diagnostic imaging findings. New and emerging technological advances in artificial intelligence (AI) now appear poised to help bring objectivity and precision to these traditionally qualitative analytic tools. In particular, one specific form of AI, known as deep learning, is achieving expert-level disease classifications in many areas of diagnostic medicine dependent on visual and image-based findings. Here, we briefly review concepts of deep learning, and more specifically recent developments in convolutional neural networks (CNNs), to highlight their transformative potential in personalized medicine and, in particular, diagnostic histopathology. Understanding the opportunities and challenges of these quantitative machine-based decision support tools is critical to their widespread introduction into routine diagnostics.	['a Department of Laboratory Medicine and Pathobiology , University of Toronto , Toronto , Canada.', 'b MacFeeters-Hamilton Brain Tumour Centre , Princess Margaret Cancer Centre , Toronto , Canada.', 'b MacFeeters-Hamilton Brain Tumour Centre , Princess Margaret Cancer Centre , Toronto , Canada.', 'c Department of Computer Science , University of Toronto , Toronto , Canada.', 'a Department of Laboratory Medicine and Pathobiology , University of Toronto , Toronto , Canada.', 'b MacFeeters-Hamilton Brain Tumour Centre , Princess Margaret Cancer Centre , Toronto , Canada.', 'b MacFeeters-Hamilton Brain Tumour Centre , Princess Margaret Cancer Centre , Toronto , Canada.', 'b MacFeeters-Hamilton Brain Tumour Centre , Princess Margaret Cancer Centre , Toronto , Canada.', 'a Department of Laboratory Medicine and Pathobiology , University of Toronto , Toronto , Canada.', 'b MacFeeters-Hamilton Brain Tumour Centre , Princess Margaret Cancer Centre , Toronto , Canada.', 'd Laboratory Medicine Program , University Health Network , Toronto , Canada.']	['10.1080/10408363.2018.1536111 [doi]']	['Xie Q', 'Faust K', 'Van Ommeren R', 'Sheikh A', 'Djuric U', 'Diamandis P']							['2019/01/11 06:00']	20190809	20190110	2019 Jan	2019/01/11 06:00		['Xie, Quin', 'Faust, Kevin', 'Van Ommeren, Randy', 'Sheikh, Adeel', 'Djuric, Ugljesa', 'Diamandis, Phedias']			1		1549-781X (Electronic) 1040-8363 (Linking)	8914816	Critical reviews in clinical laboratory sciences	['eng']	10.1080/10408363.2018.1536111 [doi]	20190809	['*Deep Learning', 'Diagnosis, Computer-Assisted', 'Humans', 'Neural Networks (Computer)', 'Pattern Recognition, Automated', '*Point-of-Care Systems', '*Precision Medicine']	2019/08/10 06:00		['*Deep learning', '*artificial intelligence', '*diagnostics', '*image analysis', '*machine learning', '*neural networks', '*personalized medicine', '*point of care', '*rapid diagnostics']	['NOTNLM']	NLM	61-73	['2019/01/11 06:00 [pubmed]', '2019/08/10 06:00 [medline]', '2019/01/11 06:00 [entrez]']	England			30628494	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"					Crit Rev Clin Lab Sci. 2019 Jan;56(1):61-73. doi: 10.1080/10408363.2018.1536111. Epub 2019 Jan 10.	MEDLINE	Crit Rev Clin Lab Sci	Deep learning for image analysis: Personalizing medicine closer to the point of care.		56	Deep learning for image analysis: Personalizing medicine closer to the point of care.
BACKGROUND: Main adverse cardiac events (MACE) are essentially composite endpoints for assessing safety and efficacy of treatment processes of acute coronary syndrome (ACS) patients. Timely prediction of MACE is highly valuable for improving the effects of ACS treatments. Most existing tools are specific to predict MACE by mainly using static patient features and neglecting dynamic treatment information during learning. METHODS: We address this challenge by developing a deep learning-based approach to utilize a large volume of heterogeneous electronic health record (EHR) for predicting MACE after ACS. Specifically, we obtain the deep representation of dynamic treatment features from EHR data, using the bidirectional recurrent neural network. And then, the extracted latent representation of treatment features can be utilized to predict whether a patient occurs MACE in his or her hospitalization. RESULTS: We validate the effectiveness of our approach on a clinical dataset containing 2930 ACS patient samples with 232 static feature types and 2194 dynamic feature types. The performance of our best model for predicting MACE after ACS remains robust and reaches 0.713 and 0.764 in terms of AUC and Accuracy, respectively, and has over 11.9% (1.2%) and 1.9% (7.5%) performance gain of AUC (Accuracy) in comparison with both logistic regression and a boosted resampling model presented in our previous work, respectively. The results are statistically significant. CONCLUSIONS: We hypothesize that our proposed model adapted to leverage dynamic treatment information in EHR data appears to boost the performance of MACE prediction for ACS, and can readily meet the demand clinical prediction of other diseases, from a large volume of EHR in an open-ended fashion.	['College of Biomedical Engineering and Instrument Science, Zhejiang University, Key Lab for Biomedical Engineering of Ministry of Education, Zheda Road, Hangzhou, China.', 'College of Biomedical Engineering and Instrument Science, Zhejiang University, Key Lab for Biomedical Engineering of Ministry of Education, Zheda Road, Hangzhou, China.', 'Department of Cardiology, Chinese PLA General Hospital, Beijing, China.', 'College of Biomedical Engineering and Instrument Science, Zhejiang University, Key Lab for Biomedical Engineering of Ministry of Education, Zheda Road, Hangzhou, China. zhengxing.h@gmail.com.']	['10.1186/s12911-018-0730-7 [doi]', '10.1186/s12911-018-0730-7 [pii]']	['Duan H', 'Sun Z', 'Dong W', 'Huang Z']	['ORCID: 0000-0002-2644-8642']						['2019/01/11 06:00']	20190715	20190109	2019 Jan 9	2019/01/11 06:00		['Duan, Huilong', 'Sun, Zhoujian', 'Dong, Wei', 'Huang, Zhengxing']			1		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-018-0730-7 [doi]	20190715	['Acute Coronary Syndrome/*complications/*diagnosis/therapy', 'Aged', 'Deep Learning', '*Electronic Health Records', 'Female', '*Hospitalization', 'Humans', 'Male', 'Middle Aged', '*Models, Theoretical', '*Neural Networks (Computer)', 'Prognosis']	2019/07/16 06:00		['*Acute coronary syndrome', '*Bidirectional recurrent neural network', '*Deep learning', '*Electronic health record', '*MACE prediction']	['NOTNLM']	NLM	5	['2017/11/24 00:00 [received]', '2018/12/27 00:00 [accepted]', '2019/01/11 06:00 [entrez]', '2019/01/11 06:00 [pubmed]', '2019/07/16 06:00 [medline]']	England	PMC6325718		30626381	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			IM		BMC Med Inform Decis Mak. 2019 Jan 9;19(1):5. doi: 10.1186/s12911-018-0730-7.	MEDLINE	BMC Med Inform Decis Mak	Utilizing dynamic treatment information for MACE prediction of acute coronary syndrome.		19	Utilizing dynamic treatment information for MACE prediction of acute coronary syndrome.
The BioCreative-V community proposed a challenging task of automatic extraction of causal relation network in Biological Expression Language (BEL) from the biomedical literature. Previous studies on this task largely used models induced from other related tasks and then transformed intermediate structures to BEL statements, which left the given training corpus unexplored. To make full use of the BEL training corpus, in this work, we propose a deep learning-based approach to extract BEL statements. Specifically, we decompose the problem into two subtasks: entity relation extraction and entity function detection. First, two attention-based bidirectional long short-term memory networks models are used to extract entity relation and entity function, respectively. Then entity relation and their functions are combined into a BEL statement. In order to boost the overall performance, a strategy of threshold filtering is applied to improve the precision of identified entity functions. We evaluate our approach on the BioCreative-V Track 4 corpus with or without gold entities. The experimental results show that our method achieves the state-of-the-art performance with an overall F1-measure of 46.9% in stage 2 and 21.3% in stage 1, respectively.	['School of Computer Science and Technology, Soochow University, Suzhou, China.', 'School of Computer Science and Technology, Soochow University, Suzhou, China.', 'School of Computer Science and Technology, Soochow University, Suzhou, China.', 'School of Computer Science and Technology, Soochow University, Suzhou, China.']	['5277249 [pii]', '10.1093/database/bay133 [doi]']	['Liu S', 'Cheng W', 'Qian L', 'Zhou G']							['2019/01/10 06:00']	20190604	20190101	2019 Jan 1	2019/01/10 06:00		['Liu, Suwen', 'Cheng, Wei', 'Qian, Longhua', 'Zhou, Guodong']					1758-0463 (Electronic) 1758-0463 (Linking)	101517697	Database : the journal of biological databases and curation	['eng']	10.1093/database/bay133 [doi]	20190604	['Computational Biology/*methods', 'Data Mining/*methods', '*Databases, Factual', 'Deep Learning', 'Humans', '*Natural Language Processing', 'Software']	2019/06/05 06:00				NLM		['2018/08/01 00:00 [received]', '2018/11/26 00:00 [accepted]', '2019/01/10 06:00 [entrez]', '2019/01/10 06:00 [pubmed]', '2019/06/05 06:00 [medline]']	England	PMC6323300		30624649	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Database (Oxford). 2019 Jan 1;2019. pii: 5277249. doi: 10.1093/database/bay133.	MEDLINE	Database (Oxford)	Combining relation extraction with function detection for BEL statement extraction.		2019	Combining relation extraction with function detection for BEL statement extraction.
BACKGROUND: The efficiency of drug development defined as a number of successfully launched new pharmaceuticals normalized by financial investments has significantly declined. Nonetheless, recent advances in high-throughput experimental techniques and computational modeling promise reductions in the costs and development times required to bring new drugs to market. The prediction of toxicity of drug candidates is one of the important components of modern drug discovery. RESULTS: In this work, we describe eToxPred, a new approach to reliably estimate the toxicity and synthetic accessibility of small organic compounds. eToxPred employs machine learning algorithms trained on molecular fingerprints to evaluate drug candidates. The performance is assessed against multiple datasets containing known drugs, potentially hazardous chemicals, natural products, and synthetic bioactive compounds. Encouragingly, eToxPred predicts the synthetic accessibility with the mean square error of only 4% and the toxicity with the accuracy of as high as 72%. CONCLUSIONS: eToxPred can be incorporated into protocols to construct custom libraries for virtual screening in order to filter out those drug candidates that are potentially toxic or would be difficult to synthesize. It is freely available as a stand-alone software at https://github.com/pulimeng/etoxpred .	['Division of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, 70803, USA.', 'Department of Biological Sciences, Louisiana State University, Baton Rouge, LA, 70803, USA.', 'Department of Mechanical Engineering, Louisiana State University, Baton Rouge, LA, 70803, USA.', 'Division of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, 70803, USA.', 'Department of Computer Science, Louisiana State University, Baton Rouge, LA, 70803, USA.', 'Department of Biological Sciences, Louisiana State University, Baton Rouge, LA, 70803, USA. michal@brylinski.org.', 'Center for Computation & Technology, Louisiana State University, Baton Rouge, LA, 70803, USA. michal@brylinski.org.']	['10.1186/s40360-018-0282-6 [doi]', '10.1186/s40360-018-0282-6 [pii]']	['Pu L', 'Naderi M', 'Liu T', 'Wu HC', 'Mukhopadhyay S', 'Brylinski M']	['ORCID: 0000-0002-6204-2869']						['2019/01/10 06:00']	20190909	20190108	2019 Jan 8	2019/01/10 06:00		['Pu, Limeng', 'Naderi, Misagh', 'Liu, Tairan', 'Wu, Hsiao-Chun', 'Mukhopadhyay, Supratik', 'Brylinski, Michal']		['R35 GM119524/GM/NIGMS NIH HHS/United States']	1		2050-6511 (Electronic) 2050-6511 (Linking)	101590449	BMC pharmacology & toxicology	['eng']	10.1186/s40360-018-0282-6 [doi]	20191008	['Algorithms', 'Animals', '*Drug Discovery', '*Drug-Related Side Effects and Adverse Reactions', 'Humans', '*Machine Learning']	2019/09/10 06:00		['*Deep belief network', '*Extremely randomized trees', '*Machine learning', '*Synthetic accessibility', '*Toxicity', '*Virtual screening']	['NOTNLM']	NLM	2	['2018/08/14 00:00 [received]', '2018/12/26 00:00 [accepted]', '2019/01/10 06:00 [entrez]', '2019/01/10 06:00 [pubmed]', '2019/09/10 06:00 [medline]']	England	PMC6325674		30621790	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		BMC Pharmacol Toxicol. 2019 Jan 8;20(1):2. doi: 10.1186/s40360-018-0282-6.	MEDLINE	BMC Pharmacol Toxicol	eToxPred: a machine learning-based approach to estimate the toxicity of drug candidates.		20	eToxPred: a machine learning-based approach to estimate the toxicity of drug candidates.
PURPOSE: With the aging population and the global diabetes epidemic, the prevalence of age-related macular degeneration (AMD) and diabetic macular edema (DME) diseases which are the leading causes of blindness is further increasing. Intravitreal injections with anti-vascular endothelial growth factor (anti-VEGF) medications are the standard of care for their indications. Optical coherence tomography (OCT), as a noninvasive imaging modality, plays a major part in guiding the administration of anti-VEGF therapy by providing detailed cross-sectional scans of the retina pathology. Fully automating OCT image detection can significantly decrease the tedious clinician labor and obtain a faithful pre-diagnosis from the analysis of the structural elements of the retina. Thereby, we explore the use of deep transfer learning method based on the visual geometry group 16 (VGG-16) network for classifying AMD and DME in OCT images accurately and automatically. METHOD: A total of 207,130 retinal OCT images between 2013 and 2017 were selected from retrospective cohorts of 5319 adult patients from the Shiley Eye Institute of the University of California San Diego, the California Retinal Research Foundation, Medical Center Ophthalmology Associates, the Shanghai First People's Hospital, and the Beijing Tongren Eye Center, with 109,312 images (37,456 with choroidal neovascularization, 11,599 with diabetic macular edema, 8867 with drusen, and 51,390 normal) for the experiment. After images preprocessing, 1000 images (250 images from each category) from 633 patients were selected as validation dataset while the rest images from another 4686 patients were used as training dataset. We used deep transfer learning method to fine-tune the VGG-16 network pre-trained on the ImageNet dataset, and evaluated its performance on the validation dataset. Then, prediction accuracy, sensitivity, specificity, and receiver-operating characteristic (ROC) were calculated. RESULTS: Experimental results proved that the proposed approach had manifested superior performance in retinal OCT images detection, which achieved a prediction accuracy of 98.6%, with a sensitivity of 97.8%, a specificity of 99.4%, and introduced an area under the ROC curve of 100%. CONCLUSION: Deep transfer learning method based on the VGG-16 network shows significant effectiveness on classification of retinal OCT images with a relatively small dataset, which can provide assistant support for medical decision-making. Moreover, the performance of the proposed approach is comparable to that of human experts with significant clinical experience. Thereby, it will find promising applications in an automatic diagnosis and classification of common retinal diseases.	['School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China. 171655822@qq.com.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China.', 'School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China.', 'Department of Precision Mechanical Engineering, Shanghai University, Shanghai, 200072, China.']	['10.1007/s00417-018-04224-8 [doi]', '10.1007/s00417-018-04224-8 [pii]']	['Li F', 'Chen H', 'Liu Z', 'Zhang X', 'Wu Z']	['ORCID: http://orcid.org/0000-0002-9462-0539']						['2019/01/06 06:00']	20190410	20190104	2019 Mar	2019/01/06 06:00		['Li, Feng', 'Chen, Hua', 'Liu, Zheng', 'Zhang, Xuedian', 'Wu, Zhizheng']		['51675321/National Natural Science Foundation of China']	3		1435-702X (Electronic) 0721-832X (Linking)	8205248	Graefe's archive for clinical and experimental ophthalmology = Albrecht von Graefes Archiv fur klinische und experimentelle Ophthalmologie	['eng']	10.1007/s00417-018-04224-8 [doi]	20190410	['*Algorithms', '*Deep Learning', 'Female', 'Follow-Up Studies', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'Middle Aged', 'Neural Networks (Computer)', 'ROC Curve', 'Reproducibility of Results', 'Retina/*diagnostic imaging', 'Retinal Diseases/*diagnosis', 'Retrospective Studies', 'Tomography, Optical Coherence/*methods']	2019/04/11 06:00		['Age-related macular degeneration', 'Deep transfer learning', 'Diabetic macular edema', 'Optical coherence tomography', 'Visual geometry group 16 network']	['NOTNLM']	NLM	495-505	['2018/08/03 00:00 [received]', '2018/12/18 00:00 [accepted]', '2018/12/10 00:00 [revised]', '2019/01/06 06:00 [pubmed]', '2019/04/11 06:00 [medline]', '2019/01/06 06:00 [entrez]']	Germany			30610422	ppublish	['Journal Article']			IM		Graefes Arch Clin Exp Ophthalmol. 2019 Mar;257(3):495-505. doi: 10.1007/s00417-018-04224-8. Epub 2019 Jan 4.	MEDLINE	Graefes Arch Clin Exp Ophthalmol	Fully automated detection of retinal disorders by image-based deep learning.		257	Fully automated detection of retinal disorders by image-based deep learning.
Face recognition using a single reference image per subject is challenging, above all when referring to a large gallery of subjects. Furthermore, the problem hardness seriously increases when the images are acquired in unconstrained conditions. In this paper we address the challenging Single Sample Per Person (SSPP) problem considering large datasets of images acquired in the wild, thus possibly featuring illumination, pose, face expression, partial occlusions, and low-resolution hurdles. The proposed technique alternates a sparse dictionary learning technique based on the method of optimal direction and the iterative l 0 -norm minimization algorithm called k-LiMapS. It works on robust deep-learned features, provided that the image variability is extended by standard augmentation techniques. Experiments show the effectiveness of our method against the hardness introduced above: first, we report extensive experiments on the unconstrained LFW dataset when referring to large galleries up to 1680 subjects; second, we present experiments on very low-resolution test images up to 8 x 8 pixels; third, tests on the AR dataset are analyzed against specific disguises such as partial occlusions, facial expressions, and illumination problems. In all the three scenarios our method outperforms the state-of-the-art approaches adopting similar configurations.	['Dipartimento di Informatica, Universita degli Studi di Milano, via Celoria 18, 20133 Milano, Italy. vittorio.cuculo@unimi.it.', 'Dipartimento di Informatica, Universita degli Studi di Milano, via Celoria 18, 20133 Milano, Italy. alessandro.damelio@unimi.it.', 'Dipartimento di Informatica, Universita degli Studi di Milano, via Celoria 18, 20133 Milano, Italy. giuliano.grossi@unimi.it.', 'Dipartimento di Informatica, Universita degli Studi di Milano, via Celoria 18, 20133 Milano, Italy. raffaella.lanzarotti@unimi.it.', 'Department of Mathematics, Khalifa University of Science and Technology, Al Saada Street, PO Box 127788, Abu Dhabi, UAE. jianyi.lin@ku.ac.ae.']	['s19010146 [pii]', '10.3390/s19010146 [doi]']	"['Cuculo V', ""D'Amelio A"", 'Grossi G', 'Lanzarotti R', 'Lin J']"	['ORCID: 0000-0002-8479-9950', 'ORCID: 0000-0002-8210-4457', 'ORCID: 0000-0001-9274-4047', 'ORCID: 0000-0002-8534-4413', 'ORCID: 0000-0002-3299-448X']						['2019/01/06 06:00']	20190129	20190103	2019 Jan 3	2019/01/06 06:00		"['Cuculo, Vittorio', ""D'Amelio, Alessandro"", 'Grossi, Giuliano', 'Lanzarotti, Raffaella', 'Lin, Jianyi']"			1		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E146 [pii] 10.3390/s19010146 [doi]	20190129	['Algorithms', 'Biometric Identification/*methods', 'Databases, Factual', '*Deep Learning', '*Facial Recognition', 'Humans', '*Image Processing, Computer-Assisted', '*Pattern Recognition, Automated']	2019/01/30 06:00		['Deep Convolutional Neural Network (DCNN) features', 'dictionary learning', 'face recognition', 'optimal directions (MOD)', 'single sample per person', 'sparse recovery']	['NOTNLM']	NLM		['2018/11/25 00:00 [received]', '2018/12/21 00:00 [revised]', '2018/12/27 00:00 [accepted]', '2019/01/06 06:00 [entrez]', '2019/01/06 06:00 [pubmed]', '2019/01/30 06:00 [medline]']	Switzerland	PMC6339043		30609846	epublish	['Journal Article']			IM		Sensors (Basel). 2019 Jan 3;19(1). pii: s19010146. doi: 10.3390/s19010146.	MEDLINE	Sensors (Basel)	Robust Single-Sample Face Recognition by Sparsity-Driven Sub-Dictionary Learning Using Deep Features.		19	Robust Single-Sample Face Recognition by Sparsity-Driven Sub-Dictionary Learning Using Deep Features.
Deep brain stimulation (DBS) represents one of the major clinical breakthroughs in the age of translational neuroscience. In 1987, Benabid and colleagues demonstrated that high-frequency stimulation can mimic the effects of ablative neurosurgery in Parkinson's disease (PD), while offering two key advantages to previous procedures: adjustability and reversibility. Deep brain stimulation is now an established therapeutic approach that robustly alleviates symptoms in patients with movement disorders, such as Parkinson's disease, essential tremor, and dystonia, who present with inadequate or adverse responses to medication. Currently, stimulation electrodes are implanted in specific target regions of the basal ganglia-thalamic circuit and stimulation pulses are delivered chronically. To achieve optimal therapeutic effect, stimulation frequency, amplitude, and pulse width must be adjusted on a patient-specific basis by a movement disorders specialist. The finding that pathological neural activity can be sampled directly from the target region using the DBS electrode has inspired a novel DBS paradigm: closed-loop adaptive DBS (aDBS). The goal of this strategy is to identify pathological and physiologically normal patterns of neuronal activity that can be used to adapt stimulation parameters to the concurrent therapeutic demand. This review will give detailed insight into potential biomarkers and discuss next-generation strategies, implementing advances in artificial intelligence, to further elevate the therapeutic potential of DBS by capitalizing on its modifiable nature. Development of intelligent aDBS, with an ability to deliver highly personalized treatment regimens and to create symptom-specific therapeutic strategies in real-time, could allow for significant further improvements in the quality of life for movement disorders patients with DBS that ultimately could outperform traditional drug treatment.	['Movement Disorder and Neuromodulation Unit, Department of Neurology, Charite - Universitatsmedizin Berlin, Campus Charite Mitte, Chariteplatz 1, 10117, Berlin, Germany. julian.neumann@charite.de.', 'Department of Neurobiology, University of Pittsburgh, Pittsburgh, PA, USA.', 'Department of Computer Science, Technische Universitat Berlin, Berlin, Germany.', 'Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Movement Disorder and Neuromodulation Unit, Department of Neurology, Charite - Universitatsmedizin Berlin, Campus Charite Mitte, Chariteplatz 1, 10117, Berlin, Germany.', 'Berlin School of Mind and Brain, Charite - Universitatsmedizin Berlin, Berlin, Germany.', 'Neurocure, Centre of Excellence, Charite - Universitatsmedizin Berlin, Berlin, Germany.', 'Department of Neurological Surgery, University of Pittsburgh, Pittsburgh, PA, USA.']	['10.1007/s13311-018-00705-0 [doi]', '10.1007/s13311-018-00705-0 [pii]']	['Neumann WJ', 'Turner RS', 'Blankertz B', 'Mitchell T', 'Kuhn AA', 'Richardson RM']	['ORCID: 0000-0002-6758-9708']						['2019/01/05 06:00']	20191122		2019 Jan	2019/01/05 06:00		['Neumann, Wolf-Julian', 'Turner, Robert S', 'Blankertz, Benjamin', 'Mitchell, Tom', 'Kuhn, Andrea A', 'Richardson, R Mark']		['CRCNS/Bundesministerium f?r Bildung und Forschung/International', 'R01 NS110424/NS/NINDS NIH HHS/United States']	1		1878-7479 (Electronic) 1878-7479 (Linking)	101290381	Neurotherapeutics : the journal of the American Society for Experimental NeuroTherapeutics	['eng']	10.1007/s13311-018-00705-0 [doi]	20191128	['Deep Brain Stimulation/*methods', 'Electrophysiology/methods', 'Humans', 'Movement Disorders/*therapy']	2019/11/23 06:00		"['*Basal ganglia', '*Closed-loop DBS', '*Deep brain stimulation', '*Dystonia', ""*Parkinson's disease"", '*Tourette syndrome']"	['NOTNLM']	NLM	105-118	['2020/01/01 00:00 [pmc-release]', '2019/01/05 06:00 [pubmed]', '2019/11/23 06:00 [medline]', '2019/01/05 06:00 [entrez]']	United States	PMC6361070	['2020/01/01 00:00']	30607748	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Neurotherapeutics. 2019 Jan;16(1):105-118. doi: 10.1007/s13311-018-00705-0.	MEDLINE	Neurotherapeutics	Toward Electrophysiology-Based Intelligent Adaptive Deep Brain Stimulation for Movement Disorders.		16	Toward Electrophysiology-Based Intelligent Adaptive Deep Brain Stimulation for Movement Disorders.
BACKGROUND: Previous studies have suggested deep learning to be a highly effective approach for screening lead compounds for new drugs. Several deep learning models have been developed by addressing the use of various kinds of fingerprints and graph convolution architectures. However, these methods are either advantageous or disadvantageous depending on whether they (1) can distinguish structural differences including chirality of compounds, and (2) can automatically discover effective features. RESULTS: We developed another deep learning model for compound classification. In this method, we constructed a distributed representation of compounds based on the SMILES notation, which linearly represents a compound structure, and applied the SMILES-based representation to a convolutional neural network (CNN). The use of SMILES allows us to process all types of compounds while incorporating a broad range of structure information, and representation learning by CNN automatically acquires a low-dimensional representation of input features. In a benchmark experiment using the TOX 21 dataset, our method outperformed conventional fingerprint methods, and performed comparably against the winning model of the TOX 21 Challenge. Multivariate analysis confirmed that the chemical space consisting of the features learned by SMILES-based representation learning adequately expressed a richer feature space that enabled the accurate discrimination of compounds. Using motif detection with the learned filters, not only important known structures (motifs) such as protein-binding sites but also structures of unknown functional groups were detected. CONCLUSIONS: The source code of our SMILES-based convolutional neural network software in the deep learning framework Chainer is available at http://www.dna.bio.keio.ac.jp/smiles/ , and the dataset used for performance evaluation in this work is available at the same URL.	['Department of Biosciences and Informatics, Keio University, Yokohama, 223-8522, Japan.', 'Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, 135-0064, Japan.', 'Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL), National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, 169-8555, Japan.', 'Department of Biosciences and Informatics, Keio University, Yokohama, 223-8522, Japan.', 'Department of Biosciences and Informatics, Keio University, Yokohama, 223-8522, Japan.', 'Department of Biosciences and Informatics, Keio University, Yokohama, 223-8522, Japan. yasu@bio.keio.ac.jp.']	['10.1186/s12859-018-2523-5 [doi]', '10.1186/s12859-018-2523-5 [pii]']	['Hirohara M', 'Saito Y', 'Koda Y', 'Sato K', 'Sakakibara Y']							['2019/01/02 06:00']	20190219	20181231	2018 Dec 31	2019/01/02 06:00		['Hirohara, Maya', 'Saito, Yutaka', 'Koda, Yuki', 'Sato, Kengo', 'Sakakibara, Yasubumi']			Suppl 19		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2523-5 [doi]	20190320	['Binding Sites', 'DNA/chemistry/*metabolism', '*Deep Learning', 'Humans', 'Models, Chemical', '*Neural Networks (Computer)', 'Pharmaceutical Preparations/chemistry/*metabolism', 'Protein Binding', 'Proteins/chemistry/*metabolism', '*Software']	2019/03/21 06:00		['Chemical compound', 'Convolutional neural network', 'SMILES', 'TOX 21 Challenge', 'Virtual screening']	['NOTNLM']	NLM	526	['2019/01/02 06:00 [entrez]', '2019/01/02 06:00 [pubmed]', '2019/03/21 06:00 [medline]']	England	PMC6311897		30598075	epublish	['Journal Article']		['0 (Pharmaceutical Preparations)', '0 (Proteins)', '9007-49-2 (DNA)']	IM		BMC Bioinformatics. 2018 Dec 31;19(Suppl 19):526. doi: 10.1186/s12859-018-2523-5.	MEDLINE	BMC Bioinformatics	Convolutional neural network based on SMILES representation of compounds for detecting chemical motif.		19	Convolutional neural network based on SMILES representation of compounds for detecting chemical motif.
Despite the superior performance of deep learning in many applications, challenges remain in the area of regression on function spaces. In particular, neural networks are unable to encode function inputs compactly as each node encodes just a real value. We propose a novel idea to address this shortcoming: to encode an entire function in a single network node. To that end, we design a compact network representation that encodes and propagates functions in single nodes for the distribution regression task. Our proposed distribution regression network (DRN) achieves higher prediction accuracies while using fewer parameters than traditional neural networks.	['School of Computing, National University of Singapore, 13 Computing Drive, 117417, Singapore; Bioinformatics Institute, Agency for Science, Technology and Research (A*STAR), 30 Biopolis Street, 138671, Singapore. Electronic address: koukl@comp.nus.edu.sg.', 'School of Computing, National University of Singapore, 13 Computing Drive, 117417, Singapore; Bioinformatics Institute, Agency for Science, Technology and Research (A*STAR), 30 Biopolis Street, 138671, Singapore; Image and Pervasive Access Lab (IPAL), CNRS UMI 2955, 1 Fusionopolis Way, 138632, Singapore; Singapore Eye Research Institute, 20 College Road, 169856, Singapore. Electronic address: leehk@bii.a-star.edu.sg.', 'School of Computing, National University of Singapore, 13 Computing Drive, 117417, Singapore. Electronic address: ngtk@comp.nus.edu.sg.']	['S0893-6080(18)30338-1 [pii]', '10.1016/j.neunet.2018.12.007 [doi]']	['Kou CKL', 'Lee HK', 'Ng TK']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2019/01/01 06:00']	20190319	20181214	2019 Feb	2019/01/01 06:00		['Kou, Connie Khor Li', 'Lee, Hwee Kuan', 'Ng, Teck Khim']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30338-1 [pii] 10.1016/j.neunet.2018.12.007 [doi]	20190319	['*Computer Communication Networks/statistics & numerical data', '*Databases, Factual/statistics & numerical data', 'Humans', '*Machine Learning', '*Neural Networks (Computer)']	2019/03/20 06:00		['Distribution regression', 'Supervised learning']	['NOTNLM']	NLM	199-212	['2018/07/09 00:00 [received]', '2018/11/02 00:00 [revised]', '2018/12/07 00:00 [accepted]', '2019/01/01 06:00 [pubmed]', '2019/03/20 06:00 [medline]', '2019/01/01 06:00 [entrez]']	United States			30597445	ppublish	['Journal Article']			IM		Neural Netw. 2019 Feb;110:199-212. doi: 10.1016/j.neunet.2018.12.007. Epub 2018 Dec 14.	MEDLINE	Neural Netw	A compact network learning model for distribution regression.		110	A compact network learning model for distribution regression.
BACKGROUND: Exon splicing is a regulated cellular process in the transcription of protein-coding genes. Technological advancements and cost reductions in RNA sequencing have made quantitative and qualitative assessments of the transcriptome both possible and widely available. RNA-seq provides unprecedented resolution to identify gene structures and resolve the diversity of splicing variants. However, currently available ab initio aligners are vulnerable to spurious alignments due to random sequence matches and sample-reference genome discordance. As a consequence, a significant set of false positive exon junction predictions would be introduced, which will further confuse downstream analyses of splice variant discovery and abundance estimation. RESULTS: In this work, we present a deep learning based splice junction sequence classifier, named DeepSplice, which employs convolutional neural networks to classify candidate splice junctions. We show (I) DeepSplice outperforms state-of-the-art methods for splice site classification when applied to the popular benchmark dataset HS3D, (II) DeepSplice shows high accuracy for splice junction classification with GENCODE annotation, and (III) the application of DeepSplice to classify putative splice junctions generated by Rail-RNA alignment of 21,504 human RNA-seq data significantly reduces 43 million candidates into around 3 million highly confident novel splice junctions. CONCLUSIONS: A model inferred from the sequences of annotated exon junctions that can then classify splice junctions derived from primary RNA-seq data has been implemented. The performance of the model was evaluated and compared through comprehensive benchmarking and testing, indicating a reliable performance and gross usability for classifying novel splice junctions derived from RNA-seq alignment.	['Department of Computer Science, University of Kentucky, Lexington, KY, 40506, USA. yi.zhang@uky.edu.', 'Department of Computer Science, University of Kentucky, Lexington, KY, 40506, USA.', 'Department of Veterinary Science, University of Kentucky, Lexington, KY, 40506, USA.', 'Department of Computer Science, University of Kentucky, Lexington, KY, 40506, USA.']	['10.1186/s12864-018-5350-1 [doi]', '10.1186/s12864-018-5350-1 [pii]']	['Zhang Y', 'Liu X', 'MacLeod J', 'Liu J']							['2018/12/29 06:00']	20190411	20181227	2018 Dec 27	2018/12/29 06:00		['Zhang, Yi', 'Liu, Xinan', 'MacLeod, James', 'Liu, Jinze']		['1054631/National Science Foundation', 'P30CA177558/National Institutes of Health', 'P30 CA177558/CA/NCI NIH HHS/United States', 'R01 HG006272/HG/NHGRI NIH HHS/United States', '5R01HG006272-03/National Institutes of Health']	1		1471-2164 (Electronic) 1471-2164 (Linking)	100965258	BMC genomics	['eng']	10.1186/s12864-018-5350-1 [doi]	20190411	['*Deep Learning', 'Exons/*genetics', 'Gene Expression Profiling', 'Genome, Human', 'Humans', '*RNA Splicing', '*Sequence Alignment', 'Sequence Analysis, RNA/*methods', 'Software']	2019/04/12 06:00		['Deep learning', 'Exon splicing', 'RNA-seq', 'Splice junction']	['NOTNLM']	NLM	971	['2017/11/16 00:00 [received]', '2018/12/03 00:00 [accepted]', '2018/12/29 06:00 [entrez]', '2018/12/29 06:00 [pubmed]', '2019/04/12 06:00 [medline]']	England	PMC6307148		30591034	epublish	['Journal Article']			IM		BMC Genomics. 2018 Dec 27;19(1):971. doi: 10.1186/s12864-018-5350-1.	MEDLINE	BMC Genomics	Discerning novel splice junctions derived from RNA-seq alignment: a deep learning approach.		19	Discerning novel splice junctions derived from RNA-seq alignment: a deep learning approach.
Human activity recognition (HAR) based on sensor data is a significant problem in pervasive computing. In recent years, deep learning has become the dominating approach in this field, due to its high accuracy. However, it is difficult to make accurate identification for the activities of one individual using a model trained on data from other users. The decline on the accuracy of recognition restricts activity recognition in practice. At present, there is little research on the transferring of deep learning model in this field. This is the first time as we known, an empirical study was carried out on deep transfer learning between users with unlabeled data of target. We compared several widely-used algorithms and found that Maximum Mean Discrepancy (MMD) method is most suitable for HAR. We studied the distribution of features generated from sensor data. We improved the existing method from the aspect of features distribution with center loss and get better results. The observations and insights in this study have deepened the understanding of transfer learning in the activity recognition field and provided guidance for further research.	['Harbin Institute of Technology, Harbin 15000, China. renjie_ding_hitwh@163.com.', 'Harbin Institute of Technology, Harbin 15000, China. lixuecs@hit.edu.cn.', 'Harbin Institute of Technology, Harbin 15000, China. nls@hit.edu.cn.', 'Harbin Institute of Technology, Harbin 15000, China. lijiazhen_smile@163.com.', 'Harbin Institute of Technology, Harbin 15000, China. 15776633420@163.com.', 'Harbin Institute of Technology, Harbin 15000, China. chudh@hit.edu.cn.', 'Harbin Institute of Technology, Harbin 15000, China. liuguozhonghit@163.com.', 'Harbin Institute of Technology, Harbin 15000, China. dechen@hit.edu.cn.']	['s19010057 [pii]', '10.3390/s19010057 [doi]']	['Ding R', 'Li X', 'Nie L', 'Li J', 'Si X', 'Chu D', 'Liu G', 'Zhan D']							['2018/12/28 06:00']	20190108	20181224	2018 Dec 24	2018/12/28 06:00		['Ding, Renjie', 'Li, Xue', 'Nie, Lanshun', 'Li, Jiazhen', 'Si, Xiandong', 'Chu, Dianhui', 'Liu, Guozhong', 'Zhan, Dechen']		['ZR2017MF026/Natural Science Foundation of Shandong Province', '61772159/National Natural Science Foundation of China', '2017QYCX12/Science and technology Special Project of National Regional Innovation', 'Center']	1		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E57 [pii] 10.3390/s19010057 [doi]	20190124	['Algorithms', '*Biosensing Techniques', 'Deep Learning', '*Human Activities', 'Humans', 'Machine Learning', 'Monitoring, Physiologic/*methods', 'Neural Networks (Computer)', '*Wearable Electronic Devices']	2019/01/09 06:00		['deep learning', 'human activity recognition', 'sensor data', 'transfer learning']	['NOTNLM']	NLM		['2018/10/29 00:00 [received]', '2018/12/21 00:00 [revised]', '2018/12/21 00:00 [accepted]', '2018/12/28 06:00 [entrez]', '2018/12/28 06:00 [pubmed]', '2019/01/09 06:00 [medline]']	Switzerland	PMC6339185		30586875	epublish	['Journal Article']			IM		Sensors (Basel). 2018 Dec 24;19(1). pii: s19010057. doi: 10.3390/s19010057.	MEDLINE	Sensors (Basel)	Empirical Study and Improvement on Deep Transfer Learning for Human Activity Recognition.		19	Empirical Study and Improvement on Deep Transfer Learning for Human Activity Recognition.
INTRODUCTION: Convolutional neural networks have begun to surpass classical statistical- and atlas based machine learning techniques in medical image segmentation in recent years, proving to be superior in performance and speed. However, a major challenge that the community faces are mismatch between variability within training and evaluation datasets and therefore a dependency on proper data pre-processing. Intensity normalization is a widely applied technique for reducing the variance of the data for which there are several methods available ranging from uniformity transformation to histogram equalization. The current study analyses the influence of intensity normalization on cerebellum segmentation performance of a convolutional neural network (CNN). METHOD: The study included three population samples with a total number of 218 datasets, all including a T1w MRI data set acquired at 3T and a ground truth segmentation delineating the cerebellum. A 12 layer deep 3D fully convolutional neural network was trained using 150 datasets from one of the population samples. Four different intensity normalization methods were separately applied to pre-process the data, and the CNN was correspondingly trained four times with respect to the different normalization techniques. A quantitative analysis of the segmentation performance, assessed via the Sorensen-Dice similarity coefficient (DSC) of all four CNNs, was performed to investigate the intensity sensitivity of the CNNs. Additionally, the optimal network performance was determined by identifying the best parameter set for intensity normalization. RESULTS: All four normalization methods led to excellent (mean DSC score=0.96) segmentation results when evaluated using known data; however, the segmentation performance differed depending on the applied intensity normalization method when testing with formerly unseen data, in which case the histogram equalization methods outperformed the unit distribution methods. A detailed, systematic analysis of intensity manipulations revealed, that the distribution of input intensities clearly affected the segmentation performance and that for each input dataset a linear intensity modification (shifting and scaling) existed leading to optimal segmentation results. This was further proven by an optimization analysis to find the optimal adjustment for an individual input evaluation sample within each normalization configuration. DISCUSSION: The findings suggest that proper preparation of the evaluation data is more crucial than the exact choice of normalization method to prepare the training data. The histogram equalization methods tested in this study were found to perform this task best, although leaving room for further improvements, as shown by the optimization analysis.	['Medical Physics Group, Institute for Diagnostic and Interventional Radiology, University Hospital Jena, Jena, Germany.', 'Medical Physics Group, Institute for Diagnostic and Interventional Radiology, University Hospital Jena, Jena, Germany; Department of Neurology, Essen University Hospital, University of Duisburg-Essen, Essen, Germany.', 'Department of Neurology, Essen University Hospital, University of Duisburg-Essen, Essen, Germany.', 'Department of Diagnostic and Interventional Radiology and Neuroradiology, University of Duisburg-Essen, Essen, Germany.', 'Medical Physics Group, Institute for Diagnostic and Interventional Radiology, University Hospital Jena, Jena, Germany; Michael Stifel Center for Data-Driven and Simulation Science, Friedrich Schiller University Jena, Jena, Germany.', 'Medical Physics Group, Institute for Diagnostic and Interventional Radiology, University Hospital Jena, Jena, Germany. Electronic address: daniel.guellmar@med.uni-jena.de.']	['S0939-3889(18)30102-8 [pii]', '10.1016/j.zemedi.2018.11.004 [doi]']	['Jacobsen N', 'Deistung A', 'Timmann D', 'Goericke SL', 'Reichenbach JR', 'Gullmar D']		['Copyright (c) 2018. Published by Elsevier GmbH.']					['2018/12/24 06:00']	20191125	20181220	2019 May	2018/12/24 06:00		['Jacobsen, Nina', 'Deistung, Andreas', 'Timmann, Dagmar', 'Goericke, Sophia L', 'Reichenbach, Jurgen R', 'Gullmar, Daniel']			2		1876-4436 (Electronic) 0939-3889 (Linking)	100886455	Zeitschrift fur medizinische Physik	['eng']	S0939-3889(18)30102-8 [pii] 10.1016/j.zemedi.2018.11.004 [doi]	20191125	['Humans', 'Image Processing, Computer-Assisted/*methods', '*Magnetic Resonance Imaging', '*Neural Networks (Computer)']	2019/11/26 06:00		['Cerebellum', 'Convolutional neural network', 'Deep learning', 'Intensity normalization', 'MRI', 'Pre-processing', 'Segmentation']	['NOTNLM']	NLM	128-138	['2018/08/13 00:00 [received]', '2018/10/24 00:00 [revised]', '2018/11/12 00:00 [accepted]', '2018/12/24 06:00 [pubmed]', '2019/11/26 06:00 [medline]', '2018/12/24 06:00 [entrez]']	Germany			30579766	ppublish	['Journal Article']			IM		Z Med Phys. 2019 May;29(2):128-138. doi: 10.1016/j.zemedi.2018.11.004. Epub 2018 Dec 20.	MEDLINE	Z Med Phys	Analysis of intensity normalization for optimal segmentation performance of a fully convolutional neural network.		29	Analysis of intensity normalization for optimal segmentation performance of a fully convolutional neural network.
The main goal of this study is to build an artificial intelligence (AI) architecture for automated extraction of dual-modal image features from both shear-wave elastography (SWE) and B-mode ultrasound, and to evaluate the AI architecture for classification between benign and malignant breast tumors. In this AI architecture, ultrasound images were segmented by the reaction diffusion level set model combined with the Gabor-based anisotropic diffusion algorithm. Then morphological features and texture features were extracted from SWE and B-mode ultrasound images at the contourlet domain. Finally, we employed a framework for feature learning and classification with the deep polynomial network (DPN) on dual-modal features to distinguish between malignant and benign breast tumors. With the leave-one-out cross validation, the DPN method on dual-modal features achieved a sensitivity of 97.8%, a specificity of 94.1%, an accuracy of 95.6%, a Youden's index of 91.9% and an area under the receiver operating characteristic curve of 0.961, which was superior to the classic single-modal methods, and the dual-modal methods using the principal component analysis and multiple kernel learning. These results have demonstrated that the dual-modal AI-based technique with DPN has the potential for breast tumor classification in future clinical practice.	['Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Room 803, Xiangying Building, No. 333, Nanchen Road, Shanghai 200444, China; The SMART (Smart Medicine and AI-based Radiology Technology) Lab, Institute of Biomedical Engineering, Shanghai University, Shanghai 200444, China. Electronic address: zhangq@t.shu.edu.cn.', 'Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Room 803, Xiangying Building, No. 333, Nanchen Road, Shanghai 200444, China; The SMART (Smart Medicine and AI-based Radiology Technology) Lab, Institute of Biomedical Engineering, Shanghai University, Shanghai 200444, China.', 'Paul C. Lauterbur Research Center for Biomedical Imaging, Institute of Biomedical and Health Engineering, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Ave., SZ University Town, Shenzhen 518055, China. Electronic address: yang.xiao@siat.ac.cn.', 'Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Room 803, Xiangying Building, No. 333, Nanchen Road, Shanghai 200444, China; The SMART (Smart Medicine and AI-based Radiology Technology) Lab, Institute of Biomedical Engineering, Shanghai University, Shanghai 200444, China.', 'Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Room 803, Xiangying Building, No. 333, Nanchen Road, Shanghai 200444, China.', 'Paul C. Lauterbur Research Center for Biomedical Imaging, Institute of Biomedical and Health Engineering, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Ave., SZ University Town, Shenzhen 518055, China.']	['S1350-4533(18)30174-7 [pii]', '10.1016/j.medengphy.2018.12.005 [doi]']	['Zhang Q', 'Song S', 'Xiao Y', 'Chen S', 'Shi J', 'Zheng H']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/12/23 06:00']	20190826	20181219	2019 Feb	2018/12/24 06:00		['Zhang, Qi', 'Song, Shuang', 'Xiao, Yang', 'Chen, Shuai', 'Shi, Jun', 'Zheng, Hairong']					1873-4030 (Electronic) 1350-4533 (Linking)	9422753	Medical engineering & physics	['eng']	S1350-4533(18)30174-7 [pii] 10.1016/j.medengphy.2018.12.005 [doi]	20190826	['*Artificial Intelligence', 'Breast Neoplasms/*diagnostic imaging', '*Elasticity Imaging Techniques', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', '*Ultrasonography, Mammary']	2019/08/27 06:00		['*Artificial intelligence', '*B-mode ultrasound', '*Breast tumor', '*Deep polynomial network', '*Dual-modal diagnosis', '*Shear-wave elastography']	['NOTNLM']	NLM	1-6	['2018/07/30 00:00 [received]', '2018/11/21 00:00 [revised]', '2018/12/04 00:00 [accepted]', '2018/12/24 06:00 [pubmed]', '2019/08/27 06:00 [medline]', '2018/12/23 06:00 [entrez]']	England			30578163	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					Med Eng Phys. 2019 Feb;64:1-6. doi: 10.1016/j.medengphy.2018.12.005. Epub 2018 Dec 19.	MEDLINE	Med Eng Phys	Dual-mode artificially-intelligent diagnosis of breast tumours in shear-wave elastography and B-mode ultrasound using deep polynomial networks.		64	Dual-mode artificially-intelligent diagnosis of breast tumours in shear-wave elastography and B-mode ultrasound using deep polynomial networks.
BACKGROUND: Bioinformatics tools have been developed to interpret gene expression data at the gene set level, and these gene set based analyses improve the biologists' capability to discover functional relevance of their experiment design. While elucidating gene set individually, inter-gene sets association is rarely taken into consideration. Deep learning, an emerging machine learning technique in computational biology, can be used to generate an unbiased combination of gene set, and to determine the biological relevance and analysis consistency of these combining gene sets by leveraging large genomic data sets. RESULTS: In this study, we proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model with the incorporation of a priori defined gene sets that retain the crucial biological features in the latent layer. We introduced the concept of the gene superset, an unbiased combination of gene sets with weights trained by the autoencoder, where each node in the latent layer is a superset. Trained with genomic data from TCGA and evaluated with their accompanying clinical parameters, we showed gene supersets' ability of discriminating tumor subtypes and their prognostic capability. We further demonstrated the biological relevance of the top component gene sets in the significant supersets. CONCLUSIONS: Using autoencoder model and gene superset at its latent layer, we demonstrated that gene supersets retain sufficient biological information with respect to tumor subtypes and clinical prognostic significance. Superset also provides high reproducibility on survival analysis and accurate prediction for cancer subtypes.	"['Department of Electrical and Computer Engineering, The University of Texas at San Antonio, San Antonio, TX, 78249, USA.', ""Greehey Children's Cancer Research Institute, The University of Texas Health Science Center at San Antonio, San Antonio, TX, 78229, USA."", ""Greehey Children's Cancer Research Institute, The University of Texas Health Science Center at San Antonio, San Antonio, TX, 78229, USA."", 'Department of Electrical and Computer Engineering, The University of Texas at San Antonio, San Antonio, TX, 78249, USA.', 'Department of Electrical and Computer Engineering, The University of Texas at San Antonio, San Antonio, TX, 78249, USA.', ""Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China."", 'Department of Electrical and Computer Engineering, The University of Texas at San Antonio, San Antonio, TX, 78249, USA. yufei.huang@utsa.edu.', ""Greehey Children's Cancer Research Institute, The University of Texas Health Science Center at San Antonio, San Antonio, TX, 78229, USA. cheny8@uthscsa.edu."", 'Department of Epidemiology & Biostatistics, The University of Texas Health Science Center at San Antonio, San Antonio, TX, 78229, USA. cheny8@uthscsa.edu.']"	['10.1186/s12918-018-0642-2 [doi]', '10.1186/s12918-018-0642-2 [pii]']	['Chen HH', 'Chiu YC', 'Zhang T', 'Zhang S', 'Huang Y', 'Chen Y']							['2018/12/23 06:00']	20190726	20181221	2018 Dec 21	2018/12/24 06:00		['Chen, Hung-I Harry', 'Chiu, Yu-Chiao', 'Zhang, Tinghe', 'Zhang, Songyao', 'Huang, Yufei', 'Chen, Yidong']		['P30 CA054174/CA/NCI NIH HHS/United States', 'R01 GM113245/GM/NIGMS NIH HHS/United States', 'UL1 RR025767/RR/NCRR NIH HHS/United States']	Suppl 8		1752-0509 (Electronic) 1752-0509 (Linking)	101301827	BMC systems biology	['eng']	10.1186/s12918-018-0642-2 [doi]	20190726	['Adenocarcinoma of Lung/diagnosis/genetics', 'Breast Neoplasms/genetics', 'Genomics/*methods', 'Humans', 'Machine Learning', 'Prognosis', 'Survival Analysis']	2019/07/28 06:00		['*Autoencoder', '*Deep learning', '*Gene superset analysis', '*Survival analysis']	['NOTNLM']	NLM	142	['2018/12/23 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/07/28 06:00 [medline]']	England	PMC6302374		30577835	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']					BMC Syst Biol. 2018 Dec 21;12(Suppl 8):142. doi: 10.1186/s12918-018-0642-2.	MEDLINE	BMC Syst Biol	GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization.		12	GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization.
"BACKGROUND: Self-interacting Proteins (SIPs) plays a critical role in a series of life function in most living cells. Researches on SIPs are important part of molecular biology. Although numerous SIPs data be provided, traditional experimental methods are labor-intensive, time-consuming and costly and can only yield limited results in real-world needs. Hence,it's urgent to develop an efficient computational SIPs prediction method to fill the gap. Deep learning technologies have proven to produce subversive performance improvements in many areas, but the effectiveness of deep learning methods for SIPs prediction has not been verified. RESULTS: We developed a deep learning model for predicting SIPs by constructing a Stacked Long Short-Term Memory (SLSTM) neural network that contains ""dropout"". We extracted features from protein sequences using a novel feature extraction scheme that combined Zernike Moments (ZMs) with Position Specific Weight Matrix (PSWM). The capability of the proposed approach was assessed on S.erevisiae and Human SIPs datasets. The result indicates that the approach based on deep learning can effectively resist data skew and achieve good accuracies of 95.69 and 97.88%, respectively. To demonstrate the progressiveness of deep learning, we compared the results of the SLSTM-based method and the celebrated Support Vector Machine (SVM) method and several other well-known methods on the same datasets. CONCLUSION: The results show that our method is overall superior to any of the other existing state-of-the-art techniques. As far as we know, this study first applies deep learning method to predict SIPs, and practical experimental results reveal its potential in SIPs identification."	['Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China.', 'University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China. zhuhongyou@ms.xjb.ac.cn.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China. xiaoli@ms.xjb.ac.cn.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China.', 'University of Chinese Academy of Sciences, Beijing, 100049, China.']	['10.1186/s12918-018-0647-x [doi]', '10.1186/s12918-018-0647-x [pii]']	['Wang YB', 'You ZH', 'Li X', 'Jiang TH', 'Cheng L', 'Chen ZH']							['2018/12/23 06:00']	20190726	20181221	2018 Dec 21	2018/12/24 06:00		['Wang, Yan-Bin', 'You, Zhu-Hong', 'Li, Xiao', 'Jiang, Tong-Hai', 'Cheng, Li', 'Chen, Zhan-Heng']			Suppl 8		1752-0509 (Electronic) 1752-0509 (Linking)	101301827	BMC systems biology	['eng']	10.1186/s12918-018-0647-x [doi]	20190726	['Computational Biology/*methods', 'Humans', '*Neural Networks (Computer)', '*Protein Interaction Mapping', 'Saccharomyces cerevisiae/metabolism']	2019/07/28 06:00		['*Deep learning', '*Dropout', '*Self-interacting proteins', '*Stacked long short-term memory']	['NOTNLM']	NLM	129	['2018/12/23 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/07/28 06:00 [medline]']	England	PMC6302371		30577794	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					BMC Syst Biol. 2018 Dec 21;12(Suppl 8):129. doi: 10.1186/s12918-018-0647-x.	MEDLINE	BMC Syst Biol	Prediction of protein self-interactions using stacked long short-term memory from protein sequences information.		12	Prediction of protein self-interactions using stacked long short-term memory from protein sequences information.
BACKGROUND: The National Cancer Institute drug pair screening effort against 60 well-characterized human tumor cell lines (NCI-60) presents an unprecedented resource for modeling combinational drug activity. RESULTS: We present a computational model for predicting cell line response to a subset of drug pairs in the NCI-ALMANAC database. Based on residual neural networks for encoding features as well as predicting tumor growth, our model explains 94% of the response variance. While our best result is achieved with a combination of molecular feature types (gene expression, microRNA and proteome), we show that most of the predictive power comes from drug descriptors. To further demonstrate value in detecting anticancer therapy, we rank the drug pairs for each cell line based on model predicted combination effect and recover 80% of the top pairs with enhanced activity. CONCLUSIONS: We present promising results in applying deep learning to predicting combinational drug response. Our feature analysis indicates screening data involving more cell lines are needed for the models to make better use of molecular features.	['Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, USA. fangfang@anl.gov.', 'Computation Institute, The University of Chicago, Chicago, IL, USA. fangfang@anl.gov.', 'Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, USA.', 'Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, USA.', 'Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, NM, USA.', 'Computer Science, Los Alamos National Laboratory, Los Alamos, NM, USA.', 'Computation Directorate, Lawrence Livermore National Laboratory, Livermore, CA, USA.', 'Department of Bioengineering and Carl R. Woese Institute for Genomic Biology, University of Illinois at Urbana-Champaign, Urbana, IL, USA.', 'Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, USA.', 'Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, USA.', 'Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, USA.', 'Data Science and Information Technology Program, Frederick National Laboratory for Cancer Research, Frederick, MD, USA.', 'Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, USA.', 'Computation Institute, The University of Chicago, Chicago, IL, USA.']	['10.1186/s12859-018-2509-3 [doi]', '10.1186/s12859-018-2509-3 [pii]']	['Xia F', 'Shukla M', 'Brettin T', 'Garcia-Cardona C', 'Cohn J', 'Allen JE', 'Maslov S', 'Holbeck SL', 'Doroshow JH', 'Evrard YA', 'Stahlberg EA', 'Stevens RL']							['2018/12/23 06:00']	20190201	20181221	2018 Dec 21	2018/12/24 06:00		['Xia, Fangfang', 'Shukla, Maulik', 'Brettin, Thomas', 'Garcia-Cardona, Cristina', 'Cohn, Judith', 'Allen, Jonathan E', 'Maslov, Sergei', 'Holbeck, Susan L', 'Doroshow, James H', 'Evrard, Yvonne A', 'Stahlberg, Eric A', 'Stevens, Rick L']		['HHSN261200800001C/RC/CCR NIH HHS/United States', 'HHSN261200800001E/CA/NCI NIH HHS/United States']	Suppl 18		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2509-3 [doi]	20190201	['Cell Line, Tumor', 'Deep Learning/*trends', 'Drug Evaluation, Preclinical/*methods', 'Humans', 'National Cancer Institute (U.S.)', 'Neural Networks (Computer)', 'United States']	2019/02/02 06:00		['Combination therapy', 'Deep learning', 'Machine learning', 'in silico drug screening']	['NOTNLM']	NLM	486	['2018/12/23 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/02/02 06:00 [medline]']	England	PMC6302446		30577754	epublish	['Journal Article']			IM		BMC Bioinformatics. 2018 Dec 21;19(Suppl 18):486. doi: 10.1186/s12859-018-2509-3.	MEDLINE	BMC Bioinformatics	Predicting tumor cell line response to drug pairs with deep learning.		19	Predicting tumor cell line response to drug pairs with deep learning.
BACKGROUND: Real-time analysis of patient data during medical procedures can provide vital diagnostic feedback that significantly improves chances of success. With sensors becoming increasingly fast, frameworks such as Deep Neural Networks are required to perform calculations within the strict timing constraints for real-time operation. However, traditional computing platforms responsible for running these algorithms incur a large overhead due to communication protocols, memory accesses, and static (often generic) architectures. In this work, we implement a low-latency Multi-Layer Perceptron (MLP) processor using Field Programmable Gate Arrays (FPGAs). Unlike CPUs and Graphics Processing Units (GPUs), our FPGA-based design can directly interface sensors, storage devices, display devices and even actuators, thus reducing the delays of data movement between ports and compute pipelines. Moreover, the compute pipelines themselves are tailored specifically to the application, improving resource utilization and reducing idle cycles. We demonstrate the effectiveness of our approach using mass-spectrometry data sets for real-time cancer detection. RESULTS: We demonstrate that correct parameter sizing, based on the application, can reduce latency by 20% on average. Furthermore, we show that in an application with tightly coupled data-path and latency constraints, having a large amount of computing resources can actually reduce performance. Using mass-spectrometry benchmarks, we show that our proposed FPGA design outperforms both CPU and GPU implementations, with an average speedup of 144x and 21x, respectively. CONCLUSION: In our work, we demonstrate the importance of application-specific optimizations in order to minimize latency and maximize resource utilization for MLP inference. By directly interfacing and processing sensor data with ultra-low latency, FPGAs can perform real-time analysis during procedures and provide diagnostic feedback that can be critical to achieving higher percentages of successful patient outcomes.	['Computer Architecture and Automated Design Lab, Boston University, Boston, MA, USA.', 'Computer Architecture and Automated Design Lab, Boston University, Boston, MA, USA.', 'Argonne Leadership Computing Facility, Argonne National Laboratory, Lemont, IL, USA.', 'Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA.', 'Computer Architecture and Automated Design Lab, Boston University, Boston, MA, USA. herbordt@bu.edu.']	['10.1186/s12859-018-2505-7 [doi]', '10.1186/s12859-018-2505-7 [pii]']	['Sanaullah A', 'Yang C', 'Alexeev Y', 'Yoshii K', 'Herbordt MC']							['2018/12/23 06:00']	20190201	20181221	2018 Dec 21	2018/12/24 06:00		['Sanaullah, Ahmed', 'Yang, Chen', 'Alexeev, Yuri', 'Yoshii, Kazutomo', 'Herbordt, Martin C']			Suppl 18		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2505-7 [doi]	20190201	['Data Analysis', 'Humans', 'Machine Learning/*trends', 'Neoplasms/*diagnosis/pathology', '*Neural Networks (Computer)']	2019/02/02 06:00		['Cancer', 'FPGA', 'Inference', 'Machine learning', 'Mass-spectrometry', 'Multi-layer perceptrons', 'Real-time']	['NOTNLM']	NLM	490	['2018/12/23 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/02/02 06:00 [medline]']	England	PMC6302367		30577751	epublish	['Journal Article']			IM		BMC Bioinformatics. 2018 Dec 21;19(Suppl 18):490. doi: 10.1186/s12859-018-2505-7.	MEDLINE	BMC Bioinformatics	Real-time data analysis for medical diagnosis using FPGA-accelerated neural networks.		19	Real-time data analysis for medical diagnosis using FPGA-accelerated neural networks.
BACKGROUND: Histopathology images of tumor biopsies present unique challenges for applying machine learning to the diagnosis and treatment of cancer. The pathology slides are high resolution, often exceeding 1GB, have non-uniform dimensions, and often contain multiple tissue slices of varying sizes surrounded by large empty regions. The locations of abnormal or cancerous cells, which may constitute a small portion of any given tissue sample, are not annotated. Cancer image datasets are also extremely imbalanced, with most slides being associated with relatively common cancers. Since deep representations trained on natural photographs are unlikely to be optimal for classifying pathology slide images, which have different spectral ranges and spatial structure, we here describe an approach for learning features and inferring representations of cancer pathology slides based on sparse coding. RESULTS: We show that conventional transfer learning using a state-of-the-art deep learning architecture pre-trained on ImageNet (RESNET) and fine tuned for a binary tumor/no-tumor classification task achieved between 85% and 86% accuracy. However, when all layers up to the last convolutional layer in RESNET are replaced with a single feature map inferred via a sparse coding using a dictionary optimized for sparse reconstruction of unlabeled pathology slides, classification performance improves to over 93%, corresponding to a 54% error reduction. CONCLUSIONS: We conclude that a feature dictionary optimized for biomedical imagery may in general support better classification performance than does conventional transfer learning using a dictionary pre-trained on natural images.	['Los Alamos National Laboratory, Los Alamos, NM, USA. wfischer@lanl.gov.', 'Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA.', 'Los Alamos National Laboratory, Los Alamos, NM, USA.', 'Los Alamos National Laboratory, Los Alamos, NM, USA.', 'Los Alamos National Laboratory, Los Alamos, NM, USA.']	['10.1186/s12859-018-2504-8 [doi]', '10.1186/s12859-018-2504-8 [pii]']	['Fischer W', 'Moudgalya SS', 'Cohn JD', 'Nguyen NTT', 'Kenyon GT']							['2018/12/23 06:00']	20190201	20181221	2018 Dec 21	2018/12/24 06:00		['Fischer, Will', 'Moudgalya, Sanketh S', 'Cohn, Judith D', 'Nguyen, Nga T T', 'Kenyon, Garrett T']			Suppl 18		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2504-8 [doi]	20190201	['Deep Learning/*trends', 'Humans', 'Neoplasms/*pathology', '*Neural Networks (Computer)']	2019/02/02 06:00		['Cancer pathology slides', 'Deep learning', 'Locally Competitive Algorithm', 'Sparse coding', 'TCGA', 'Transfer learning', 'Unsupervised learning']	['NOTNLM']	NLM	489	['2018/12/23 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/02/02 06:00 [medline]']	England	PMC6302377		30577746	epublish	['Journal Article']			IM		BMC Bioinformatics. 2018 Dec 21;19(Suppl 18):489. doi: 10.1186/s12859-018-2504-8.	MEDLINE	BMC Bioinformatics	Sparse coding of pathology slides compared to transfer learning with deep neural networks.		19	Sparse coding of pathology slides compared to transfer learning with deep neural networks.
BACKGROUND: Deep Learning (DL) has advanced the state-of-the-art capabilities in bioinformatics applications which has resulted in trends of increasingly sophisticated and computationally demanding models trained by larger and larger data sets. This vastly increased computational demand challenges the feasibility of conducting cutting-edge research. One solution is to distribute the vast computational workload across multiple computing cluster nodes with data parallelism algorithms. In this study, we used a High-Performance Computing environment and implemented the Downpour Stochastic Gradient Descent algorithm for data parallelism to train a Convolutional Neural Network (CNN) for the natural language processing task of information extraction from a massive dataset of cancer pathology reports. We evaluated the scalability improvements using data parallelism training and the Titan supercomputer at Oak Ridge Leadership Computing Facility. To evaluate scalability, we used different numbers of worker nodes and performed a set of experiments comparing the effects of different training batch sizes and optimizer functions. RESULTS: We found that Adadelta would consistently converge at a lower validation loss, though requiring over twice as many training epochs as the fastest converging optimizer, RMSProp. The Adam optimizer consistently achieved a close 2nd place minimum validation loss significantly faster; using a batch size of 16 and 32 allowed the network to converge in only 4.5 training epochs. CONCLUSIONS: We demonstrated that the networked training process is scalable across multiple compute nodes communicating with message passing interface while achieving higher classification accuracy compared to a traditional machine learning algorithm.	['Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA.', 'Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA. yoonh@ornl.gov.', 'Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA.', 'Herff College of Engineering, University of Memphis, Memphis, TN, USA.', 'Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA.', 'Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA.', 'Louisiana Tumor Registry, Louisiana State University Health Sciences Center, New Orleans, LA, USA.', 'Surveillance Research Program, National Cancer Institute, Bethesda, MD, USA.', 'Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA.']	['10.1186/s12859-018-2511-9 [doi]', '10.1186/s12859-018-2511-9 [pii]']	['Qiu JX', 'Yoon HJ', 'Srivastava K', 'Watson TP', 'Blair Christian J', 'Ramanathan A', 'Wu XC', 'Fearn PA', 'Tourassi GD']							['2018/12/23 06:00']	20190201	20181221	2018 Dec 21	2018/12/24 06:00		['Qiu, John X', 'Yoon, Hong-Jun', 'Srivastava, Kshitij', 'Watson, Thomas P', 'Blair Christian, J', 'Ramanathan, Arvind', 'Wu, Xiao C', 'Fearn, Paul A', 'Tourassi, Georgia D']			Suppl 18		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2511-9 [doi]	20190201	['Comprehension', '*Computing Methodologies', 'Deep Learning/*trends', 'Humans', 'Neoplasms/*diagnosis/pathology', 'Neural Networks (Computer)']	2019/02/02 06:00				NLM	488	['2018/12/23 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/02/02 06:00 [medline]']	England	PMC6302459		30577743	epublish	['Journal Article']			IM		BMC Bioinformatics. 2018 Dec 21;19(Suppl 18):488. doi: 10.1186/s12859-018-2511-9.	MEDLINE	BMC Bioinformatics	Scalable deep text comprehension for Cancer surveillance on high-performance computing.		19	Scalable deep text comprehension for Cancer surveillance on high-performance computing.
Biomedical researchers regularly discover new interactions between chemical compounds/drugs and genes/proteins, and report them in research literature. Having knowledge about these interactions is crucially important in many research areas such as precision medicine and drug discovery. The BioCreative VI Task 5 (CHEMPROT) challenge promotes the development and evaluation of computer systems that can automatically recognize and extract statements of such interactions from biomedical literature. We participated in this challenge with a Support Vector Machine (SVM) system and a deep learning-based system (ST-ANN), and achieved an F-score of 60.99 for the task. After the shared task, we have significantly improved the performance of the ST-ANN system. Additionally, we have developed a new deep learning-based system (I-ANN) that considerably outperforms the ST-ANN system. Both ST-ANN and I-ANN systems are centered around training an ensemble of artificial neural networks and utilizing different bidirectional Long Short-Term Memory (LSTM) chains for representing the shortest dependency path and/or the full sentence. By combining the predictions of the SVM and the I-ANN systems, we achieved an F-score of 63.10 for the task, improving our previous F-score by 2.11 percentage points. Our systems are fully open-source and publicly available. We highlight that the systems we present in this study are not applicable only to the BioCreative VI Task 5, but can be effortlessly re-trained to extract any types of relations of interest, with no modifications of the source code required, if a manually annotated corpus is provided as training data in a specific file format.	['TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland.', 'University of Turku Graduate School, Turku, Finland.', 'TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland.', 'Turku Centre for Computer Science, Turku, Finland.', 'TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland.', 'Turku Centre for Computer Science, Turku, Finland.', 'TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland.']	['5255148 [pii]', '10.1093/database/bay120 [doi]']	['Mehryary F', 'Bjorne J', 'Salakoski T', 'Ginter F']							['2018/12/22 06:00']	20190528	20180101	2018 Jan 1	2018/12/24 06:00		['Mehryary, Farrokh', 'Bjorne, Jari', 'Salakoski, Tapio', 'Ginter, Filip']					1758-0463 (Electronic) 1758-0463 (Linking)	101517697	Database : the journal of biological databases and curation	['eng']	10.1093/database/bay120 [doi]	20190528	['Data Mining', 'Databases, Chemical', 'Databases, Protein', 'Deep Learning', 'Drug Discovery/*methods', '*Neural Networks (Computer)', '*Pharmaceutical Preparations/chemistry/metabolism', 'Protein Binding', '*Proteins/chemistry/metabolism', '*Support Vector Machine']	2019/05/29 06:00				NLM		['2018/02/26 00:00 [received]', '2018/10/07 00:00 [accepted]', '2018/12/22 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/05/29 06:00 [medline]']	England	PMC6310522		30576487	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Pharmaceutical Preparations)', '0 (Proteins)']	IM		Database (Oxford). 2018 Jan 1;2018. pii: 5255148. doi: 10.1093/database/bay120.	MEDLINE	Database (Oxford)	Potent pairing: ensemble of long short-term memory networks and support vector machine for chemical-protein relation extraction.		2018	Potent pairing: ensemble of long short-term memory networks and support vector machine for chemical-protein relation extraction.
This article aims to model the thermal behaviour of a wall using deep learning techniques. The Fourier theoretical model which is traditionally used to model such enclosures is not capable of considering several factors that affect a prediction that is often incorrect. These results motivate us to try to obtain a better thermal model of the enclosure. For this reason, a connexionist model is provided capable of modelling the behaviour of the enclosure from actual observed temperature data. For the training of this model, several measurements have been obtained over the course of more than one year in a specific enclosure, distributing the readings among the different layers of it. In this work, the predictions of both the theoretical model and the connexionist model have been tested, contrasting them with the measurements obtained previously. It has been observed that the connexionist model substantially improves the theoretical predictions of the Fourier method, thus allowing better approximations to be made regarding the real energy consumption of the building and, in general, the prediction of the energy behaviour of the enclosure.	['Department of Computer Science and Artificial Intelligence, University of Alicante, San Vicente del Raspeig, Alicante, Spain.', 'Department of Architectural Constructions. University of Alicante, San Vicente del Raspeig, Alicante, Spain.', 'Department of Architectural Constructions. University of Alicante, San Vicente del Raspeig, Alicante, Spain.', 'Department of Computer Science and Artificial Intelligence, University of Alicante, San Vicente del Raspeig, Alicante, Spain.']	['10.1371/journal.pone.0207616 [doi]', 'PONE-D-18-11538 [pii]']	['Aznar F', 'Echarri V', 'Rizo C', 'Rizo R']	['ORCID: 0000-0003-4521-956X', 'ORCID: 0000-0001-7250-2067']				['The authors have declared that no competing interests exist.']		['2018/12/22 06:00']	20190429	20181221	2018	2018/12/24 06:00		['Aznar, Fidel', 'Echarri, Victor', 'Rizo, Carlos', 'Rizo, Ramon']			12		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0207616 [doi]	20190429	['Construction Materials', '*Deep Learning', '*Models, Theoretical', '*Temperature']	2019/04/30 06:00				NLM	e0207616	['2018/04/17 00:00 [received]', '2018/11/02 00:00 [accepted]', '2018/12/22 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/04/30 06:00 [medline]']	United States	PMC6303092		30576329	epublish	['Journal Article']			IM		PLoS One. 2018 Dec 21;13(12):e0207616. doi: 10.1371/journal.pone.0207616. eCollection 2018.	MEDLINE	PLoS One	Modelling the thermal behaviour of a building facade using deep learning.		13	Modelling the thermal behaviour of a building facade using deep learning.
We present DeepNovo-DIA, a de novo peptide-sequencing method for data-independent acquisition (DIA) mass spectrometry data. We use neural networks to capture precursor and fragment ions across m/z, retention-time, and intensity dimensions. They are then further integrated with peptide sequence patterns to address the problem of highly multiplexed spectra. DIA coupled with de novo sequencing allowed us to identify novel peptides in human antibodies and antigens.	['David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada.', 'Department of Statistics and Actuarial Science, University of Waterloo, Waterloo, ON, Canada.', 'Bioinformatics Solutions Inc., Waterloo, ON, Canada.', 'Bioinformatics Solutions Inc., Waterloo, ON, Canada.', 'Department of Electrical & Computer Engineering, University of Waterloo, Waterloo, ON, Canada.', 'State Key Laboratory of Pathogen and Biosecurity, Beijing Institute of Microbiology and Epidemiology, Beijing, China.', 'Bioinformatics Solutions Inc., Waterloo, ON, Canada.', 'Department of Statistics and Actuarial Science, University of Waterloo, Waterloo, ON, Canada.', 'David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada. mli@uwaterloo.ca.']	['10.1038/s41592-018-0260-3 [doi]', '10.1038/s41592-018-0260-3 [pii]']	['Tran NH', 'Qiao R', 'Xin L', 'Chen X', 'Liu C', 'Zhang X', 'Shan B', 'Ghodsi A', 'Li M']	['ORCID: http://orcid.org/0000-0001-5186-8852', 'ORCID: http://orcid.org/0000-0002-2157-2775']						['2018/12/22 06:00']	20190624	20181220	2019 Jan	2018/12/24 06:00		['Tran, Ngoc Hieu', 'Qiao, Rui', 'Xin, Lei', 'Chen, Xin', 'Liu, Chuyi', 'Zhang, Xianglilan', 'Shan, Baozhen', 'Ghodsi, Ali', 'Li, Ming']			1		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/s41592-018-0260-3 [doi]	20191204	['Databases, Protein', '*Deep Learning', 'Humans', 'Mass Spectrometry/*methods', 'Peptides/*chemistry']	2019/06/25 06:00				NLM	63-66	['2018/05/15 00:00 [received]', '2018/11/09 00:00 [accepted]', '2018/12/22 06:00 [entrez]', '2018/12/24 06:00 [pubmed]', '2019/06/25 06:00 [medline]']	United States			30573815	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Peptides)']	IM		Nat Methods. 2019 Jan;16(1):63-66. doi: 10.1038/s41592-018-0260-3. Epub 2018 Dec 20.	MEDLINE	Nat Methods	Deep learning enables de novo peptide sequencing from data-independent-acquisition mass spectrometry.		16	Deep learning enables de novo peptide sequencing from data-independent-acquisition mass spectrometry.
Rice is a staple food in Asia and it contributes significantly to the Gross Domestic Product (GDP) of Malaysia and other developing countries. Brown Planthopper (BPH) causes high levels of economic loss in Malaysia. Identification of BPH presence and monitoring of its abundance has been conducted manually by experts and is time-consuming, fatiguing and tedious. Automated detection of BPH has been proposed by many studies to overcome human fallibility. However, all studies regarding automated recognition of BPH are investigated based on intact specimen although most of the specimens are imperfect, with missing parts have distorted shapes. The automated recognition of an imperfect insect image is more difficult than recognition of the intact specimen. This study proposes an automated, deep-learning-based detection pipeline, PENYEK, to identify BPH pest in images taken from a readily available sticky pad, constructed by clipping plastic sheets onto steel plates and spraying with glue. This study explores the effectiveness of a convolutional neural network (CNN) architecture, VGG16, in classifying insects as BPH or benign based on grayscale images constructed from Euclidean Distance Maps (EDM). The pipeline identified imperfect images of BPH with an accuracy of 95% using deep-learning's hyperparameters: softmax, a mini-batch of 30 and an initial learning rate of 0.0001.	['Faculty of Computer Science & Information Technology, UPM, Serdang, Malaysia.', 'Institute of BioScience, UPM, Serdang, Malaysia.', 'Faculty of Agriculture, UPM, Serdang, Malaysia.', 'Faculty of Agriculture, UPM, Serdang, Malaysia.']	['10.1371/journal.pone.0208501 [doi]', 'PONE-D-18-15391 [pii]']	['Nazri A', 'Mazlan N', 'Muharam F']	['ORCID: 0000-0001-6362-5006']				['The authors have declared that no competing interests exist.']		['2018/12/21 06:00']	20190530	20181220	2018	2018/12/21 06:00		['Nazri, Azree', 'Mazlan, Norida', 'Muharam, Farrah']			12		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0208501 [doi]	20190530	['Agriculture/methods', 'Algorithms', 'Animals', '*Deep Learning', '*Electronic Data Processing/instrumentation/methods', '*Environmental Monitoring/instrumentation/methods', 'Humans', 'Insect Control/instrumentation/methods', '*Insecta', 'Malaysia', '*Neural Networks (Computer)', 'Oryza/parasitology', '*Pattern Recognition, Automated/methods', 'Software']	2019/05/31 06:00				NLM	e0208501	['2018/06/11 00:00 [received]', '2018/11/18 00:00 [accepted]', '2018/12/21 06:00 [entrez]', '2018/12/21 06:00 [pubmed]', '2019/05/31 06:00 [medline]']	United States	PMC6301652		30571683	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Dec 20;13(12):e0208501. doi: 10.1371/journal.pone.0208501. eCollection 2018.	MEDLINE	PLoS One	PENYEK: Automated brown planthopper detection from imperfect sticky pad images using deep convolutional neural network.		13	PENYEK: Automated brown planthopper detection from imperfect sticky pad images using deep convolutional neural network.
Information on changes in a drug's effect when taken in combination with a second drug, known as drug-drug interaction (DDI), is relevant in the pharmaceutical industry. DDIs can delay, decrease, or enhance absorption of either drug and thus decrease or increase their action or cause adverse effects. Information Extraction (IE) can be of great benefit in allowing identification and extraction of relevant information on DDIs. We here propose an approach for the extraction of DDI from text using neural word embedding to train a machine learning system. Results show that our system is competitive against other systems for the task of extracting DDIs, and that significant improvements can be achieved by learning from word features and using a deep-learning approach. Our study demonstrates that machine learning techniques such as neural networks and deep learning methods can efficiently aid in IE from text. Our proposed approach is well suited to play a significant role in future research.	['1 Department of Computer Science and Information Engineering, National Taiwan Normal University, No 88, Tingzhou Road, Sec. 4, Taipei 116, Taiwan R.O.C.', '1 Department of Computer Science and Information Engineering, National Taiwan Normal University, No 88, Tingzhou Road, Sec. 4, Taipei 116, Taiwan R.O.C.']	['10.1142/S0219720018400279 [doi]']	['Hou WJ', 'Ceesay B']							['2018/12/21 06:00']	20190920	20181030	2018 Dec	2018/12/21 06:00		['Hou, Wen Juan', 'Ceesay, Bamfa']			6		1757-6334 (Electronic) 0219-7200 (Linking)	101187344	Journal of bioinformatics and computational biology	['eng']	10.1142/S0219720018400279 [doi]	20190920	['Algorithms', 'Computational Biology/*methods', 'Data Mining/methods', 'Databases, Pharmaceutical', 'Deep Learning', 'Drug Interactions/*physiology', 'Humans', 'Machine Learning', 'Neural Networks (Computer)']	2019/09/21 06:00		['*Drug-drug interaction', '*data abstraction', '*long short term memory (LSTM)', '*neural networks', '*word embedding']	['NOTNLM']	NLM	1840027	['2018/12/21 06:00 [pubmed]', '2019/09/21 06:00 [medline]', '2018/12/21 06:00 [entrez]']	Singapore			30567477	ppublish	['Journal Article']			IM		J Bioinform Comput Biol. 2018 Dec;16(6):1840027. doi: 10.1142/S0219720018400279. Epub 2018 Oct 30.	MEDLINE	J Bioinform Comput Biol	Extraction of drug-drug interaction using neural embedding.		16	Extraction of drug-drug interaction using neural embedding.
We present deep-learning-enabled super-resolution across different fluorescence microscopy modalities. This data-driven approach does not require numerical modeling of the imaging process or the estimation of a point-spread-function, and is based on training a generative adversarial network (GAN) to transform diffraction-limited input images into super-resolved ones. Using this framework, we improve the resolution of wide-field images acquired with low-numerical-aperture objectives, matching the resolution that is acquired using high-numerical-aperture objectives. We also demonstrate cross-modality super-resolution, transforming confocal microscopy images to match the resolution acquired with a stimulated emission depletion (STED) microscope. We further demonstrate that total internal reflection fluorescence (TIRF) microscopy images of subcellular structures within cells and tissues can be transformed to match the results obtained with a TIRF-based structured illumination microscope. The deep network rapidly outputs these super-resolved images, without any iterations or parameter search, and could serve to democratize super-resolution imaging.	['Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA.', 'Bioengineering Department, University of California, Los Angeles, CA, USA.', 'California NanoSystems Institute, University of California, Los Angeles, CA, USA.', 'Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA.', 'Bioengineering Department, University of California, Los Angeles, CA, USA.', 'California NanoSystems Institute, University of California, Los Angeles, CA, USA.', 'Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA.', 'Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA.', 'Computer Science Department, University of California, Los Angeles, CA, USA.', 'Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA.', 'California NanoSystems Institute, University of California, Los Angeles, CA, USA.', 'Department of Chemistry and Biochemistry, University of California, Los Angeles, CA, USA.', 'Department of Physics, Ohio State University, Columbus, OH, USA.', 'Biophysics Graduate Program, Ohio State University, Columbus, OH, USA.', 'Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA. ozcan@ucla.edu.', 'Bioengineering Department, University of California, Los Angeles, CA, USA. ozcan@ucla.edu.', 'California NanoSystems Institute, University of California, Los Angeles, CA, USA. ozcan@ucla.edu.', 'Department of Surgery, David Geffen School of Medicine, University of California, Los Angeles, CA, USA. ozcan@ucla.edu.']	['10.1038/s41592-018-0239-0 [doi]', '10.1038/s41592-018-0239-0 [pii]']	['Wang H', 'Rivenson Y', 'Jin Y', 'Wei Z', 'Gao R', 'Gunaydin H', 'Bentolila LA', 'Kural C', 'Ozcan A']	['ORCID: http://orcid.org/0000-0003-0110-5624', 'ORCID: http://orcid.org/0000-0002-0880-6514', 'ORCID: http://orcid.org/0000-0002-0717-683X']						['2018/12/19 06:00']	20190624	20181217	2019 Jan	2018/12/19 06:00		['Wang, Hongda', 'Rivenson, Yair', 'Jin, Yiyin', 'Wei, Zhensong', 'Gao, Ronald', 'Gunaydin, Harun', 'Bentolila, Laurent A', 'Kural, Comert', 'Ozcan, Aydogan']		['R01 GM127526/GM/NIGMS NIH HHS/United States']	1		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/s41592-018-0239-0 [doi]	20191204	['Animals', 'Cattle', '*Deep Learning', 'Endothelial Cells/cytology', 'HeLa Cells', 'Humans', 'Microscopy, Confocal/*methods', 'Microscopy, Fluorescence/*methods', 'Pulmonary Artery/cytology', 'Subcellular Fractions/ultrastructure']	2019/06/25 06:00				NLM	103-110	['2018/04/23 00:00 [received]', '2018/11/05 00:00 [accepted]', '2018/12/19 06:00 [pubmed]', '2019/06/25 06:00 [medline]', '2018/12/19 06:00 [entrez]']	United States			30559434	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Nat Methods. 2019 Jan;16(1):103-110. doi: 10.1038/s41592-018-0239-0. Epub 2018 Dec 17.	MEDLINE	Nat Methods	Deep learning enables cross-modality super-resolution in fluorescence microscopy.		16	Deep learning enables cross-modality super-resolution in fluorescence microscopy.
U-Net is a generic deep-learning solution for frequently occurring quantification tasks such as cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service. The plugin comes with pretrained models for single-cell segmentation and allows for U-Net to be adapted to new tasks on the basis of a few annotated samples.	['Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'CIBSS Centre for Integrative Biological Signalling Studies, Albert-Ludwigs-University, Freiburg, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'Life Imaging Center, Center for Biological Systems Analysis, Albert-Ludwigs-University, Freiburg, Germany.', 'SICK AG, Waldkirch, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'ANavS GmbH, Munchen, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'University Hospital of Old Age Psychiatry and Psychotherapy, University of Bern, Bern, Switzerland.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'CIBSS Centre for Integrative Biological Signalling Studies, Albert-Ludwigs-University, Freiburg, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'Optophysiology Lab, Institute of Biology III, Albert-Ludwigs-University, Freiburg, Germany.', 'BrainLinks-BrainTools, Albert-Ludwigs-University, Freiburg, Germany.', 'Optophysiology Lab, Institute of Biology III, Albert-Ludwigs-University, Freiburg, Germany.', 'BrainLinks-BrainTools, Albert-Ludwigs-University, Freiburg, Germany.', 'Optophysiology Lab, Institute of Biology III, Albert-Ludwigs-University, Freiburg, Germany.', 'Institute of Biology II, Albert-Ludwigs-University, Freiburg, Germany.', 'ScreenSYS GmbH, Freiburg, Germany.', 'Institute of Biology II, Albert-Ludwigs-University, Freiburg, Germany.', 'ScreenSYS GmbH, Freiburg, Germany.', 'Institute of Biology II, Albert-Ludwigs-University, Freiburg, Germany.', 'Institute of Biology II, Albert-Ludwigs-University, Freiburg, Germany.', 'ScreenSYS GmbH, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'Center for Biological Systems Analysis (ZBSA), Albert-Ludwigs-University, Freiburg, Germany.', 'Renal Division, University Medical Centre, Freiburg, Germany.', 'Spemann Graduate School of Biology and Medicine (SGBM), Albert-Ludwigs-University, Freiburg, Germany.', 'BrainLinks-BrainTools, Albert-Ludwigs-University, Freiburg, Germany.', 'Institute of Neuropathology, University Medical Centre, Freiburg, Germany.', 'Institute of Biology I, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'CIBSS Centre for Integrative Biological Signalling Studies, Albert-Ludwigs-University, Freiburg, Germany.', 'Institute of Neuropathology, University Medical Centre, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'Institute of Biology II, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'Center for Biological Systems Analysis (ZBSA), Albert-Ludwigs-University, Freiburg, Germany.', 'Renal Division, University Medical Centre, Freiburg, Germany.', 'Paris Descartes University-Sorbonne Paris Cite, Imagine Institute, Paris, France.', 'Optophysiology Lab, Institute of Biology III, Albert-Ludwigs-University, Freiburg, Germany.', 'BrainLinks-BrainTools, Albert-Ludwigs-University, Freiburg, Germany.', 'Bernstein Center Freiburg, Albert-Ludwigs-University, Freiburg, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany.', 'CIBSS Centre for Integrative Biological Signalling Studies, Albert-Ludwigs-University, Freiburg, Germany.', 'BrainLinks-BrainTools, Albert-Ludwigs-University, Freiburg, Germany.', 'Department of Computer Science, Albert-Ludwigs-University, Freiburg, Germany. ronneber@informatik.uni-freiburg.de.', 'BIOSS Centre for Biological Signalling Studies, Freiburg, Germany. ronneber@informatik.uni-freiburg.de.', 'DeepMind, London, UK. ronneber@informatik.uni-freiburg.de.']	['10.1038/s41592-018-0261-2 [doi]', '10.1038/s41592-018-0261-2 [pii]']	['Falk T', 'Mai D', 'Bensch R', 'Cicek O', 'Abdulkadir A', 'Marrakchi Y', 'Bohm A', 'Deubner J', 'Jackel Z', 'Seiwald K', 'Dovzhenko A', 'Tietz O', 'Dal Bosco C', 'Walsh S', 'Saltukoglu D', 'Tay TL', 'Prinz M', 'Palme K', 'Simons M', 'Diester I', 'Brox T', 'Ronneberger O']							['2018/12/19 06:00']	20190624	20181217	2019 Jan	2018/12/19 06:00	['Nat Methods. 2019 Apr;16(4):351. PMID: 30804552']	['Falk, Thorsten', 'Mai, Dominic', 'Bensch, Robert', 'Cicek, Ozgun', 'Abdulkadir, Ahmed', 'Marrakchi, Yassine', 'Bohm, Anton', 'Deubner, Jan', 'Jackel, Zoe', 'Seiwald, Katharina', 'Dovzhenko, Alexander', 'Tietz, Olaf', 'Dal Bosco, Cristina', 'Walsh, Sean', 'Saltukoglu, Deniz', 'Tay, Tuan Leng', 'Prinz, Marco', 'Palme, Klaus', 'Simons, Matias', 'Diester, Ilka', 'Brox, Thomas', 'Ronneberger, Olaf']			1		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/s41592-018-0261-2 [doi]	20190624	['*Cell Count', 'Cloud Computing', '*Deep Learning', 'Neural Networks (Computer)', 'Software Design']	2019/06/25 06:00				NLM	67-70	['2018/07/26 00:00 [received]', '2018/11/19 00:00 [accepted]', '2018/12/19 06:00 [pubmed]', '2019/06/25 06:00 [medline]', '2018/12/19 06:00 [entrez]']	United States			30559429	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Methods. 2019 Jan;16(1):67-70. doi: 10.1038/s41592-018-0261-2. Epub 2018 Dec 17.	MEDLINE	Nat Methods	U-Net: deep learning for cell counting, detection, and morphometry.		16	U-Net: deep learning for cell counting, detection, and morphometry.
The identification of patients with aggressive cancer who require immediate therapy is a health challenge in low-income and middle-income countries. Limited pathology resources, high healthcare costs and large-case loads call for the development of advanced standalone diagnostics. Here, we report and validate an automated, low-cost point-of-care device for the molecular diagnosis of aggressive lymphomas. The device uses contrast-enhanced microholography and a deep-learning algorithm to directly analyse percutaneously obtained fine-needle aspirates. We show the feasibility and high accuracy of the device in cells, as well as the prospective validation of the results in 40 patients clinically referred for image-guided aspiration of nodal mass lesions suspicious for lymphoma. Automated analysis of human samples with the portable device should allow for the accurate classification of patients with benign and malignant adenopathy.	"['Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Pathology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Engineering and Management, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Health Sciences, Northeastern University, Boston, MA, USA.', 'Massachusetts General Hospital Cancer Center, Boston, MA, USA.', 'Botswana Harvard AIDS Institute, Gaborone, Botswana.', ""Division of Infectious Diseases, Brigham and Women's Hospital, Boston, MA, USA."", 'Harvard T.H. Chan School of Public Health, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, MA, USA.', 'Massachusetts General Hospital Cancer Center, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, MA, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA. Castro.Cesar@mgh.harvard.edu.', 'Massachusetts General Hospital Cancer Center, Boston, MA, USA. Castro.Cesar@mgh.harvard.edu.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, MA, USA. rweissleder@mgh.harvard.edu.', 'Department of Radiology, Massachusetts General Hospital, Boston, MA, USA. rweissleder@mgh.harvard.edu.', 'Department of Systems Biology, Harvard Medical School, Boston, MA, USA. rweissleder@mgh.harvard.edu.']"	['10.1038/s41551-018-0265-3 [doi]', '10.1038/s41551-018-0265-3 [pii]']	['Im H', 'Pathania D', 'McFarland PJ', 'Sohani AR', 'Degani I', 'Allen M', 'Coble B', 'Kilcoyne A', 'Hong S', 'Rohrer L', 'Abramson JS', 'Dryden-Peterson S', 'Fexon L', 'Pivovarov M', 'Chabner B', 'Lee H', 'Castro CM', 'Weissleder R']	['ORCID: http://orcid.org/0000-0002-0626-1346', 'ORCID: http://orcid.org/0000-0001-6454-0768', 'ORCID: http://orcid.org/0000-0001-6210-1200', 'ORCID: http://orcid.org/0000-0003-1440-5167', 'ORCID: http://orcid.org/0000-0002-0087-0909', 'ORCID: http://orcid.org/0000-0002-1159-5658']				['Competing interests The authors declare that they have no competing interests.']		['2018/12/18 06:00']		20180723	2018 Sep	2018/12/18 06:00		['Im, Hyungsoon', 'Pathania, Divya', 'McFarland, Philip J', 'Sohani, Aliyah R', 'Degani, Ismail', 'Allen, Matthew', 'Coble, Benjamin', 'Kilcoyne, Aoife', 'Hong, Seonki', 'Rohrer, Lucas', 'Abramson, Jeremy S', 'Dryden-Peterson, Scott', 'Fexon, Lioubov', 'Pivovarov, Misha', 'Chabner, Bruce', 'Lee, Hakho', 'Castro, Cesar M', 'Weissleder, Ralph']		['UH2 CA202637/CA/NCI NIH HHS/United States', 'R21 CA205322/CA/NCI NIH HHS/United States', 'R00 CA201248/CA/NCI NIH HHS/United States', 'UH3 CA202637/CA/NCI NIH HHS/United States', 'R01 HL113156/HL/NHLBI NIH HHS/United States']	9		2157-846X (Print) 2157-846X (Linking)	101696896	Nature biomedical engineering	['eng']	10.1038/s41551-018-0265-3 [doi]	20191120		2018/12/18 06:01	['NIHMS975832']	['adenopathy', 'artificial intelligence', 'cancer', 'deep learning', 'diagnostics', 'holography', 'low-middle income countries', 'lymphoma']	['NOTNLM']	NLM	666-674	['2018/12/18 06:00 [entrez]', '2018/12/18 06:00 [pubmed]', '2018/12/18 06:01 [medline]']	England	PMC6291220		30555750	ppublish	['Journal Article']				['figshare/10.6084/m9.figshare.6356867']	Nat Biomed Eng. 2018 Sep;2(9):666-674. doi: 10.1038/s41551-018-0265-3. Epub 2018 Jul 23.	PubMed-not-MEDLINE	Nat Biomed Eng	Design and clinical validation of a point-of-care device for the diagnosis of lymphoma via contrast-enhanced microholography and machine learning.		2	Design and clinical validation of a point-of-care device for the diagnosis of lymphoma via contrast-enhanced microholography and machine learning.
According to NHTSA, more than 3477 people (including 551 non-occupants) were killed and 391,000 were injured due to distraction-related crashes in 2015. The distracted driving epidemic has long been under research to identify its impact on driving behavior. There have been a few attempts to detect drivers' engagement in secondary tasks from observed driving behavior. Yet, to the authors' knowledge, not much effort has been directed to identify the types of secondary tasks from driving behavior parameters. This study proposes a bi-level hierarchical classification methodology using machine learning to identify the different types of secondary tasks drivers are engaged in using their driving behavior parameters. At the first level, drivers' engagement in secondary tasks is detected, while at the second level, the distinct types of secondary tasks are identified. Comparative evaluation is performed between nine ensemble tree classification methods to identify three types of secondary tasks (hand-held cellphone calling, cellphone texting, and interaction with an adjacent passenger). The inputs to the models are five driving behavior parameters (speed, longitudinal acceleration, lateral acceleration, pedal position, and yaw rate) along with their standard deviations. The results showed that the overall secondary task detection accuracy ranged from 66% to 96%, except for the Decision Tree that was able to detect engagement in secondary tasks with a high accuracy of 99.8%. For the identification of secondary tasks types, the overall accuracy ranged from 55% to 79%, with the highest accuracy of 82.2% achieved by the Random Forest method. The findings of the paper show the proposed methodology promising to (1) characterize drivers' engagement in unlawful secondary tasks (such as texting) as a counter measure to prevent crashes, and (2) alert drivers to pay attention back to the main driving task when risky changes to their driving behavior take place.	['Department of Civil and Environmental Engineering, Louisiana State University, Baton Rouge, LA 70803, United States. Electronic address: oosman@vtti.vt.edu.', 'Department of Computer Science and Engineering, University of South Florida, Tampa, FL 33620, United States. Electronic address: hajij.1@osu.edu.', 'Department of Civil and Environmental Engineering, Louisiana State University, Baton Rouge, LA 70803, United States. Electronic address: skarba1@lsu.edu.', 'Department of Civil and Environmental Engineering, University of Alabama, Huntsville, AL 35899, United States. Electronic address: sishak@odu.edu.']	['S0001-4575(18)31114-X [pii]', '10.1016/j.aap.2018.12.005 [doi]']	['Osman OA', 'Hajij M', 'Karbalaieali S', 'Ishak S']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/12/17 06:00']	20190227	20181213	2019 Feb	2018/12/17 06:00		['Osman, Osama A', 'Hajij, Mustafa', 'Karbalaieali, Sogand', 'Ishak, Sherif']					1879-2057 (Electronic) 0001-4575 (Linking)	1254476	Accident; analysis and prevention	['eng']	S0001-4575(18)31114-X [pii] 10.1016/j.aap.2018.12.005 [doi]	20190227	['Accidents, Traffic/prevention & control', 'Adult', 'Behavior Observation Techniques/*methods', 'Cell Phone/statistics & numerical data', '*Deep Learning', 'Distracted Driving/*psychology', 'Female', 'Humans', 'Male', 'Text Messaging/statistics & numerical data']	2019/02/28 06:00		['Accident investigations', 'Detection', 'Distracted driving', 'Driving behavior', 'Ensemble tree', 'Identification', 'In-vehicle systems', 'Machine learning', 'Secondary tasks']	['NOTNLM']	NLM	274-281	['2018/05/02 00:00 [received]', '2018/11/09 00:00 [revised]', '2018/12/06 00:00 [accepted]', '2018/12/17 06:00 [pubmed]', '2019/02/28 06:00 [medline]', '2018/12/17 06:00 [entrez]']	England			30554059	ppublish	['Journal Article']			IM		Accid Anal Prev. 2019 Feb;123:274-281. doi: 10.1016/j.aap.2018.12.005. Epub 2018 Dec 13.	MEDLINE	Accid Anal Prev	A hierarchical machine learning classification approach for secondary task identification from observed driving behavior data.		123	A hierarchical machine learning classification approach for secondary task identification from observed driving behavior data.
The fields of radiotherapy and clinical oncology have been rapidly changed by the advances of technology. Improvement in computer processing power and imaging quality heralded precision radiotherapy allowing radiotherapy to be delivered efficiently, safely and effectively for patient benefit. Artificial intelligence (AI) is an emerging field of computer science which uses computer models and algorithms to replicate human-like intelligence and perform specific tasks which offers a huge potential to healthcare. We reviewed and presented the history, evolution and advancement in the fields of radiotherapy, clinical oncology and machine learning. Radiotherapy target delineation is a complex task of outlining tumour and organ at risks volumes to allow accurate delivery of radiotherapy. We discussed the radiotherapy planning, treatment delivery and reviewed how technology can help with this challenging process. We explored the evidence and clinical application of machine learning to radiotherapy. We concluded on the challenges, possible future directions and potential collaborations to achieve better outcome for cancer patients.	"[""Department of Clinical Oncology, Leeds Cancer Centre, St James's Institute of Oncology, Leeds Teaching Hospitals NHS Trust, Leeds LS9 7TF, UK. ian.boon@nhs.net."", 'Department of Radiology, Worcestershire Acute Hospitals NHS Trust, Worcester WR5 1DD, UK. tracy.ay@gmail.com.', 'Worcestershire Oncology Centre, Worcestershire Acute Hospitals NHS Trust, Worcester WR5 1DD, UK. cheng.boon@nhs.net.']"	['medicines5040131 [pii]', '10.3390/medicines5040131 [doi]']	['Boon IS', 'Au Yong TPT', 'Boon CS']							['2018/12/15 06:00']		20181211	2018 Dec 11	2018/12/14 06:00		['Boon, Ian S', 'Au Yong, Tracy P T', 'Boon, Cheng S']			4		2305-6320 (Print) 2305-6320 (Linking)	101671069	Medicines (Basel, Switzerland)	['eng']	E131 [pii] 10.3390/medicines5040131 [doi]	20191120		2018/12/14 06:01		['artificial intelligence (AI)', 'clinical oncology', 'deep learning', 'image guided radiotherapy (IGRT)', 'intensity modulated radiotherapy (IMRT)', 'machine learning', 'radiotherapy', 'stereotactic ablative radiotherapy (SABR)', 'target volume delineation', 'volumetric modulated arc therapy (VMAT)']	['NOTNLM']	NLM		['2018/11/30 00:00 [received]', '2018/12/04 00:00 [revised]', '2018/12/07 00:00 [accepted]', '2018/12/15 06:00 [entrez]', '2018/12/14 06:00 [pubmed]', '2018/12/14 06:01 [medline]']	Switzerland	PMC6313566		30544901	epublish	['Journal Article', 'Review']					Medicines (Basel). 2018 Dec 11;5(4). pii: medicines5040131. doi: 10.3390/medicines5040131.	PubMed-not-MEDLINE	Medicines (Basel)	Assessing the Role of Artificial Intelligence (AI) in Clinical Oncology: Utility of Machine Learning in Radiotherapy Target Volume Delineation.		5	Assessing the Role of Artificial Intelligence (AI) in Clinical Oncology: Utility of Machine Learning in Radiotherapy Target Volume Delineation.
Automatic tumor segmentation from medical images is an important step for computer-aided cancer diagnosis and treatment. Recently, deep learning has been successfully applied to this task, leading to state-of-the-art performance. However, most of existing deep learning segmentation methods only work for a single imaging modality. PET/CT scanner is nowadays widely used in the clinic, and is able to provide both metabolic information and anatomical information through integrating PET and CT into the same utility. In this study, we proposed a novel multi-modality segmentation method based on a 3D fully convolutional neural network (FCN), which is capable of taking account of both PET and CT information simultaneously for tumor segmentation. The network started with a multi-task training module, in which two parallel sub-segmentation architectures constructed using deep convolutional neural networks (CNNs) were designed to automatically extract feature maps from PET and CT respectively. A feature fusion module was subsequently designed based on cascaded convolutional blocks, which re-extracted features from PET/CT feature maps using a weighted cross entropy minimization strategy. The tumor mask was obtained as the output at the end of the network using a softmax function. The effectiveness of the proposed method was validated on a clinic PET/CT dataset of 84 patients with lung cancer. The results demonstrated that the proposed network was effective, fast and robust and achieved significantly performance gain over CNN-based methods and traditional methods using PET or CT only, two V-net based co-segmentation methods, two variational co-segmentation methods based on fuzzy set theory and a deep learning co-segmentation method using W-net.	"[""Key Laboratory of Image Processing and Intelligent Control of Ministry of Education of China, School of Automation, Huazhong University of Science and Technology, Wuhan 430074, People's Republic of China.""]"	['10.1088/1361-6560/aaf44b [doi]']	['Zhao X', 'Li L', 'Lu W', 'Tan S']							['2018/12/08 06:00']	20190920	20181221	2018 Dec 21	2018/12/14 06:00		['Zhao, Xiangming', 'Li, Laquan', 'Lu, Wei', 'Tan, Shan']		['R01 CA172638/CA/NCI NIH HHS/United States', 'P30 CA008748/CA/NCI NIH HHS/United States']	1		1361-6560 (Electronic) 0031-9155 (Linking)	0401220	Physics in medicine and biology	['eng']	10.1088/1361-6560/aaf44b [doi]	20190920	['*Deep Learning', 'Humans', 'Neoplasms/*diagnostic imaging', 'Positron Emission Tomography Computed Tomography/*methods/standards']	2019/09/21 06:00				NLM	015011	['2018/12/14 06:00 [pubmed]', '2019/09/21 06:00 [medline]', '2018/12/08 06:00 [entrez]']	England			30523964	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Phys Med Biol. 2018 Dec 21;64(1):015011. doi: 10.1088/1361-6560/aaf44b.	MEDLINE	Phys Med Biol	Tumor co-segmentation in PET/CT using multi-modality fully convolutional neural network.		64	Tumor co-segmentation in PET/CT using multi-modality fully convolutional neural network.
OBJECTIVES: We sought to investigate the diagnostic performance of coronary CT angiography (cCTA)-derived plaque markers combined with deep machine learning-based fractional flow reserve (CT-FFR) to identify lesion-specific ischemia using invasive FFR as the reference standard. METHODS: Eighty-four patients (61 +/- 10 years, 65% male) who had undergone cCTA followed by invasive FFR were included in this single-center retrospective, IRB-approved, HIPAA-compliant study. Various plaque markers were derived from cCTA using a semi-automatic software prototype and deep machine learning-based CT-FFR. The discriminatory value of plaque markers and CT-FFR to identify lesion-specific ischemia on a per-vessel basis was evaluated using invasive FFR as the reference standard. RESULTS: One hundred three lesion-containing vessels were investigated. 32/103 lesions were hemodynamically significant by invasive FFR. In a multivariate analysis (adjusted for Framingham risk score), the following markers showed predictive value for lesion-specific ischemia (odds ratio [OR]): lesion length (OR 1.15, p = 0.037), non-calcified plaque volume (OR 1.02, p = 0.007), napkin-ring sign (OR 5.97, p = 0.014), and CT-FFR (OR 0.81, p < 0.0001). A receiver operating characteristics analysis showed the benefit of identifying plaque markers over cCTA stenosis grading alone, with AUCs increasing from 0.61 with >/= 50% stenosis to 0.83 with addition of plaque markers to detect lesion-specific ischemia. Further incremental benefit was realized with the addition of CT-FFR (AUC 0.93). CONCLUSION: Coronary CTA-derived plaque markers portend predictive value to identify lesion-specific ischemia when compared to cCTA stenosis grading alone. The addition of CT-FFR to plaque markers shows incremental discriminatory power. KEY POINTS: * Coronary CT angiography (cCTA)-derived quantitative plaque markers of atherosclerosis portend high discriminatory power to identify lesion-specific ischemia. * Coronary CT angiography-derived fractional flow reserve (CT-FFR) shows superior diagnostic performance over cCTA alone in detecting lesion-specific ischemia. * A combination of plaque markers with CT-FFR provides incremental discriminatory value for detecting flow-limiting stenosis.	"['Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Institute of Clinical Radiology and Nuclear Medicine, University Medical Center Mannheim, Medical Faculty Mannheim-Heidelberg University, Mannheim, Germany.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA. schoepf@musc.edu.', 'Division of Cardiology, Department of Medicine, Medical University of South Carolina, Charleston, SC, USA. schoepf@musc.edu.', 'Heart & Vascular Center, Ashley River Tower, Medical University of South Carolina, 25 Courtenay Drive, Charleston, SC, 29425-2260, USA. schoepf@musc.edu.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Center for Medical Imaging North East Netherlands, University Medical Center Groningen, University of Groningen, Groningen, The Netherlands.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Diagnostic and Interventional Radiology, University Hospital Frankfurt, Frankfurt, Germany.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Radiological Sciences, Oncology and Pathology, University of Rome ""Sapienza"", Rome, Italy.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiology, Department of Medicine, Medical University of South Carolina, Charleston, SC, USA.', 'Institute of Clinical Radiology and Nuclear Medicine, University Medical Center Mannheim, Medical Faculty Mannheim-Heidelberg University, Mannheim, Germany.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Division of Cardiovascular Imaging, Department of Radiology and Radiological Science, Medical University of South Carolina, Charleston, SC, USA.', 'Department of Cardiology and Intensive Care Medicine, Heart Center Munich-Bogenhausen, Munich, Germany.']"	['10.1007/s00330-018-5834-z [doi]', '10.1007/s00330-018-5834-z [pii]']	['von Knebel Doeberitz PL', 'De Cecco CN', 'Schoepf UJ', 'Duguay TM', 'Albrecht MH', 'van Assen M', 'Bauer MJ', 'Savage RH', 'Pannell JT', 'De Santis D', 'Johnson AA', 'Varga-Szemes A', 'Bayer RR', 'Schonberg SO', 'Nance JW', 'Tesche C']	['ORCID: http://orcid.org/0000-0002-6164-5641']						['2018/12/08 06:00']	20190605	20181206	2019 May	2018/12/14 06:00		['von Knebel Doeberitz, Philipp L', 'De Cecco, Carlo N', 'Schoepf, U Joseph', 'Duguay, Taylor M', 'Albrecht, Moritz H', 'van Assen, Marly', 'Bauer, Maximilian J', 'Savage, Rock H', 'Pannell, J Trent', 'De Santis, Domenico', 'Johnson, Addison A', 'Varga-Szemes, Akos', 'Bayer, Richard R', 'Schonberg, Stefan O', 'Nance, John W', 'Tesche, Christian']			5		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-018-5834-z [doi]	20190605	['Computed Tomography Angiography/*methods', 'Coronary Angiography/*methods', 'Coronary Stenosis/*diagnosis/etiology/physiopathology', 'Diagnosis, Computer-Assisted/*methods', 'Female', 'Fractional Flow Reserve, Myocardial/*physiology', 'Humans', '*Machine Learning', 'Male', 'Middle Aged', 'Plaque, Atherosclerotic/complications/*diagnosis/physiopathology', 'ROC Curve', 'Retrospective Studies']	2019/06/06 06:00		['Angiography', 'Coronary artery disease', 'Spiral computed tomography']	['NOTNLM']	NLM	2378-2387	['2018/08/09 00:00 [received]', '2018/10/12 00:00 [accepted]', '2018/09/29 00:00 [revised]', '2018/12/14 06:00 [pubmed]', '2019/06/06 06:00 [medline]', '2018/12/08 06:00 [entrez]']	Germany			30523456	ppublish	['Journal Article']			IM		Eur Radiol. 2019 May;29(5):2378-2387. doi: 10.1007/s00330-018-5834-z. Epub 2018 Dec 6.	MEDLINE	Eur Radiol	Coronary CT angiography-derived plaque quantification with artificial intelligence CT fractional flow reserve for the identification of lesion-specific ischemia.		29	Coronary CT angiography-derived plaque quantification with artificial intelligence CT fractional flow reserve for the identification of lesion-specific ischemia.
BACKGROUND: Access to palliative care is a key quality metric which most healthcare organizations strive to improve. The primary challenges to increasing palliative care access are a combination of physicians over-estimating patient prognoses, and a shortage of palliative staff in general. This, in combination with treatment inertia can result in a mismatch between patient wishes, and their actual care towards the end of life. METHODS: In this work, we address this problem, with Institutional Review Board approval, using machine learning and Electronic Health Record (EHR) data of patients. We train a Deep Neural Network model on the EHR data of patients from previous years, to predict mortality of patients within the next 3-12 month period. This prediction is used as a proxy decision for identifying patients who could benefit from palliative care. RESULTS: The EHR data of all admitted patients are evaluated every night by this algorithm, and the palliative care team is automatically notified of the list of patients with a positive prediction. In addition, we present a novel technique for decision interpretation, using which we provide explanations for the model's predictions. CONCLUSION: The automatic screening and notification saves the palliative care team the burden of time consuming chart reviews of all patients, and allows them to take a proactive approach in reaching out to such patients rather then relying on referrals from the treating physicians.	['Department of Computer Science, Stanford University, Stanford, CA, USA. avati@cs.stanford.edu.', 'Center for Biomedical Informatics Research, Stanford University, Stanford, CA, USA.', 'Department of Medicine, Stanford University School of Medicine, Stanford, CA, USA.', 'Center for Biomedical Informatics Research, Stanford University, Stanford, CA, USA.', 'Department of Computer Science, Stanford University, Stanford, CA, USA.', 'Center for Biomedical Informatics Research, Stanford University, Stanford, CA, USA.']	['10.1186/s12911-018-0677-8 [doi]', '10.1186/s12911-018-0677-8 [pii]']	['Avati A', 'Jung K', 'Harman S', 'Downing L', 'Ng A', 'Shah NH']							['2018/12/13 06:00']	20190624	20181212	2018 Dec 12	2018/12/13 06:00		['Avati, Anand', 'Jung, Kenneth', 'Harman, Stephanie', 'Downing, Lance', 'Ng, Andrew', 'Shah, Nigam H']		['UL1 TR001085/TR/NCATS NIH HHS/United States']	Suppl 4		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-018-0677-8 [doi]	20190624	['*Clinical Decision-Making', '*Deep Learning', 'Electronic Health Records', 'Humans', '*Palliative Care', '*Patient Selection', 'Prognosis']	2019/06/25 06:00		['*Deep learning', '*Electronic health records', '*Interpretation', '*Palliative care']	['NOTNLM']	NLM	122	['2018/12/13 06:00 [entrez]', '2018/12/13 06:00 [pubmed]', '2019/06/25 06:00 [medline]']	England	PMC6290509		30537977	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		BMC Med Inform Decis Mak. 2018 Dec 12;18(Suppl 4):122. doi: 10.1186/s12911-018-0677-8.	MEDLINE	BMC Med Inform Decis Mak	Improving palliative care with deep learning.		18	Improving palliative care with deep learning.
BACKGROUND: Accurate predictive modeling in clinical research enables effective early intervention that patients are most likely to benefit from. However, due to the complex biological nature of disease progression, capturing the highly non-linear information from low-level input features is quite challenging. This requires predictive models with high-capacity. In practice, clinical datasets are often of limited size, bringing danger of overfitting for high-capacity models. To address these two challenges, we propose a deep multi-task neural network for predictive modeling. METHODS: The proposed network leverages clinical measures as auxiliary targets that are related to the primary target. The predictions for the primary and auxiliary targets are made simultaneously by the neural network. Network structure is specifically designed to capture the clinical relevance by learning a shared feature representation between the primary and auxiliary targets. We apply the proposed model in a hypertension dataset and a breast cancer dataset, where the primary tasks are to predict the left ventricular mass indexed to body surface area and the time of recurrence of breast cancer. Moreover, we analyze the weights of the proposed neural network to rank input features for model interpretability. RESULTS: The experimental results indicate that the proposed model outperforms other different models, achieving the best predictive accuracy (mean squared error 199.76 for hypertension data, 860.62 for Wisconsin prognostic breast cancer data) with the ability to rank features according to their contributions to the targets. The ranking is supported by previous related research. CONCLUSION: We propose a novel effective method for clinical predictive modeling by combing the deep neural network and multi-task learning. By leveraging auxiliary measures clinically related to the primary target, our method improves the predictive accuracy. Based on featue ranking, our model is interpreted and shows consistency with previous studies on cardiovascular diseases and cancers.	['Department of Computer Science, Wayne State University, Detroit, MI, USA.', 'Department of Computer Science, Wayne State University, Detroit, MI, USA. dzhu@wayne.edu.', 'Department of Emergency Medicine, Wayne State University, Detroit, MI, USA.', 'Integrative Biosciences Center, Wayne State University, Detroit, MI, USA.']	['10.1186/s12911-018-0676-9 [doi]', '10.1186/s12911-018-0676-9 [pii]']	['Li X', 'Zhu D', 'Levy P']							['2018/12/13 06:00']	20190624	20181212	2018 Dec 12	2018/12/13 06:00		['Li, Xiangrui', 'Zhu, Dongxiao', 'Levy, Phillip']		['R01 MD005849/MD/NIMHD NIH HHS/United States']	Suppl 4		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-018-0676-9 [doi]	20190624	['Breast Neoplasms/*complications/diagnosis', 'Humans', 'Hypertension/*complications/diagnosis', '*Machine Learning', '*Neural Networks (Computer)', 'Predictive Value of Tests', 'Prognosis', 'Risk Assessment']	2019/06/25 06:00		['*Auxiliary task', '*Deep neural network', '*Multi-task learning', '*Predictive modeling']	['NOTNLM']	NLM	126	['2018/12/13 06:00 [entrez]', '2018/12/13 06:00 [pubmed]', '2019/06/25 06:00 [medline]']	England	PMC6290511		30537954	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		BMC Med Inform Decis Mak. 2018 Dec 12;18(Suppl 4):126. doi: 10.1186/s12911-018-0676-9.	MEDLINE	BMC Med Inform Decis Mak	Leveraging auxiliary measures: a deep multi-task neural network for predictive modeling in clinical research.		18	Leveraging auxiliary measures: a deep multi-task neural network for predictive modeling in clinical research.
Computer-aided diagnosis offers a promising solution to reduce variation in colonoscopy performance. Pooled miss rates for polyps are as high as 22%, and associated interval colorectal cancers after colonoscopy are of concern. Optical biopsy, whereby in-vivo classification of polyps based on enhanced imaging replaces histopathology, has not been incorporated into routine practice because it is limited by interobserver variability and generally only meets accepted standards in expert settings. Real-time decision-support software has been developed to detect and characterise polyps, and also to offer feedback on the technical quality of inspection. Some of the current algorithms, particularly with recent advances in artificial intelligence techniques, match human expert performance for optical biopsy. In this Review, we summarise the evidence for clinical applications of computer-aided diagnosis and artificial intelligence in colonoscopy.	['Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, UK; Gastrointestinal Services, University College London Hospital, London, UK. Electronic address: o.ahmad@ucl.ac.uk.', 'Division of Surgery & Interventional Science, University College London, London, UK.', 'Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, UK.', 'Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, UK.', 'Gastrointestinal Services, University College London Hospital, London, UK.', 'Gastrointestinal Services, University College London Hospital, London, UK.', 'Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, UK.', 'Division of Surgery & Interventional Science, University College London, London, UK; Gastrointestinal Services, University College London Hospital, London, UK.', 'Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, UK; Division of Surgery & Interventional Science, University College London, London, UK; Gastrointestinal Services, University College London Hospital, London, UK.']	['S2468-1253(18)30282-6 [pii]', '10.1016/S2468-1253(18)30282-6 [doi]']	['Ahmad OF', 'Soares AS', 'Mazomenos E', 'Brandao P', 'Vega R', 'Seward E', 'Stoyanov D', 'Chand M', 'Lovat LB']		['Copyright (c) 2019 Elsevier Ltd. All rights reserved.']					['2018/12/12 06:00']	20190429	20181206	2019 Jan	2018/12/12 06:00		['Ahmad, Omer F', 'Soares, Antonio S', 'Mazomenos, Evangelos', 'Brandao, Patrick', 'Vega, Roser', 'Seward, Edward', 'Stoyanov, Danail', 'Chand, Manish', 'Lovat, Laurence B']			1		2468-1253 (Electronic)	101690683	The lancet. Gastroenterology & hepatology	['eng']	S2468-1253(18)30282-6 [pii] 10.1016/S2468-1253(18)30282-6 [doi]	20190429	['Algorithms', 'Colonoscopy/*methods/standards', 'Colorectal Neoplasms/*diagnosis/pathology', 'Decision Support Techniques', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods/standards', 'Humans', 'Intestinal Polyps/*diagnosis/pathology', 'Quality Control', 'Software', 'Spectrometry, Fluorescence']	2019/04/30 06:00				NLM	71-80	['2018/06/29 00:00 [received]', '2018/08/10 00:00 [revised]', '2018/08/20 00:00 [accepted]', '2018/12/12 06:00 [entrez]', '2018/12/12 06:00 [pubmed]', '2019/04/30 06:00 [medline]']	Netherlands			30527583	ppublish	['Journal Article', 'Review']			IM		Lancet Gastroenterol Hepatol. 2019 Jan;4(1):71-80. doi: 10.1016/S2468-1253(18)30282-6. Epub 2018 Dec 6.	MEDLINE	Lancet Gastroenterol Hepatol	Artificial intelligence and computer-aided diagnosis in colonoscopy: current evidence and future directions.		4	Artificial intelligence and computer-aided diagnosis in colonoscopy: current evidence and future directions.
	['Graduate Institute of Biomedical Informatics, College of Medicine Science and Technology, Taipei Medical University, Taipei, Taiwan; International Center for Health Information Technology (ICHIT), Taipei Medical University, Taipei, Taiwan.', 'Graduate Institute of Biomedical Informatics, College of Medicine Science and Technology, Taipei Medical University, Taipei, Taiwan; International Center for Health Information Technology (ICHIT), Taipei Medical University, Taipei, Taiwan.', 'Graduate Institute of Biomedical Informatics, College of Medicine Science and Technology, Taipei Medical University, Taipei, Taiwan; International Center for Health Information Technology (ICHIT), Taipei Medical University, Taipei, Taiwan; Chair, Dept. of Dermatology, Wan Fang Hospital, Taipei, Taiwan. Electronic address: jack@tmu.edu.tw.']	['S0169-2607(18)31709-7 [pii]', '10.1016/j.cmpb.2018.11.007 [doi]']	['Yang HC', 'Poly TN', 'Jack Li YC']							['2018/12/12 06:00']	20190514		2019 Jan	2018/12/12 06:00		['Yang, Hsuan-Chia', 'Poly, Tahmina Nasrin', 'Jack Li, Yu-Chuan']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)31709-7 [pii] 10.1016/j.cmpb.2018.11.007 [doi]	20190514	['Algorithms', 'Computer Simulation', '*Computer Systems', '*Deep Learning', 'Genome-Wide Association Study', 'Humans', 'Leukocytes', 'Medical Informatics/*methods', 'Models, Statistical', 'Neural Networks (Computer)', 'Patient Care', 'Programming Languages', 'Proportional Hazards Models', 'Reproducibility of Results', 'Software', 'Treatment Outcome']	2019/05/15 06:00				NLM	A1-A2	['2018/04/21 00:00 [received]', '2018/09/04 00:00 [revised]', '2018/10/01 00:00 [accepted]', '2018/12/12 06:00 [entrez]', '2018/12/12 06:00 [pubmed]', '2019/05/15 06:00 [medline]']	Ireland			30527131	ppublish	['Editorial']			IM		Comput Methods Programs Biomed. 2019 Jan;168:A1-A2. doi: 10.1016/j.cmpb.2018.11.007.	MEDLINE	Comput Methods Programs Biomed	Deep into Patient care: An automated deep learning approach for reshaping patient care in clinical setting.		168	Deep into Patient care: An automated deep learning approach for reshaping patient care in clinical setting.
BACKGROUND: Automated seizure detection from clinical EEG data can reduce the diagnosis time and facilitate targeting treatment for epileptic patients. However, current detection approaches mainly rely on limited features manually designed by domain experts, which are inflexible for the detection of a variety of patterns in a large amount of patients' EEG data. Moreover, conventional machine learning algorithms for seizure detection cannot accommodate multi-channel Electroencephalogram (EEG) data effectively, which contains both temporal and spatial information. Recently, deep learning technology has been widely applied to perform image processing tasks, which could learns useful features from data and process multi-channel data automatically. To provide an effective system for automatic seizure detection, we proposed a new three-dimensional (3D) convolutional neural network (CNN) structure, whose inputs are multi-channel EEG signals. METHODS: EEG data of 13 patients were collected from one center hospital, which has already been inspected by experts. To represent EEG data in CNN, firstly time series of each channel of EEG data was converted into the two-dimensional image. Then all channel images were combined into 3D images according to the mutual correlation intensity between different electrodes. Finally, a CNN was constructed using 3D kernels to predict different stages of EEG data, including inter-ictal, pre-ictal, and ictal stages. The system performance was evaluated and compared with the traditional feature-based classifier and the two-dimensional (2D) deep learning method. RESULTS: It demonstrated that multi-channel EEG data could provide more information for increasing the specificity and sensitivity in cpmparison result between the single and multi-channel. And the 3D CNN based on multi-channel outperformed the 2D CNN and traditional signal processing methods with an accuracy of more than 90%, an sensitivity of 88.90% and an specificity of 93.78%. CONCLUSIONS: This is the first effort to apply 3D CNN in detecting seizures from EEG. It provides a new way of learning patterns simultaneously from multi-channel EEG signals, and demonstrates that deep neural networks in combination with 3D kernels can establish an effective system for seizure detection.	['Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, 510080, Guangdong Province, China.', 'Software Engineering, School of Computer and Data Science, Sun Yat-sen University, Guangzhou, 510006, Guangdong Province, China.', 'Department of Neurology, The First Affiliated Hospital, Sun Yat-sen University, Guangzhou, 510080, Guangdong Province, China.', 'Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, 510080, Guangdong Province, China.', 'Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, 510080, Guangdong Province, China. zhouyi@mail.sysu.edu.cn.']	['10.1186/s12911-018-0693-8 [doi]', '10.1186/s12911-018-0693-8 [pii]']	['Wei X', 'Zhou L', 'Chen Z', 'Zhang L', 'Zhou Y']							['2018/12/12 06:00']	20190627	20181207	2018 Dec 7	2018/12/12 06:00		['Wei, Xiaoyan', 'Zhou, Lin', 'Chen, Ziyi', 'Zhang, Liangjun', 'Zhou, Yi']			Suppl 5		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-018-0693-8 [doi]	20190627	['Electroencephalography/*methods', 'Epilepsy/*diagnosis', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', 'Seizures/*diagnosis', '*Signal Processing, Computer-Assisted']	2019/06/30 06:00		['*Convolutional neural network', '*Epilepsy', '*Multi-channel', '*Seizure detection', '*Three-dimensional']	['NOTNLM']	NLM	111	['2018/12/12 06:00 [entrez]', '2018/12/12 06:00 [pubmed]', '2019/06/30 06:00 [medline]']	England	PMC6284363		30526571	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Inform Decis Mak. 2018 Dec 7;18(Suppl 5):111. doi: 10.1186/s12911-018-0693-8.	MEDLINE	BMC Med Inform Decis Mak	Automatic seizure detection using three-dimensional CNN based on multi-channel EEG.		18	Automatic seizure detection using three-dimensional CNN based on multi-channel EEG.
Inferring potential adverse drug reactions is an important and challenging task for the drug discovery and healthcare industry. Many previous studies in computational pharmacology have proposed utilizing multi-source drug information to predict drug side effects have and achieved initial success. However, most of the prediction methods mainly rely on direct similarities inferred from drug information and cannot fully utilize the drug information about the impact of protein(-)protein interactions (PPI) on potential drug targets. Moreover, most of the methods are designed for specific tasks. In this work, we propose a novel heterogeneous network embedding approach for learning drug representations called SDHINE, which integrates PPI information into drug embeddings and is generic for different adverse drug reaction (ADR) prediction tasks. To integrate heterogeneous drug information and learn drug representations, we first design different meta-path-based proximities to calculate drug similarities, especially target propagation meta-path-based proximity based on PPI network, and then construct a semi-supervised stacking deep neural network model that is jointly optimized by the defined meta-path proximities. Extensive experiments with three state-of-the-art network embedding methods on three ADR prediction tasks demonstrate the effectiveness of the SDHINE model. Furthermore, we compare the drug representations in terms of drug differentiation by mapping the representations into 2D space; the results show that the performance of our approach is superior to that of the comparison methods.	"['School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China. hubaofang@sdwu.edu.cn.', ""School of Data and Computer Science, Shandong Women's University, Jinan 250014, China. hubaofang@sdwu.edu.cn."", 'Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan 250014, China. hubaofang@sdwu.edu.cn.', 'School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China. wanghong106@163.com.', 'Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan 250014, China. wanghong106@163.com.', 'School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China. wanglutong1002@163.com.', 'Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan 250014, China. wanglutong1002@163.com.', 'School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China. weihuayuan_qingdao@126.com.', 'Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan 250014, China. weihuayuan_qingdao@126.com.']"	['molecules23123193 [pii]', '10.3390/molecules23123193 [doi]']	['Hu B', 'Wang H', 'Wang L', 'Yuan W']	['ORCID: 0000-0002-7585-2246', 'ORCID: 0000-0003-1480-2920']						['2018/12/07 06:00']	20190826	20181204	2018 Dec 4	2018/12/07 06:00		['Hu, Baofang', 'Wang, Hong', 'Wang, Lutong', 'Yuan, Weihua']		['61672329/National Natural Science Foundation of China', 'J18KA370/Project of Shandong ProvinceHigher Educational Science and Technology', 'Program']	12		1420-3049 (Electronic) 1420-3049 (Linking)	100964009	Molecules (Basel, Switzerland)	['eng']	E3193 [pii] 10.3390/molecules23123193 [doi]	20190826	['Algorithms', 'Drug Discovery', '*Drug-Related Side Effects and Adverse Reactions', 'Machine Learning', '*Neural Networks (Computer)']	2019/08/27 06:00		['adverse drug reaction prediction', 'heterogeneous information network embedding', 'meta-path-based proximity', 'stacking denoising auto-encoder']	['NOTNLM']	NLM		['2018/11/05 00:00 [received]', '2018/11/30 00:00 [revised]', '2018/11/30 00:00 [accepted]', '2018/12/07 06:00 [entrez]', '2018/12/07 06:00 [pubmed]', '2019/08/27 06:00 [medline]']	Switzerland	PMC6320974		30518099	epublish	['Journal Article']					Molecules. 2018 Dec 4;23(12). pii: molecules23123193. doi: 10.3390/molecules23123193.	MEDLINE	Molecules	Adverse Drug Reaction Predictions Using Stacking Deep Heterogeneous Information Network Embedding Approach.		23	Adverse Drug Reaction Predictions Using Stacking Deep Heterogeneous Information Network Embedding Approach.
"Many vision science studies employ machine learning, especially the version called ""deep learning."" Neuroscientists use machine learning to decode neural responses. Perception scientists try to understand how living organisms recognize objects. To them, deep neural networks offer benchmark accuracies for recognition of learned stimuli. Originally machine learning was inspired by the brain. Today, machine learning is used as a statistical tool to decode brain activity. Tomorrow, deep neural networks might become our best model of brain function. This brief overview of the use of machine learning in biological vision touches on its strengths, weaknesses, milestones, controversies, and current directions. Here, we hope to help vision scientists assess what role machine learning should play in their research."	['Center for Neural Science, New York University, New York, NY, USA.', 'Department of Psychology and Center for Neural Science, New York University, New York, NY, USA.']	['2717771 [pii]', '10.1167/18.13.2 [doi]']	['Majaj NJ', 'Pelli DG']							['2018/12/04 06:00']	20190412		2018 Dec 3	2018/12/07 06:00		['Majaj, Najib J', 'Pelli, Denis G']		['R01 EY027964/EY/NEI NIH HHS/United States']	13		1534-7362 (Electronic) 1534-7362 (Linking)	101147197	Journal of vision	['eng']	10.1167/18.13.2 [doi]	20190412	['Algorithms', 'Brain', '*Deep Learning', 'Humans', '*Neural Networks (Computer)', 'Vision, Ocular/*physiology']	2019/04/13 06:00				NLM	2	['2018/12/04 06:00 [entrez]', '2018/12/07 06:00 [pubmed]', '2019/04/13 06:00 [medline]']	United States	PMC6279369		30508427	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		J Vis. 2018 Dec 3;18(13):2. doi: 10.1167/18.13.2.	MEDLINE	J Vis	Deep learning-Using machine learning to study biological vision.		18	Deep learning-Using machine learning to study biological vision.
PURPOSE: Benefiting from multi-energy x-ray imaging technology, material decomposition facilitates the characterization of different materials in x-ray imaging. However, the performance of material decomposition is limited by the accuracy of the decomposition model. Due to the presence of nonideal effects in x-ray imaging systems, it is difficult to explicitly build the imaging system models for material decomposition. As an alternative, this paper explores the feasibility of using machine learning approaches for material decomposition tasks. METHODS: In this work, we propose a learning-based pipeline to perform material decomposition. In this pipeline, the step of feature extraction is implemented to integrate more informative features, such as neighboring information, to facilitate material decomposition tasks, and the step of hold-out validation with continuous interleaved sampling is employed to perform model evaluation and selection. We demonstrate the material decomposition capability of our proposed pipeline with promising machine learning algorithms in both simulation and experimentation, the algorithms of which are artificial neural network (ANN), Random Tree, REPTree and Random Forest. The performance was quantitatively evaluated using a simulated XCAT phantom and an anthropomorphic torso phantom. In order to evaluate the proposed method, two measurement-based material decomposition methods were used as the reference methods for comparison studies. In addition, deep learning-based solutions were also investigated to complete this work as a comprehensive comparison of machine learning solution for material decomposition. RESULTS: In both the simulation study and the experimental study, the introduced machine learning algorithms are able to train models for the material decomposition tasks. With the application of neighboring information, the performance of each machine learning algorithm is strongly improved. Compared to the state-of-the-art method, the performance of ANN in the simulation study is an improvement of over 24% in the noiseless scenarios and over 169% in the noisy scenario, while the performance of the Random Forest is an improvement of over 40% and 165%, respectively. Similarly, the performance of ANN in the experimental study is an improvement of over 42% in the denoised scenario and over 45% in the original scenario, while the performance of Random Forest is an improvement by over 33% and 40%, respectively. CONCLUSIONS: The proposed pipeline is able to build generic material decomposition models for different scenarios, and it was validated by quantitative evaluation in both simulation and experimentation. Compared to the reference methods, appropriate features and machine learning algorithms can significantly improve material decomposition performance. The results indicate that it is feasible and promising to perform material decomposition using machine learning methods, and our study will facilitate future efforts toward clinical applications.	['Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany.', 'Advanced Therapies, Siemens Healthineers, 91301, Forchheim, Germany.', 'Advanced Therapies, Siemens Healthineers, 91301, Forchheim, Germany.', 'Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, 200240, Shanghai, P.R. China.', 'Radiological Sciences Lab, Stanford University, 94305, CA, USA.', 'Division of Mechanical and Biomedical Engineering, Ewha Womans University, 03760, Seoul, Korea.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany.', 'Department of Biomedical Engineering, Peking University, 100871, Beijing, China.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany.', 'Advanced Therapies, Siemens Healthineers, 91301, Forchheim, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany.']	['10.1002/mp.13317 [doi]']	['Lu Y', 'Kowarschik M', 'Huang X', 'Xia Y', 'Choi JH', 'Chen S', 'Hu S', 'Ren Q', 'Fahrig R', 'Hornegger J', 'Maier A']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/12/04 06:00']	20190227	20181224	2019 Feb	2018/12/07 06:00		['Lu, Yanye', 'Kowarschik, Markus', 'Huang, Xiaolin', 'Xia, Yan', 'Choi, Jang-Hwan', 'Chen, Shuqing', 'Hu, Shiyang', 'Ren, Qiushi', 'Fahrig, Rebecca', 'Hornegger, Joachim', 'Maier, Andreas']		['German Research Foundation', 'The German Academic Exchange Service', 'Siemens Healthineers Advanced Therapies', 'NVIDIA Corporation']	2		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13317 [doi]	20190227	['Image Processing, Computer-Assisted/*methods', '*Machine Learning', '*Tomography, X-Ray Computed']	2019/02/28 06:00		['deep learning', 'feature extraction', 'machine learning', 'material decomposition', 'model selection', 'multi-energy', 'spectral x-ray imaging']	['NOTNLM']	NLM	689-703	['2018/02/16 00:00 [received]', '2018/11/18 00:00 [revised]', '2018/11/22 00:00 [accepted]', '2018/12/07 06:00 [pubmed]', '2019/02/28 06:00 [medline]', '2018/12/04 06:00 [entrez]']	United States			30508253	ppublish	['Journal Article']			IM		Med Phys. 2019 Feb;46(2):689-703. doi: 10.1002/mp.13317. Epub 2018 Dec 24.	MEDLINE	Med Phys	A learning-based material decomposition pipeline for multi-energy x-ray imaging.		46	A learning-based material decomposition pipeline for multi-energy x-ray imaging.
BACKGROUND AND OBJECTIVE: Computer aided detection (CAD) offers an efficient way to assist doctors to interpret fundus images. In a CAD system, retinal vessel (RV) detection is a crucial step to identify the retinal disease regions. However, RV detection is still a challenging problem due to variations in morphology of the vessels on noisy and low contrast fundus images. METHODS: In this paper, we formulate the detection task as a classification problem and solve it using a multiple classifier framework based on deep convolutional neural networks. The multiple deep convolutional neural network (MDCNN) is constructed and trained on fundus images with limited image quantity. The MDCNN is trained using an incremental learning strategy to improve the networks' performance. The final classification results are obtained from the voting procedure on the results of MDCNN. RESULTS: The MDCNN achieves better performance and significantly outperforms the state-of-the-art for automatic retinal vessel segmentation on the DRIVE dataset with 95.97% and 96.13% accuracy and 0.9726 and 0.9737 AUC (area below the operator receiver character curve) score on training and testing sets, respectively. Another public dataset, STARE, is also used to evaluate the proposed network. The experimental results demonstrate that the proposed MDCNN network achieves 95.39% accuracy and 0.9539 AUC score in STARE dataset. We further compare our result with several state-of-the-art methods based on AUC values. The comparison is shown that our proposal yields the third best AUC value. CONCLUSIONS: Our method yields the better performance in the compared the state of the art methods. In addition, our proposal has no preprocessing stage, and the input color fundus images are fed into the CNN directly.	['Department of Computer Science, University of Illinois, Springfield, IL, USA. Electronic address: yguo56@uis.edu.', 'Department of Electrical-Electronics Engineering, Bitlis Eren University, Bitlis, Turkey.', 'Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey.']	['S0169-2607(18)30781-8 [pii]', '10.1016/j.cmpb.2018.10.021 [doi]']	['Guo Y', 'Budak U', 'Sengur A']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/12/04 06:00']	20190514	20181030	2018 Dec	2018/12/07 06:00		['Guo, Yanhui', 'Budak, Umit', 'Sengur, Abdulkadir']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30781-8 [pii] 10.1016/j.cmpb.2018.10.021 [doi]	20190514	['Algorithms', 'Computer Systems', 'Diagnosis, Computer-Assisted', 'Fundus Oculi', 'Humans', 'Machine Learning', 'Models, Statistical', '*Neural Networks (Computer)', 'Reproducibility of Results', 'Retinal Diseases/diagnostic imaging', 'Retinal Vessels/*diagnostic imaging', 'Sensitivity and Specificity']	2019/05/15 06:00		['Image segmentation', 'Multiple deep convolution neural network', 'Retinal vessels segmentation']	['NOTNLM']	NLM	43-48	['2018/05/23 00:00 [received]', '2018/10/12 00:00 [revised]', '2018/10/29 00:00 [accepted]', '2018/12/04 06:00 [entrez]', '2018/12/07 06:00 [pubmed]', '2019/05/15 06:00 [medline]']	Ireland			30501859	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Dec;167:43-48. doi: 10.1016/j.cmpb.2018.10.021. Epub 2018 Oct 30.	MEDLINE	Comput Methods Programs Biomed	A novel retinal vessel detection approach based on multiple deep convolution neural networks.		167	A novel retinal vessel detection approach based on multiple deep convolution neural networks.
Background: Atypical vascular pattern is one of the most important features by differentiating between benign and malignant pigmented skin lesions. Detection and analysis of vascular structures is a necessary initial step for skin mole assessment; it is a prerequisite step to provide an accurate outcome for the widely used 7-point checklist diagnostic algorithm. Methods: In this research we present a fully automated machine learning approach for segmenting vascular structures in dermoscopy colour images. The U-Net architecture is based on convolutional networks and designed for fast and precise segmentation of images. After preprocessing the images are randomly divided into 146516 patches of 64 x 64 pixels each. Results: On the independent validation dataset including 74 images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network, an average DSC of 0.84, sensitivity 0.85, and specificity 0.81 has been achieved. Conclusion: Vascular structures due to small size and similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use of advanced segmentation methods like deep learning, especially convolutional neural networks, has the potential to improve the accuracy of advanced local structure detection.	['Department of Automatic Control and Robotics, AGH University of Science and Technology, Cracow, Poland.']	['10.1155/2018/5049390 [doi]']	['Jaworek-Korjakowska J']	['ORCID: 0000-0003-0146-8652']						['2018/12/06 06:00']	20190319	20181101	2018	2018/12/06 06:00		['Jaworek-Korjakowska, Joanna']					2314-6141 (Electronic)	101600173	BioMed research international	['eng']	10.1155/2018/5049390 [doi]	20190319	['Blood Vessels/*diagnostic imaging/physiopathology', 'Deep Learning', 'Dermoscopy/methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Neoplasms/diagnosis/*diagnostic imaging/physiopathology', 'Nevus/diagnosis/*diagnostic imaging/physiopathology', 'Specimen Handling']	2019/03/20 06:00				NLM	5049390	['2018/07/02 00:00 [received]', '2018/10/03 00:00 [revised]', '2018/10/14 00:00 [accepted]', '2018/12/06 06:00 [entrez]', '2018/12/06 06:00 [pubmed]', '2019/03/20 06:00 [medline]']	United States	PMC6236870		30515404	epublish	['Journal Article']			IM		Biomed Res Int. 2018 Nov 1;2018:5049390. doi: 10.1155/2018/5049390. eCollection 2018.	MEDLINE	Biomed Res Int	A Deep Learning Approach to Vascular Structure Segmentation in Dermoscopy Colour Images.		2018	A Deep Learning Approach to Vascular Structure Segmentation in Dermoscopy Colour Images.
Conventional machine learning approaches for predicting material properties from elemental compositions have emphasized the importance of leveraging domain knowledge when designing model inputs. Here, we demonstrate that by using a deep learning approach, we can bypass such manual feature engineering requiring domain knowledge and achieve much better results, even with only a few thousand training samples. We present the design and implementation of a deep neural network model referred to as ElemNet; it automatically captures the physical and chemical interactions and similarities between different elements using artificial intelligence which allows it to predict the materials properties with better accuracy and speed. The speed and best-in-class accuracy of ElemNet enable us to perform a fast and robust screening for new material candidates in a huge combinatorial space; where we predict hundreds of thousands of chemical systems that could contain yet-undiscovered compounds.	['Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, USA.', 'Computation Institute, University of Chicago, Chicago, USA.', 'Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, USA.', 'Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, USA.', 'Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, USA.', 'Department of Materials Science and Engineering, Northwestern University, Evanston, USA.', 'Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, USA. ankitag@eecs.northwestern.edu.']	['10.1038/s41598-018-35934-y [doi]', '10.1038/s41598-018-35934-y [pii]']	['Jha D', 'Ward L', 'Paul A', 'Liao WK', 'Choudhary A', 'Wolverton C', 'Agrawal A']	['ORCID: http://orcid.org/0000-0002-1323-5939']						['2018/12/06 06:00']		20181204	2018 Dec 4	2018/12/06 06:00		['Jha, Dipendra', 'Ward, Logan', 'Paul, Arindam', 'Liao, Wei-Keng', 'Choudhary, Alok', 'Wolverton, Chris', 'Agrawal, Ankit']		['70NANB14H012/U.S. Department of Commerce (DOC)', '70NANB14H12/U.S. Department of Commerce (DOC)', '70NANB14H012/U.S. Department of Commerce (DOC)', '70NANB14H012/U.S. Department of Commerce (DOC)', '70NANB14H012/U.S. Department of Commerce (DOC)', '70NANB14H012/U.S. Department of Commerce (DOC)', '70NANB14H012/DOC | National Institute of Standards and Technology (NIST)', '70NANB14H012/DOC | National Institute of Standards and Technology (NIST)', '70NANB14H012/DOC | National Institute of Standards and Technology (NIST)', '70NANB14H012/DOC | National Institute of Standards and Technology (NIST)', '70NANB14H012/DOC | National Institute of Standards and Technology (NIST)']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-35934-y [doi]	20191120		2018/12/06 06:01				NLM	17593	['2018/08/01 00:00 [received]', '2018/11/06 00:00 [accepted]', '2018/12/06 06:00 [entrez]', '2018/12/06 06:00 [pubmed]', '2018/12/06 06:01 [medline]']	England	PMC6279928		30514926	epublish	['Journal Article']					Sci Rep. 2018 Dec 4;8(1):17593. doi: 10.1038/s41598-018-35934-y.	PubMed-not-MEDLINE	Sci Rep	ElemNet: Deep Learning the Chemistry of Materials From Only Elemental Composition.		8	ElemNet: Deep Learning the Chemistry of Materials From Only Elemental Composition.
BACKGROUND: Accurately detecting and examining lung nodules early is key in diagnosing lung cancers and thus one of the best ways to prevent lung cancer deaths. Radiologists spend countless hours detecting small spherical-shaped nodules in computed tomography (CT) images. In addition, even after detecting nodule candidates, a considerable amount of effort and time is required for them to determine whether they are real nodules. The aim of this paper is to introduce a high performance nodule classification method that uses three dimensional deep convolutional neural networks (DCNNs) and an ensemble method to distinguish nodules between non-nodules. METHODS: In this paper, we use a three dimensional deep convolutional neural network (3D DCNN) with shortcut connections and a 3D DCNN with dense connections for lung nodule classification. The shortcut connections and dense connections successfully alleviate the gradient vanishing problem by allowing the gradient to pass quickly and directly. Connections help deep structured networks to obtain general as well as distinctive features of lung nodules. Moreover, we increased the dimension of DCNNs from two to three to capture 3D features. Compared with shallow 3D CNNs used in previous studies, deep 3D CNNs more effectively capture the features of spherical-shaped nodules. In addition, we use an alternative ensemble method called the checkpoint ensemble method to boost performance. RESULTS: The performance of our nodule classification method is compared with that of the state-of-the-art methods which were used in the LUng Nodule Analysis 2016 Challenge. Our method achieves higher competition performance metric (CPM) scores than the state-of-the-art methods using deep learning. In the experimental setup ESB-ALL, the 3D DCNN with shortcut connections and the 3D DCNN with dense connections using the checkpoint ensemble method achieved the highest CPM score of 0.910. CONCLUSION: The result demonstrates that our method of using a 3D DCNN with shortcut connections, a 3D DCNN with dense connections, and the checkpoint ensemble method is effective for capturing 3D features of nodules and distinguishing nodules between non-nodules.	['Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea. kangj@korea.ac.kr.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, Republic of Korea. kangj@korea.ac.kr.']	['10.1186/s12880-018-0286-0 [doi]', '10.1186/s12880-018-0286-0 [pii]']	['Jung H', 'Kim B', 'Lee I', 'Lee J', 'Kang J']	['ORCID: 0000-0001-6798-9106']						['2018/12/05 06:00']	20190610	20181203	2018 Dec 3	2018/12/05 06:00		['Jung, Hwejin', 'Kim, Bumsoo', 'Lee, Inyeop', 'Lee, Junhyun', 'Kang, Jaewoo']			1		1471-2342 (Electronic) 1471-2342 (Linking)	100968553	BMC medical imaging	['eng']	10.1186/s12880-018-0286-0 [doi]	20190613	['Deep Learning', 'Humans', 'Imaging, Three-Dimensional', 'Lung Neoplasms/*diagnostic imaging', 'Radiographic Image Interpretation, Computer-Assisted', 'Solitary Pulmonary Nodule/*diagnostic imaging', 'Tomography, X-Ray Computed/*methods']	2019/06/14 06:00		['*Convolutional neural network', '*Deep learning', '*Ensemble', '*Lung cancer', '*Lung nodule']	['NOTNLM']	NLM	48	['2018/05/03 00:00 [received]', '2018/10/24 00:00 [accepted]', '2018/12/05 06:00 [entrez]', '2018/12/05 06:00 [pubmed]', '2019/06/14 06:00 [medline]']	England	PMC6276244		30509191	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Imaging. 2018 Dec 3;18(1):48. doi: 10.1186/s12880-018-0286-0.	MEDLINE	BMC Med Imaging	Classification of lung nodules in CT scans using three-dimensional deep convolutional neural networks with a checkpoint ensemble method.		18	Classification of lung nodules in CT scans using three-dimensional deep convolutional neural networks with a checkpoint ensemble method.
	['Department of Radiology, The Institute of Medical Science, The University of Tokyo, Tokyo, Japan.', 'Department of Radiology, Graduate School of Medicine, The University of Tokyo, Tokyo, Japan.']	['10.1371/journal.pmed.1002707 [doi]', 'PMEDICINE-D-18-03577 [pii]']	['Yasaka K', 'Abe O']	['ORCID: 0000-0002-0324-6562']				"[""I have read the journal's policy and the authors of this manuscript have the"", 'following competing interests: KY receives a research grant from Japan', 'Radiological Society. OA has no competing interest regarding this work.']"		['2018/12/01 06:00']	20190422	20181130	2018 Nov	2018/12/01 06:00		['Yasaka, Koichiro', 'Abe, Osamu']			11		1549-1676 (Electronic) 1549-1277 (Linking)	101231360	PLoS medicine	['eng']	10.1371/journal.pmed.1002707 [doi]	20190422	['*Deep Learning/trends', 'Diagnosis, Computer-Assisted/*methods/trends', 'Diffusion of Innovation', 'Humans', 'Predictive Value of Tests', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Radiology/*methods/trends', 'Reproducibility of Results']	2019/04/23 06:00				NLM	e1002707	['2018/12/01 06:00 [entrez]', '2018/12/01 06:00 [pubmed]', '2019/04/23 06:00 [medline]']	United States	PMC6267951		30500815	epublish	"['Introductory Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS Med. 2018 Nov 30;15(11):e1002707. doi: 10.1371/journal.pmed.1002707. eCollection 2018 Nov.	MEDLINE	PLoS Med	Deep learning and artificial intelligence in radiology: Current applications and future directions.		15	Deep learning and artificial intelligence in radiology: Current applications and future directions.
"Deep learning has been developed by computer scientists. Here, we discuss techniques for improving the image quality of diagnostic computed tomography and magnetic resonance imaging with the aid of deep learning. We categorize the techniques for improving the image quality as ""noise and artifact reduction"", ""super resolution"" and ""image acquisition and reconstruction"". For each category, we present and outline the features of some studies."	['Department of Diagnostic Radiology, Graduate School of Biomedical and Health Science, Hiroshima University, 1-2-3 Kasumi, Minami-ku, Hiroshima, 734-8551, Japan. higaki@hiroshima-u.ac.jp.', 'Department of Diagnostic Radiology, Graduate School of Biomedical and Health Science, Hiroshima University, 1-2-3 Kasumi, Minami-ku, Hiroshima, 734-8551, Japan.', 'Department of Diagnostic Radiology, Graduate School of Biomedical and Health Science, Hiroshima University, 1-2-3 Kasumi, Minami-ku, Hiroshima, 734-8551, Japan.', 'Department of Diagnostic Radiology, Graduate School of Medical Sciences, Kumamoto University, Kumamoto, 860-8556, Japan.', 'Department of Diagnostic Radiology, Graduate School of Biomedical and Health Science, Hiroshima University, 1-2-3 Kasumi, Minami-ku, Hiroshima, 734-8551, Japan.']	['10.1007/s11604-018-0796-2 [doi]', '10.1007/s11604-018-0796-2 [pii]']	['Higaki T', 'Nakamura Y', 'Tatsugami F', 'Nakaura T', 'Awai K']	['ORCID: http://orcid.org/0000-0003-0631-7271']						['2018/12/01 06:00']	20190311	20181129	2019 Jan	2018/12/01 06:00		['Higaki, Toru', 'Nakamura, Yuko', 'Tatsugami, Fuminari', 'Nakaura, Takeshi', 'Awai, Kazuo']			1		1867-108X (Electronic) 1867-1071 (Linking)	101490689	Japanese journal of radiology	['eng']	10.1007/s11604-018-0796-2 [doi]	20190311	['Algorithms', 'Artifacts', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/*methods', 'Tomography, X-Ray Computed/*methods']	2019/03/12 06:00		['Computed tomography', 'Deep learning', 'Image quality improvement', 'Magnetic resonance imaging']	['NOTNLM']	NLM	73-80	['2018/10/17 00:00 [received]', '2018/11/18 00:00 [accepted]', '2018/12/01 06:00 [pubmed]', '2019/03/12 06:00 [medline]', '2018/12/01 06:00 [entrez]']	Japan			30498876	ppublish	['Journal Article', 'Review']			IM		Jpn J Radiol. 2019 Jan;37(1):73-80. doi: 10.1007/s11604-018-0796-2. Epub 2018 Nov 29.	MEDLINE	Jpn J Radiol	Improvement of image quality at CT and MRI using deep learning.		37	Improvement of image quality at CT and MRI using deep learning.
Deep neural networks have shown superior performance in many regimes to remember familiar patterns with large amounts of data. However, the standard supervised deep learning paradigm is still limited when facing the need to learn new concepts efficiently from scarce data. In this paper, we present a memory-augmented neural network which is motivated by the process of human concept learning. The training procedure, imitating the concept formation course of human, learns how to distinguish samples from different classes and aggregate samples of the same kind. In order to better utilize the advantages originated from the human behavior, we propose a sequential process, during which the network should decide how to remember each sample at every step. In this sequential process, a stable and interactive memory serves as an important module. We validate our model in some typical one-shot learning tasks and also an exploratory outlier detection problem. In all the experiments, our model gets highly competitive to reach or outperform those strong baselines.	['Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China; Research Center for Brain-inspired Intelligence, CASIA, China; University of Chinese Academy of Sciences, China.', 'Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China; Research Center for Brain-inspired Intelligence, CASIA, China. Electronic address: jiaming.xu@ia.ac.cn.', 'Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China; Research Center for Brain-inspired Intelligence, CASIA, China; University of Chinese Academy of Sciences, China.', 'Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China; Research Center for Brain-inspired Intelligence, CASIA, China; University of Chinese Academy of Sciences, China; Center for Excellence in Brain Science and Intelligence Technology, CAS, China.']	['S0893-6080(18)30313-7 [pii]', '10.1016/j.neunet.2018.10.018 [doi]']	['Shi J', 'Xu J', 'Yao Y', 'Xu B']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/11/30 06:00']	20190319	20181112	2019 Feb	2018/11/30 06:00		['Shi, Jing', 'Xu, Jiaming', 'Yao, Yiqun', 'Xu, Bo']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30313-7 [pii] 10.1016/j.neunet.2018.10.018 [doi]	20190319	['*Concept Formation/physiology', '*Deep Learning/trends', 'Humans', '*Memory/physiology', '*Neural Networks (Computer)', '*Reinforcement (Psychology)']	2019/03/20 06:00		['Attention', 'Deep reinforcement learning', 'Memory', 'Neural networks', 'One-shot learning']	['NOTNLM']	NLM	47-54	['2018/06/20 00:00 [received]', '2018/09/14 00:00 [revised]', '2018/10/30 00:00 [accepted]', '2018/11/30 06:00 [pubmed]', '2019/03/20 06:00 [medline]', '2018/11/30 06:00 [entrez]']	United States			30496914	ppublish	['Journal Article']			IM		Neural Netw. 2019 Feb;110:47-54. doi: 10.1016/j.neunet.2018.10.018. Epub 2018 Nov 12.	MEDLINE	Neural Netw	Concept learning through deep reinforcement learning with memory-augmented neural networks.		110	Concept learning through deep reinforcement learning with memory-augmented neural networks.
Long noncoding RNAs (lncRNAs) can exert their function by interacting with the DNA via triplex structure formation. Even though this has been validated with a handful of experiments, a genome-wide analysis of lncRNA-DNA binding is needed. In this paper, we develop and interpret deep learning models that predict the genome-wide binding sites deciphered by ChIRP-Seq experiments of 12 different lncRNAs. Among the several deep learning architectures tested, a simple architecture consisting of two convolutional neural network layers performed the best suggesting local sequence patterns as determinants of the interaction. Further interpretation of the kernels in the model revealed that these local sequence patterns form triplex structures with the corresponding lncRNAs. We uncovered several novel triplexes forming domains (TFDs) of these 12 lncRNAs and previously experimentally verified TFDs of lncRNAs HOTAIR and MEG3. We experimentally verified such two novel TFDs of lncRNAs HOTAIR and TUG1 predicted by our method (but previously unreported) using Electrophoretic mobility shift assays. In conclusion, we show that simple deep learning architecture can accurately predict genome-wide binding sites of lncRNAs and interpretation of the models suggest RNA:DNA:DNA triplex formation as a viable mechanism underlying lncRNA-DNA interactions at genome-wide level.	"[""a Department of Oncology , The First Affiliated Hospital of Xian Jiaotong University , Xi'an , P.R. China."", 'b Department of Biology and Biochemistry , University of Houston , Houston , TX , USA.', 'c Computer Science and Engineering Technology , University of Houston-Downtown , Houston , TX , USA.', 'c Computer Science and Engineering Technology , University of Houston-Downtown , Houston , TX , USA.', ""a Department of Oncology , The First Affiliated Hospital of Xian Jiaotong University , Xi'an , P.R. China."", 'b Department of Biology and Biochemistry , University of Houston , Houston , TX , USA.', 'c Computer Science and Engineering Technology , University of Houston-Downtown , Houston , TX , USA.']"	['10.1080/15476286.2018.1551704 [doi]']	['Wang F', 'Chainani P', 'White T', 'Yang J', 'Liu Y', 'Soibam B']	['ORCID: 0000-0002-1282-4897']						['2018/11/30 06:00']	20190911	20181128	2018	2018/11/30 06:00		['Wang, Fan', 'Chainani, Pranik', 'White, Tommy', 'Yang, Jin', 'Liu, Yu', 'Soibam, Benjamin']			12		1555-8584 (Electronic) 1547-6286 (Linking)	101235328	RNA biology	['eng']	10.1080/15476286.2018.1551704 [doi]	20190911	['Animals', '*Binding Sites', 'DNA', '*Deep Learning', 'Gene Expression Regulation', '*Genome-Wide Association Study', 'Humans', 'Mice', 'RNA, Long Noncoding/*genetics', 'Reproducibility of Results']	2019/09/12 06:00		['*Long noncoding RNAs', '*deep learning', '*triplex']	['NOTNLM']	NLM	1468-1476	['2018/11/30 06:00 [pubmed]', '2019/09/12 06:00 [medline]', '2018/11/30 06:00 [entrez]']	United States	PMC6333433		30486737	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (RNA, Long Noncoding)', '0 (triplex DNA)', '9007-49-2 (DNA)']	IM		RNA Biol. 2018;15(12):1468-1476. doi: 10.1080/15476286.2018.1551704. Epub 2018 Nov 28.	MEDLINE	RNA Biol	Deep learning identifies genome-wide DNA binding sites of long noncoding RNAs.		15	Deep learning identifies genome-wide DNA binding sites of long noncoding RNAs.
BACKGROUND: Cervical cancer is the fifth most common cancer among women, which is the third leading cause of cancer death in women worldwide. Brachytherapy is the most effective treatment for cervical cancer. For brachytherapy, computed tomography (CT) imaging is necessary since it conveys tissue density information which can be used for dose planning. However, the metal artifacts caused by brachytherapy applicators remain a challenge for the automatic processing of image data for image-guided procedures or accurate dose calculations. Therefore, developing an effective metal artifact reduction (MAR) algorithm in cervical CT images is of high demand. METHODS: A novel residual learning method based on convolutional neural network (RL-ARCNN) is proposed to reduce metal artifacts in cervical CT images. For MAR, a dataset is generated by simulating various metal artifacts in the first step, which will be applied to train the CNN. This dataset includes artifact-insert, artifact-free, and artifact-residual images. Numerous image patches are extracted from the dataset for training on deep residual learning artifact reduction based on CNN (RL-ARCNN). Afterwards, the trained model can be used for MAR on cervical CT images. RESULTS: The proposed method provides a good MAR result with a PSNR of 38.09 on the test set of simulated artifact images. The PSNR of residual learning (38.09) is higher than that of ordinary learning (37.79) which shows that CNN-based residual images achieve favorable artifact reduction. Moreover, for a 512 x 512 image, the average removal artifact time is less than 1 s. CONCLUSIONS: The RL-ARCNN indicates that residual learning of CNN remarkably reduces metal artifacts and improves critical structure visualization and confidence of radiation oncologists in target delineation. Metal artifacts are eliminated efficiently free of sinogram data and complicated post-processing procedure.	['School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, Guangdong, China. yuzhang@smu.edu.cn.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, Southern Medical University, Guangzhou, 510515, Guangdong, China. yuzhang@smu.edu.cn.']	['10.1186/s12938-018-0609-y [doi]', '10.1186/s12938-018-0609-y [pii]']	['Huang X', 'Wang J', 'Tang F', 'Zhong T', 'Zhang Y']							['2018/11/29 06:00']	20190325	20181127	2018 Nov 27	2018/11/30 06:00		['Huang, Xia', 'Wang, Jian', 'Tang, Fan', 'Zhong, Tao', 'Zhang, Yu']		['No. 61671230/National Natural Science Foundation of China under Grant', 'No.31271067/National Natural Science Foundation of China under Grant', 'No. 2017A020211012/Science and Technology Program of Guangdong Province under', 'Grant', 'No.2014B030301042/Guangdong Provincial Key Laboratory of Medical Image Processing', 'under Grant', 'No. 201607010097/Science and Technology Program of Guangzhou under Grant']	1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-018-0609-y [doi]	20190325	['*Artifacts', 'Cervix Uteri/*diagnostic imaging', '*Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Metals', '*Tomography, X-Ray Computed']	2019/03/26 06:00		['Cervical CT', 'Convolutional neural network', 'Metal artifact reduction', 'Residual learning']	['NOTNLM']	NLM	175	['2018/07/25 00:00 [received]', '2018/11/22 00:00 [accepted]', '2018/11/29 06:00 [entrez]', '2018/11/30 06:00 [pubmed]', '2019/03/26 06:00 [medline]']	England	PMC6260559		30482231	epublish	['Journal Article']		['0 (Metals)']	IM		Biomed Eng Online. 2018 Nov 27;17(1):175. doi: 10.1186/s12938-018-0609-y.	MEDLINE	Biomed Eng Online	Metal artifact reduction on cervical CT images by deep residual learning.		17	Metal artifact reduction on cervical CT images by deep residual learning.
PURPOSE: To build a deep learning model to diagnose glaucoma using fundus photography. DESIGN: Cross sectional case study Subjects, Participants and Controls: A total of 1,542 photos (786 normal controls, 467 advanced glaucoma and 289 early glaucoma patients) were obtained by fundus photography. METHOD: The whole dataset of 1,542 images were split into 754 training, 324 validation and 464 test datasets. These datasets were used to construct simple logistic classification and convolutional neural network using Tensorflow. The same datasets were used to fine tune pre-trained GoogleNet Inception v3 model. RESULTS: The simple logistic classification model showed a training accuracy of 82.9%, validation accuracy of 79.9% and test accuracy of 77.2%. Convolutional neural network achieved accuracy and area under the receiver operating characteristic curve (AUROC) of 92.2% and 0.98 on the training data, 88.6% and 0.95 on the validation data, and 87.9% and 0.94 on the test data. Transfer-learned GoogleNet Inception v3 model achieved accuracy and AUROC of 99.7% and 0.99 on training data, 87.7% and 0.95 on validation data, and 84.5% and 0.93 on test data. CONCLUSION: Both advanced and early glaucoma could be correctly detected via machine learning, using only fundus photographs. Our new model that is trained using convolutional neural network is more efficient for the diagnosis of early glaucoma than previously published models.	"['Department of Bioinformatics and Life Science, Soongsil University, Seoul, Korea.', 'Department of Bioinformatics and Life Science, Soongsil University, Seoul, Korea.', 'Functional Genome Institute, PDXen Biosystems Inc., Seoul, Korea.', 'Functional Genome Institute, PDXen Biosystems Inc., Seoul, Korea.', ""Kim's Eye Hospital, Seoul, Korea."", ""Kim's Eye Hospital, Seoul, Korea."", 'Department of Ophthalmology, Konyang University College of Medicine, Daejeon, Korea.']"	['10.1371/journal.pone.0207982 [doi]', 'PONE-D-18-08957 [pii]']	['Ahn JM', 'Kim S', 'Ahn KS', 'Cho SH', 'Lee KB', 'Kim US']	['ORCID: 0000-0003-2373-6240']				['We have the following interests: PDXen partially funded and sponsored the study.', 'SHC and KSA: Employees - PDXen. There are no patents, products in development or', 'marketed products to declare. This does not alter our adherence to all the PLOS', 'ONE policies on sharing data and materials.']		['2018/11/28 06:00']	20190425	20181127	2018	2018/11/28 06:00	['PLoS One. 2019 Jan 25;14(1):e0211579. PMID: 30682186']	['Ahn, Jin Mo', 'Kim, Sangsoo', 'Ahn, Kwang-Sung', 'Cho, Sung-Hoon', 'Lee, Kwan Bok', 'Kim, Ungsoo Samuel']			11		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0207982 [doi]	20190425	['Cross-Sectional Studies', '*Deep Learning', '*Diagnostic Techniques, Ophthalmological', 'Disease Progression', 'Fundus Oculi', 'Glaucoma/*diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Logistic Models', 'ROC Curve']	2019/04/26 06:00				NLM	e0207982	['2018/03/24 00:00 [received]', '2018/11/11 00:00 [accepted]', '2018/11/28 06:00 [entrez]', '2018/11/28 06:00 [pubmed]', '2019/04/26 06:00 [medline]']	United States	PMC6258525		30481205	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Nov 27;13(11):e0207982. doi: 10.1371/journal.pone.0207982. eCollection 2018.	MEDLINE	PLoS One	A deep learning model for the detection of both advanced and early glaucoma using fundus photography.		13	A deep learning model for the detection of both advanced and early glaucoma using fundus photography.
BACKGROUND: Magnetic resonance imaging (MRI) of the knee is the preferred method for diagnosing knee injuries. However, interpretation of knee MRI is time-intensive and subject to diagnostic error and variability. An automated system for interpreting knee MRI could prioritize high-risk patients and assist clinicians in making diagnoses. Deep learning methods, in being able to automatically learn layers of features, are well suited for modeling the complex relationships between medical images and their interpretations. In this study we developed a deep learning model for detecting general abnormalities and specific diagnoses (anterior cruciate ligament [ACL] tears and meniscal tears) on knee MRI exams. We then measured the effect of providing the model's predictions to clinical experts during interpretation. METHODS AND FINDINGS: Our dataset consisted of 1,370 knee MRI exams performed at Stanford University Medical Center between January 1, 2001, and December 31, 2012 (mean age 38.0 years; 569 [41.5%] female patients). The majority vote of 3 musculoskeletal radiologists established reference standard labels on an internal validation set of 120 exams. We developed MRNet, a convolutional neural network for classifying MRI series and combined predictions from 3 series per exam using logistic regression. In detecting abnormalities, ACL tears, and meniscal tears, this model achieved area under the receiver operating characteristic curve (AUC) values of 0.937 (95% CI 0.895, 0.980), 0.965 (95% CI 0.938, 0.993), and 0.847 (95% CI 0.780, 0.914), respectively, on the internal validation set. We also obtained a public dataset of 917 exams with sagittal T1-weighted series and labels for ACL injury from Clinical Hospital Centre Rijeka, Croatia. On the external validation set of 183 exams, the MRNet trained on Stanford sagittal T2-weighted series achieved an AUC of 0.824 (95% CI 0.757, 0.892) in the detection of ACL injuries with no additional training, while an MRNet trained on the rest of the external data achieved an AUC of 0.911 (95% CI 0.864, 0.958). We additionally measured the specificity, sensitivity, and accuracy of 9 clinical experts (7 board-certified general radiologists and 2 orthopedic surgeons) on the internal validation set both with and without model assistance. Using a 2-sided Pearson's chi-squared test with adjustment for multiple comparisons, we found no significant differences between the performance of the model and that of unassisted general radiologists in detecting abnormalities. General radiologists achieved significantly higher sensitivity in detecting ACL tears (p-value = 0.002; q-value = 0.019) and significantly higher specificity in detecting meniscal tears (p-value = 0.003; q-value = 0.019). Using a 1-tailed t test on the change in performance metrics, we found that providing model predictions significantly increased clinical experts' specificity in identifying ACL tears (p-value < 0.001; q-value = 0.006). The primary limitations of our study include lack of surgical ground truth and the small size of the panel of clinical experts. CONCLUSIONS: Our deep learning model can rapidly generate accurate clinical pathology classifications of knee MRI exams from both internal and external datasets. Moreover, our results support the assertion that deep learning models can improve the performance of clinical experts during medical imaging interpretation. Further research is needed to validate the model prospectively and to determine its utility in the clinical setting.	['Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Quantitative Sciences Unit, Department of Medicine, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Orthopedic Surgery, Stanford University, Stanford, California, United States of America.', 'Department of Orthopedic Surgery, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.']	['10.1371/journal.pmed.1002699 [doi]', 'PMEDICINE-D-18-01996 [pii]']	['Bien N', 'Rajpurkar P', 'Ball RL', 'Irvin J', 'Park A', 'Jones E', 'Bereket M', 'Patel BN', 'Yeom KW', 'Shpanskaya K', 'Halabi S', 'Zucker E', 'Fanton G', 'Amanatullah DF', 'Beaulieu CF', 'Riley GM', 'Stewart RJ', 'Blankenberg FG', 'Larson DB', 'Jones RH', 'Langlotz CP', 'Ng AY', 'Lungren MP']	['ORCID: 0000-0002-7731-3510', 'ORCID: 0000-0002-8030-3727', 'ORCID: 0000-0002-7335-3339', 'ORCID: 0000-0002-0395-4403', 'ORCID: 0000-0003-1494-9615', 'ORCID: 0000-0001-9860-3368', 'ORCID: 0000-0003-2741-4046', 'ORCID: 0000-0003-1317-984X', 'ORCID: 0000-0002-7570-2141', 'ORCID: 0000-0002-8972-8051']				"[""I have read the journal's policy and the authors of this manuscript have the"", 'following competing interests: CL is a shareholder of whiterabbit.ai and', 'nines.ai. Since submitting this manuscript, RLB has joined and received stock', 'options from Roam Analytics, whose mission is to use AI methodology to improve', 'human health.']"		['2018/11/28 06:00']	20190422	20181127	2018 Nov	2018/11/28 06:00		['Bien, Nicholas', 'Rajpurkar, Pranav', 'Ball, Robyn L', 'Irvin, Jeremy', 'Park, Allison', 'Jones, Erik', 'Bereket, Michael', 'Patel, Bhavik N', 'Yeom, Kristen W', 'Shpanskaya, Katie', 'Halabi, Safwan', 'Zucker, Evan', 'Fanton, Gary', 'Amanatullah, Derek F', 'Beaulieu, Christopher F', 'Riley, Geoffrey M', 'Stewart, Russell J', 'Blankenberg, Francis G', 'Larson, David B', 'Jones, Ricky H', 'Langlotz, Curtis P', 'Ng, Andrew Y', 'Lungren, Matthew P']		['R01 EB000898/EB/NIBIB NIH HHS/United States']	11		1549-1676 (Electronic) 1549-1277 (Linking)	101231360	PLoS medicine	['eng']	10.1371/journal.pmed.1002699 [doi]	20190614	['Adult', 'Anterior Cruciate Ligament Injuries/*diagnostic imaging', 'Automation', 'Databases, Factual', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Knee/*diagnostic imaging', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', 'Predictive Value of Tests', 'Reproducibility of Results', 'Retrospective Studies', 'Tibial Meniscus Injuries/*diagnostic imaging', 'Young Adult']	2019/04/23 06:00				NLM	e1002699	['2018/06/02 00:00 [received]', '2018/10/23 00:00 [accepted]', '2018/11/28 06:00 [entrez]', '2018/11/28 06:00 [pubmed]', '2019/04/23 06:00 [medline]']	United States	PMC6258509		30481176	epublish	['Journal Article', 'Validation Studies']			IM		PLoS Med. 2018 Nov 27;15(11):e1002699. doi: 10.1371/journal.pmed.1002699. eCollection 2018 Nov.	MEDLINE	PLoS Med	Deep-learning-assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet.		15	Deep-learning-assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet.
PURPOSE: Radiation therapy (RT) is a common treatment option for head and neck (HaN) cancer. An important step involved in RT planning is the delineation of organs-at-risks (OARs) based on HaN computed tomography (CT). However, manually delineating OARs is time-consuming as each slice of CT images needs to be individually examined and a typical CT consists of hundreds of slices. Automating OARs segmentation has the benefit of both reducing the time and improving the quality of RT planning. Existing anatomy autosegmentation algorithms use primarily atlas-based methods, which require sophisticated atlas creation and cannot adequately account for anatomy variations among patients. In this work, we propose an end-to-end, atlas-free three-dimensional (3D) convolutional deep learning framework for fast and fully automated whole-volume HaN anatomy segmentation. METHODS: Our deep learning model, called AnatomyNet, segments OARs from head and neck CT images in an end-to-end fashion, receiving whole-volume HaN CT images as input and generating masks of all OARs of interest in one shot. AnatomyNet is built upon the popular 3D U-net architecture, but extends it in three important ways: (a) a new encoding scheme to allow autosegmentation on whole-volume CT images instead of local patches or subsets of slices, (b) incorporating 3D squeeze-and-excitation residual blocks in encoding layers for better feature representation, and (c) a new loss function combining Dice scores and focal loss to facilitate the training of the neural model. These features are designed to address two main challenges in deep learning-based HaN segmentation: (a) segmenting small anatomies (i.e., optic chiasm and optic nerves) occupying only a few slices, and (b) training with inconsistent data annotations with missing ground truth for some anatomical structures. RESULTS: We collected 261 HaN CT images to train AnatomyNet and used MICCAI Head and Neck Auto Segmentation Challenge 2015 as a benchmark dataset to evaluate the performance of AnatomyNet. The objective is to segment nine anatomies: brain stem, chiasm, mandible, optic nerve left, optic nerve right, parotid gland left, parotid gland right, submandibular gland left, and submandibular gland right. Compared to previous state-of-the-art results from the MICCAI 2015 competition, AnatomyNet increases Dice similarity coefficient by 3.3% on average. AnatomyNet takes about 0.12 s to fully segment a head and neck CT image of dimension 178 x 302 x 225, significantly faster than previous methods. In addition, the model is able to process whole-volume CT images and delineate all OARs in one pass, requiring little pre- or postprocessing. CONCLUSION: Deep learning models offer a feasible solution to the problem of delineating OARs from CT images. We demonstrate that our proposed model can improve segmentation accuracy and simplify the autosegmentation pipeline. With this method, it is possible to delineate OARs of a head and neck CT within a fraction of a second.	['Department of Computer Science, University of California, Irvine, CA, USA.', 'Lenovo Research, Beijing, China.', 'Deepvoxel Inc, Shanghai, China.', 'Department of Radiation Oncology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China.', 'Department of Radiation Oncology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China.', 'Tencent Medical AI Lab, Palo Alto, CA, USA.', 'Tencent Medical AI Lab, Palo Alto, CA, USA.', 'Tencent Medical AI Lab, Palo Alto, CA, USA.', 'Department of Computer Science, University of California, Irvine, CA, USA.']	['10.1002/mp.13300 [doi]']	['Zhu W', 'Huang Y', 'Zeng L', 'Chen X', 'Liu Y', 'Qian Z', 'Du N', 'Fan W', 'Xie X']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/11/28 06:00']	20190225	20181217	2019 Feb	2018/11/28 06:00		['Zhu, Wentao', 'Huang, Yufang', 'Zeng, Liang', 'Chen, Xuming', 'Liu, Yong', 'Qian, Zhen', 'Du, Nan', 'Fan, Wei', 'Xie, Xiaohui']			2		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13300 [doi]	20190225	['Automation', '*Deep Learning', 'Head and Neck Neoplasms/*diagnostic imaging/*pathology', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Time Factors', 'Tomography, X-Ray Computed']	2019/02/26 06:00		['U-Net', 'automated anatomy segmentation', 'deep learning', 'head and neck cancer', 'radiation therapy']	['NOTNLM']	NLM	576-589	['2018/08/13 00:00 [received]', '2018/11/06 00:00 [revised]', '2018/11/07 00:00 [accepted]', '2018/11/28 06:00 [pubmed]', '2019/02/26 06:00 [medline]', '2018/11/28 06:00 [entrez]']	United States			30480818	ppublish	['Journal Article']			IM		Med Phys. 2019 Feb;46(2):576-589. doi: 10.1002/mp.13300. Epub 2018 Dec 17.	MEDLINE	Med Phys	AnatomyNet: Deep learning for fast and fully automated whole-volume segmentation of head and neck anatomy.		46	AnatomyNet: Deep learning for fast and fully automated whole-volume segmentation of head and neck anatomy.
Purpose The Radiological Society of North America (RSNA) Pediatric Bone Age Machine Learning Challenge was created to show an application of machine learning (ML) and artificial intelligence (AI) in medical imaging, promote collaboration to catalyze AI model creation, and identify innovators in medical imaging. Materials and Methods The goal of this challenge was to solicit individuals and teams to create an algorithm or model using ML techniques that would accurately determine skeletal age in a curated data set of pediatric hand radiographs. The primary evaluation measure was the mean absolute distance (MAD) in months, which was calculated as the mean of the absolute values of the difference between the model estimates and those of the reference standard, bone age. Results A data set consisting of 14 236 hand radiographs (12 611 training set, 1425 validation set, 200 test set) was made available to registered challenge participants. A total of 260 individuals or teams registered on the Challenge website. A total of 105 submissions were uploaded from 48 unique users during the training, validation, and test phases. Almost all methods used deep neural network techniques based on one or more convolutional neural networks (CNNs). The best five results based on MAD were 4.2, 4.4, 4.4, 4.5, and 4.5 months, respectively. Conclusion The RSNA Pediatric Bone Age Machine Learning Challenge showed how a coordinated approach to solving a medical imaging problem can be successfully conducted. Future ML challenges will catalyze collaboration and development of ML tools and methods that can potentially improve diagnostic accuracy and patient care. (c) RSNA, 2018 Online supplemental material is available for this article. See also the editorial by Siegel in this issue.	"[""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.)."", ""From the Department of Radiology, Stanford University, 300 Pasteur Dr, MC 5105, Stanford, CA 94305 (S.S.H.); Department of Radiology, The Ohio State University Wexner Medical Center, Columbus, Ohio (L.M.P.); Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital/Harvard Medical School, Boston, Mass (J.K.C.); Massachusetts General Hospital & Brigham and Women's Hospital Center for Clinical Data Science, Boston, Mass (A.B.M., K.A.); Department of Radiology, University of Toronto, Toronto, Ontario, Canada (A.B.); Department of Radiology, St. Michael's Hospital, Toronto, Ontario, Canada (M.C.); Department of Diagnostic Imaging, Warren Alpert Medical School of Brown University, Rhode Island Hospital, Providence, RI (I.P.); Universidade Federal de Goias, Goiania, Brazil (L.A.P., R.T.S.); Universidade Federal de Sao Paulo, Sao Paulo, Brazil (N.A., F.C.K.); Visiana, Horsholm, Denmark (H.H.T.); MD.ai, New York, NY (L.C.); Department of Radiology, Weill Cornell Medicine, New York, NY (G.S.) Department of Radiology, University of California-San Francisco, San Francisco, Calif (M.D.K.); Department of Radiology, Mayo Clinic, Rochester, Minn (B.J.E.); and Department of Radiology, Thomas Jefferson University, Philadelphia, Pa (A.E.F.).""]"	['10.1148/radiol.2018180736 [doi]']	['Halabi SS', 'Prevedello LM', 'Kalpathy-Cramer J', 'Mamonov AB', 'Bilbily A', 'Cicero M', 'Pan I', 'Pereira LA', 'Sousa RT', 'Abdala N', 'Kitamura FC', 'Thodberg HH', 'Chen L', 'Shih G', 'Andriole K', 'Kohli MD', 'Erickson BJ', 'Flanders AE']	['ORCID: 0000-0003-1317-984X', 'ORCID: 0000-0001-8906-9618', 'ORCID: 0000-0002-4679-0787']		['Radiology. 2019 Feb;290(2):504-505. PMID: 30615556']				['2018/11/28 06:00']	20191126	20181127	2019 Feb	2018/11/28 06:00		['Halabi, Safwan S', 'Prevedello, Luciano M', 'Kalpathy-Cramer, Jayashree', 'Mamonov, Artem B', 'Bilbily, Alexander', 'Cicero, Mark', 'Pan, Ian', 'Pereira, Lucas Araujo', 'Sousa, Rafael Teixeira', 'Abdala, Nitamar', 'Kitamura, Felipe Campos', 'Thodberg, Hans H', 'Chen, Leon', 'Shih, George', 'Andriole, Katherine', 'Kohli, Marc D', 'Erickson, Bradley J', 'Flanders, Adam E']		['U24 CA180927/CA/NCI NIH HHS/United States']	2		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2018180736 [doi]	20191126	['Age Determination by Skeleton/*methods', 'Algorithms', 'Child', 'Databases, Factual', 'Female', 'Hand Bones/diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Male', 'Radiography/*methods']	2019/11/27 06:00				NLM	498-503	['2020/02/01 00:00 [pmc-release]', '2018/11/28 06:00 [pubmed]', '2019/11/27 06:00 [medline]', '2018/11/28 06:00 [entrez]']	United States	PMC6358027	['2020/02/01 00:00']	30480490	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			AIM IM		Radiology. 2019 Feb;290(2):498-503. doi: 10.1148/radiol.2018180736. Epub 2018 Nov 27.	MEDLINE	Radiology	The RSNA Pediatric Bone Age Machine Learning Challenge.		290	The RSNA Pediatric Bone Age Machine Learning Challenge.
BACKGROUND: Artificial intelligence (AI) is revolutionizing our world, with applications ranging from medicine to engineering. OBJECTIVES: Here we discuss the promise, challenges, and probable data sources needed to apply AI in the fields of exposure science and environmental health. In particular, we focus on the use of deep convolutional neural networks to estimate environmental exposures using images and other complementary data sources such as cell phone mobility and social media information. DISCUSSION: Characterizing the health impacts of multiple spatially-correlated exposures remains a challenge in environmental epidemiology. A shift toward integrated measures that simultaneously capture multiple aspects of the urban built environment could improve efficiency and provide important insights into how our collective environments influence population health. The widespread adoption of AI in exposure science is on the frontier. This will likely result in new ways of understanding environmental impacts on health and may allow for analyses to be efficiently scaled for broad coverage. Image-based convolutional neural networks may also offer a cost-effective means of estimating local environmental exposures in low and middle-income countries where monitoring and surveillance infrastructure is limited. However, suitable databases must first be assembled to train and evaluate these models and these novel approaches should be complemented with traditional exposure metrics. CONCLUSIONS: The promise of deep learning in environmental health is great and will complement existing measurements for data-rich settings and could enhance the resolution and accuracy of estimates in data poor scenarios. Interdisciplinary partnerships will be needed to fully realize this potential.	['McGill University, Department of Epidemiology, Biostatistics and Occupational Health, Montreal, QC, Canada. Electronic address: scott.weichenthal@mcgill.ca.', 'University of Toronto, Department of Civil Engineering, Toronto, ON, Canada.', 'University of British Columbia, School of Population and Public Health, Vancouver, BC, Canada.']	['S0160-4120(18)32200-1 [pii]', '10.1016/j.envint.2018.11.042 [doi]']	['Weichenthal S', 'Hatzopoulou M', 'Brauer M']		['Copyright (c) 2018 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2018/11/27 06:00']	20190517	20181122	2019 Jan	2018/11/27 06:00		['Weichenthal, Scott', 'Hatzopoulou, Marianne', 'Brauer, Michael']		['CIHR/Canada', 'Wellcome Trust/United Kingdom']			1873-6750 (Electronic) 0160-4120 (Linking)	7807270	Environment international	['eng']	S0160-4120(18)32200-1 [pii] 10.1016/j.envint.2018.11.042 [doi]	20190517	['*Deep Learning', '*Environmental Exposure', 'Environmental Health/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods']	2019/05/18 06:00				NLM	3-10	['2018/09/27 00:00 [received]', '2018/11/16 00:00 [revised]', '2018/11/17 00:00 [accepted]', '2018/11/27 06:00 [pubmed]', '2019/05/18 06:00 [medline]', '2018/11/27 06:00 [entrez]']	Netherlands			30473381	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Environ Int. 2019 Jan;122:3-10. doi: 10.1016/j.envint.2018.11.042. Epub 2018 Nov 22.	MEDLINE	Environ Int	A picture tells a thousand...exposures: Opportunities and challenges of deep learning image analyses in exposure science and environmental epidemiology.		122	A picture tells a thousand...exposures: Opportunities and challenges of deep learning image analyses in exposure science and environmental epidemiology.
Clinical success of immunotherapy is driving the need for new prognostic and predictive assays to inform patient selection and stratification. This requirement can be met by a combination of computational pathology and artificial intelligence. Here, we critically assess computational approaches supporting the development of a standardized methodology in the assessment of immune-oncology biomarkers, such as PD-L1 and immune cell infiltrates. We examine immunoprofiling through spatial analysis of tumor-immune cell interactions and multiplexing technologies as a predictor of patient response to cancer treatment. Further, we discuss how integrated bioinformatics can enable the amalgamation of complex morphological phenotypes with the multiomics datasets that drive precision medicine. We provide an outline to machine learning (ML) and artificial intelligence tools and illustrate fields of application in immune-oncology, such as pattern-recognition in large and complex datasets and deep learning approaches for survival analysis. Synergies of surgical pathology and computational analyses are expected to improve patient stratification in immuno-oncology. We propose that future clinical demands will be best met by (1) dedicated research at the interface of pathology and bioinformatics, supported by professional societies, and (2) the integration of data sciences and digital image analysis in the professional education of pathologists.	['Institute of Cancer and Genomic Science, University of Birmingham, 6 Mindelsohn Way, Birmingham, B15 2SY, UK. vkoelzer@well.ox.ac.uk.', 'Molecular and Population Genetics Laboratory, Wellcome Centre for Human Genetics, University of Oxford, Headington, Oxford, OX3 7BN, UK. vkoelzer@well.ox.ac.uk.', 'Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Old Road Campus Research Building, Headington, Oxford, OX3 7DQ, UK.', 'Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Old Road Campus Research Building, Headington, Oxford, OX3 7DQ, UK.', 'Ludwig Institute for Cancer Research, Nuffield Department of Medicine, University of Oxford, Old Road Campus Research Building, Oxford, OX3 7DQ, UK.', 'Target Discovery Institute, NDM Research Building, University of Oxford, Old Road Campus, Headington, OX3 7FZ, UK.', 'Institute of Pathology, Cantonal Hospital Baselland, Muhlemattstrasse 11, CH-4410, Liestal, Switzerland.']	['10.1007/s00428-018-2485-z [doi]', '10.1007/s00428-018-2485-z [pii]']	['Koelzer VH', 'Sirinukunwattana K', 'Rittscher J', 'Mertz KD']	['ORCID: http://orcid.org/0000-0001-9206-4885']						['2018/11/25 06:00']	20190415	20181123	2019 Apr	2018/11/25 06:00		['Koelzer, Viktor H', 'Sirinukunwattana, Korsuk', 'Rittscher, Jens', 'Mertz, Kirsten D']		['P2SKP3_168322/2/Schweizerischer Nationalfonds zur Forderung der', 'Wissenschaftlichen Forschung', 'KLbB-4182-03-2017/Krebsliga Beider Basel']	4		1432-2307 (Electronic) 0945-6317 (Linking)	9423843	Virchows Archiv : an international journal of pathology	['eng']	10.1007/s00428-018-2485-z [doi]	20190418	['*Artificial Intelligence', 'Biomarkers, Tumor/*analysis/immunology', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Immunophenotyping/*methods', 'Precision Medicine/*methods']	2019/04/16 06:00		['Artificial intelligence', 'Digital pathology', 'Image analysis', 'Immuno-oncology', 'Immunotherapy', 'Machine learning', 'Personalized medicine']	['NOTNLM']	NLM	511-522	['2018/05/15 00:00 [received]', '2018/11/09 00:00 [accepted]', '2018/11/06 00:00 [revised]', '2018/11/25 06:00 [pubmed]', '2019/04/16 06:00 [medline]', '2018/11/25 06:00 [entrez]']	Germany	PMC6447694		30470933	ppublish	['Journal Article', 'Review']		['0 (Biomarkers, Tumor)']	IM		Virchows Arch. 2019 Apr;474(4):511-522. doi: 10.1007/s00428-018-2485-z. Epub 2018 Nov 23.	MEDLINE	Virchows Arch	Precision immunoprofiling by image analysis and artificial intelligence.		474	Precision immunoprofiling by image analysis and artificial intelligence.
Ventricular fibrillation and ventricular tachycardia (VF/VT), known as shockable (SH) rhythms, are the mainly cause of sudden cardiac arrests (SCA), which is cured efficiently by the automated external defibrillator (AED). The performance of the shock advice algorithm (SAA) applied in the AED has been improved by using machine learning technique and variously conventional features, recently. In this paper, we propose a novel algorithm with relatively high performance for the SCA detection on electrocardiogram (ECG) signal. The algorithm consists of a convolutional neural network as a feature extractor (CNNE) and a Boosting (BS) classifier. A grid search with nested 5-folds cross validation (CV) is used to select the CNNE trained with preprocessed ECG, SH, and NSH signals using the modified variational mode decomposition technique. The deep feature vector learned by this CNNE is extracted at the first fully connected layer and then fed into BS classifier to validate its performance using 5-folds CV procedure. The secondary learning of the BS classifier and the use of three input channels for the CNNE improve certainly the detection performance of the proposed SAA with the validated accuracy of 99.26%, sensitivity of 97.07%, and specificity of 99.44%.	['School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, 61005, South Korea.', 'School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, 61005, South Korea.', 'School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, 61005, South Korea. kskim@gist.ac.kr.']	['10.1038/s41598-018-33424-9 [doi]', '10.1038/s41598-018-33424-9 [pii]']	['Nguyen MT', 'Nguyen BV', 'Kim K']	['ORCID: http://orcid.org/0000-0001-6069-1323', 'ORCID: http://orcid.org/0000-0002-0170-2093']						['2018/11/23 06:00']	20191104	20181121	2018 Nov 21	2018/11/23 06:00		['Nguyen, Minh Tuan', 'Nguyen, Binh Van', 'Kim, Kiseon']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-33424-9 [doi]	20191121	['Algorithms', '*Death, Sudden, Cardiac', '*Defibrillators', 'Electric Countershock/*methods', 'Humans', 'Machine Learning', 'Sensitivity and Specificity', 'Tachycardia/*diagnosis/*therapy', 'Ventricular Fibrillation/*diagnosis/*therapy']	2019/11/05 06:00				NLM	17196	['2018/06/26 00:00 [received]', '2018/09/25 00:00 [accepted]', '2018/11/23 06:00 [entrez]', '2018/11/23 06:00 [pubmed]', '2019/11/05 06:00 [medline]']	England	PMC6249221		30464177	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Nov 21;8(1):17196. doi: 10.1038/s41598-018-33424-9.	MEDLINE	Sci Rep	Deep Feature Learning for Sudden Cardiac Arrest Detection in Automated External Defibrillators.		8	Deep Feature Learning for Sudden Cardiac Arrest Detection in Automated External Defibrillators.
BACKGROUND: Epilepsy is a neurological disease characterized by unprovoked seizures in the brain. The recent advances in sensor technologies allow researchers to analyze the collected biological records to improve the treatment of epilepsy. Electroencephalogram (EEG) is the most commonly used biological measurement to effectively capture the abnormalities of different brain areas during the EEG seizures. To avoid manual visual inspection from long-term EEG readings, automatic epileptic EEG seizure detection has become an important research issue in bioinformatics. RESULTS: We present a multi-context learning approach to automatically detect EEG seizures by incorporating a feature fusion strategy. We generate EEG scalogram sequences from the EEG records by utilizing waveform transform to describe the frequency content over time. We propose a multi-stage unsupervised model that integrates the features extracted from the global handcrafted engineering, channel-wise deep learning, and EEG embeddings, respectively. The learned multi-context features are subsequently merged to train a seizure detector. CONCLUSIONS: To validate the effectiveness of the proposed approach, extensive experiments against several baseline methods are carried out on two benchmark biological datasets. The experimental results demonstrate that the representative context features from multiple perspectives can be learned by the proposed model, and further improve the performance for the task of EEG seizure detection.	['College of Information and Communication Engineering, Beijing University of Technology, Beijing, China.', 'Beijing Laboratory of Advanced Information Networks, Beijing University of Technology, Beijing, China.', 'Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China.', 'Department of Computer Science and Engineering, State University of New York at Buffalo, Buffalo, USA.', 'College of Information and Communication Engineering, Beijing University of Technology, Beijing, China. kebinj@bjut.edu.cn.', 'Beijing Laboratory of Advanced Information Networks, Beijing University of Technology, Beijing, China. kebinj@bjut.edu.cn.', 'Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China. kebinj@bjut.edu.cn.', 'Department of Computer Science and Engineering, State University of New York at Buffalo, Buffalo, USA.']	['10.1186/s12918-018-0626-2 [doi]', '10.1186/s12918-018-0626-2 [pii]']	['Yuan Y', 'Xun G', 'Jia K', 'Zhang A']							['2018/11/23 06:00']	20190729	20181122	2018 Nov 22	2018/11/23 06:00		['Yuan, Ye', 'Xun, Guangxu', 'Jia, Kebin', 'Zhang, Aidong']			Suppl 6		1752-0509 (Electronic) 1752-0509 (Linking)	101301827	BMC systems biology	['eng']	10.1186/s12918-018-0626-2 [doi]	20190729	['Computational Biology/*methods', '*Electroencephalography', 'Humans', '*Machine Learning', 'Principal Component Analysis', 'Seizures/*diagnosis', 'Signal Processing, Computer-Assisted']	2019/07/30 06:00		['*Context learning', '*Deep learning', '*Electroencephalogram', '*Epileptic seizure', '*Feature extraction']	['NOTNLM']	NLM	107	['2018/11/23 06:00 [entrez]', '2018/11/23 06:00 [pubmed]', '2019/07/30 06:00 [medline]']	England	PMC6249720		30463546	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					BMC Syst Biol. 2018 Nov 22;12(Suppl 6):107. doi: 10.1186/s12918-018-0626-2.	MEDLINE	BMC Syst Biol	A multi-context learning approach for EEG epileptic seizure detection.		12	A multi-context learning approach for EEG epileptic seizure detection.
BACKGROUND: Chest radiograph interpretation is critical for the detection of thoracic diseases, including tuberculosis and lung cancer, which affect millions of people worldwide each year. This time-consuming task typically requires expert radiologists to read the images, leading to fatigue-based diagnostic error and lack of diagnostic expertise in areas of the world where radiologists are not available. Recently, deep learning approaches have been able to achieve expert-level performance in medical image interpretation tasks, powered by large network architectures and fueled by the emergence of large labeled datasets. The purpose of this study is to investigate the performance of a deep learning algorithm on the detection of pathologies in chest radiographs compared with practicing radiologists. METHODS AND FINDINGS: We developed CheXNeXt, a convolutional neural network to concurrently detect the presence of 14 different pathologies, including pneumonia, pleural effusion, pulmonary masses, and nodules in frontal-view chest radiographs. CheXNeXt was trained and internally validated on the ChestX-ray8 dataset, with a held-out validation set consisting of 420 images, sampled to contain at least 50 cases of each of the original pathology labels. On this validation set, the majority vote of a panel of 3 board-certified cardiothoracic specialist radiologists served as reference standard. We compared CheXNeXt's discriminative performance on the validation set to the performance of 9 radiologists using the area under the receiver operating characteristic curve (AUC). The radiologists included 6 board-certified radiologists (average experience 12 years, range 4-28 years) and 3 senior radiology residents, from 3 academic institutions. We found that CheXNeXt achieved radiologist-level performance on 11 pathologies and did not achieve radiologist-level performance on 3 pathologies. The radiologists achieved statistically significantly higher AUC performance on cardiomegaly, emphysema, and hiatal hernia, with AUCs of 0.888 (95% confidence interval [CI] 0.863-0.910), 0.911 (95% CI 0.866-0.947), and 0.985 (95% CI 0.974-0.991), respectively, whereas CheXNeXt's AUCs were 0.831 (95% CI 0.790-0.870), 0.704 (95% CI 0.567-0.833), and 0.851 (95% CI 0.785-0.909), respectively. CheXNeXt performed better than radiologists in detecting atelectasis, with an AUC of 0.862 (95% CI 0.825-0.895), statistically significantly higher than radiologists' AUC of 0.808 (95% CI 0.777-0.838); there were no statistically significant differences in AUCs for the other 10 pathologies. The average time to interpret the 420 images in the validation set was substantially longer for the radiologists (240 minutes) than for CheXNeXt (1.5 minutes). The main limitations of our study are that neither CheXNeXt nor the radiologists were permitted to use patient history or review prior examinations and that evaluation was limited to a dataset from a single institution. CONCLUSIONS: In this study, we developed and validated a deep learning algorithm that classified clinically important abnormalities in chest radiographs at a performance level comparable to practicing radiologists. Once tested prospectively in clinical settings, the algorithm could have the potential to expand patient access to chest radiograph diagnostics.	['Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Medicine, Quantitative Sciences Unit, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Duke University, Durham, North Carolina, United States of America.', 'Department of Radiology, University of Colorado, Denver, Colorado, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.', 'Department of Computer Science, Stanford University, Stanford, California, United States of America.', 'Department of Radiology, Stanford University, Stanford, California, United States of America.']	['10.1371/journal.pmed.1002686 [doi]', 'PMEDICINE-D-18-01880 [pii]']	['Rajpurkar P', 'Irvin J', 'Ball RL', 'Zhu K', 'Yang B', 'Mehta H', 'Duan T', 'Ding D', 'Bagul A', 'Langlotz CP', 'Patel BN', 'Yeom KW', 'Shpanskaya K', 'Blankenberg FG', 'Seekins J', 'Amrhein TJ', 'Mong DA', 'Halabi SS', 'Zucker EJ', 'Ng AY', 'Lungren MP']	['ORCID: 0000-0002-8030-3727', 'ORCID: 0000-0002-0395-4403', 'ORCID: 0000-0002-8972-8051', 'ORCID: 0000-0001-9860-3368', 'ORCID: 0000-0003-2741-4046', 'ORCID: 0000-0002-9354-9486', 'ORCID: 0000-0003-1317-984X']				"[""I have read the journal's policy and the authors of this manuscript have the"", 'following competing interests: CPL holds shares in whiterabbit.ai and Nines.ai,', 'is on the Advisory Board of Nuance Communications and on the Board of Directors', 'for the Radiological Society of North America, and has other research support', 'from Philips, GE Healthcare, and Philips Healthcare. MPL holds shares in and', 'serves on the Advisory Board for Nines.ai. None of these organizations have a', 'financial interest in the results of this study.']"		['2018/11/21 06:00']	20190422	20181120	2018 Nov	2018/11/21 06:00		['Rajpurkar, Pranav', 'Irvin, Jeremy', 'Ball, Robyn L', 'Zhu, Kaylie', 'Yang, Brandon', 'Mehta, Hershel', 'Duan, Tony', 'Ding, Daisy', 'Bagul, Aarti', 'Langlotz, Curtis P', 'Patel, Bhavik N', 'Yeom, Kristen W', 'Shpanskaya, Katie', 'Blankenberg, Francis G', 'Seekins, Jayne', 'Amrhein, Timothy J', 'Mong, David A', 'Halabi, Safwan S', 'Zucker, Evan J', 'Ng, Andrew Y', 'Lungren, Matthew P']		['R01 EB000898/EB/NIBIB NIH HHS/United States']	11		1549-1676 (Electronic) 1549-1277 (Linking)	101231360	PLoS medicine	['eng']	10.1371/journal.pmed.1002686 [doi]	20190614	['*Clinical Competence', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Humans', 'Pneumonia/*diagnostic imaging', 'Predictive Value of Tests', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Radiography, Thoracic/*methods', '*Radiologists', 'Reproducibility of Results', 'Retrospective Studies']	2019/04/23 06:00				NLM	e1002686	['2018/05/29 00:00 [received]', '2018/10/03 00:00 [accepted]', '2018/11/21 06:00 [entrez]', '2018/11/21 06:00 [pubmed]', '2019/04/23 06:00 [medline]']	United States	PMC6245676		30457988	epublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			IM		PLoS Med. 2018 Nov 20;15(11):e1002686. doi: 10.1371/journal.pmed.1002686. eCollection 2018 Nov.	MEDLINE	PLoS Med	Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists.		15	Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists.
BACKGROUND: Human Down syndrome (DS) is usually caused by genomic micro-duplications and dosage imbalances of human chromosome 21. It is associated with many genomic and phenotype abnormalities. Even though human DS occurs about 1 per 1,000 births worldwide, which is a very high rate, researchers haven't found any effective method to cure DS. Currently, the most efficient ways of human DS prevention are screening and early detection. METHODS: In this study, we used deep learning techniques and analyzed a set of Illumina genotyping array data. We built a bi-stream convolutional neural networks model to screen/predict the occurrence of DS. Firstly, we built image input data by converting the intensities of each SNP site into chromosome SNP maps. Next, we proposed a bi-stream convolutional neural network (CNN) architecture with nine layers and two branch models. We further merged two CNN branch models into one model in the fourth convolutional layer, and output the prediction in the last layer. RESULTS: Our bi-stream CNN model achieved 99.3% average accuracies, and very low false-positive and false-negative rates, which was necessary for further applications in disease prediction and medical practice. We further visualized the feature maps and learned filters from intermediate convolutional layers, which showed the genomic patterns and correlated SNPs variations in human DS genomes. We also compared our methods with other CNN and traditional machine learning models. We further analyzed and discussed the characteristics and strengths of our bi-stream CNN model. CONCLUSIONS: Our bi-stream model used two branch CNN models to learn the local genome features and regional patterns among adjacent genes and SNP sites from two chromosomes simultaneously. It achieved the best performance in all evaluating metrics when compared with two single-stream CNN models and three traditional machine-learning algorithms. The visualized feature maps also provided opportunities to study the genomic markers and pathway components associated with Human DS, which provided insights for gene therapy and genomic medicine developments.	"[""College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, People's Republic of China."", 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA.', 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA.', 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA.', ""School of Computer Science and Technology, Tianjin University, 300072, Tianjin, 300072, People's Republic of China."", 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA.', 'Vanderbilt University School of Medicine,Vanderbilt University, Nashville, 37232, TN, USA.', 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA.', 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA.', ""College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, People's Republic of China."", ""College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, People's Republic of China. jtang@cse.sc.edu."", 'Department of Computer Science and Engineering,University of South Carolina, Columbia, 29208, SC, USA. jtang@cse.sc.edu.', ""School of Computer Science and Technology, Tianjin University, 300072, Tianjin, 300072, People's Republic of China. jtang@cse.sc.edu."", 'School of Medicine,The University of New Mexico, Albuquerque, 87131, NM, USA. yaguo@salud.unm.edu.']"	['10.1186/s12920-018-0416-0 [doi]', '10.1186/s12920-018-0416-0 [pii]']	['Feng B', 'Hoskins W', 'Zhang Y', 'Meng Z', 'Samuels DC', 'Wang J', 'Xia R', 'Liu C', 'Tang J', 'Guo Y']							['2018/11/21 06:00']	20190529	20181120	2018 Nov 20	2018/11/21 06:00		['Feng, Bing', 'Hoskins, William', 'Zhang, Yan', 'Meng, Zibo', 'Samuels, David C', 'Wang, Jiandong', 'Xia, Ruofan', 'Liu, Chao', 'Tang, Jijun', 'Guo, Yan']		['P30 CA118100/CA/NCI NIH HHS/United States']	Suppl 5		1755-8794 (Electronic) 1755-8794 (Linking)	101319628	BMC medical genomics	['eng']	10.1186/s12920-018-0416-0 [doi]	20191008	['Chromosome Mapping', 'Deep Learning', 'Down Syndrome/*diagnosis/genetics', 'Genotype', 'Humans', '*Neural Networks (Computer)', 'Polymorphism, Single Nucleotide']	2019/05/30 06:00		['*Convolutional neural networks', '*Deep learning', '*Genotyping', '*Human down syndrome']	['NOTNLM']	NLM	105	['2018/11/21 06:00 [entrez]', '2018/11/21 06:00 [pubmed]', '2019/05/30 06:00 [medline]']	England	PMC6245487		30453947	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		BMC Med Genomics. 2018 Nov 20;11(Suppl 5):105. doi: 10.1186/s12920-018-0416-0.	MEDLINE	BMC Med Genomics	Bi-stream CNN Down Syndrome screening model based on genotyping array.		11	Bi-stream CNN Down Syndrome screening model based on genotyping array.
Lens-free digital in-line holography (LDIH) is a promising microscopic tool that overcomes several drawbacks (e.g., limited field of view) of traditional lens-based microcopy. However, extensive computation is required to reconstruct object images from the complex diffraction patterns produced by LDIH. This limits LDIH utility for point-of-care applications, particularly in resource limited settings. We describe a deep transfer learning (DTL) based approach to process LDIH images in the context of cellular analyses. Specifically, we captured holograms of cells labeled with molecular-specific microbeads and trained neural networks to classify these holograms without reconstruction. Using raw holograms as input, the trained networks were able to classify individual cells according to the number of cell-bound microbeads. The DTL-based approach including a VGG19 pretrained network showed robust performance with experimental data. Combined with the developed DTL approach, LDIH could be realized as a low-cost, portable tool for point-of-care diagnostics.	['Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA.', 'Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA.', 'Department of Computer Science, Worcester Polytechnic Institute, Worcester, Massachusetts, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA.', 'Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA.', 'Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, USA.', 'Department of Systems Biology, Harvard Medical School, Boston, Massachusetts, USA.', 'Center for Systems Biology, Massachusetts General Hospital, Boston, Massachusetts, USA. hlee@mgh.harvard.edu.', 'Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, USA. hlee@mgh.harvard.edu.', 'Department of Biomedical Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA. klee@wpi.edu.', 'Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Worcester, Massachusetts, USA. klee@wpi.edu.']	['10.1038/s41598-018-35274-x [doi]', '10.1038/s41598-018-35274-x [pii]']	['Kim SJ', 'Wang C', 'Zhao B', 'Im H', 'Min J', 'Choi HJ', 'Tadros J', 'Choi NR', 'Castro CM', 'Weissleder R', 'Lee H', 'Lee K']	['ORCID: http://orcid.org/0000-0002-0626-1346', 'ORCID: http://orcid.org/0000-0002-6737-7254', 'ORCID: http://orcid.org/0000-0002-0087-0909', 'ORCID: http://orcid.org/0000-0001-6838-7094']						['2018/11/20 06:00']	20191031	20181119	2018 Nov 19	2018/11/20 06:00		['Kim, Sung-Jin', 'Wang, Chuangqi', 'Zhao, Bing', 'Im, Hyungsoon', 'Min, Jouha', 'Choi, Hee June', 'Tadros, Joseph', 'Choi, Nu Ri', 'Castro, Cesar M', 'Weissleder, Ralph', 'Lee, Hakho', 'Lee, Kwonmoo']		['T32 CA079443/CA/NCI NIH HHS/United States', 'R01 CA229777/CA/NCI NIH HHS/United States', 'R01 EB010011/EB/NIBIB NIH HHS/United States', 'K99 CA201248/CA/NCI NIH HHS/United States', 'R01 CA204019/CA/NCI NIH HHS/United States', 'UH3 CA202637/CA/NCI NIH HHS/United States', 'U01 CA233360/CA/NCI NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-35274-x [doi]	20191119	['*Algorithms', 'Biomarkers, Tumor/metabolism', '*Deep Learning', 'Holography/*methods', 'Humans', 'Image Enhancement', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Neoplasms/*classification/*diagnosis/metabolism', 'Neural Networks (Computer)', 'Pathology, Molecular', 'Tumor Cells, Cultured']	2019/11/02 06:00				NLM	17003	['2018/03/27 00:00 [received]', '2018/11/02 00:00 [accepted]', '2018/11/20 06:00 [entrez]', '2018/11/20 06:00 [pubmed]', '2019/11/02 06:00 [medline]']	England	PMC6242900		30451953	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (Biomarkers, Tumor)']	IM		Sci Rep. 2018 Nov 19;8(1):17003. doi: 10.1038/s41598-018-35274-x.	MEDLINE	Sci Rep	Deep transfer learning-based hologram classification for molecular diagnostics.		8	Deep transfer learning-based hologram classification for molecular diagnostics.
Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.	['Computer Science Department, Bahria University, E-8 Islamabad 44000, Pakistan. shehlasaif7@gmail.com.', 'Computer Science Department, Bahria University, E-8 Islamabad 44000, Pakistan. stehseen.buic@bahria.edu.pk.', 'Computer Science Department, Bahria University, E-8 Islamabad 44000, Pakistan. sumairakausar@bui.edu.pk.']	['s18113979 [pii]', '10.3390/s18113979 [doi]']	['Saif S', 'Tehseen S', 'Kausar S']							['2018/11/18 06:00']	20181211	20181115	2018 Nov 15	2018/11/18 06:00		['Saif, Shahela', 'Tehseen, Samabia', 'Kausar, Sumaira']			11		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E3979 [pii] 10.3390/s18113979 [doi]	20181217	['*Deep Learning', '*Human Activities', 'Humans', 'Spatio-Temporal Analysis', 'Surveys and Questionnaires', '*Visual Perception']	2018/12/12 06:00		['action recognition', 'computer vision', 'deep learning', 'visual action recognition']	['NOTNLM']	NLM		['2018/09/29 00:00 [received]', '2018/10/24 00:00 [revised]', '2018/11/09 00:00 [accepted]', '2018/11/18 06:00 [entrez]', '2018/11/18 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	Switzerland	PMC6263411		30445801	epublish	['Journal Article', 'Review']			IM		Sensors (Basel). 2018 Nov 15;18(11). pii: s18113979. doi: 10.3390/s18113979.	MEDLINE	Sensors (Basel)	A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.		18	A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.
Objectives: Scoring laboratory polysomnography (PSG) data remains a manual task of visually annotating 3 primary categories: sleep stages, sleep disordered breathing, and limb movements. Attempts to automate this process have been hampered by the complexity of PSG signals and physiological heterogeneity between patients. Deep neural networks, which have recently achieved expert-level performance for other complex medical tasks, are ideally suited to PSG scoring, given sufficient training data. Methods: We used a combination of deep recurrent and convolutional neural networks (RCNN) for supervised learning of clinical labels designating sleep stages, sleep apnea events, and limb movements. The data for testing and training were derived from 10 000 clinical PSGs and 5804 research PSGs. Results: When trained on the clinical dataset, the RCNN reproduces PSG diagnostic scoring for sleep staging, sleep apnea, and limb movements with accuracies of 87.6%, 88.2% and 84.7% on held-out test data, a level of performance comparable to human experts. The RCNN model performs equally well when tested on the independent research PSG database. Only small reductions in accuracy were noted when training on limited channels to mimic at-home monitoring devices: frontal leads only for sleep staging, and thoracic belt signals only for the apnea-hypopnea index. Conclusions: By creating accurate deep learning models for sleep scoring, our work opens the path toward broader and more timely access to sleep diagnostics. Accurate scoring automation can improve the utility and efficiency of in-lab and at-home approaches to sleep diagnostics, potentially extending the reach of sleep expertise beyond specialty clinics.	['School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, USA.', 'Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, USA.', 'Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, USA.', 'Division of Sleep Medicine, Harvard Medical School, Boston, MA, USA.', 'Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, USA.', 'School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, USA.', 'Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, USA.', 'Division of Sleep Medicine, Harvard Medical School, Boston, MA, USA.']	['5185596 [pii]', '10.1093/jamia/ocy131 [doi]']	['Biswal S', 'Sun H', 'Goparaju B', 'Westover MB', 'Sun J', 'Bianchi MT']							['2018/11/17 06:00']	20191129		2018 Dec 1	2018/11/18 06:00		['Biswal, Siddharth', 'Sun, Haoqi', 'Goparaju, Balaji', 'Westover, M Brandon', 'Sun, Jimeng', 'Bianchi, Matt T']		['K23 NS090900/NS/NINDS NIH HHS/United States', 'R01 MD011682/MD/NIMHD NIH HHS/United States', 'R56 HL138415/HL/NHLBI NIH HHS/United States']	12		1527-974X (Electronic) 1067-5027 (Linking)	9430800	Journal of the American Medical Informatics Association : JAMIA	['eng']	10.1093/jamia/ocy131 [doi]	20191129	['Classification', 'Datasets as Topic', '*Electroencephalography', 'Humans', 'Machine Learning', 'Models, Biological', '*Neural Networks (Computer)', 'Polysomnography/*methods', 'Sleep/physiology', 'Sleep Apnea Syndromes/*diagnosis/physiopathology', 'Sleep Stages/*physiology']	2019/11/30 06:00				NLM	1643-1650	['2018/04/10 00:00 [received]', '2018/09/21 00:00 [accepted]', '2018/11/18 06:00 [pubmed]', '2019/11/30 06:00 [medline]', '2018/11/17 06:00 [entrez]']	England	PMC6289549		30445569	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		J Am Med Inform Assoc. 2018 Dec 1;25(12):1643-1650. doi: 10.1093/jamia/ocy131.	MEDLINE	J Am Med Inform Assoc	Expert-level sleep scoring with deep neural networks.		25	Expert-level sleep scoring with deep neural networks.
BACKGROUND: Although artificial intelligence performs promisingly in medicine, few automatic disease diagnosis platforms can clearly explain why a specific medical decision is made. OBJECTIVE: We aimed to devise and develop an interpretable and expandable diagnosis framework for automatically diagnosing multiple ocular diseases and providing treatment recommendations for the particular illness of a specific patient. METHODS: As the diagnosis of ocular diseases highly depends on observing medical images, we chose ophthalmic images as research material. All medical images were labeled to 4 types of diseases or normal (total 5 classes); each image was decomposed into different parts according to the anatomical knowledge and then annotated. This process yields the positions and primary information on different anatomical parts and foci observed in medical images, thereby bridging the gap between medical image and diagnostic process. Next, we applied images and the information produced during the annotation process to implement an interpretable and expandable automatic diagnostic framework with deep learning. RESULTS: This diagnosis framework comprises 4 stages. The first stage identifies the type of disease (identification accuracy, 93%). The second stage localizes the anatomical parts and foci of the eye (localization accuracy: images under natural light without fluorescein sodium eye drops, 82%; images under cobalt blue light or natural light with fluorescein sodium eye drops, 90%). The third stage carefully classifies the specific condition of each anatomical part or focus with the result from the second stage (average accuracy for multiple classification problems, 79%-98%). The last stage provides treatment advice according to medical experience and artificial intelligence, which is merely involved with pterygium (accuracy, >95%). Based on this, we developed a telemedical system that can show detailed reasons for a particular diagnosis to doctors and patients to help doctors with medical decision making. This system can carefully analyze medical images and provide treatment advices according to the analysis results and consultation between a doctor and a patient. CONCLUSIONS: The interpretable and expandable medical artificial intelligence platform was successfully built; this system can identify the disease, distinguish different anatomical parts and foci, discern the diagnostic information relevant to the diagnosis of diseases, and provide treatment suggestions. During this process, the whole diagnostic flow becomes clear and understandable to both doctors and their patients. Moreover, other diseases can be seamlessly integrated into this system without any influence on existing modules or diseases. Furthermore, this framework can assist in the clinical training of junior doctors. Owing to the rare high-grade medical resource, it is impossible that everyone receives high-quality professional diagnosis and treatment service. This framework can not only be applied in hospitals with insufficient medical resources to decrease the pressure on experienced doctors but also deployed in remote areas to help doctors diagnose common ocular diseases.	"[""School of Computer Science and Technology, Xidian University, Xi'an, China."", 'State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China.', ""School of Computer Science and Technology, Xidian University, Xi'an, China."", ""School of Software, Xidian University, Xi'an, China."", ""Institute of Software Engineering, Xidian University, Xi'an, China."", ""School of Software, Xidian University, Xi'an, China."", ""School of Computer Science and Technology, Xidian University, Xi'an, China."", ""School of Computer Science and Technology, Xidian University, Xi'an, China."", 'State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China.', 'State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China.', ""School of Software, Xidian University, Xi'an, China."", ""School of Computer Science and Technology, Xidian University, Xi'an, China."", 'State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China.', 'State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China.', 'State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China.']"	['v20i11e11144 [pii]', '10.2196/11144 [doi]']	['Zhang K', 'Liu X', 'Liu F', 'He L', 'Zhang L', 'Yang Y', 'Li W', 'Wang S', 'Liu L', 'Liu Z', 'Wu X', 'Lin H']	['ORCID: 0000-0001-9054-288X', 'ORCID: 0000-0001-5214-3677', 'ORCID: 0000-0002-9627-1125', 'ORCID: 0000-0003-0588-4098', 'ORCID: 0000-0002-6428-3287', 'ORCID: 0000-0003-3870-1235', 'ORCID: 0000-0001-7070-5768', 'ORCID: 0000-0003-2751-0812', 'ORCID: 0000-0003-2940-9830', 'ORCID: 0000-0002-4853-2474', 'ORCID: 0000-0002-9398-4330', 'ORCID: 0000-0003-4672-9721']	['(c)Kai Zhang, Xiyang Liu, Fan Liu, Lin He, Lei Zhang, Yahan Yang, Wangting Li,', 'Shuai Wang, Lin Liu, Zhenzhen Liu, Xiaohang Wu, Haotian Lin. Originally published', 'in the Journal of Medical Internet Research (http://www.jmir.org), 14.11.2018.']					['2018/11/16 06:00']	20190829	20181114	2018 Nov 14	2018/11/16 06:00		['Zhang, Kai', 'Liu, Xiyang', 'Liu, Fan', 'He, Lin', 'Zhang, Lei', 'Yang, Yahan', 'Li, Wangting', 'Wang, Shuai', 'Liu, Lin', 'Liu, Zhenzhen', 'Wu, Xiaohang', 'Lin, Haotian']			11		1438-8871 (Electronic) 1438-8871 (Linking)	100959882	Journal of medical Internet research	['eng']	10.2196/11144 [doi]	20190829	['Deep Learning/*trends', 'Eye Diseases/classification/*diagnosis', 'Humans', '*Qualitative Research']	2019/08/30 06:00		['*deep learning', '*interpretable and expandable diagnosis framework', '*making medical decisions', '*multiple ocular diseases', '*object localization']	['NOTNLM']	NLM	e11144	['2018/05/26 00:00 [received]', '2018/08/02 00:00 [accepted]', '2018/07/31 00:00 [revised]', '2018/11/16 06:00 [entrez]', '2018/11/16 06:00 [pubmed]', '2019/08/30 06:00 [medline]']	Canada	PMC6301833		30429111	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Med Internet Res. 2018 Nov 14;20(11):e11144. doi: 10.2196/11144.	MEDLINE	J Med Internet Res	An Interpretable and Expandable Deep Learning Diagnostic System for Multiple Ocular Diseases: Qualitative Study.		20	An Interpretable and Expandable Deep Learning Diagnostic System for Multiple Ocular Diseases: Qualitative Study.
	"['1 Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer Institute, Boston, MA, USA.', '2 Harvard T. H. Chan School of Public Health, Boston, MA, USA.', '1 Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer Institute, Boston, MA, USA.', '3 Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', '4 College of Science and Mathematics, University of Massachusetts Boston, Boston, MA, USA.', '2 Harvard T. H. Chan School of Public Health, Boston, MA, USA.', '2 Harvard T. H. Chan School of Public Health, Boston, MA, USA.', ""5 Division of Pulmonary and Critical Care Medicine, Department of Medicine, Brigham and Women's Hospital, Boston, MA, USA."", '6 Division of General Internal Medicine and Health Services Research, David Geffen School of Medicine, University of California, Los Angeles, Los Angeles, CA, USA.', '7 Palliative Care, VA Greater Los Angeles Healthcare System, Los Angeles, CA, USA.', '1 Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer Institute, Boston, MA, USA.', ""8 Division of Palliative Medicine, Department of Medicine, Brigham and Women's Hospital, Boston, MA, USA."", '1 Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer Institute, Boston, MA, USA.', ""8 Division of Palliative Medicine, Department of Medicine, Brigham and Women's Hospital, Boston, MA, USA.""]"	['10.1177/0269216318810421 [doi]']	['Chan A', 'Chien I', 'Moseley E', 'Salman S', 'Kaminer Bourland S', 'Lamas D', 'Walling AM', 'Tulsky JA', 'Lindvall C']	['ORCID: 0000-0002-2116-4544']						['2018/11/15 06:00']	20191202	20181114	2019 Feb	2018/11/15 06:00		['Chan, Alex', 'Chien, Isabel', 'Moseley, Edward', 'Salman, Saad', 'Kaminer Bourland, Sarah', 'Lamas, Daniela', 'Walling, Anne M', 'Tulsky, James A', 'Lindvall, Charlotta']			2		1477-030X (Electronic) 0269-2163 (Linking)	8704926	Palliative medicine	['eng']	10.1177/0269216318810421 [doi]	20191202	['Admitting Department, Hospital/*standards', 'Adult', 'Algorithms', 'Boston', 'Critical Care/*standards', 'Deep Learning/*standards', 'Documentation/*standards', 'Female', '*Guidelines as Topic', 'Health Personnel/*education', 'Humans', 'Intensive Care Units/*standards', 'Male', 'Middle Aged']	2019/12/04 06:00		['*Quality indicators (healthcare)', '*advance care planning', '*end-of-life care', '*intensive care units', '*machine learning']	['NOTNLM']	NLM	187-196	['2018/11/15 06:00 [pubmed]', '2019/12/04 06:00 [medline]', '2018/11/15 06:00 [entrez]']	England			30427267	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Palliat Med. 2019 Feb;33(2):187-196. doi: 10.1177/0269216318810421. Epub 2018 Nov 14.	MEDLINE	Palliat Med	Deep learning algorithms to identify documentation of serious illness conversations during intensive care unit admissions.		33	Deep learning algorithms to identify documentation of serious illness conversations during intensive care unit admissions.
Acute coronary syndrome (ACS) is a syndrome caused by a decrease in blood flow in the coronary arteries. The ACS is usually related to coronary thrombosis and is primarily caused by plaque rupture followed by plaque erosion and calcified nodule. Thin-cap fibroatheroma (TCFA) is known to be the most similar lesion morphologically to a plaque rupture. In this paper, we propose methods to classify TCFA using various machine learning classifiers including feed-forward neural network (FNN), K-nearest neighbor (KNN), random forest (RF), and convolutional neural network (CNN) to figure out a classifier that shows optimal TCFA classification accuracy. In addition, we suggest pixel range-based feature extraction method to extract the ratio of pixels in the different region of interests to reflect the physician's TCFA discrimination criteria. Our feature extraction method examines the pixel distribution of the intravascular ultrasound (IVUS) image at a given ROI, which allows us to extract general characteristics of the IVUS image while simultaneously reflecting the different properties of the vessel's substances such as necrotic core and calcified nodule depending on the brightness of the pixel. A total of 12,325 IVUS images were labeled with corresponding optical coherence tomography (OCT) images to train and evaluate the classifiers. We achieved 0.859, 0.848, 0.844, and 0.911 area under the ROC curve (AUC) in the order of using FNN, KNN, RF, and CNN classifiers. As a result, the CNN classifier performed best and the top 10 features of the feature-based classifiers (FNN, KNN, RF) were found to be similar to the physician's TCFA diagnostic criteria. Graphical Abstract AUC result of proposed classifiers.	['School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea. taejoon89@kaist.ac.kr.', 'Division of Cardiology, University of Ulsan College of Medicine, Asan Medical Center, Seoul, Republic of Korea.', 'Asan Institute for Life Sciences, Asan Medical Center, Seoul, Republic of Korea.', 'Division of Cardiology, University of Ulsan College of Medicine, Asan Medical Center, Seoul, Republic of Korea.', 'Division of Cardiology, University of Ulsan College of Medicine, Asan Medical Center, Seoul, Republic of Korea.', 'School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea.', 'School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea.', 'School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea.', 'Division of Cardiology, University of Ulsan College of Medicine, Asan Medical Center, Seoul, Republic of Korea.']	['10.1007/s11517-018-1925-x [doi]', '10.1007/s11517-018-1925-x [pii]']	['Jun TJ', 'Kang SJ', 'Lee JG', 'Kweon J', 'Na W', 'Kang D', 'Kim D', 'Kim D', 'Kim YH']	['ORCID: http://orcid.org/0000-0002-6808-5149']						['2018/11/15 06:00']	20190725	20181114	2019 Apr	2018/11/15 06:00		['Jun, Tae Joon', 'Kang, Soo-Jin', 'Lee, June-Goo', 'Kweon, Jihoon', 'Na, Wonjun', 'Kang, Daeyoun', 'Kim, Dohyeun', 'Kim, Daeyoung', 'Kim, Young-Hak']		['2016K1A3A7A03952054/Ministry of Science, ICT and Future Planning (KR)']	4		1741-0444 (Electronic) 0140-0118 (Linking)	7704869	Medical & biological engineering & computing	['eng']	10.1007/s11517-018-1925-x [doi]	20190725	['Algorithms', 'Area Under Curve', 'Automation', 'Humans', '*Image Processing, Computer-Assisted', 'Neural Networks (Computer)', 'Plaque, Atherosclerotic/*diagnosis/*diagnostic imaging', 'Reproducibility of Results', 'Tomography, Optical Coherence', '*Ultrasonography, Interventional']	2019/07/26 06:00		['Deep learning', 'Intravascular ultrasound', 'Machine learning', 'Optical coherence tomography', 'Vulnerable plaque']	['NOTNLM']	NLM	863-876	['2018/04/18 00:00 [received]', '2018/10/30 00:00 [accepted]', '2018/11/15 06:00 [pubmed]', '2019/07/26 06:00 [medline]', '2018/11/15 06:00 [entrez]']	United States			30426362	ppublish	['Journal Article']					Med Biol Eng Comput. 2019 Apr;57(4):863-876. doi: 10.1007/s11517-018-1925-x. Epub 2018 Nov 14.	MEDLINE	Med Biol Eng Comput	Automated detection of vulnerable plaque in intravascular ultrasound images.		57	Automated detection of vulnerable plaque in intravascular ultrasound images.
N (6)-Methyladenosine (m(6)A) refers to methylation modification of the adenosine nucleotide acid at the nitrogen-6 position. Many conventional computational methods for identifying N (6)-methyladenosine sites are limited by the small amount of data available. Taking advantage of the thousands of m(6)A sites detected by high-throughput sequencing, it is now possible to discover the characteristics of m(6)A sequences using deep learning techniques. To the best of our knowledge, our work is the first attempt to use word embedding and deep neural networks for m(6)A prediction from mRNA sequences. Using four deep neural networks, we developed a model inferred from a larger sequence shifting window that can predict m(6)A accurately and robustly. Four prediction schemes were built with various RNA sequence representations and optimized convolutional neural networks. The soft voting results from the four deep networks were shown to outperform all of the state-of-the-art methods. We evaluated these predictors mentioned above on a rigorous independent test data set and proved that our proposed method outperforms the state-of-the-art predictors. The training, independent, and cross-species testing data sets are much larger than in previous studies, which could help to avoid the problem of overfitting. Furthermore, an online prediction web server implementing the four proposed predictors has been built and is available at http://server.malab.cn/Gene2vec/.	['Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China, 610051 Chengdu, China.', 'School of Computer Science and Technology, Tianjin University, 300350 Tianjin, China.', 'School of Computer Science and Technology, Tianjin University, 300350 Tianjin, China.', 'School of Computer Science and Technology, Tianjin University, 300350 Tianjin, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, 150001 Shenzhen, China.']	['rna.069112.118 [pii]', '10.1261/rna.069112.118 [doi]']	['Zou Q', 'Xing P', 'Wei L', 'Liu B']	['ORCID: 0000-0001-6406-1142']	['(c) 2019 Zou et al.; Published by Cold Spring Harbor Laboratory Press for the RNA', 'Society.']					['2018/11/15 06:00']	20190320	20181113	2019 Feb	2018/11/15 06:00		['Zou, Quan', 'Xing, Pengwei', 'Wei, Leyi', 'Liu, Bin']			2		1469-9001 (Electronic) 1355-8382 (Linking)	9509184	RNA (New York, N.Y.)	['eng']	10.1261/rna.069112.118 [doi]	20190320	['Adenosine/*analogs & derivatives/genetics', 'Base Sequence/genetics', 'Computational Biology/*methods', 'High-Throughput Nucleotide Sequencing', 'Machine Learning', 'Models, Theoretical', 'Neural Networks (Computer)', 'RNA, Messenger/*genetics/*metabolism', 'Sequence Analysis, RNA/*methods']	2019/03/21 06:00		['*N6-methyladenosine', '*RNA word embedding', '*deep learning', '*mRNA', '*machine learning']	['NOTNLM']	NLM	205-218	['2018/10/03 00:00 [received]', '2018/11/01 00:00 [accepted]', '2020/02/01 00:00 [pmc-release]', '2018/11/15 06:00 [pubmed]', '2019/03/21 06:00 [medline]', '2018/11/15 06:00 [entrez]']	United States	PMC6348985	['2020/02/01 00:00']	30425123	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA, Messenger)', '1867-73-8 (N(6)-methyladenosine)', 'K72T3FS567 (Adenosine)']	IM		RNA. 2019 Feb;25(2):205-218. doi: 10.1261/rna.069112.118. Epub 2018 Nov 13.	MEDLINE	RNA	Gene2vec: gene subsequence embedding for prediction of mammalian N (6)-methyladenosine sites from mRNA.		25	Gene2vec: gene subsequence embedding for prediction of mammalian N (6)-methyladenosine sites from mRNA.
BACKGROUND: An increasing number of doctor reviews are being generated by patients on the internet. These reviews address a diverse set of topics (features), including wait time, office staff, doctor's skills, and bedside manners. Most previous work on automatic analysis of Web-based customer reviews assumes that (1) product features are described unambiguously by a small number of keywords, for example, battery for phones and (2) the opinion for each feature has a positive or negative sentiment. However, in the domain of doctor reviews, this setting is too restrictive: a feature such as visit duration for doctor reviews may be expressed in many ways and does not necessarily have a positive or negative sentiment. OBJECTIVE: This study aimed to adapt existing and propose novel text classification methods on the domain of doctor reviews. These methods are evaluated on their accuracy to classify a diverse set of doctor review features. METHODS: We first manually examined a large number of reviews to extract a set of features that are frequently mentioned in the reviews. Then we proposed a new algorithm that goes beyond bag-of-words or deep learning classification techniques by leveraging natural language processing (NLP) tools. Specifically, our algorithm automatically extracts dependency tree patterns and uses them to classify review sentences. RESULTS: We evaluated several state-of-the-art text classification algorithms as well as our dependency tree-based classifier algorithm on a real-world doctor review dataset. We showed that methods using deep learning or NLP techniques tend to outperform traditional bag-of-words methods. In our experiments, the 2 best methods used NLP techniques; on average, our proposed classifier performed 2.19% better than an existing NLP-based method, but many of its predictions of specific opinions were incorrect. CONCLUSIONS: We conclude that it is feasible to classify doctor reviews. Automatically classifying these reviews would allow patients to easily search for doctors based on their personal preference criteria.	['Department of Computer Science and Engineering, University of California, Riverside, Riverside, CA, United States.', 'Department of Computer Science and Engineering, University of California, Riverside, Riverside, CA, United States.', 'Department of Computer Science and Engineering, University of California, Riverside, Riverside, CA, United States.', 'Department of Computer Science and Engineering, University of California, Riverside, Riverside, CA, United States.']	['v20i11e11141 [pii]', '10.2196/11141 [doi]']	['Rivas R', 'Montazeri N', 'Le NX', 'Hristidis V']	['ORCID: 0000-0001-5590-0274', 'ORCID: 0000-0002-9755-598X', 'ORCID: 0000-0001-9406-8716', 'ORCID: 0000-0001-8679-4988']	['(c)Ryan Rivas, Niloofar Montazeri, Nhat XT Le, Vagelis Hristidis. Originally', 'published in the Journal of Medical Internet Research (http://www.jmir.org),', '12.11.2018.']					['2018/11/15 06:00']	20190829	20181112	2018 Nov 12	2018/11/15 06:00		['Rivas, Ryan', 'Montazeri, Niloofar', 'Le, Nhat Xt', 'Hristidis, Vagelis']			11		1438-8871 (Electronic) 1438-8871 (Linking)	100959882	Journal of medical Internet research	['eng']	10.2196/11141 [doi]	20190829	['Algorithms', 'Attitude', 'Humans', 'Internet', 'Language', 'Machine Learning/*standards', 'Patient Reported Outcome Measures', 'Physicians', 'Quality Indicators, Health Care/*standards', '*Review Literature as Topic']	2019/08/30 06:00		['*patient reported outcome measures', '*patient satisfaction', '*quality indicators, health care', '*supervised machine learning']	['NOTNLM']	NLM	e11141	['2018/05/30 00:00 [received]', '2018/09/04 00:00 [accepted]', '2018/08/21 00:00 [revised]', '2018/11/15 06:00 [entrez]', '2018/11/15 06:00 [pubmed]', '2019/08/30 06:00 [medline]']	Canada	PMC6256102		30425030	epublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		J Med Internet Res. 2018 Nov 12;20(11):e11141. doi: 10.2196/11141.	MEDLINE	J Med Internet Res	Automatic Classification of Online Doctor Reviews: Evaluation of Text Classifier Algorithms.		20	Automatic Classification of Online Doctor Reviews: Evaluation of Text Classifier Algorithms.
In this paper, the effectiveness of deep learning for automatic classification of grouper species by their vocalizations has been investigated. In the proposed approach, wavelet denoising is used to reduce ambient ocean noise, and a deep neural network is then used to classify sounds generated by different species of groupers. Experimental results for four species of groupers show that the proposed approach achieves a classification accuracy of around 90% or above in all of the tested cases, a result that is significantly better than the one obtained by a previously reported method for automatic classification of grouper calls.	['Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, 777 Glades Road, Boca Raton, Florida 33431, USA Aibrahim2014@fau.edu, zhuang@fau.edu.', 'Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, 777 Glades Road, Boca Raton, Florida 33431, USA Aibrahim2014@fau.edu, zhuang@fau.edu.', 'Harbor Branch Oceanographic Institute, Florida Atlantic University, 5600 US1 North, Fort Pierce, Florida 34946, USA lcherubin@fau.edu.', 'HJR Reefscaping, P.O. Box 1442, Boqueron 00622, Puerto Rico michelle.scharer@upr.edu.', 'Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, 777 Glades Road, Boca Raton, Florida 33431, USA erdol@fau.edu.']	['10.1121/1.5054911 [doi]']	['Ibrahim AK', 'Zhuang H', 'Cherubin LM', 'Scharer-Umpierre MT', 'Erdol N']							['2018/11/15 06:00']	20191107		2018 Sep	2018/11/15 06:00		['Ibrahim, Ali K', 'Zhuang, Hanqi', 'Cherubin, Laurent M', 'Scharer-Umpierre, Michelle T', 'Erdol, Nurgun']			3		1520-8524 (Electronic) 0001-4966 (Linking)	7503051	The Journal of the Acoustical Society of America	['eng']	10.1121/1.5054911 [doi]	20191107	['Animals', 'Deep Learning/*classification', 'Fishes', '*Neural Networks (Computer)', '*Sound', 'Vocalization, Animal/*physiology']	2019/11/08 06:00				NLM	EL196	['2018/11/15 06:00 [entrez]', '2018/11/15 06:00 [pubmed]', '2019/11/08 06:00 [medline]']	United States			30424627	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		J Acoust Soc Am. 2018 Sep;144(3):EL196. doi: 10.1121/1.5054911.	MEDLINE	J Acoust Soc Am	Automatic classification of grouper species by their sounds using deep neural networks.		144	Automatic classification of grouper species by their sounds using deep neural networks.
Recently, deep learning based speech segregation has been shown to improve human speech intelligibility in noisy environments. However, one important factor not yet considered is room reverberation, which characterizes typical daily environments. The combination of reverberation and background noise can severely degrade speech intelligibility for hearing-impaired (HI) listeners. In the current study, a deep learning based time-frequency masking algorithm was proposed to address both room reverberation and background noise. Specifically, a deep neural network was trained to estimate the ideal ratio mask, where anechoic-clean speech was considered as the desired signal. Intelligibility testing was conducted under reverberant-noisy conditions with reverberation time T 60 = 0.6 s, plus speech-shaped noise or babble noise at various signal-to-noise ratios. The experiments demonstrated that substantial speech intelligibility improvements were obtained for HI listeners. The algorithm was also somewhat beneficial for normal-hearing (NH) listeners. In addition, sentence intelligibility scores for HI listeners with algorithm processing approached or matched those of young-adult NH listeners without processing. The current study represents a step toward deploying deep learning algorithms to help the speech understanding of HI listeners in everyday conditions.	['Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Speech and Hearing Science, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Speech and Hearing Science, The Ohio State University, Columbus, Ohio 43210, USA.']	['10.1121/1.5055562 [doi]']	['Zhao Y', 'Wang D', 'Johnson EM', 'Healy EW']							['2018/11/15 06:00']	20191107		2018 Sep	2018/11/15 06:00		['Zhao, Yan', 'Wang, DeLiang', 'Johnson, Eric M', 'Healy, Eric W']		['R01 DC015521/DC/NIDCD NIH HHS/United States']	3		1520-8524 (Electronic) 0001-4966 (Linking)	7503051	The Journal of the Acoustical Society of America	['eng']	10.1121/1.5055562 [doi]	20191107	['Aged', '*Algorithms', '*Deep Learning', 'Female', 'Hearing Aids', 'Hearing Loss, Sensorineural/physiopathology/*therapy', 'Humans', 'Male', 'Middle Aged', '*Noise/adverse effects', 'Perceptual Masking/*physiology', 'Speech Intelligibility/*physiology', 'Young Adult']	2019/11/08 06:00				NLM	1627	['2018/11/15 06:00 [entrez]', '2018/11/15 06:00 [pubmed]', '2019/11/08 06:00 [medline]']	United States	PMC6167229		30424625	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		J Acoust Soc Am. 2018 Sep;144(3):1627. doi: 10.1121/1.5055562.	MEDLINE	J Acoust Soc Am	A deep learning based segregation algorithm to increase speech intelligibility for hearing-impaired listeners in reverberant-noisy conditions.		144	A deep learning based segregation algorithm to increase speech intelligibility for hearing-impaired listeners in reverberant-noisy conditions.
Motivation: The complexes formed by binding of proteins to RNAs play key roles in many biological processes, such as splicing, gene expression regulation, translation and viral replication. Understanding protein-RNA binding may thus provide important insights to the functionality and dynamics of many cellular processes. This has sparked substantial interest in exploring protein-RNA binding experimentally, and predicting it computationally. The key computational challenge is to efficiently and accurately infer protein-RNA binding models that will enable prediction of novel protein-RNA interactions to additional transcripts of interest. Results: We developed DLPRB (Deep Learning for Protein-RNA Binding), a new deep neural network (DNN) approach for learning intrinsic protein-RNA binding preferences and predicting novel interactions. We present two different network architectures: a convolutional neural network (CNN), and a recurrent neural network (RNN). The novelty of our network hinges upon two key aspects: (i) the joint analysis of both RNA sequence and structure, which is represented as a probability vector of different RNA structural contexts; (ii) novel features in the architecture of the networks, such as the application of RNNs to RNA-binding prediction, and the combination of hundreds of variable-length filters in the CNN. Our results in inferring accurate RNA-binding models from high-throughput in vitro data exhibit substantial improvements, compared to all previous approaches for protein-RNA binding prediction (both DNN and non-DNN based). A more modest, yet statistically significant, improvement is achieved for in vivo binding prediction. When incorporating experimentally-measured RNA structure, compared to predicted one, the improvement on in vivo data increases. By visualizing the binding specificities, we can gain biological insights underlying the mechanism of protein RNA-binding. Availability and implementation: The source code is publicly available at https://github.com/ilanbb/dlprb. Supplementary information: Supplementary data are available at Bioinformatics online.	['Blavatnik School of Computer Science, Tel-Aviv University, Tel-Aviv, Israel.', 'Blavatnik School of Computer Science, Tel-Aviv University, Tel-Aviv, Israel.', 'Department of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel.']	['5093226 [pii]', '10.1093/bioinformatics/bty600 [doi]']	['Ben-Bassat I', 'Chor B', 'Orenstein Y']							['2018/11/14 06:00']	20190923		2018 Sep 1	2018/11/14 06:00		['Ben-Bassat, Ilan', 'Chor, Benny', 'Orenstein, Yaron']			17		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty600 [doi]	20190923	['*Deep Learning', '*Neural Networks (Computer)', 'RNA/*metabolism', 'RNA-Binding Proteins/*metabolism', 'Software']	2019/09/24 06:00				NLM	i638-i646	['2018/11/14 06:00 [entrez]', '2018/11/14 06:00 [pubmed]', '2019/09/24 06:00 [medline]']	England			30423078	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA-Binding Proteins)', '63231-63-0 (RNA)']	IM		Bioinformatics. 2018 Sep 1;34(17):i638-i646. doi: 10.1093/bioinformatics/bty600.	MEDLINE	Bioinformatics	A deep neural network approach for learning intrinsic protein-RNA binding preferences.		34	A deep neural network approach for learning intrinsic protein-RNA binding preferences.
Motivation: Computational methods that predict differential gene expression from histone modification signals are highly desirable for understanding how histone modifications control the functional heterogeneity of cells through influencing differential gene regulation. Recent studies either failed to capture combinatorial effects on differential prediction or primarily only focused on cell type-specific analysis. In this paper we develop a novel attention-based deep learning architecture, DeepDiff, that provides a unified and end-to-end solution to model and to interpret how dependencies among histone modifications control the differential patterns of gene regulation. DeepDiff uses a hierarchy of multiple Long Short-Term Memory (LSTM) modules to encode the spatial structure of input signals and to model how various histone modifications cooperate automatically. We introduce and train two levels of attention jointly with the target prediction, enabling DeepDiff to attend differentially to relevant modifications and to locate important genome positions for each modification. Additionally, DeepDiff introduces a novel deep-learning based multi-task formulation to use the cell-type-specific gene expression predictions as auxiliary tasks, encouraging richer feature embeddings in our primary task of differential expression prediction. Results: Using data from Roadmap Epigenomics Project (REMC) for ten different pairs of cell types, we show that DeepDiff significantly outperforms the state-of-the-art baselines for differential gene expression prediction. The learned attention weights are validated by observations from previous studies about how epigenetic mechanisms connect to differential gene expression. Availability and implementation: Codes and results are available at deepchrome.org. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of Virginia, Charlottesville, VA, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA, USA.']	['5093224 [pii]', '10.1093/bioinformatics/bty612 [doi]']	['Sekhon A', 'Singh R', 'Qi Y']							['2018/11/14 06:00']	20190930		2018 Sep 1	2018/11/14 06:00		['Sekhon, Arshdeep', 'Singh, Ritambhara', 'Qi, Yanjun']			17		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty612 [doi]	20190930	['*Gene Expression', 'Histone Code', 'Histones/*metabolism', 'Humans', '*Machine Learning', 'Protein Processing, Post-Translational', 'Software']	2019/10/01 06:00				NLM	i891-i900	['2018/11/14 06:00 [entrez]', '2018/11/14 06:00 [pubmed]', '2019/10/01 06:00 [medline]']	England			30423076	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Histones)']	IM		Bioinformatics. 2018 Sep 1;34(17):i891-i900. doi: 10.1093/bioinformatics/bty612.	MEDLINE	Bioinformatics	DeepDiff: DEEP-learning for predicting DIFFerential gene expression from histone modifications.		34	DeepDiff: DEEP-learning for predicting DIFFerential gene expression from histone modifications.
Motivation: The prediction of off-target mutations in CRISPR-Cas9 is a hot topic due to its relevance to gene editing research. Existing prediction methods have been developed; however, most of them just calculated scores based on mismatches to the guide sequence in CRISPR-Cas9. Therefore, the existing prediction methods are unable to scale and improve their performance with the rapid expansion of experimental data in CRISPR-Cas9. Moreover, the existing methods still cannot satisfy enough precision in off-target predictions for gene editing at the clinical level. Results: To address it, we design and implement two algorithms using deep neural networks to predict off-target mutations in CRISPR-Cas9 gene editing (i.e. deep convolutional neural network and deep feedforward neural network). The models were trained and tested on the recently released off-target dataset, CRISPOR dataset, for performance benchmark. Another off-target dataset identified by GUIDE-seq was adopted for additional evaluation. We demonstrate that convolutional neural network achieves the best performance on CRISPOR dataset, yielding an average classification area under the ROC curve (AUC) of 97.2% under stratified 5-fold cross-validation. Interestingly, the deep feedforward neural network can also be competitive at the average AUC of 97.0% under the same setting. We compare the two deep neural network models with the state-of-the-art off-target prediction methods (i.e. CFD, MIT, CROP-IT, and CCTop) and three traditional machine learning models (i.e. random forest, gradient boosting trees, and logistic regression) on both datasets in terms of AUC values, demonstrating the competitive edges of the proposed algorithms. Additional analyses are conducted to investigate the underlying reasons from different perspectives. Availability and implementation: The example code are available at https://github.com/MichaelLinn/off_target_prediction. The related datasets are available at https://github.com/MichaelLinn/off_target_prediction/tree/master/data.	['Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong SAR.', 'Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong SAR.']	['5093220 [pii]', '10.1093/bioinformatics/bty554 [doi]']	['Lin J', 'Wong KC']							['2018/11/14 06:00']	20190923		2018 Sep 1	2018/11/14 06:00		['Lin, Jiecong', 'Wong, Ka-Chun']			17		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty554 [doi]	20190923	['Algorithms', 'Area Under Curve', 'CRISPR-Cas Systems', '*Deep Learning', '*Gene Editing', 'Logistic Models']	2019/09/24 06:00				NLM	i656-i663	['2018/11/14 06:00 [entrez]', '2018/11/14 06:00 [pubmed]', '2019/09/24 06:00 [medline]']	England	PMC6129261		30423072	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Bioinformatics. 2018 Sep 1;34(17):i656-i663. doi: 10.1093/bioinformatics/bty554.	MEDLINE	Bioinformatics	Off-target predictions in CRISPR-Cas9 gene editing using deep learning.		34	Off-target predictions in CRISPR-Cas9 gene editing using deep learning.
OBJECTIVE: Artificial intelligence (AI) neural networks rapidly convert disparate facts and data into highly predictive analytic models. Machine learning maps image-patient phenotype correlations opaque to standard statistics. Deep learning performs accurate image-derived tissue characterization and can generate virtual CT images from MRI datasets. Natural language processing reads medical literature and efficiently reconfigures years of PACS and electronic medical record information. CONCLUSION: AI logistics solve radiology informatics workflow pain points. Imaging professionals and companies will drive health care AI technology insertion. Data science and computer science will jointly potentiate the impact of AI applications for medical imaging.	['1 Department of Medicine, Medical College of Georgia at Augusta University, 1120 15th St, Office BBR-6518, Augusta, GA 30912.', '2 Department of Radiology, Medical College of Georgia at Augusta University, Augusta, GA.', '3 Foundational Innovations, IBM Watson Health, Yorktown Heights, NY.']	['10.2214/AJR.18.19914 [doi]']	['Miller DD', 'Brown EW']							['2018/11/14 06:00']	20191017	20181113	2019 Jan	2018/11/14 06:00		['Miller, D Douglas', 'Brown, Eric W']			1		1546-3141 (Electronic) 0361-803X (Linking)	7708173	AJR. American journal of roentgenology	['eng']	10.2214/AJR.18.19914 [doi]	20191017	['Algorithms', '*Artificial Intelligence', 'Deep Learning', '*Diagnostic Imaging', 'Electronic Health Records', 'Humans', 'Image Processing, Computer-Assisted/*trends', 'Machine Learning', 'Natural Language Processing', 'Neural Networks (Computer)']	2019/10/18 06:00		['*artificial intelligence', '*deep learning', '*machine learning', '*natural language processing', '*technology insertion']	['NOTNLM']	NLM	9-14	['2018/11/14 06:00 [pubmed]', '2019/10/18 06:00 [medline]', '2018/11/14 06:00 [entrez]']	United States			30422716	ppublish	['Journal Article']			AIM IM		AJR Am J Roentgenol. 2019 Jan;212(1):9-14. doi: 10.2214/AJR.18.19914. Epub 2018 Nov 13.	MEDLINE	AJR Am J Roentgenol	How Cognitive Machines Can Augment Medical Imaging.		212	How Cognitive Machines Can Augment Medical Imaging.
Metastasis is the cause of death in most patients of breast cancer and other solid malignancies. Identification of cancer cells with highly migratory capability to metastasize relies on markers for epithelial-to-mesenchymal transition (EMT), a process increasing cell migration and metastasis. Marker-based approaches are limited by inconsistences among patients, types of cancer, and partial EMT states. Alternatively, we analyzed cancer cell migration behavior using computer vision. Using a microfluidic single-cell migration chip and high-content imaging, we extracted morphological features and recorded migratory direction and speed of breast cancer cells. By applying a Random Decision Forest (RDF) and an Artificial Neural Network (ANN), we achieved over 99% accuracy for cell movement direction prediction and 91% for speed prediction. Unprecedentedly, we identified highly motile cells and non-motile cells based on microscope images and a machine learning model, and pinpointed and validated morphological features determining cell migration, including not only known features related to cell polarization but also novel ones that can drive future mechanistic studies. Predicting cell movement by computer vision and machine learning establishes a ground-breaking approach to analyze cell migration and metastasis.	['Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, MI 48109-2122, USA. zhangzx@umich.edu esyoon@umich.edu.']	['10.1039/c8ib00106e [doi]']	['Zhang Z', 'Chen L', 'Humphries B', 'Brien R', 'Wicha MS', 'Luker KE', 'Luker GD', 'Chen YC', 'Yoon E']							['2018/11/14 06:00']	20190729		2018 Dec 19	2018/11/14 06:00		['Zhang, Zhixiong', 'Chen, Lili', 'Humphries, Brock', 'Brien, Riley', 'Wicha, Max S', 'Luker, Kathryn E', 'Luker, Gary D', 'Chen, Yu-Chih', 'Yoon, Euisik']		['R01 CA196018/CA/NCI NIH HHS/United States', 'R21 CA175857/CA/NCI NIH HHS/United States', 'R21 CA195016/CA/NCI NIH HHS/United States', 'U01 CA210152/CA/NCI NIH HHS/United States']	12		1757-9708 (Electronic) 1757-9694 (Linking)	101478378	Integrative biology : quantitative biosciences from nano to macro	['eng']	10.1039/c8ib00106e [doi]	20190729	['Algorithms', 'Animals', 'Breast Neoplasms/diagnosis/pathology', 'Cell Line, Tumor', '*Cell Movement', '*Decision Support Techniques', 'Deep Learning', 'Epithelial-Mesenchymal Transition', 'Female', 'Humans', 'Lab-On-A-Chip Devices', 'Mice', 'Models, Biological', 'Neoplasm Metastasis', 'Neoplasms/*diagnosis/*pathology', '*Neural Networks (Computer)', 'Reproducibility of Results', 'Single-Cell Analysis']	2019/07/30 06:00	['NIHMS997474']			NLM	758-767	['2019/12/19 00:00 [pmc-release]', '2018/11/14 06:00 [pubmed]', '2019/07/30 06:00 [medline]', '2018/11/14 06:00 [entrez]']	England	PMC6329292	['2019/12/19 00:00']	30420987	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"					Integr Biol (Camb). 2018 Dec 19;10(12):758-767. doi: 10.1039/c8ib00106e.	MEDLINE	Integr Biol (Camb)	Morphology-based prediction of cancer cell migration using an artificial neural network and a random decision forest.		10	Morphology-based prediction of cancer cell migration using an artificial neural network and a random decision forest.
Protein secondary structure prediction (PSSP) is an important research field in bioinformatics. The representation of protein sequence features could be treated as a matrix, which includes the amino-acid residue (time-step) dimension and the feature vector dimension. Common approaches to predict secondary structures only focus on the amino-acid residue dimension. However, the feature vector dimension may also contain useful information for PSSP. To integrate the information on both dimensions of the matrix, we propose a hybrid deep learning framework, two-dimensional convolutional bidirectional recurrent neural network (2C-BRNN), for improving the accuracy of 8-class secondary structure prediction. The proposed hybrid framework is to extract the discriminative local interactions between amino-acid residues by two-dimensional convolutional neural networks (2DCNNs), and then further capture long-range interactions between amino-acid residues by bidirectional gated recurrent units (BGRUs) or bidirectional long short-term memory (BLSTM). Specifically, our proposed 2C-BRNNs framework consists of four models: 2DConv-BGRUs, 2DCNN-BGRUs, 2DConv-BLSTM and 2DCNN-BLSTM. Among these four models, the 2DConv- models only contain two-dimensional (2D) convolution operations. Moreover, the 2DCNN- models contain 2D convolutional and pooling operations. Experiments are conducted on four public datasets. The experimental results show that our proposed 2DConv-BLSTM model performs significantly better than the benchmark models. Furthermore, the experiments also demonstrate that the proposed models can extract more meaningful features from the matrix of proteins, and the feature vector dimension is also useful for PSSP. The codes and datasets of our proposed methods are available at https://github.com/guoyanb/JBCB2018/ .	"['* School of Information Science and Engineering, Yunnan University, No. 2 North Cuihu Road, Kunming 650091, P. R. China.', 'dagger The Research Institute of Resource Insects, Chinese Academy of Forestry, Bailongsi, Kunming 650224, P. R. China.', '* School of Information Science and Engineering, Yunnan University, No. 2 North Cuihu Road, Kunming 650091, P. R. China.', ""double dagger MD. Cardiology Department, The Second People's Hospital of Yunnan Province, No. 176 Qingnian Road, Kunming 650021, P. R. China.""]"	['10.1142/S021972001850021X [doi]']	['Guo Y', 'Wang B', 'Li W', 'Yang B']	['ORCID: 0000-0001-9532-2309', 'ORCID: 0000-0002-9060-382X']						['2018/11/14 06:00']	20190916		2018 Oct	2018/11/14 06:00		['Guo, Yanbu', 'Wang, Bingyi', 'Li, Weihua', 'Yang, Bei']			5		1757-6334 (Electronic) 0219-7200 (Linking)	101187344	Journal of bioinformatics and computational biology	['eng']	10.1142/S021972001850021X [doi]	20190916	['Computational Biology/*methods', 'Databases, Protein', 'Deep Learning', '*Neural Networks (Computer)', 'Protein Structure, Secondary', 'Proteins/*chemistry']	2019/09/17 06:00		['*Bioinformatics', '*convolutional neural networks (CNNs)', '*gated recurrent units (GRUs)', '*long short-term memory (LSTM)', '*protein secondary structure predication (PSSP)', '*recurrent neural networks (RNNs)']	['NOTNLM']	NLM	1850021	['2018/11/14 06:00 [entrez]', '2018/11/14 06:00 [pubmed]', '2019/09/17 06:00 [medline]']	Singapore			30419785	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		J Bioinform Comput Biol. 2018 Oct;16(5):1850021. doi: 10.1142/S021972001850021X.	MEDLINE	J Bioinform Comput Biol	Protein secondary structure prediction improved by recurrent neural networks integrated with two-dimensional convolutional neural networks.		16	Protein secondary structure prediction improved by recurrent neural networks integrated with two-dimensional convolutional neural networks.
The number of images taken per patient scan has rapidly increased due to advances in software, hardware and digital imaging in the medical domain. There is the need for medical image annotation systems that are accurate as manual annotation is impractical, time-consuming and prone to errors. This paper presents modeling approaches performed to automatically classify and annotate radiographs using several classification schemes, which can be further applied for automatic content-based image retrieval (CBIR) and computer-aided diagnosis (CAD). Different image preprocessing and enhancement techniques were applied to augment grayscale radiographs by virtually adding two extra layers. The Image Retrieval in Medical Applications (IRMA) Code, a mono-hierarchical multi-axial code, served as a basis for this work. To extensively evaluate the image enhancement techniques, five classification schemes including the complete IRMA code were adopted. The deep convolutional neural network systems Inception-v3 and Inception-ResNet-v2, and Random Forest models with 1000 trees were trained using extracted Bag-of-Keypoints visual representations. The classification model performances were evaluated using the ImageCLEF 2009 Medical Annotation Task test set. The applied visual enhancement techniques proved to achieve better annotation accuracy in all classification schemes.	['Department of Computer Science, University of Applied Sciences and Arts Dortmund (FHDO), Dortmund, NRW Germany.', 'Faculty of Medicine, University of Duisburg-Essen, Essen, NRW, Germany.', 'Department of Diagnostic and Interventional Radiology and Neuroradiology, University Hospital Essen, Essen, NRW, Germany.', 'Department of Computer Science, University of Applied Sciences and Arts Dortmund (FHDO), Dortmund, NRW Germany.', 'Institute for Medical Informatics, Biometry and Epidemiology (IMIBE), University Hospital Essen, Essen, NRW, Germany.']	['10.1371/journal.pone.0206229 [doi]', 'PONE-D-18-15717 [pii]']	['Pelka O', 'Nensa F', 'Friedrich CM']	['ORCID: 0000-0001-5156-4429', 'ORCID: 0000-0001-7906-0038']				['The authors have declared that no competing interests exist.']		['2018/11/13 06:00']	20190405	20181112	2018	2018/11/13 06:00		['Pelka, Obioma', 'Nensa, Felix', 'Friedrich, Christoph M']			11		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0206229 [doi]	20190405	['Algorithms', 'Diagnosis, Computer-Assisted/*statistics & numerical data', 'Humans', 'Image Processing, Computer-Assisted/*methods/statistics & numerical data', 'Machine Learning', '*Neural Networks (Computer)', 'Radiography/*methods']	2019/04/06 06:00				NLM	e0206229	['2018/05/25 00:00 [received]', '2018/10/05 00:00 [accepted]', '2018/11/13 06:00 [entrez]', '2018/11/13 06:00 [pubmed]', '2019/04/06 06:00 [medline]']	United States	PMC6231616		30419028	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Nov 12;13(11):e0206229. doi: 10.1371/journal.pone.0206229. eCollection 2018.	MEDLINE	PLoS One	Annotation of enhanced radiographs for medical image retrieval with deep convolutional neural networks.		13	Annotation of enhanced radiographs for medical image retrieval with deep convolutional neural networks.
Objectives: To evaluate the application of a deep learning architecture, based on the convolutional neural network (CNN) technique, to perform automatic tumor segmentation of magnetic resonance imaging (MRI) for nasopharyngeal carcinoma (NPC). Materials and Methods: In this prospective study, 87 MRI containing tumor regions were acquired from newly diagnosed NPC patients. These 87 MRI were augmented to >60,000 images. The proposed CNN network is composed of two phases: feature representation and scores map reconstruction. We designed a stepwise scheme to train our CNN network. To evaluate the performance of our method, we used case-by-case leave-one-out cross-validation (LOOCV). The ground truth of tumor contouring was acquired by the consensus of two experienced radiologists. Results: The mean values of dice similarity coefficient, percent match, and their corresponding ratio with our method were 0.89+/-0.05, 0.90+/-0.04, and 0.84+/-0.06, respectively, all of which were better than reported values in the similar studies. Conclusions: We successfully established a segmentation method for NPC based on deep learning in contrast-enhanced magnetic resonance imaging. Further clinical trials with dedicated algorithms are warranted.	['School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China.', 'School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China.', 'School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China.', 'Department of Radiology, Guangzhou Panyu Central Hospital, Guangzhou, China.', 'Medical Imaging Institute of Panyu, Guangzhou, China.', 'Department of Radiology, First Affiliated Hospital, Sun Yat-Sen University, Guangzhou, China.', 'Department of Radiology, Queen Mary Hospital, Hong Kong.', 'Department of Radiology, Guangzhou Panyu Central Hospital, Guangzhou, China.', 'Medical Imaging Institute of Panyu, Guangzhou, China.', 'School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China.']	['10.1155/2018/9128527 [doi]']	['Li Q', 'Xu Y', 'Chen Z', 'Liu D', 'Feng ST', 'Law M', 'Ye Y', 'Huang B']	['ORCID: 0000-0003-2876-4152', 'ORCID: 0000-0002-0473-3928', 'ORCID: 0000-0002-9843-475X', 'ORCID: 0000-0002-1183-7506']						['2018/11/13 06:00']	20190220	20181017	2018	2018/11/13 06:00		['Li, Qiaoliang', 'Xu, Yuzhen', 'Chen, Zhewei', 'Liu, Dexiang', 'Feng, Shi-Ting', 'Law, Martin', 'Ye, Yufeng', 'Huang, Bingsheng']					2314-6141 (Electronic)	101600173	BioMed research international	['eng']	10.1155/2018/9128527 [doi]	20190320	['Algorithms', 'Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Machine Learning', 'Magnetic Resonance Imaging/*methods', 'Nasopharyngeal Carcinoma/*pathology', 'Neural Networks (Computer)', 'Prospective Studies']	2019/03/21 06:00				NLM	9128527	['2018/05/14 00:00 [received]', '2018/09/12 00:00 [revised]', '2018/10/02 00:00 [accepted]', '2018/11/13 06:00 [entrez]', '2018/11/13 06:00 [pubmed]', '2019/03/21 06:00 [medline]']	United States	PMC6207874		30417017	epublish	['Journal Article']			IM		Biomed Res Int. 2018 Oct 17;2018:9128527. doi: 10.1155/2018/9128527. eCollection 2018.	MEDLINE	Biomed Res Int	Tumor Segmentation in Contrast-Enhanced Magnetic Resonance Imaging for Nasopharyngeal Carcinoma: Deep Learning with Convolutional Neural Network.		2018	Tumor Segmentation in Contrast-Enhanced Magnetic Resonance Imaging for Nasopharyngeal Carcinoma: Deep Learning with Convolutional Neural Network.
BACKGROUND AND OBJECTIVE: Nowadays, getting an efficient Brain Tumor Segmentation in Multi-Sequence MR images as soon as possible, gives an early clinical diagnosis, treatment and follow-up. The aim of this study is to develop a new deep learning model for the segmentation of brain tumors. The proposed models are used to segment the brain tumors of Glioblastomas (with both high and low grade). Glioblastomas have four properties: different sizes, shapes, contrasts, in addition, Glioblastomas appear anywhere in the brain. METHODS: In this paper, we propose three end-to-end Incremental Deep Convolutional Neural Networks models for fully automatic Brain Tumor Segmentation. Our proposed models are different from the other CNNs-based models that follow the technique of trial and error process which does not use any guided approach to get the suitable hyper-parameters. Moreover, we adopt the technique of Ensemble Learning to design a more efficient model. For solving the problem of training CNNs model, we propose a new training strategy which takes into account the most influencing hyper-parameters by bounding and setting a roof to these hyper-parameters to accelerate the training. RESULTS: Our experiment results reported on BRATS-2017 dataset. The proposed deep learning models achieve the state-of-the-art performance without any post-processing operations. Indeed, our models achieve in average 0.88 Dice score over the complete region. Moreover, the efficient design with the advantage of GPU implementation, allows our three deep learning models to achieve brain segmentation results in average 20.87 s. CONCLUSIONS: The proposed deep learning models are effective for the segmentation of brain tumors and allow to obtain high accurate results. Moreover, the proposed models could help the physician experts to reduce the time of diagnostic.	['Smart Computer Sciences Laboratory, Department of Computer Sciences, University of Biskra, Biskra, Algeria; Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallee, France. Electronic address: mostefa.bennaceur@univ-biskra.dz.', 'Smart Computer Sciences Laboratory, Department of Computer Sciences, University of Biskra, Biskra, Algeria. Electronic address: rachida.saouli@esiee.fr.', 'Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallee, France. Electronic address: mohamed.akil@esiee.fr.', 'Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallee, France. Electronic address: rostom.kachouri@esiee.fr.']	['S0169-2607(18)30901-5 [pii]', '10.1016/j.cmpb.2018.09.007 [doi]']	['Naceur MB', 'Saouli R', 'Akil M', 'Kachouri R']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/11/13 06:00']	20190228	20180921	2018 Nov	2018/11/13 06:00		['Naceur, Mostefa Ben', 'Saouli, Rachida', 'Akil, Mohamed', 'Kachouri, Rostom']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30901-5 [pii] 10.1016/j.cmpb.2018.09.007 [doi]	20190228	['Algorithms', 'Brain/*diagnostic imaging/pathology', 'Brain Neoplasms/*diagnostic imaging/pathology', 'Diagnosis, Computer-Assisted/*methods', 'Glioblastoma/*diagnostic imaging/pathology', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', '*Magnetic Resonance Imaging', 'Neural Networks (Computer)', 'Pattern Recognition, Automated']	2019/03/01 06:00		['Brain tumor segmentation', 'Convolutional neural networks', 'Deep learning', 'Fully automatic', 'Hyper-parameters', 'Training']	['NOTNLM']	NLM	39-49	['2018/06/20 00:00 [received]', '2018/09/16 00:00 [revised]', '2018/09/18 00:00 [accepted]', '2018/11/13 06:00 [entrez]', '2018/11/13 06:00 [pubmed]', '2019/03/01 06:00 [medline]']	Ireland			30415717	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Nov;166:39-49. doi: 10.1016/j.cmpb.2018.09.007. Epub 2018 Sep 21.	MEDLINE	Comput Methods Programs Biomed	Fully Automatic Brain Tumor Segmentation using End-To-End Incremental Deep Neural Networks in MRI images.		166	Fully Automatic Brain Tumor Segmentation using End-To-End Incremental Deep Neural Networks in MRI images.
Magnetic resonance imaging (MRI) has been proposed as a complimentary method to measure bone quality and assess fracture risk. However, manual segmentation of MR images of bone is time-consuming, limiting the use of MRI measurements in the clinical practice. The purpose of this paper is to present an automatic proximal femur segmentation method that is based on deep convolutional neural networks (CNNs). This study had institutional review board approval and written informed consent was obtained from all subjects. A dataset of volumetric structural MR images of the proximal femur from 86 subjects were manually-segmented by an expert. We performed experiments by training two different CNN architectures with multiple number of initial feature maps, layers and dilation rates, and tested their segmentation performance against the gold standard of manual segmentations using four-fold cross-validation. Automatic segmentation of the proximal femur using CNNs achieved a high dice similarity score of 0.95 +/- 0.02 with precision = 0.95 +/- 0.02, and recall = 0.95 +/- 0.03. The high segmentation accuracy provided by CNNs has the potential to help bring the use of structural MRI measurements of bone quality into clinical practice for management of osteoporosis.	['Department of Radiology, New York University School of Medicine, New York, NY, 10016, USA. cem.deniz@nyulangone.org.', 'Bernard and Irene Schwartz Center for Biomedical Imaging, New York University School of Medicine, New York, NY, 10016, USA. cem.deniz@nyulangone.org.', 'Center for Data Science, New York University, New York, NY, 10012, USA.', 'Harvard College, Cambridge, MA, 02138, USA.', 'Bernard and Irene Schwartz Center for Biomedical Imaging, New York University School of Medicine, New York, NY, 10016, USA.', 'Bernard and Irene Schwartz Center for Biomedical Imaging, New York University School of Medicine, New York, NY, 10016, USA.', 'Osteoporosis Center, Hospital for Joint Diseases, New York University Langone Medical Center, New York, NY, 10003, USA.', 'Center for Data Science, New York University, New York, NY, 10012, USA.', 'Courant Institute of Mathematical Science, New York University, New York, NY, 10012, USA.', 'Department of Radiology, New York University School of Medicine, New York, NY, 10016, USA.']	['10.1038/s41598-018-34817-6 [doi]', '10.1038/s41598-018-34817-6 [pii]']	['Deniz CM', 'Xiang S', 'Hallyburton RS', 'Welbeck A', 'Babb JS', 'Honig S', 'Cho K', 'Chang G']	['ORCID: http://orcid.org/0000-0001-8809-5945']						['2018/11/09 06:00']	20191025	20181107	2018 Nov 7	2018/11/09 06:00		['Deniz, Cem M', 'Xiang, Siyuan', 'Hallyburton, R Spencer', 'Welbeck, Arakua', 'Babb, James S', 'Honig, Stephen', 'Cho, Kyunghyun', 'Chang, Gregory']		['R01 AR070131/AR/NIAMS NIH HHS/United States', 'R01 AR066008/AR/NIAMS NIH HHS/United States', 'P41 EB017183/EB/NIBIB NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-34817-6 [doi]	20191107	['Algorithms', 'Femur/*diagnostic imaging', 'Humans', '*Image Processing, Computer-Assisted/methods', 'Machine Learning', '*Magnetic Resonance Imaging', 'Mammography', '*Neural Networks (Computer)', 'ROC Curve', 'Reproducibility of Results']	2019/10/28 06:00				NLM	16485	['2018/03/12 00:00 [received]', '2018/10/26 00:00 [accepted]', '2018/11/09 06:00 [entrez]', '2018/11/09 06:00 [pubmed]', '2019/10/28 06:00 [medline]']	England	PMC6220200		30405145	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Nov 7;8(1):16485. doi: 10.1038/s41598-018-34817-6.	MEDLINE	Sci Rep	Segmentation of the Proximal Femur from MR Images using Deep Convolutional Neural Networks.		8	Segmentation of the Proximal Femur from MR Images using Deep Convolutional Neural Networks.
PURPOSE: To develop a deep learning bone age assessment model based on pelvic radiographs for forensic age estimation and compare its performance to that of the existing cubic regression model. MATERIALS AND METHOD: A retrospective collection data of 1875 clinical pelvic radiographs between 10 and 25 years of age was obtained to develop the model. Model performance was assessed by comparing the testing results to estimated ages calculated directly using the existing cubic regression model based on ossification staging methods. The mean absolute error (MAE) and root-mean-squared error (RMSE) between the estimated ages and chronological age were calculated for both models. RESULTS: For all test samples (between 10 and 25 years old), the mean MAE and RMSE between the automatic estimates using the proposed deep learning model and the reference standard were 0.94 and 1.30 years, respectively. For the test samples comparable to those of the existing cubic regression model (between 14 and 22 years old), the mean MAE and RMSE for the deep learning model were 0.89 and 1.21 years, respectively. For the existing cubic regression model, the mean MAE and RMSE were 1.05 and 1.61 years, respectively. CONCLUSION: The deep learning convolutional neural network model achieves performance on par with the existing cubic regression model, demonstrating predictive ability capable of automated skeletal bone assessment based on pelvic radiographic images. KEY POINTS: * The pelvis has considerable value in determining the bone age. * Deep learning can be used to create an automated bone age assessment model based on pelvic radiographs. * The deep learning convolutional neural network model achieves performance on par with the existing cubic regression model.	"[""Department of Forensic Genetics, West China School of Preclinical and Forensic Medicine, Sichuan University, Chengdu, 610041, Sichuan, People's Republic of China."", ""Department of Forensic Pathology, West China School of Preclinical and Forensic Medicine, Sichuan University, No. three, 17 South Renmin Road, Wuhou District, Chengdu City, 610041, Sichuan, People's Republic of China."", 'College of Computer Science, Sichuan University, No.24 South Section 1, Yihuan Road, Chengdu, 610065, China.', ""Department of Forensic Pathology, West China School of Preclinical and Forensic Medicine, Sichuan University, No. three, 17 South Renmin Road, Wuhou District, Chengdu City, 610041, Sichuan, People's Republic of China."", ""Department of Forensic Genetics, West China School of Preclinical and Forensic Medicine, Sichuan University, Chengdu, 610041, Sichuan, People's Republic of China."", ""Department of Radiology, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, People's Republic of China."", ""Department of Forensic Genetics, West China School of Preclinical and Forensic Medicine, Sichuan University, Chengdu, 610041, Sichuan, People's Republic of China."", 'College of Computer Science, Sichuan University, No.24 South Section 1, Yihuan Road, Chengdu, 610065, China. yzhang@scu.edu.cn.', ""Department of Forensic Pathology, West China School of Preclinical and Forensic Medicine, Sichuan University, No. three, 17 South Renmin Road, Wuhou District, Chengdu City, 610041, Sichuan, People's Republic of China. fydzh63@163.com.""]"	['10.1007/s00330-018-5791-6 [doi]', '10.1007/s00330-018-5791-6 [pii]']	['Li Y', 'Huang Z', 'Dong X', 'Liang W', 'Xue H', 'Zhang L', 'Zhang Y', 'Deng Z']	['ORCID: http://orcid.org/0000-0002-0355-1006']						['2018/11/08 06:00']	20190529	20181106	2019 May	2018/11/08 06:00		['Li, Yuan', 'Huang, Zhizhong', 'Dong, Xiaoai', 'Liang, Weibo', 'Xue, Hui', 'Zhang, Lin', 'Zhang, Yi', 'Deng, Zhenhua']			5		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-018-5791-6 [doi]	20190529	['Adolescent', 'Adult', 'Age Determination by Skeleton/*methods', 'Child', '*Deep Learning', 'Female', 'Humans', 'Male', 'Pelvic Bones/*diagnostic imaging', 'Radiography', 'Retrospective Studies', 'Young Adult']	2019/05/30 06:00		['Age determination by skeleton', 'Forensic anthropology', 'Machine learning', 'Pelvis', 'Radiography']	['NOTNLM']	NLM	2322-2329	['2018/05/16 00:00 [received]', '2018/09/21 00:00 [accepted]', '2018/09/06 00:00 [revised]', '2018/11/08 06:00 [pubmed]', '2019/05/30 06:00 [medline]', '2018/11/08 06:00 [entrez]']	Germany			30402703	ppublish	['Journal Article']			IM		Eur Radiol. 2019 May;29(5):2322-2329. doi: 10.1007/s00330-018-5791-6. Epub 2018 Nov 6.	MEDLINE	Eur Radiol	Forensic age estimation for pelvic X-ray images using deep learning.		29	Forensic age estimation for pelvic X-ray images using deep learning.
BACKGROUND: Despite the effectiveness of levodopa for treatment of Parkinson's disease (PD), prolonged usage leads to development of motor complications, most notably levodopa-induced dyskinesia (LID). Persons with PD and their physicians must regularly modify treatment regimens and timing for optimal relief of symptoms. While standardized clinical rating scales exist for assessing the severity of PD symptoms, they must be administered by a trained medical professional and are inherently subjective. Computer vision is an attractive, non-contact, potential solution for automated assessment of PD, made possible by recent advances in computational power and deep learning algorithms. The objective of this paper was to evaluate the feasibility of vision-based assessment of parkinsonism and LID using pose estimation. METHODS: Nine participants with PD and LID completed a levodopa infusion protocol, where symptoms were assessed at regular intervals using the Unified Dyskinesia Rating Scale (UDysRS) and Unified Parkinson's Disease Rating Scale (UPDRS). Movement trajectories of individual joints were extracted from videos of PD assessment using Convolutional Pose Machines, a pose estimation algorithm built with deep learning. Features of the movement trajectories (e.g. kinematic, frequency) were used to train random forests to detect and estimate the severity of parkinsonism and LID. Communication and drinking tasks were used to assess LID, while leg agility and toe tapping tasks were used to assess parkinsonism. Feature sets from tasks were also combined to predict total UDysRS and UPDRS Part III scores. RESULTS: For LID, the communication task yielded the best results (detection: AUC = 0.930, severity estimation: r = 0.661). For parkinsonism, leg agility had better results for severity estimation (r = 0.618), while toe tapping was better for detection (AUC = 0.773). UDysRS and UPDRS Part III scores were predicted with r = 0.741 and 0.530, respectively. CONCLUSION: The proposed system provides insight into the potential of computer vision and deep learning for clinical application in PD and demonstrates promising performance for the future translation of deep learning to PD clinical practices. Convenient and objective assessment of PD symptoms will facilitate more frequent touchpoints between patients and clinicians, leading to better tailoring of treatment and quality of care.	"['Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, ON, M5G 2A2, Canada.', 'Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Room 407, Toronto, ON, M5S 3G9, Canada.', ""Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, ON, M5T 2S8, Canada."", 'The Ottawa Hospital Research Institute, 1053 Carling Ave, Ottawa, ON, K1Y 4E9, Canada.', 'Division of Neurology, Department of Medicine, 1053 Carling Ave, Ottawa, ON, K1Y 4E9, Canada.', 'Division of Neurology, University of Toronto, Suite RFE 3-805, 200 Elizabeth St, Toronto, ON, M5G 2C4, Canada.', ""Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, ON, M5T 2S8, Canada."", 'Division of Neurology, University of Toronto, Suite RFE 3-805, 200 Elizabeth St, Toronto, ON, M5G 2C4, Canada.', 'Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, ON, M5G 2A2, Canada. babak.taati@uhn.ca.', 'Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Room 407, Toronto, ON, M5S 3G9, Canada. babak.taati@uhn.ca.', ""Department of Computer Science, University of Toronto, 10 King's College Road, Room 3302, Toronto, ON, M5S 3G4, Canada. babak.taati@uhn.ca.""]"	['10.1186/s12984-018-0446-z [doi]', '10.1186/s12984-018-0446-z [pii]']	['Li MH', 'Mestre TA', 'Fox SH', 'Taati B']							['2018/11/08 06:00']	20191009	20181106	2018 Nov 6	2018/11/08 06:00		['Li, Michael H', 'Mestre, Tiago A', 'Fox, Susan H', 'Taati, Babak']			1		1743-0003 (Electronic) 1743-0003 (Linking)	101232233	Journal of neuroengineering and rehabilitation	['eng']	10.1186/s12984-018-0446-z [doi]	20191010	['Aged', 'Algorithms', 'Antiparkinson Agents/*adverse effects', 'Biomechanical Phenomena', 'Deep Learning', 'Dyskinesia, Drug-Induced/*diagnosis', 'Female', 'Humans', 'Levodopa/*adverse effects', 'Male', 'Middle Aged', 'Parkinson Disease/*drug therapy', '*Video Recording']	2019/10/11 06:00		['*Computer vision', '*Deep learning', '*Levodopa-induced dyskinesia', '*Parkinsonism', '*Pose estimation']	['NOTNLM']	NLM	97	['2018/04/17 00:00 [received]', '2018/10/18 00:00 [accepted]', '2018/11/08 06:00 [entrez]', '2018/11/08 06:00 [pubmed]', '2019/10/11 06:00 [medline]']	England	PMC6219082		30400914	epublish	"['Clinical Trial', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Antiparkinson Agents)', '46627O600J (Levodopa)']	IM		J Neuroeng Rehabil. 2018 Nov 6;15(1):97. doi: 10.1186/s12984-018-0446-z.	MEDLINE	J Neuroeng Rehabil	Vision-based assessment of parkinsonism and levodopa-induced dyskinesia with pose estimation.		15	Vision-based assessment of parkinsonism and levodopa-induced dyskinesia with pose estimation.
Electrocardiography (ECG) sensors play a vital role in the Internet of Medical Things, and these sensors help in monitoring the electrical activity of the heart. ECG signal analysis can improve human life in many ways, from diagnosing diseases among cardiac patients to managing the lifestyles of diabetic patients. Abnormalities in heart activities lead to different cardiac diseases and arrhythmia. However, some cardiac diseases, such as myocardial infarction (MI) and atrial fibrillation (Af), require special attention due to their direct impact on human life. The classification of flattened T wave cases of MI in ECG signals and how much of these cases are similar to ST-T changes in MI remain an open issue for researchers. This article presents a novel contribution to classify MI and Af. To this end, we propose a new approach called deep deterministic learning (DDL), which works by combining predefined heart activities with fused datasets. In this research, we used two datasets. The first dataset, Massachusetts Institute of Technology-Beth Israel Hospital, is publicly available, and we exclusively obtained the second dataset from the University of Malaya Medical Center, Kuala Lumpur Malaysia. We first initiated predefined activities on each individual dataset to recognize patterns between the ST-T change and flattened T wave cases and then used the data fusion approach to merge both datasets in a manner that delivers the most accurate pattern recognition results. The proposed DDL approach is a systematic stage-wise methodology that relies on accurate detection of R peaks in ECG signals, time domain features of ECG signals, and fine tune-up of artificial neural networks. The empirical evaluation shows high accuracy (i.e., </=99.97%) in pattern matching ST-T changes and flattened T waves using the proposed DDL approach. The proposed pattern recognition approach is a significant contribution to the diagnosis of special cases of MI.	['Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia.', 'Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia. tehyw@um.edu.my.', 'Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia.', 'Department of Computer Science, National University of Computer & Emerging Sciences, Lahore, Pakistan.', 'Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia.', 'Department of Computer Science, Sukkur IBA University, Sukkur, 65200, Pakistan.', 'College of Computer and Information Science, King Saud University, Riyadh, Saudi Arabia.', 'College of Computer and Information Science, King Saud University, Riyadh, Saudi Arabia.']	['10.1007/s10916-018-1107-2 [doi]', '10.1007/s10916-018-1107-2 [pii]']	['Iqbal U', 'Wah TY', 'Habib Ur Rehman M', 'Mujtaba G', 'Imran M', 'Shoaib M']							['2018/11/07 06:00']	20190226	20181105	2018 Nov 5	2018/11/07 06:00		['Iqbal, Uzair', 'Wah, Teh Ying', 'Habib Ur Rehman, Muhammad', 'Mujtaba, Ghulam', 'Imran, Muhammad', 'Shoaib, Muhammad']			12		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-018-1107-2 [doi]	20190226	['Atrial Fibrillation/*diagnosis/pathology', '*Deep Learning', 'Electrocardiography/*methods', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Internet', 'Male', 'Myocardial Infarction/*diagnosis/pathology', 'Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods']	2019/02/27 06:00		['Artificial neural network', 'Cardiovascular diseases', 'Deep deterministic learning', 'Electrocardiography', 'Internet of medical things', 'Pattern recognition']	['NOTNLM']	NLM	252	['2018/08/11 00:00 [received]', '2018/10/18 00:00 [accepted]', '2018/11/07 06:00 [entrez]', '2018/11/07 06:00 [pubmed]', '2019/02/27 06:00 [medline]']	United States			30397730	epublish	['Journal Article']			IM		J Med Syst. 2018 Nov 5;42(12):252. doi: 10.1007/s10916-018-1107-2.	MEDLINE	J Med Syst	Deep Deterministic Learning for Pattern Recognition of Different Cardiac Diseases through the Internet of Medical Things.		42	Deep Deterministic Learning for Pattern Recognition of Different Cardiac Diseases through the Internet of Medical Things.
There is a critical need for better analytical methods to study mitochondria in normal and diseased states. Mitochondrial image analysis is typically done on still images using slow manual methods or automated methods of limited types of features. MitoMo integrated software overcomes these bottlenecks by automating rapid unbiased quantitative analysis of mitochondrial morphology, texture, motion, and morphogenesis and advances machine-learning classification to predict cell health by combining features. Our pixel-based approach for motion analysis evaluates the magnitude and direction of motion of: (1) molecules within mitochondria, (2) individual mitochondria, and (3) distinct morphological classes of mitochondria. MitoMo allows analysis of mitochondrial morphogenesis in time-lapse videos to study early progression of cellular stress. Biological applications are presented including: (1) establishing normal phenotypes of mitochondria in different cell types; (2) quantifying stress-induced mitochondrial hyperfusion in cells treated with an environmental toxicant, (3) tracking morphogenesis in mitochondria undergoing swelling, and (4) evaluating early changes in cell health when morphological abnormalities are not apparent. MitoMo unlocks new information on mitochondrial phenotypes and dynamics by enabling deep analysis of mitochondrial features in any cell type and can be applied to a broad spectrum of research problems in cell biology, drug testing, toxicology, and medicine.	['Graduate Program in Bioengineering, University of California, Riverside, CA., USA.', 'Department of Molecular, Cell and Systems Biology, University of California, Riverside, CA., USA.', 'Department of Electrical & Computer Engineering, University of California, Riverside, CA., USA.', 'Department of Molecular, Cell and Systems Biology, University of California, Riverside, CA., USA.', 'Department of Molecular, Cell and Systems Biology, University of California, Riverside, CA., USA.', 'Department of Molecular, Cell and Systems Biology, University of California, Riverside, CA., USA.', 'Graduate Program in Bioengineering, University of California, Riverside, CA., USA.', 'Department of Electrical & Computer Engineering, University of California, Riverside, CA., USA.', 'Department of Computer Science, University of California, Riverside, CA., USA.', 'Graduate Program in Bioengineering, University of California, Riverside, CA., USA. talbot@ucr.edu.', 'Department of Molecular, Cell and Systems Biology, University of California, Riverside, CA., USA. talbot@ucr.edu.']	['10.1038/s41598-018-34455-y [doi]', '10.1038/s41598-018-34455-y [pii]']	['Zahedi A', 'On V', 'Phandthong R', 'Chaili A', 'Remark G', 'Bhanu B', 'Talbot P']	['ORCID: http://orcid.org/0000-0001-8971-6416']						['2018/11/07 06:00']	20191022	20181105	2018 Nov 5	2018/11/07 06:00		['Zahedi, Atena', 'On, Vincent', 'Phandthong, Rattapol', 'Chaili, Angela', 'Remark, Guadalupe', 'Bhanu, Bir', 'Talbot, Prue']		['R21 DA037365/DA/NIDA NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-34455-y [doi]	20191105	['A549 Cells', 'Computational Biology/*methods', 'Humans', '*Machine Learning', 'Mitochondria/drug effects/*metabolism', 'Movement/drug effects', 'Phenotype', 'Selenium/pharmacology', 'Stress, Physiological', 'Supervised Machine Learning']	2019/10/23 06:00				NLM	16354	['2018/03/06 00:00 [received]', '2018/10/16 00:00 [accepted]', '2018/11/07 06:00 [entrez]', '2018/11/07 06:00 [pubmed]', '2019/10/23 06:00 [medline]']	England	PMC6218515		30397207	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['H6241UJ22B (Selenium)']	IM		Sci Rep. 2018 Nov 5;8(1):16354. doi: 10.1038/s41598-018-34455-y.	MEDLINE	Sci Rep	Deep Analysis of Mitochondria and Cell Health Using Machine Learning.		8	Deep Analysis of Mitochondria and Cell Health Using Machine Learning.
Background: Deep learning is gaining importance in the prediction of cognitive states and brain pathology based on neuroimaging data. Including multiple hidden layers in artificial neural networks enables unprecedented predictive power; however, the proper training of deep neural networks requires thousands of exemplars. Collecting this amount of data is not feasible in typical neuroimaging experiments. A handy solution to this problem, which has largely fallen outside the scope of deep learning applications in neuroimaging, is to repurpose deep networks that have already been trained on large datasets by fine-tuning them to target datasets/tasks with fewer exemplars. Here, we investigated how this method, called transfer learning, can aid age category classification and regression based on brain functional connectivity patterns derived from resting-state functional magnetic resonance imaging. We trained a connectome-convolutional neural network on a larger public dataset and then examined how the knowledge learned can be used effectively to perform these tasks on smaller target datasets collected with a different type of scanner and/or imaging protocol and pre-processing pipeline. Results: Age classification on the target datasets benefitted from transfer learning. Significant improvement ( approximately 9%-13% increase in accuracy) was observed when the convolutional layers' weights were initialized based on the values learned on the public dataset and then fine-tuned to the target datasets. Transfer learning also appeared promising in improving the otherwise poor prediction of chronological age. Conclusions: Transfer learning is a plausible solution to adapt convolutional neural networks to neuroimaging data with few exemplars and different data acquisition and pre-processing protocols.	['Brain Imaging Centre, Research Centre for Natural Sciences, Hungarian Academy of Sciences, Magyar tudosok korutja 2., 1117 Budapest, Hungary.', 'Brain Imaging Centre, Research Centre for Natural Sciences, Hungarian Academy of Sciences, Magyar tudosok korutja 2., 1117 Budapest, Hungary.', 'Department of Cognitive Science, Budapest University of Technology and Economics, Egry Jozsef utca 1., 1111 Budapest, Hungary.', 'Brain Imaging Centre, Research Centre for Natural Sciences, Hungarian Academy of Sciences, Magyar tudosok korutja 2., 1117 Budapest, Hungary.', 'Brain Imaging Centre, Research Centre for Natural Sciences, Hungarian Academy of Sciences, Magyar tudosok korutja 2., 1117 Budapest, Hungary.', 'Department of Cognitive Science, Budapest University of Technology and Economics, Egry Jozsef utca 1., 1111 Budapest, Hungary.']	['5160132 [pii]', '10.1093/gigascience/giy130 [doi]']	['Vakli P', 'Deak-Meszlenyi RJ', 'Hermann P', 'Vidnyanszky Z']							['2018/11/06 06:00']	20190411	20181201	2018 Dec 1	2018/11/06 06:00		['Vakli, Pal', 'Deak-Meszlenyi, Regina J', 'Hermann, Petra', 'Vidnyanszky, Zoltan']			12		2047-217X (Electronic) 2047-217X (Linking)	101596872	GigaScience	['eng']	10.1093/gigascience/giy130 [doi]	20190411	['Aging', 'Brain/diagnostic imaging', 'Databases, Factual', 'Deep Learning', 'Humans', 'Image Processing, Computer-Assisted', 'Magnetic Resonance Imaging', '*Neural Networks (Computer)']	2019/04/12 06:00				NLM		['2018/03/19 00:00 [received]', '2018/10/24 00:00 [accepted]', '2018/11/06 06:00 [pubmed]', '2019/04/12 06:00 [medline]', '2018/11/06 06:00 [entrez]']	United States	PMC6283213		30395218	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Gigascience. 2018 Dec 1;7(12). pii: 5160132. doi: 10.1093/gigascience/giy130.	MEDLINE	Gigascience	Transfer learning improves resting-state functional connectivity pattern analysis using convolutional neural networks.		7	Transfer learning improves resting-state functional connectivity pattern analysis using convolutional neural networks.
PURPOSE: Automated segmentation of torso organs from positron emission tomography/computed tomography (PET/CT) images is a prerequisite step for nuclear medicine image analysis. However, accurate organ segmentation from clinical PET/CT is challenging due to the poor soft tissue contrast in the low-dose CT image and the low spatial resolution of the PET image. To overcome these challenges, we developed a multi-atlas segmentation (MAS) framework for torso organ segmentation from 2-deoxy-2-[(18)F]fluoro-D-glucose PET/CT images. METHOD: Our key idea is to use PET information to compensate for the imperfect CT contrast and use surface-based atlas fusion to overcome the low PET resolution. First, all the organs are segmented from CT using a conventional MAS method, and then the abdomen region of the PET image is automatically cropped. Focusing on the cropped PET image, a refined MAS segmentation of the abdominal organs is performed, using a surface-based atlas fusion approach to reach subvoxel accuracy. RESULTS: This method was validated based on 69 PET/CT images. The Dice coefficients of the target organs were between 0.80 and 0.96, and the average surface distances were between 1.58 and 2.44 mm. Compared to the CT-based segmentation, the PET-based segmentation gained a Dice increase of 0.06 and an ASD decrease of 0.38 mm. The surface-based atlas fusion leads to significant accuracy improvement for the liver and kidneys and saved ~ 10 min computation time compared to volumetric atlas fusion. CONCLUSIONS: The presented method achieves better segmentation accuracy than conventional MAS method within acceptable computation time for clinical applications.	['Department of Biomedical Engineering, Dalian University of Technology, Dalian, Liaoning, China.', 'Department of Biomedical Engineering, Dalian University of Technology, Dalian, Liaoning, China.', 'Department of Nuclear Medicine, Peking Union Medical College Hospital, Beijing, China.', 'Department of Biomedical Engineering, Dalian University of Technology, Dalian, Liaoning, China. medimg@qq.com.']	['10.1007/s11548-018-1879-3 [doi]', '10.1007/s11548-018-1879-3 [pii]']	['Wang H', 'Zhang N', 'Huo L', 'Zhang B']							['2018/11/04 06:00']	20190422	20181102	2019 Mar	2018/11/06 06:00		['Wang, Hongkai', 'Zhang, Nan', 'Huo, Li', 'Zhang, Bin']		['81401475/the youth program of National Natural Science Fund of China', '61571076/National Natural Science Fund of China', '2015020040/Liaoning Science and Technology Project', '2016RQ019/the Since and Technology Star Project Fund of Dalian City', 'DUT14RC(3)066/the Xinghai Scholar Cultivating Funding of Dalian University of', 'Technology', '91546123/the cultivating program of Major National Natural Science Fund of China', '2016YFC0103101/the National Key Research and Development Program', '2016YFC0103102/the National Key Research and Development Program', '2016YFC0106402/the National Key Research and Development Program', 'DUT15LN02/the Fundamental Research Funds for Central Universities', 'DUT16RC(3)099/the Fundamental Research Funds for Central Universities']	3		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-018-1879-3 [doi]	20190422	['Body Mass Index', 'Deep Learning', 'Female', 'Fluorodeoxyglucose F18', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Kidney/diagnostic imaging', 'Liver/*diagnostic imaging', 'Male', '*Positron Emission Tomography Computed Tomography', 'Torso/*diagnostic imaging']	2019/04/23 06:00		['Atlas fusion', 'Multi-atlas segmentation', 'Nuclear medicine image analysis', 'PET/CT']	['NOTNLM']	NLM	473-482	['2018/05/23 00:00 [received]', '2018/10/23 00:00 [accepted]', '2018/11/06 06:00 [pubmed]', '2019/04/23 06:00 [medline]', '2018/11/04 06:00 [entrez]']	Germany			30390179	ppublish	['Journal Article']		['0Z5B2CJX4D (Fluorodeoxyglucose F18)']	IM		Int J Comput Assist Radiol Surg. 2019 Mar;14(3):473-482. doi: 10.1007/s11548-018-1879-3. Epub 2018 Nov 2.	MEDLINE	Int J Comput Assist Radiol Surg	Dual-modality multi-atlas segmentation of torso organs from [(18)F]FDG-PET/CT images.		14	Dual-modality multi-atlas segmentation of torso organs from [(18)F]FDG-PET/CT images.
Skeletal bone age assessment is a widely used standard procedure in both disease detection and growth prediction for children in endocrinology. Conventional manual assessment methods mainly rely on personal experience in observing X-ray images of left hand and wrist to calculate bone age, which show some intrinsic limitations from low efficiency to unstable accuracy. To address these problems, some automated methods based on image processing or machine learning have been proposed, while their performances are not satisfying enough yet in assessment accuracy. Motivated by the remarkable success of deep learning (DL) techniques in the fields of image classification and speech recognition, we develop a deep automated skeletal bone age assessment model based on convolutional neural networks (CNNs) and support vector regression (SVR) using multiple kernel learning (MKL) algorithm to process heterogeneous features in this paper. This deep framework has been constructed, not only exploring the X-ray images of hand and twist but also some other heterogeneous information like race and gender. The experiment results prove its better performance with higher bone age assessment accuracy on two different data sets compared with the state of the art, indicating that the fused heterogeneous features provide a better description of the degree of bones' maturation.	['School of Computer Science and Engineering, Beihang, Beijing, 100191, China.', 'National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China.', 'School of Computer Science and Engineering, Beihang, Beijing, 100191, China.', 'National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China.', 'School of Computer Science and Engineering, Beihang, Beijing, 100191, China.', 'National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China.', 'School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China. zhengzhigao@hust.edu.cn.']	['10.1007/s10916-018-1091-6 [doi]', '10.1007/s10916-018-1091-6 [pii]']	['Tong C', 'Liang B', 'Li J', 'Zheng Z']							['2018/11/04 06:00']	20190226	20181103	2018 Nov 3	2018/11/06 06:00		['Tong, Chao', 'Liang, Baoyu', 'Li, Jun', 'Zheng, Zhigao']		['61472024/National Natural Science Foundation of China', 'U1433203/National Natural Science Foundation of China', 'NELIMSA2018P01/National Engineering Laboratory for Internet Medical System and', 'Application']	12		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-018-1091-6 [doi]	20190226	['Adolescent', 'Age Determination by Skeleton/*methods', 'Age Factors', 'Algorithms', 'Child', 'Child, Preschool', 'Continental Population Groups', 'Female', 'Hand/anatomy & histology', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Infant', 'Infant, Newborn', 'Male', '*Neural Networks (Computer)', 'Sex Factors', '*Support Vector Machine', 'Wrist/anatomy & histology']	2019/02/27 06:00		['Convolutional neural networks', 'Heterogeneous features', 'Skeletal bone age assessment model', 'Support vector regression']	['NOTNLM']	NLM	249	['2018/07/17 00:00 [received]', '2018/09/27 00:00 [accepted]', '2018/11/04 06:00 [entrez]', '2018/11/06 06:00 [pubmed]', '2019/02/27 06:00 [medline]']	United States			30390162	epublish	['Journal Article']			IM		J Med Syst. 2018 Nov 3;42(12):249. doi: 10.1007/s10916-018-1091-6.	MEDLINE	J Med Syst	A Deep Automated Skeletal Bone Age Assessment Model with Heterogeneous Features Learning.		42	A Deep Automated Skeletal Bone Age Assessment Model with Heterogeneous Features Learning.
Recently, modern smartphones equipped with a variety of embedded-sensors, such as accelerometers and gyroscopes, have been used as an alternative platform for human activity recognition (HAR), since they are cost-effective, unobtrusive and they facilitate real-time applications. However, the majority of the related works have proposed a position-dependent HAR, i.e., the target subject has to fix the smartphone in a pre-defined position. Few studies have tackled the problem of position-independent HAR. They have tackled the problem either using handcrafted features that are less influenced by the position of the smartphone or by building a position-aware HAR. The performance of these studies still needs more improvement to produce a reliable smartphone-based HAR. Thus, in this paper, we propose a deep convolution neural network model that provides a robust position-independent HAR system. We build and evaluate the performance of the proposed model using the RealWorld HAR public dataset. We find that our deep learning proposed model increases the overall performance compared to the state-of-the-art traditional machine learning method from 84% to 88% for position-independent HAR. In addition, the position detection performance of our model improves superiorly from 89% to 98%. Finally, the recognition time of the proposed model is evaluated in order to validate the applicability of the model for real-time applications.	['Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh 11543, Saudi Arabia. 434108029@student.ksu.edu.sa.', 'Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh 11543, Saudi Arabia. aartoli@ksu.edu.sa.', 'Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh 11543, Saudi Arabia. jalal@ccis.edu.sa.']	['s18113726 [pii]', '10.3390/s18113726 [doi]']	['Almaslukh B', 'Artoli AM', 'Al-Muhtadi J']							['2018/11/04 06:00']	20190116	20181101	2018 Nov 1	2018/11/06 06:00		['Almaslukh, Bandar', 'Artoli, Abdel Monim', 'Al-Muhtadi, Jalal']			11		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E3726 [pii] 10.3390/s18113726 [doi]	20190116	['Adult', 'Algorithms', '*Deep Learning', 'Female', '*Human Activities', 'Humans', 'Male', 'Neural Networks (Computer)', '*Smartphone', 'Time Factors']	2019/01/17 06:00		['convolution neural networks', 'deep learning', 'human activity recognition', 'position detection', 'position-independent', 'smartphone']	['NOTNLM']	NLM		['2018/09/30 00:00 [received]', '2018/10/18 00:00 [revised]', '2018/10/23 00:00 [accepted]', '2018/11/04 06:00 [entrez]', '2018/11/06 06:00 [pubmed]', '2019/01/17 06:00 [medline]']	Switzerland	PMC6263408		30388855	epublish	['Journal Article']			IM		Sensors (Basel). 2018 Nov 1;18(11). pii: s18113726. doi: 10.3390/s18113726.	MEDLINE	Sensors (Basel)	A Robust Deep Learning Approach for Position-Independent Smartphone-Based Human Activity Recognition.		18	A Robust Deep Learning Approach for Position-Independent Smartphone-Based Human Activity Recognition.
The design of novel proteins has many applications but remains an attritional process with success in isolated cases. Meanwhile, deep learning technologies have exploded in popularity in recent years and are increasingly applicable to biology due to the rise in available data. We attempt to link protein design and deep learning by using variational autoencoders to generate protein sequences conditioned on desired properties. Potential copper and calcium binding sites are added to non-metal binding proteins without human intervention and compared to a hidden Markov model. In another use case, a grammar of protein structures is developed and used to produce sequences for a novel protein topology. One candidate structure is found to be stable by molecular dynamics simulation. The ability of our model to confine the vast search space of protein sequences and to scale easily has the potential to assist in a variety of protein design tasks.	['Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, UK.', 'Francis Crick Institute, 1 Midland Road, London, NW1 1AT, UK.', 'Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, UK.', 'Francis Crick Institute, 1 Midland Road, London, NW1 1AT, UK.', 'Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, UK. d.t.jones@ucl.ac.uk.', 'Francis Crick Institute, 1 Midland Road, London, NW1 1AT, UK. d.t.jones@ucl.ac.uk.']	['10.1038/s41598-018-34533-1 [doi]', '10.1038/s41598-018-34533-1 [pii]']	['Greener JG', 'Moffat L', 'Jones DT']							['2018/11/03 06:00']	20191014	20181101	2018 Nov 1	2018/11/06 06:00		['Greener, Joe G', 'Moffat, Lewis', 'Jones, David T']		['Wellcome Trust/United Kingdom', 'BB/M011712/1/Biotechnology and Biological Sciences Research Council', '(BBSRC)/International']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-34533-1 [doi]	20191014	['Amino Acid Sequence/genetics', 'Binding Sites', '*Computational Biology', 'Deep Learning', 'Humans', 'Metalloproteins/*chemistry', 'Molecular Dynamics Simulation', '*Protein Folding']	2019/10/15 06:00				NLM	16189	['2018/06/28 00:00 [received]', '2018/10/19 00:00 [accepted]', '2018/11/03 06:00 [entrez]', '2018/11/06 06:00 [pubmed]', '2019/10/15 06:00 [medline]']	England	PMC6212568		30385875	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Metalloproteins)']	IM		Sci Rep. 2018 Nov 1;8(1):16189. doi: 10.1038/s41598-018-34533-1.	MEDLINE	Sci Rep	Design of metalloproteins and novel protein folds using variational autoencoders.		8	Design of metalloproteins and novel protein folds using variational autoencoders.
PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm. METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation. RESULTS: Our results demonstrate that the deep learning method can predict clinically acceptable dose distributions. There is no statistically significant difference between prediction and real clinical plan for all clinically relevant dose-volume histogram (DVH) indices, except brainstem, right and left lens. However, the predicted plans were still clinically acceptable. The results of plan generation show no statistically significant differences between the automatic generated plan and the predicted plan except PTV70.4 , but the difference is only 0.5% which is still clinically acceptable. CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.	['Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.', 'Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.', 'Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.', 'Department of Medical Physics, Shanghai Proton and Heavy Ion Center, Shanghai, 201321, China.', 'Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.', 'Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.', 'Department of Radiation Oncology, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, 200032, China.']	['10.1002/mp.13271 [doi]']	['Fan J', 'Wang J', 'Chen Z', 'Hu C', 'Zhang Z', 'Hu W']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/11/02 06:00']	20190121	20181128	2019 Jan	2018/11/02 06:00		['Fan, Jiawei', 'Wang, Jiazhou', 'Chen, Zhi', 'Hu, Chaosu', 'Zhang, Zhen', 'Hu, Weigang']		['11675042/National Natural Science Foundation of China', '11805039/National Natural Science Foundation of China', 'SKQY1601/Shanghai Emerging Frontier Technology Joint Research']	1		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13271 [doi]	20190121	['Algorithms', 'Automation', '*Deep Learning', 'Head and Neck Neoplasms/radiotherapy', 'Humans', '*Radiation Dosage', 'Radiotherapy Dosage', 'Radiotherapy Planning, Computer-Assisted/*methods', 'Radiotherapy, Intensity-Modulated']	2019/01/22 06:00		['deep learning', 'dose distribution prediction', 'knowledge-based planning', 'voxel-by-voxel dose optimization']	['NOTNLM']	NLM	370-381	['2018/07/19 00:00 [received]', '2018/10/16 00:00 [revised]', '2018/10/26 00:00 [accepted]', '2018/11/02 06:00 [pubmed]', '2019/01/22 06:00 [medline]', '2018/11/02 06:00 [entrez]']	United States			30383300	ppublish	['Journal Article']			IM		Med Phys. 2019 Jan;46(1):370-381. doi: 10.1002/mp.13271. Epub 2018 Nov 28.	MEDLINE	Med Phys	Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.		46	Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.
OBJECTIVE: To evaluate the application of artificial intelligence (AI), i.e. deep learning and other machine-learning techniques, to amniotic fluid (AF) metabolomics and proteomics, alone and in combination with sonographic, clinical and demographic factors, in the prediction of perinatal outcome in asymptomatic pregnant women with short cervical length (CL). METHODS: AF samples, which had been obtained in the second trimester from asymptomatic women with short CL (< 15 mm) identified on transvaginal ultrasound, were analyzed. CL, funneling and the presence of AF 'sludge' were assessed in all cases close to the time of amniocentesis. A combination of liquid chromatography coupled with mass spectrometry and proton nuclear magnetic resonance spectroscopy-based metabolomics, as well as targeted proteomics analysis, including chemokines, cytokines and growth factors, was performed on the AF samples. To determine the robustness of the markers, we used six different machine-learning techniques, including deep learning, to predict preterm delivery < 34 weeks, latency period prior to delivery < 28 days after amniocentesis and requirement for admission to a neonatal intensive care unit (NICU). Omics biomarkers were evaluated alone and in combination with standard sonographic, clinical and demographic factors to predict outcome. Predictive accuracy was assessed using the area under the receiver-operating characteristics curve (AUC) with 95% CI, sensitivity and specificity. RESULTS: Of the 32 patients included in the study, complete omics, demographic and clinical data and outcome information were available for 26. Of these, 11 (42.3%) patients delivered >/= 34 weeks, while 15 (57.7%) delivered < 34 weeks. There was no statistically significant difference in CL between these two groups (mean +/- SD, 11.2 +/- 4.4 mm vs 8.9 +/- 5.3 mm, P = 0.31). Using combined omics, demographic and clinical data, deep learning displayed good to excellent performance, with an AUC (95% CI) of 0.890 (0.810-0.970) for delivery < 34 weeks' gestation, 0.890 (0.790-0.990) for delivery < 28 days post-amniocentesis and 0.792 (0.689-0.894) for NICU admission. These values were higher overall than for the other five machine-learning methods, although each individual machine-learning technique yielded statistically significant prediction of the different perinatal outcomes. CONCLUSIONS: This is the first study to report use of AI with AF proteomics and metabolomics and ultrasound assessment in pregnancy. Machine learning, particularly deep learning, achieved good to excellent prediction of perinatal outcome in asymptomatic pregnant women with short CL in the second trimester. Copyright (c) 2018 ISUOG. Published by John Wiley & Sons Ltd.	['Department of Obstetrics and Gynecology, Beaumont Research Institute, Royal Oak, MI, USA.', 'Division of Maternal Fetal Medicine, Wright State University, Dayton, OH, USA.', 'Department of Obstetrics and Gynecology, Miami Valley Hospital South, Tampa, FL, USA.', 'Department of Pharmacology and Toxicology, Wright State University, Dayton, OH, USA.', 'Department of Computer Science, Albion College, Albion, MI, USA.', 'Department of Obstetrics and Gynecology, Beaumont Research Institute, Royal Oak, MI, USA.', 'Department of Biological Science, University of Alberta, Edmonton, AB, Canada.', 'Department of Biological Science, University of Alberta, Edmonton, AB, Canada.', 'Department of Biological Science, University of Alberta, Edmonton, AB, Canada.', 'Department of Obstetrics and Gynecology, Beaumont Research Institute, Royal Oak, MI, USA.', 'Department of Obstetrics and Gynecology, Beaumont Research Institute, Royal Oak, MI, USA.', 'Department of Obstetrics and Gynecology, Beaumont Research Institute, Royal Oak, MI, USA.']	['10.1002/uog.20168 [doi]']	['Bahado-Singh RO', 'Sonek J', 'McKenna D', 'Cool D', 'Aydas B', 'Turkoglu O', 'Bjorndahl T', 'Mandal R', 'Wishart D', 'Friedman P', 'Graham SF', 'Yilmaz A']		['Copyright (c) 2018 ISUOG. Published by John Wiley & Sons Ltd.']					['2018/11/02 06:00']			2019 Jul	2018/11/02 06:00		['Bahado-Singh, R O', 'Sonek, J', 'McKenna, D', 'Cool, D', 'Aydas, B', 'Turkoglu, O', 'Bjorndahl, T', 'Mandal, R', 'Wishart, D', 'Friedman, P', 'Graham, S F', 'Yilmaz, A']			1		1469-0705 (Electronic) 0960-7692 (Linking)	9108340	Ultrasound in obstetrics & gynecology : the official journal of the International Society of Ultrasound in Obstetrics and Gynecology	['eng']	10.1002/uog.20168 [doi]	20190730		2018/11/02 06:00		['artificial intelligence', 'deep learning', 'metabolomics', 'multiomics', 'perinatal', 'proteomics', 'ultrasound']	['NOTNLM']	NLM	110-118	['2018/07/20 00:00 [received]', '2018/08/30 00:00 [revised]', '2018/09/07 00:00 [accepted]', '2018/11/02 06:00 [pubmed]', '2018/11/02 06:00 [medline]', '2018/11/02 06:00 [entrez]']	England			30381856	ppublish	['Journal Article']			IM		Ultrasound Obstet Gynecol. 2019 Jul;54(1):110-118. doi: 10.1002/uog.20168.	In-Process	Ultrasound Obstet Gynecol	Artificial intelligence and amniotic fluid multiomics: prediction of perinatal outcome in asymptomatic women with short cervix.		54	Artificial intelligence and amniotic fluid multiomics: prediction of perinatal outcome in asymptomatic women with short cervix.
"Knowing the full set of essential genes for a given organism provides important information about ways to promote, and to limit, its growth and survival. For many non-model organisms, the lack of a stable haploid state and low transformation efficiencies impede the use of conventional approaches to generate a genome-wide comprehensive set of mutant strains and the identification of the genes essential for growth. Here we report on the isolation and utilization of a highly stable haploid derivative of the human pathogenic fungus Candida albicans, together with a modified heterologous transposon and machine learning (ML) analysis method, to predict the degree to which all of the open reading frames are required for growth under standard laboratory conditions. We identified 1,610 C. albicans essential genes, including 1,195 with high ""essentiality confidence"" scores, thereby increasing the number of essential genes (currently 66 in the Candida Genome Database) by >20-fold and providing an unbiased approach to determine the degree of confidence in the determination of essentiality. Among the genes essential in C. albicans were 602 genes also essential in the model budding and fission yeasts analyzed by both deletion and transposon mutagenesis. We also identified essential genes conserved among the four major human pathogens C. albicans, Aspergillus fumigatus, Cryptococcus neoformans, and Histoplasma capsulatum and highlight those that lack homologs in humans and that thus could serve as potential targets for the design of antifungal therapies.IMPORTANCE Comprehensive understanding of an organism requires that we understand the contributions of most, if not all, of its genes. Classical genetic approaches to this issue have involved systematic deletion of each gene in the genome, with comprehensive sets of mutants available only for very-well-studied model organisms. We took a different approach, harnessing the power of in vivo transposition coupled with deep sequencing to identify >500,000 different mutations, one per cell, in the prevalent human fungal pathogen Candida albicans and to map their positions across the genome. The transposition approach is efficient and less labor-intensive than classic approaches. Here, we describe the production and analysis (aided by machine learning) of a large collection of mutants and the comprehensive identification of 1,610 C. albicans genes that are essential for growth under standard laboratory conditions. Among these C. albicans essential genes, we identify those that are also essential in two distantly related model yeasts as well as those that are conserved in all four major human fungal pathogens and that are not conserved in the human genome. This list of genes with functions important for the survival of the pathogen provides a good starting point for the development of new antifungal drugs, which are greatly needed because of the emergence of fungal pathogens with elevated resistance and/or tolerance of the currently limited set of available antifungal drugs."	['School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel.', 'School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel.', 'School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel.', 'School of Medical Sciences, Institute of Medical Sciences, University of Aberdeen, Aberdeen, United Kingdom.', 'School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel.', 'Department of Biological Sciences, Vanderbilt University, Nashville, Tennessee, USA.', 'School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel.', 'Institute of Biology, Dahlem Centre of Plant Sciences, Freie Universitat Berlin, Berlin, Germany.', 'Department of Biological Sciences, Vanderbilt University, Nashville, Tennessee, USA.', 'School of Medical Sciences, Institute of Medical Sciences, University of Aberdeen, Aberdeen, United Kingdom.', 'Institute of Biology, Dahlem Centre of Plant Sciences, Freie Universitat Berlin, Berlin, Germany.', 'The Blavatnik School of Computer Science, Raymond & Beverly Sackler Faculty of Exact Sciences, Tel Aviv University, Tel Aviv, Israel.', 'School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel jberman@tauex.tau.ac.il.']	['mBio.02048-18 [pii]', '10.1128/mBio.02048-18 [doi]']	['Segal ES', 'Gritsenko V', 'Levitan A', 'Yadav B', 'Dror N', 'Steenwyk JL', 'Silberberg Y', 'Mielich K', 'Rokas A', 'Gow NAR', 'Kunze R', 'Sharan R', 'Berman J']	['ORCID: 0000-0002-7248-6551', 'ORCID: 0000-0002-8577-0084']	['Copyright (c) 2018 Segal et al.']					['2018/11/01 06:00']	20190226	20181030	2018 Oct 30	2018/11/01 06:00		['Segal, Ella Shtifman', 'Gritsenko, Vladimir', 'Levitan, Anton', 'Yadav, Bhawna', 'Dror, Naama', 'Steenwyk, Jacob L', 'Silberberg, Yael', 'Mielich, Kevin', 'Rokas, Antonis', 'Gow, Neil A R', 'Kunze, Reinhard', 'Sharan, Roded', 'Berman, Judith']		['Wellcome Trust/United Kingdom', '086827/Wellcome Trust/United Kingdom', '075470/Wellcome Trust/United Kingdom', '101873/Wellcome Trust/United Kingdom', '200208/Wellcome Trust/United Kingdom', 'N006364/1/Medical Research Council/United Kingdom']	5		2150-7511 (Electronic)	101519231	mBio	['eng']	e02048-18 [pii] 10.1128/mBio.02048-18 [doi]	20190226	['Aspergillus fumigatus/genetics', 'Candida albicans/*genetics/growth & development', 'Cryptococcus neoformans/genetics', 'DNA Transposable Elements', '*Genes, Essential', '*Genes, Fungal', 'Genetics, Microbial/*methods', 'Haploidy', 'Histoplasma/genetics', '*Machine Learning', 'Mutagenesis, Insertional/*methods']	2019/02/27 06:00		['*Candida albicans', '*genome analysis', '*genomics', '*machine learning', '*phenotypic identification', '*transposons']	['NOTNLM']	NLM		['2018/11/01 06:00 [entrez]', '2018/11/01 06:00 [pubmed]', '2019/02/27 06:00 [medline]']	United States	PMC6212825		30377286	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (DNA Transposable Elements)']	IM	['figshare/10.6084/m9.figshare.c.4251182']	MBio. 2018 Oct 30;9(5). pii: mBio.02048-18. doi: 10.1128/mBio.02048-18.	MEDLINE	MBio	Gene Essentiality Analyzed by In Vivo Transposon Mutagenesis and Machine Learning in a Stable Haploid Isolate of Candida albicans.		9	Gene Essentiality Analyzed by In Vivo Transposon Mutagenesis and Machine Learning in a Stable Haploid Isolate of Candida albicans.
Current liver fibrosis scoring by computer-assisted image analytics is not fully automated as it requires manual preprocessing (segmentation and feature extraction) typically based on domain knowledge in liver pathology. Deep learning-based algorithms can potentially classify these images without the need for preprocessing through learning from a large dataset of images. We investigated the performance of classification models built using a deep learning-based algorithm pre-trained using multiple sources of images to score liver fibrosis and compared them against conventional non-deep learning-based algorithms - artificial neural networks (ANN), multinomial logistic regression (MLR), support vector machines (SVM) and random forests (RF). Automated feature classification and fibrosis scoring were achieved by using a transfer learning-based deep learning network, AlexNet-Convolutional Neural Networks (CNN), with balanced area under receiver operating characteristic (AUROC) values of up to 0.85-0.95 versus ANN (AUROC of up to 0.87-1.00), MLR (AUROC of up to 0.73-1.00), SVM (AUROC of up to 0.69-0.99) and RF (AUROC of up to 0.94-0.99). Results indicate that a deep learning-based algorithm with transfer learning enables the construction of a fully automated and accurate prediction model for scoring liver fibrosis stages that is comparable to other conventional non-deep learning-based algorithms that are not fully automated.	['Institute of Bioengineering and Nanotechnology, Agency for Science, Technology and Research (A*STAR), Singapore, 138669, Singapore.', 'Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 117597, Singapore.', 'BioSystems and Micromechanics (BioSyM), Singapore-MIT Alliance for Research and Technology, Singapore, 138602, Singapore.', 'Institute of Neuroscience, Department of Neurobiology, Key Laboratory of Medical Neurobiology of the Ministry of Health of China, Zhejiang Province Key Laboratory of Neurobiology, School of Medicine, Zhejiang University, Zhejiang, 310058, China.', 'Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 117597, Singapore.', 'NUS Graduate School of Integrative Sciences and Engineering, National University of Singapore, Singapore, 117411, Singapore.', 'Mechanobiology Institute, National University of Singapore, Singapore, 117411, Singapore.', 'Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 117597, Singapore.', 'Mechanobiology Institute, National University of Singapore, Singapore, 117411, Singapore.', 'Institute of Bioengineering and Nanotechnology, Agency for Science, Technology and Research (A*STAR), Singapore, 138669, Singapore.', 'Department of Biomedical Engineering, National University of Singapore, Singapore, 117583, Singapore.', 'Institute of Bioengineering and Nanotechnology, Agency for Science, Technology and Research (A*STAR), Singapore, 138669, Singapore.', 'Institute of Bioengineering and Nanotechnology, Agency for Science, Technology and Research (A*STAR), Singapore, 138669, Singapore.', 'Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 117597, Singapore.', 'Duke-NUS Graduate Medical School Singapore, National University of Singapore, Singapore, 169857, Singapore.', 'Institute of Neuroscience, Department of Neurobiology, Key Laboratory of Medical Neurobiology of the Ministry of Health of China, Zhejiang Province Key Laboratory of Neurobiology, School of Medicine, Zhejiang University, Zhejiang, 310058, China.', 'State Key Laboratory of Modern Optical Instrumentation, College of Optical Science and Engineering, Zhejiang University, Zhejiang, 310027, China.', 'Department of Pathology, National University Hospital, Singapore, 119074, Singapore.', 'Department of Pathology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 119074, Singapore.', 'Sloan School of Management, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA.', 'Center for Statistics and Data Science, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA.', 'BioSystems and Micromechanics (BioSyM), Singapore-MIT Alliance for Research and Technology, Singapore, 138602, Singapore.', 'Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA.', 'Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, MA, 02139, USA.', 'Institute of Bioengineering and Nanotechnology, Agency for Science, Technology and Research (A*STAR), Singapore, 138669, Singapore. hanry_yu@nuhs.edu.sg.', 'Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 117597, Singapore. hanry_yu@nuhs.edu.sg.', 'BioSystems and Micromechanics (BioSyM), Singapore-MIT Alliance for Research and Technology, Singapore, 138602, Singapore. hanry_yu@nuhs.edu.sg.', 'Mechanobiology Institute, National University of Singapore, Singapore, 117411, Singapore. hanry_yu@nuhs.edu.sg.', 'Confocal Microscopy Unit & Flow Cytometry Laboratory, National University Health System, Singapore, 119228, Singapore. hanry_yu@nuhs.edu.sg.', 'Gastroenterology Department, Nanfang Hospital, Southern Medical University, Guangzhou, 510515, China. hanry_yu@nuhs.edu.sg.']	['10.1038/s41598-018-34300-2 [doi]', '10.1038/s41598-018-34300-2 [pii]']	['Yu Y', 'Wang J', 'Ng CW', 'Ma Y', 'Mo S', 'Fong ELS', 'Xing J', 'Song Z', 'Xie Y', 'Si K', 'Wee A', 'Welsch RE', 'So PTC', 'Yu H']	['ORCID: http://orcid.org/0000-0001-8328-4325', 'ORCID: http://orcid.org/0000-0002-0339-3685']						['2018/10/31 06:00']	20191025	20181030	2018 Oct 30	2018/10/31 06:00		['Yu, Yang', 'Wang, Jiahao', 'Ng, Chan Way', 'Ma, Yukun', 'Mo, Shupei', 'Fong, Eliza Li Shan', 'Xing, Jiangwa', 'Song, Ziwei', 'Xie, Yufei', 'Si, Ke', 'Wee, Aileen', 'Welsch, Roy E', 'So, Peter T C', 'Yu, Hanry']		['P41 EB015871/EB/NIBIB NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-34300-2 [doi]	20191030	['Algorithms', 'Animals', 'Biomarkers', 'Biopsy', 'Collagen/metabolism', 'Deep Learning', '*Diagnostic Imaging/methods', 'Image Processing, Computer-Assisted/*methods/standards', 'Liver Cirrhosis/*diagnostic imaging/pathology', 'Machine Learning', 'Magnetic Resonance Imaging', 'Male', 'Microscopy', 'Neural Networks (Computer)', 'Rats', 'Reproducibility of Results', 'Tomography, X-Ray Computed']	2019/10/28 06:00				NLM	16016	['2018/02/15 00:00 [received]', '2018/10/12 00:00 [accepted]', '2018/10/31 06:00 [entrez]', '2018/10/31 06:00 [pubmed]', '2019/10/28 06:00 [medline]']	England	PMC6207665		30375454	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Biomarkers)', '9007-34-5 (Collagen)']	IM		Sci Rep. 2018 Oct 30;8(1):16016. doi: 10.1038/s41598-018-34300-2.	MEDLINE	Sci Rep	Deep learning enables automated scoring of liver fibrosis stages.		8	Deep learning enables automated scoring of liver fibrosis stages.
PURPOSE: Due to the low contrast, blurry boundaries, and large amount of shadows in breast ultrasound (BUS) images, automatic tumor segmentation remains a challenging task. Deep learning provides a solution to this problem, since it can effectively extract representative features from lesions and the background in BUS images. METHODS: A novel automatic tumor segmentation method is proposed by combining a dilated fully convolutional network (DFCN) with a phase-based active contour (PBAC) model. The DFCN is an improved fully convolutional neural network with dilated convolution in deeper layers, fewer parameters, and batch normalization techniques; and has a large receptive field that can separate tumors from background. The predictions made by the DFCN are relatively rough due to blurry boundaries and variations in tumor sizes; thus, the PBAC model, which adds both region-based and phase-based energy functions, is applied to further improve segmentation results. The DFCN model is trained and tested in dataset 1 which contains 570 BUS images from 89 patients. In dataset 2, a 10-fold support vector machine (SVM) classifier is employed to verify the diagnostic ability using 460 features extracted from the segmentation results of the proposed method. RESULTS: Advantages of the present method were compared with three state-of-the-art networks; the FCN-8s, U-net, and dilated residual network (DRN). Experimental results from 170 BUS images show that the proposed method had a Dice Similarity coefficient of 88.97 +/- 10.01%, a Hausdorff distance (HD) of 35.54 +/- 29.70 pixels, and a mean absolute deviation (MAD) of 7.67 +/- 6.67 pixels, which showed the best segmentation performance. In dataset 2, the area under curve (AUC) of the 10-fold SVM classifier was 0.795 which is similar to the classification using the manual segmentation results. CONCLUSIONS: The proposed automatic method may be sufficiently accurate, robust, and efficient for medical ultrasound applications.	['Departmentof Electronic Engineering, Fudan University, Shanghai, 200433, China.', 'Departmentof Electronic Engineering, Fudan University, Shanghai, 200433, China.', 'Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai, Shanghai, 200433, China.', 'Departmentof Electronic Engineering, Fudan University, Shanghai, 200433, China.', 'Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai, Shanghai, 200433, China.', 'Departmentof Electronic Engineering, Fudan University, Shanghai, 200433, China.', 'Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai, Shanghai, 200433, China.', 'Department of Ultrasound, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Ultrasound, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.', 'Department of Ultrasound, Fudan University Shanghai Cancer Center, Shanghai, 200032, China.']	['10.1002/mp.13268 [doi]']	['Hu Y', 'Guo Y', 'Wang Y', 'Yu J', 'Li J', 'Zhou S', 'Chang C']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/10/31 06:00']	20190121	20181128	2019 Jan	2018/10/31 06:00		['Hu, Yuzhou', 'Guo, Yi', 'Wang, Yuanyuan', 'Yu, Jinhua', 'Li, Jiawei', 'Zhou, Shichong', 'Chang, Cai']		['61771143/National Natural Science Foundation of China', '81627804/National Natural Science Foundation of China']	1		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13268 [doi]	20190121	['Automation', 'Breast Neoplasms/*diagnostic imaging', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Models, Theoretical', '*Neural Networks (Computer)', '*Ultrasonography, Mammary']	2019/01/22 06:00		['automatic tumor segmentation', 'breast ultrasound', 'dilated fully convolutional network', 'phase-based active contours']	['NOTNLM']	NLM	215-228	['2018/04/19 00:00 [received]', '2018/09/30 00:00 [revised]', '2018/10/16 00:00 [accepted]', '2018/10/31 06:00 [pubmed]', '2019/01/22 06:00 [medline]', '2018/10/31 06:00 [entrez]']	United States			30374980	ppublish	['Journal Article']			IM		Med Phys. 2019 Jan;46(1):215-228. doi: 10.1002/mp.13268. Epub 2018 Nov 28.	MEDLINE	Med Phys	Automatic tumor segmentation in breast ultrasound images using a dilated fully convolutional network combined with an active contour model.		46	Automatic tumor segmentation in breast ultrasound images using a dilated fully convolutional network combined with an active contour model.
Intra-arterial therapies are the standard of care for patients with hepatocellular carcinoma who cannot undergo surgical resection. The objective of this study was to develop a method to predict response to intra-arterial treatment prior to intervention. The method provides a general framework for predicting outcomes prior to intra-arterial therapy. It involves pooling clinical, demographic and imaging data across a cohort of patients and using these data to train a machine learning model. The trained model is applied to new patients in order to predict their likelihood of response to intra-arterial therapy. The method entails the acquisition and parsing of clinical, demographic and imaging data from N patients who have already undergone trans-arterial therapies. These data are parsed into discrete features (age, sex, cirrhosis, degree of tumor enhancement, etc.) and binarized into true/false values (e.g., age over 60, male gender, tumor enhancement beyond a set threshold, etc.). Low-variance features and features with low univariate associations with the outcome are removed. Each treated patient is labeled according to whether they responded or did not respond to treatment. Each training patient is thus represented by a set of binary features and an outcome label. Machine learning models are trained using N - 1 patients with testing on the left-out patient. This process is repeated for each of the N patients. The N models are averaged to arrive at a final model. The technique is extensible and enables inclusion of additional features in the future. It is also a generalizable process that may be applied to clinical research questions outside of interventional radiology. The main limitation is the need to derive features manually from each patient. A popular modern form of machine learning called deep learning does not suffer from this limitation, but requires larger datasets.	['Department of Radiology and Biomedical Imaging, Yale School of Medicine', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine; Department of Diagnostic and Interventional Radiology, Universitatsmedizin Charite Berlin.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine.', 'Department of Biomedical Engineering, Yale School of Engineering and Applied Science.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine.', 'Philips Research North America.', 'Prescience Labs.', 'Department of Radiology and Biomedical Imaging, Yale School of Medicine; julius.chapiro@yale.edu']	['10.3791/58382 [doi]']	['Abajian A', 'Murali N', 'Savic LJ', 'Laage-Gaupp FM', 'Nezami N', 'Duncan JS', 'Schlachter T', 'Lin M', 'Geschwind JF', 'Chapiro J']							['2018/10/30 06:00']	20190404	20181010	2018 Oct 10	2018/10/30 06:00		['Abajian, Aaron', 'Murali, Nikitha', 'Savic, Lynn Jeanette', 'Laage-Gaupp, Fabian Max', 'Nezami, Nariman', 'Duncan, James S', 'Schlachter, Todd', 'Lin, MingDe', 'Geschwind, Jean-Francois', 'Chapiro, Julius']		['R01 CA206180/CA/NCI NIH HHS/United States']	140		1940-087X (Electronic) 1940-087X (Linking)	101313252	Journal of visualized experiments : JoVE	['eng']	10.3791/58382 [doi]	20190615	['Carcinoma, Hepatocellular/*diagnostic imaging/pathology/therapy', 'Humans', 'Injections, Intra-Arterial/*methods', 'Liver Neoplasms/*diagnostic imaging/pathology/therapy', 'Machine Learning/*trends', 'Male', 'Middle Aged', 'Surgery, Computer-Assisted/*methods']	2019/04/05 06:00				NLM		['2020/10/10 00:00 [pmc-release]', '2018/10/30 06:00 [entrez]', '2018/10/30 06:00 [pubmed]', '2019/04/05 06:00 [medline]']	United States	PMC6235502	['2020/10/10 00:00']	30371657	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", 'Video-Audio Media']"			IM		J Vis Exp. 2018 Oct 10;(140). doi: 10.3791/58382.	MEDLINE	J Vis Exp	Predicting Treatment Response to Image-Guided Therapies Using Machine Learning: An Example for Trans-Arterial Treatment of Hepatocellular Carcinoma.			Predicting Treatment Response to Image-Guided Therapies Using Machine Learning: An Example for Trans-Arterial Treatment of Hepatocellular Carcinoma.
Predicting protein structure from sequence alone is challenging. Thus, the majority of methods for protein structure prediction rely on evolutionary information from multiple sequence alignments. In previous work we showed that Long Short-Term Bidirectional Recurrent Neural Networks (LSTM-BRNNs) improved over regular neural networks by better capturing intra-sequence dependencies. Here we show a single-sequence-based prediction method employing LSTM-BRNNs (SPIDER3-Single), that consistently achieves Q3 accuracy of 72.5%, and correlation coefficient of 0.67 between predicted and actual solvent accessible surface area. Moreover, it yields reasonably accurate prediction of eight-state secondary structure, main-chain angles (backbone varphi and psi torsion angles and C alpha-atom-based theta and tau angles), half-sphere exposure, and contact number. The method is more accurate than the corresponding evolutionary-based method for proteins with few sequence homologs, and computationally efficient for large-scale screening of protein-structural properties. It is available as an option in the SPIDER3 server, and a standalone version for download, at http://sparks-lab.org. (c) 2018 Wiley Periodicals, Inc.	['Signal Processing Laboratory, Griffith University, Brisbane, QLD, 4111, Australia.', 'Signal Processing Laboratory, Griffith University, Brisbane, QLD, 4111, Australia.', 'Signal Processing Laboratory, Griffith University, Brisbane, QLD, 4111, Australia.', 'Signal Processing Laboratory, Griffith University, Brisbane, QLD, 4111, Australia.', 'School of Data and Computer Science, Sun Yet-Sen University, Guangzhou, China.', 'Institute for Glycomics and School of Information and Communication Technology, Griffith University, Southport, QLD, 4222, Australia.']	['10.1002/jcc.25534 [doi]']	['Heffernan R', 'Paliwal K', 'Lyons J', 'Singh J', 'Yang Y', 'Zhou Y']	['ORCID: 0000-0002-9946-1995', 'ORCID: 0000-0002-9958-5699']	['(c) 2018 Wiley Periodicals, Inc.']					['2018/10/29 06:00']	20190918	20181014	2018 Oct 5	2018/10/29 06:00		['Heffernan, Rhys', 'Paliwal, Kuldip', 'Lyons, James', 'Singh, Jaswinder', 'Yang, Yuedong', 'Zhou, Yaoqi']			26		1096-987X (Electronic) 0192-8651 (Linking)	9878362	Journal of computational chemistry	['eng']	10.1002/jcc.25534 [doi]	20190918	['*Deep Learning', '*Protein Structure, Secondary', 'Proteins/*chemistry', 'Solvents/*chemistry']	2019/09/19 06:00		['*backbone angles', '*contact prediction', '*protein structure prediction', '*secondary structure prediction', '*solvent accessibility prediction']	['NOTNLM']	NLM	2210-2216	['2018/02/12 00:00 [received]', '2018/05/11 00:00 [revised]', '2018/06/14 00:00 [accepted]', '2018/10/29 06:00 [pubmed]', '2019/09/19 06:00 [medline]', '2018/10/29 06:00 [entrez]']	United States			30368831	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)', '0 (Solvents)']	IM		J Comput Chem. 2018 Oct 5;39(26):2210-2216. doi: 10.1002/jcc.25534. Epub 2018 Oct 14.	MEDLINE	J Comput Chem	Single-sequence-based prediction of protein secondary structures and solvent accessibility by deep whole-sequence learning.		39	Single-sequence-based prediction of protein secondary structures and solvent accessibility by deep whole-sequence learning.
PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans. METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation. RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 +/- 6.1% vs 5.5 +/- 7.9%, P < 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P > 0.05), except for the bilateral optic nerves and the optic chiasm. CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.	['National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China.', 'National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China.']	['10.1002/mp.13262 [doi]']	['Chen X', 'Men K', 'Li Y', 'Yi J', 'Dai J']		['(c) 2018 The Authors Medical Physics published by Wiley Periodicals, Inc. on', 'behalf of American Association of Physicists in Medicine.']					['2018/10/28 06:00']	20190121	20181123	2019 Jan	2018/10/28 06:00		['Chen, Xinyuan', 'Men, Kuo', 'Li, Yexiong', 'Yi, Junlin', 'Dai, Jianrong']		['2017YFC0107500/National Key Projects of Research and Development of China', '2016YFC0904600/National Key Projects of Research and Development of China', 'LC2015B06/Cancer Foundation of China', '11605291/National Natural Science Foundation of China', '11275270/National Natural Science Foundation of China']	1		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13262 [doi]	20190121	['Automation', '*Deep Learning', 'Feasibility Studies', 'Humans', 'Neural Networks (Computer)', '*Radiation Dosage', 'Radiotherapy Dosage', 'Radiotherapy Planning, Computer-Assisted/*methods', 'Radiotherapy, Intensity-Modulated']	2019/01/22 06:00		['automatic', 'deep learning', 'dose prediction', 'radiotherapy', 'treatment planning']	['NOTNLM']	NLM	56-64	['2018/04/09 00:00 [received]', '2018/10/17 00:00 [revised]', '2018/10/21 00:00 [accepted]', '2018/10/28 06:00 [pubmed]', '2019/01/22 06:00 [medline]', '2018/10/28 06:00 [entrez]']	United States			30367492	ppublish	['Journal Article']			IM		Med Phys. 2019 Jan;46(1):56-64. doi: 10.1002/mp.13262. Epub 2018 Nov 23.	MEDLINE	Med Phys	A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.		46	A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.
PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions. METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used. RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more). CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.	['Department of Radiation Convergence Engineering, Research Institute of Health Science, Yonsei Univeristy, 1 Yonseidae-gil, Wonju, Gangwon, 26493, Korea.', 'Department of Radiological Science, College of Health Science, Yonsei University, 1 Yonseidae-gil, Wonju, Gangwon, 26493, Korea.', 'Department of Radiation Convergence Engineering, Research Institute of Health Science, Yonsei Univeristy, 1 Yonseidae-gil, Wonju, Gangwon, 26493, Korea.', 'Department of Radiological Science, College of Health Science, Yonsei University, 1 Yonseidae-gil, Wonju, Gangwon, 26493, Korea.']	['10.1002/mp.13258 [doi]']	['Lee D', 'Choi S', 'Kim HJ']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/10/27 06:00']	20190121	20181128	2019 Jan	2018/10/27 06:00		['Lee, Donghoon', 'Choi, Sunghoon', 'Kim, Hee-Joung']		['NRF-2017M2A2A6A01070263/National Research Foundation of Korea']	1		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13258 [doi]	20190121	['*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Lung/diagnostic imaging', 'Quality Control', 'Radiation Dosage', '*Tomography, X-Ray Computed', '*Wavelet Analysis']	2019/01/22 06:00		['deep learning', 'sparse sampling', 'wavelet transform']	['NOTNLM']	NLM	104-115	['2018/04/30 00:00 [received]', '2018/10/17 00:00 [revised]', '2018/10/18 00:00 [accepted]', '2018/10/27 06:00 [pubmed]', '2019/01/22 06:00 [medline]', '2018/10/27 06:00 [entrez]']	United States			30362117	ppublish	['Journal Article']			IM		Med Phys. 2019 Jan;46(1):104-115. doi: 10.1002/mp.13258. Epub 2018 Nov 28.	MEDLINE	Med Phys	High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.		46	High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.
BACKGROUND: Automated cardiac image interpretation has the potential to transform clinical practice in multiple ways, including enabling serial assessment of cardiac function by nonexperts in primary care and rural settings. We hypothesized that advances in computer vision could enable building a fully automated, scalable analysis pipeline for echocardiogram interpretation, including (1) view identification, (2) image segmentation, (3) quantification of structure and function, and (4) disease detection. METHODS: Using 14 035 echocardiograms spanning a 10-year period, we trained and evaluated convolutional neural network models for multiple tasks, including automated identification of 23 viewpoints and segmentation of cardiac chambers across 5 common views. The segmentation output was used to quantify chamber volumes and left ventricular mass, determine ejection fraction, and facilitate automated determination of longitudinal strain through speckle tracking. Results were evaluated through comparison to manual segmentation and measurements from 8666 echocardiograms obtained during the routine clinical workflow. Finally, we developed models to detect 3 diseases: hypertrophic cardiomyopathy, cardiac amyloid, and pulmonary arterial hypertension. RESULTS: Convolutional neural networks accurately identified views (eg, 96% for parasternal long axis), including flagging partially obscured cardiac chambers, and enabled the segmentation of individual cardiac chambers. The resulting cardiac structure measurements agreed with study report values (eg, median absolute deviations of 15% to 17% of observed values for left ventricular mass, left ventricular diastolic volume, and left atrial volume). In terms of function, we computed automated ejection fraction and longitudinal strain measurements (within 2 cohorts), which agreed with commercial software-derived values (for ejection fraction, median absolute deviation=9.7% of observed, N=6407 studies; for strain, median absolute deviation=7.5%, n=419, and 9.0%, n=110) and demonstrated applicability to serial monitoring of patients with breast cancer for trastuzumab cardiotoxicity. Overall, we found automated measurements to be comparable or superior to manual measurements across 11 internal consistency metrics (eg, the correlation of left atrial and ventricular volumes). Finally, we trained convolutional neural networks to detect hypertrophic cardiomyopathy, cardiac amyloidosis, and pulmonary arterial hypertension with C statistics of 0.93, 0.87, and 0.85, respectively. CONCLUSIONS: Our pipeline lays the groundwork for using automated interpretation to support serial patient tracking and scalable analysis of millions of echocardiograms archived within healthcare systems.	['Cardiovascular Research Institute (J.Z., R.C.D.).', 'Department of Electrical Engineering and Computer Science, University of California, Berkeley (J.Z., P.A., L.A.H., R.B.).', 'University of California, San Francisco (S.G.).', 'Department of Electrical Engineering and Computer Science, University of California, Berkeley (J.Z., P.A., L.A.H., R.B.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Department of Electrical Engineering and Computer Science, University of California, Berkeley (J.Z., P.A., L.A.H., R.B.).', 'Department of Medicine, Division of Cardiology, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL (L.B.-N., M.M., A.Q., S.J.S.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Department of Medicine, Division of Cardiology, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL (L.B.-N., M.M., A.Q., S.J.S.).', 'Department of Medicine, Division of Cardiology, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL (L.B.-N., M.M., A.Q., S.J.S.).', 'Department of Medicine, Division of Cardiology, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL (L.B.-N., M.M., A.Q., S.J.S.).', 'Department of Electrical Engineering and Computer Science, University of California, Berkeley (J.Z., P.A., L.A.H., R.B.).', 'Cardiovascular Research Institute (J.Z., R.C.D.).', 'Department of Medicine (G.H.T., M.H.L., E.F., M.A.A., C.J., K.E.F., R.C.D.).', 'Institute for Human Genetics (R.C.D.).', 'Institute for Computational Health Sciences (R.C.D.).', 'Center for Digital Health Innovation (R.C.D.).', 'California Institute for Quantitative Biosciences, San Francisco (R.C.D.).']	['10.1161/CIRCULATIONAHA.118.034338 [doi]']	['Zhang J', 'Gajjala S', 'Agrawal P', 'Tison GH', 'Hallock LA', 'Beussink-Nelson L', 'Lassen MH', 'Fan E', 'Aras MA', 'Jordan C', 'Fleischmann KE', 'Melisko M', 'Qasim A', 'Shah SJ', 'Bajcsy R', 'Deo RC']			['Circulation. 2018 Oct 16;138(16):1636-1638. PMID: 30354471', 'Circulation. 2018 Oct 16;138(16):1639-1642. PMID: 30354473']				['2018/10/26 06:00']	20190930		2018 Oct 16	2018/10/26 06:00		['Zhang, Jeffrey', 'Gajjala, Sravani', 'Agrawal, Pulkit', 'Tison, Geoffrey H', 'Hallock, Laura A', 'Beussink-Nelson, Lauren', 'Lassen, Mats H', 'Fan, Eugene', 'Aras, Mandar A', 'Jordan, ChaRandle', 'Fleischmann, Kirsten E', 'Melisko, Michelle', 'Qasim, Atif', 'Shah, Sanjiv J', 'Bajcsy, Ruzena', 'Deo, Rahul C']		['K23 HL135274/HL/NHLBI NIH HHS/United States', 'P30 DK090868/DK/NIDDK NIH HHS/United States']	16		1524-4539 (Electronic) 0009-7322 (Linking)	0147763	Circulation	['eng']	10.1161/CIRCULATIONAHA.118.034338 [doi]	20190930	['Amyloidosis/*diagnostic imaging/physiopathology', 'Automation', 'Cardiomyopathy, Hypertrophic/*diagnostic imaging/physiopathology', '*Deep Learning', 'Echocardiography/*methods', 'Humans', 'Hypertension, Pulmonary/*diagnostic imaging/physiopathology', 'Image Interpretation, Computer-Assisted/*methods', 'Predictive Value of Tests', 'Reproducibility of Results', 'Stroke Volume', 'Ventricular Function, Left']	2019/10/01 06:00		['*diagnosis', '*echocardiography', '*machine learning']	['NOTNLM']	NLM	1623-1635	['2018/10/26 06:00 [entrez]', '2018/10/26 06:00 [pubmed]', '2019/10/01 06:00 [medline]']	United States	PMC6200386		30354459	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural', 'Validation Studies']			AIM IM		Circulation. 2018 Oct 16;138(16):1623-1635. doi: 10.1161/CIRCULATIONAHA.118.034338.	MEDLINE	Circulation	Fully Automated Echocardiogram Interpretation in Clinical Practice.		138	Fully Automated Echocardiogram Interpretation in Clinical Practice.
"One of the most promising areas of health innovation is the application of artificial intelligence (AI), primarily in medical imaging. This article provides basic definitions of terms such as ""machine/deep learning"" and analyses the integration of AI into radiology. Publications on AI have drastically increased from about 100-150 per year in 2007-2008 to 700-800 per year in 2016-2017. Magnetic resonance imaging and computed tomography collectively account for more than 50% of current articles. Neuroradiology appears in about one-third of the papers, followed by musculoskeletal, cardiovascular, breast, urogenital, lung/thorax, and abdomen, each representing 6-9% of articles. With an irreversible increase in the amount of data and the possibility to use AI to identify findings either detectable or not by the human eye, radiology is now moving from a subjective perceptual skill to a more objective science. Radiologists, who were on the forefront of the digital era in medicine, can guide the introduction of AI into healthcare. Yet, they will not be replaced because radiology includes communication of diagnosis, consideration of patient's values and preferences, medical judgment, quality assurance, education, policy-making, and interventional procedures. The higher efficiency provided by AI will allow radiologists to perform more value-added tasks, becoming more visible to patients and playing a vital role in multidisciplinary clinical teams."	['Postgraduate School in Radiodiagnostics, Universita degli Studi di Milano, Via Festa del Perdono 7, 20122, Milan, Italy.', 'Unit of Radiology, IRCCS Policlinico San Donato, Via Morandi 30, 20097 San Donato Milanese, Milan, Italy. marina.codari@grupposandonato.it.', 'Unit of Radiology, IRCCS Policlinico San Donato, Via Morandi 30, 20097 San Donato Milanese, Milan, Italy.', 'Department of Biomedical Sciences for Health, Universita degli Studi di Milano, Via Morandi 30, 20097 San Donato Milanese, Milan, Italy.']	['10.1186/s41747-018-0061-6 [doi]', '10.1186/s41747-018-0061-6 [pii]']	['Pesapane F', 'Codari M', 'Sardanelli F']	['ORCID: http://orcid.org/0000-0001-8475-2071']						['2018/10/25 06:00']		20181024	2018 Oct 24	2018/10/26 06:00		['Pesapane, Filippo', 'Codari, Marina', 'Sardanelli, Francesco']		['Ricerca Corrente/Ministero della Salute']	1		2509-9280 (Electronic) 2509-9280 (Linking)	101721752	European radiology experimental	['eng']	10.1186/s41747-018-0061-6 [doi]	20191120		2018/10/26 06:01		['Artificial intelligence', 'Deep learning', 'Machine learning', 'Neural networks (computer)', 'Radiology']	['NOTNLM']	NLM	35	['2018/05/07 00:00 [received]', '2018/07/31 00:00 [accepted]', '2018/10/25 06:00 [entrez]', '2018/10/26 06:00 [pubmed]', '2018/10/26 06:01 [medline]']	England	PMC6199205		30353365	epublish	['Journal Article', 'Review']					Eur Radiol Exp. 2018 Oct 24;2(1):35. doi: 10.1186/s41747-018-0061-6.	PubMed-not-MEDLINE	Eur Radiol Exp	Artificial intelligence in medical imaging: threat or opportunity? Radiologists again at the forefront of innovation in medicine.		2	Artificial intelligence in medical imaging: threat or opportunity? Radiologists again at the forefront of innovation in medicine.
In a mass casualty incident, the factors that determine the survival rate of injured patients are diverse, but one of the key factors is the time for triage. Additionally, the main factor that determines the time of triage is the number of medical personnel. However, when relying on a small number of medical personnel, the ability to increase survivability is limited. Therefore, developing a classification model for survival prediction that can quickly and precisely triage via wearable devices without medical personnel is important. In this study, we designed a consciousness index to substitute the factor by manpower and improved the classification accuracy by applying a machine learning algorithm. First, logistic regression analysis using vital signs and a consciousness index capable of remote monitoring through wearable devices confirmed the high efficiency of the consciousness index. We then developed a classification model with high accuracy which corresponds to existing injury severity scoring systems through the machine learning algorithms. We extracted 460,865 cases which met our criteria for developing the survival prediction from the national sample project in the national trauma databank which contains 408,316 cases of blunt injury and 52,549 cases of penetrating injury. Among the dataset, 17,918 (3.9%) cases died while the other survived. The AUCs with 95% confidence intervals (CIs) for the different models with the proposed simplified consciousness score as follows: RTS (as baseline), 0.78 (95% CI = 0.775 to 0.785); logistic regression, 0.87 (95% CI = 0.862 to 0.870); random forest, 0.87 (95% CI = 0.862 to 0.872); deep neural network, 0.89 (95% CI = 0.882 to 0.890). As a result, we confirmed the possibility of remote triage using a wearable device. It is expected that the time required for triage can be effectively reduced by using the developed classification model of survival prediction.	['Convergence Research Center for Diagnosis, Treatment, and Care of Dementia, Korea Institute of Science and Technology, Seoul, South Korea.', 'Department of Biomedical Engineering, Hanyang University, Seoul, South Korea.', 'Department of Biomedical Engineering, Hanyang University, Seoul, South Korea.', 'Department of Biomedical Engineering, Hanyang University, Seoul, South Korea.', 'Department of Biomedical Engineering, Hanyang University, Seoul, South Korea.', 'Department of Biomedical Engineering, Hanyang University, Seoul, South Korea.', 'Department of Biomedical Engineering, Hanyang University, Seoul, South Korea.', 'Smart Healthcare & Device Research Center, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea.', 'Smart Healthcare & Device Research Center, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea.', 'Department of Emergency Medicine, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea.', 'Department of Digital Health, Samsung Advanced Institute for Health Sciences & Technology, Sungkyunkwan University, Seoul, South Korea.', 'Department of Digital Health, Samsung Advanced Institute for Health Sciences & Technology, Sungkyunkwan University, Seoul, South Korea.', 'Department of Family Medicine, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea.', 'Smart Healthcare & Device Research Center, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea.', 'Department of Medical Device Management and Research, Samsung Advanced Institute for Health Sciences & Technology, Sungkyunkwan University, Seoul, South Korea.', 'Department of Family Medicine, Hanyang University College of Medicine, Seoul, South Korea.']	['10.1371/journal.pone.0206006 [doi]', 'PONE-D-18-25210 [pii]']	['Kim D', 'You S', 'So S', 'Lee J', 'Yook S', 'Jang DP', 'Kim IY', 'Park E', 'Cho K', 'Cha WC', 'Shin DW', 'Cho BH', 'Park HK']	['ORCID: 0000-0002-2144-9523']				['The authors have declared that no competing interests exist.']		['2018/10/24 06:00']	20190401	20181023	2018	2018/10/24 06:00		['Kim, Dohyun', 'You, Sungmin', 'So, Soonwon', 'Lee, Jongshill', 'Yook, Sunhyun', 'Jang, Dong Pyo', 'Kim, In Young', 'Park, Eunkyoung', 'Cho, Kyeongwon', 'Cha, Won Chul', 'Shin, Dong Wook', 'Cho, Baek Hwan', 'Park, Hoon-Ki']			10		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0206006 [doi]	20190401	['Algorithms', '*Artificial Intelligence', 'Consciousness', 'Data Analysis', 'False Positive Reactions', 'Glasgow Coma Scale', '*Hospitals', 'Humans', 'Machine Learning', 'Middle Aged', 'Neural Networks (Computer)', 'ROC Curve', 'Survival Analysis', '*Triage']	2019/04/02 06:00				NLM	e0206006	['2018/08/28 00:00 [received]', '2018/10/04 00:00 [accepted]', '2018/10/24 06:00 [entrez]', '2018/10/24 06:00 [pubmed]', '2019/04/02 06:00 [medline]']	United States	PMC6198975		30352077	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Oct 23;13(10):e0206006. doi: 10.1371/journal.pone.0206006. eCollection 2018.	MEDLINE	PLoS One	A data-driven artificial intelligence model for remote triage in the prehospital environment.		13	A data-driven artificial intelligence model for remote triage in the prehospital environment.
Acute Leukemia is a life-threatening disease common both in children and adults that can lead to death if left untreated. Acute Lymphoblastic Leukemia (ALL) spreads out in children's bodies rapidly and takes the life within a few weeks. To diagnose ALL, the hematologists perform blood and bone marrow examination. Manual blood testing techniques that have been used since long time are often slow and come out with the less accurate diagnosis. This work improves the diagnosis of ALL with a computer-aided system, which yields accurate result by using image processing and deep learning techniques. This research proposed a method for the classification of ALL into its subtypes and reactive bone marrow (normal) in stained bone marrow images. A robust segmentation and deep learning techniques with the convolutional neural network are used to train the model on the bone marrow images to achieve accurate classification results. Experimental results thus obtained and compared with the results of other classifiers Naive Bayesian, KNN, and SVM. Experimental results reveal that the proposed method achieved 97.78% accuracy. The obtained results exhibit that the proposed approach could be used as a tool to diagnose Acute Lymphoblastic Leukemia and its sub-types that will definitely assist pathologists.	['College of Computer and Information Systems, Al Yamamah University, Riyadh, Saudi Arabia.', 'Department of Computer Science, Islamia College University Peshawar, Pakistan.', 'College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia.', 'Department of Computer Science, Islamia College University Peshawar, Pakistan.', 'Department of Software Engineering, University of Engineering and Technology Taxila, Pakistan.', 'Department of Computer Science, Liverpool John Moores University, Liverpool, United Kingdom.']	['10.1002/jemt.23139 [doi]']	['Rehman A', 'Abbas N', 'Saba T', 'Rahman SIU', 'Mehmood Z', 'Kolivand H']	['ORCID: https://orcid.org/0000-0002-3817-2655', 'ORCID: https://orcid.org/0000-0003-3138-3801']	['(c) 2018 Wiley Periodicals, Inc.']					['2018/10/24 06:00']	20190128	20181023	2018 Nov	2018/10/24 06:00		['Rehman, Amjad', 'Abbas, Naveed', 'Saba, Tanzila', 'Rahman, Syed Ijaz Ur', 'Mehmood, Zahid', 'Kolivand, Hoshang']		['[RG-CCIS-2017-06-02]/Prince Sultan University Riyadh KSA', 'RG-CCIS-2017-06-02/Machine Learning Research Group']	11		1097-0029 (Electronic) 1059-910X (Linking)	9203012	Microscopy research and technique	['eng']	10.1002/jemt.23139 [doi]	20190128	['Bone Marrow/*pathology', '*Deep Learning', 'Hematologic Tests/*methods', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Image Processing, Computer-Assisted/methods', 'Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', 'Precursor Cell Lymphoblastic Leukemia-Lymphoma/classification/*diagnosis/pathology']	2019/01/29 06:00		['acute lymphoblastic leukemia', 'bone marrow', 'deep learning', 'segmentation and classification']	['NOTNLM']	NLM	1310-1317	['2018/05/14 00:00 [received]', '2018/08/25 00:00 [revised]', '2018/09/01 00:00 [accepted]', '2018/10/24 06:00 [pubmed]', '2019/01/29 06:00 [medline]', '2018/10/24 06:00 [entrez]']	United States			30351463	ppublish	['Journal Article']			IM		Microsc Res Tech. 2018 Nov;81(11):1310-1317. doi: 10.1002/jemt.23139. Epub 2018 Oct 23.	MEDLINE	Microsc Res Tech	Classification of acute lymphoblastic leukemia using deep learning.		81	Classification of acute lymphoblastic leukemia using deep learning.
Suspected fractures are among the most common reasons for patients to visit emergency departments (EDs), and X-ray imaging is the primary diagnostic tool used by clinicians to assess patients for fractures. Missing a fracture in a radiograph often has severe consequences for patients, resulting in delayed treatment and poor recovery of function. Nevertheless, radiographs in emergency settings are often read out of necessity by emergency medicine clinicians who lack subspecialized expertise in orthopedics, and misdiagnosed fractures account for upward of four of every five reported diagnostic errors in certain EDs. In this work, we developed a deep neural network to detect and localize fractures in radiographs. We trained it to accurately emulate the expertise of 18 senior subspecialized orthopedic surgeons by having them annotate 135,409 radiographs. We then ran a controlled experiment with emergency medicine clinicians to evaluate their ability to detect fractures in wrist radiographs with and without the assistance of the deep learning model. The average clinician's sensitivity was 80.8% (95% CI, 76.7-84.1%) unaided and 91.5% (95% CI, 89.3-92.9%) aided, and specificity was 87.5% (95 CI, 85.3-89.5%) unaided and 93.9% (95% CI, 92.9-94.9%) aided. The average clinician experienced a relative reduction in misinterpretation rate of 47.0% (95% CI, 37.4-53.9%). The significant improvements in diagnostic accuracy that we observed in this study show that deep learning methods are a mechanism by which senior medical specialists can deliver their expertise to generalists on the front lines of medicine, thereby providing substantial improvements to patient care.	['Imagen Technologies, New York, NY 10012; rob@imagen.ai.', 'Faculty of Medicine, McGill University, Montreal, QC, Canada, H3A 2R7.', 'Imagen Technologies, New York, NY 10012.', 'Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, NY 10021.', 'Imagen Technologies, New York, NY 10012.', 'Imagen Technologies, New York, NY 10012.', 'Faculty of Medicine, McGill University, Montreal, QC, Canada, H3A 2R7.', 'Imagen Technologies, New York, NY 10012.', 'Department of Computer Science, University of Colorado, Boulder, CO 80309.', 'Imagen Technologies, New York, NY 10012.', 'Department of Radiology, Mount Sinai Health System, New York, NY 10029.', 'Imagen Technologies, New York, NY 10012.', 'Department of Orthopaedics and Sports Medicine, Harborview Medical Center, University of Washington, Seattle, WA 98104.', 'Imagen Technologies, New York, NY 10012.', 'Department of Orthopaedic Surgery, Stanford University School of Medicine, Stanford, CA 94305.', 'Imagen Technologies, New York, NY 10012.', 'Department of Emergency Medicine, Northwell Health, New Hyde Park, NY 11040.', 'Imagen Technologies, New York, NY 10012.', 'Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, NY 10021.', 'Imagen Technologies, New York, NY 10012.', 'Department of Radiology and Imaging, Hospital for Special Surgery, New York, NY 10021.']	['1806905115 [pii]', '10.1073/pnas.1806905115 [doi]']	['Lindsey R', 'Daluiski A', 'Chopra S', 'Lachapelle A', 'Mozer M', 'Sicular S', 'Hanel D', 'Gardner M', 'Gupta A', 'Hotchkiss R', 'Potter H']	['ORCID: 0000-0001-8561-8990']	['Copyright (c) 2018 the Author(s). Published by PNAS.']			['Conflict of interest statement: The authors are affiliated with Imagen', 'Technologies, a startup company, the eventual products and services of which will', 'be related to the subject matter of the article. The research was funded by', 'Imagen Technologies. The authors own stock options in the company.']		['2018/10/24 06:00']	20190501	20181022	2018 Nov 6	2018/10/24 06:00		['Lindsey, Robert', 'Daluiski, Aaron', 'Chopra, Sumit', 'Lachapelle, Alexander', 'Mozer, Michael', 'Sicular, Serge', 'Hanel, Douglas', 'Gardner, Michael', 'Gupta, Anurag', 'Hotchkiss, Robert', 'Potter, Hollis']			45		1091-6490 (Electronic) 0027-8424 (Linking)	7505876	Proceedings of the National Academy of Sciences of the United States of America	['eng']	10.1073/pnas.1806905115 [doi]	20190501	['Deep Learning/*statistics & numerical data', 'Diagnostic Errors/prevention & control', 'Emergency Medicine/methods', 'Fractures, Bone/*diagnostic imaging/pathology', 'Hospital Rapid Response Team', 'Humans', 'Image Interpretation, Computer-Assisted/*statistics & numerical data', '*Neural Networks (Computer)', 'Radiography/*methods', 'Sensitivity and Specificity', 'Wrist/diagnostic imaging/pathology']	2019/05/02 06:00		['*CAD', '*X-ray', '*deep learning', '*fractures', '*radiology']	['NOTNLM']	NLM	11591-11596	['2018/10/24 06:00 [pubmed]', '2019/05/02 06:00 [medline]', '2018/10/24 06:00 [entrez]']	United States	PMC6233134		30348771	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Proc Natl Acad Sci U S A. 2018 Nov 6;115(45):11591-11596. doi: 10.1073/pnas.1806905115. Epub 2018 Oct 22.	MEDLINE	Proc Natl Acad Sci U S A	Deep neural network improves fracture detection by clinicians.		115	Deep neural network improves fracture detection by clinicians.
In computed tomography coronary angiography (CTCA), calcification and stent make it difficult to evaluate intravascular lumen. This is a cause of low positive-predictive value of coronary stenosis. Therefore, it is expected to develop a computer-aided diagnosis (CAD) system that can automatically detect stenosis in coronary arteries. The purpose of this study is to automatically recognize calcifications or stents in coronary arteries and classify them from the normal coronary artery in CTCA. We used 4960 coronary-cross-sectional images, which consisted of 1113 images with calcification, 1353 images with a stent, and 2494 normal artery images. These images were automatically classified using the deep convolutional neural network (LeNet, AlexNet, and GoogLeNet). The classification accuracy of LeNet, AlexNet, and GoogLeNet were 58.4%, 75.9%, and 81.3%, respectively. The proposed method would be a fundamental technique of CAD in CTCA.	['School of Health Sciences, Faculty of Medicine, Niigata University.', 'Graduate School of Medical Science, Kanazawa University.', 'School of Health Sciences, Faculty of Medicine, Niigata University.', 'School of Health Sciences, Faculty of Medicine, Niigata University (Current address: Department of Radiology, Yokohama Minami Kyousai Hospital).', 'Institute of Medical, Pharmaceutical and Health Sciences, Kanazawa University.']	['10.6009/jjrt.2018_JSRT_74.10.1138 [doi]']	['Hasegawa A', 'Lee Y', 'Takeuchi Y', 'Ichikawa K']							['2018/10/23 06:00']	20190325		2018	2018/10/23 06:00		['Hasegawa, Akira', 'Lee, Yongbum', 'Takeuchi, Yu', 'Ichikawa, Katsuhiro']			10		0369-4305 (Print) 0369-4305 (Linking)	7505722	Nihon Hoshasen Gijutsu Gakkai zasshi	['jpn']	10.6009/jjrt.2018_JSRT_74.10.1138 [doi]	20190325	['Automation', '*Calcinosis/diagnostic imaging', '*Cardiomyopathies/diagnostic imaging', 'Computed Tomography Angiography', '*Coronary Angiography', '*Coronary Artery Disease', 'Cross-Sectional Studies', '*Deep Learning', 'Humans', 'Sensitivity and Specificity', 'Stents', 'Tomography, X-Ray Computed']	2019/03/26 06:00		['*computed tomography', '*computer-aided diagnosis (CAD)', '*coronary angiography', '*deep convolutional neural network', '*stenosis']	['NOTNLM']	NLM	1138-1143	['2018/10/23 06:00 [entrez]', '2018/10/23 06:00 [pubmed]', '2019/03/26 06:00 [medline]']	Japan			30344210	ppublish	['Journal Article']			IM		Nihon Hoshasen Gijutsu Gakkai Zasshi. 2018;74(10):1138-1143. doi: 10.6009/jjrt.2018_JSRT_74.10.1138.	MEDLINE	Nihon Hoshasen Gijutsu Gakkai Zasshi	[Automated Classification of Calcification and Stent on Computed Tomography Coronary Angiography Using Deep Learning].		74	[Automated Classification of Calcification and Stent on Computed Tomography Coronary Angiography Using Deep Learning].
BACKGROUND: The wide adoption of electronic health record systems (EHRs) in hospitals in China has made large amounts of data available for clinical research including breast cancer. Unfortunately, much of detailed clinical information is embedded in clinical narratives e.g., breast radiology reports. The American College of Radiology (ACR) has developed a Breast Imaging Reporting and Data System (BI-RADS) to standardize the clinical findings from breast radiology reports. OBJECTIVES: This study aims to develop natural language processing (NLP) methods to extract BI-RADS findings from breast ultrasound reports in Chinese, thus to support clinical operation and breast cancer research in China. METHODS: We developed and compared three different types of NLP approaches, including a rule-based method, a traditional machine learning-based method using the Conditional Random Fields (CRF) algorithm, and deep learning-based approaches, to extract all BI-RADS finding categories from breast ultrasound reports in Chinese. RESULTS: Using a manually annotated dataset containing 540 reports, our evaluation shows that the deep learning-based method achieved the best F1-score of 0.904, when compared with rule-based and CRF-based approaches (0.848 and 0.881 respectively). CONCLUSIONS: This is the first study that applies deep learning technologies to BI-RADS findings extraction in Chinese breast ultrasound reports, demonstrating its potential on enabling international collaborations on breast cancer research.	['Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.', 'Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China.', 'Department of Medical Informatics, Medical School, Nantong University, Nantong, Jiangsu, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.', 'Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China. Electronic address: ws0801@hotmail.com.', 'Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China. Electronic address: liuyun@njmu.edu.cn.']	['S1386-5056(18)30922-5 [pii]', '10.1016/j.ijmedinf.2018.08.009 [doi]']	['Miao S', 'Xu T', 'Wu Y', 'Xie H', 'Wang J', 'Jing S', 'Zhang Y', 'Zhang X', 'Yang Y', 'Zhang X', 'Shan T', 'Wang L', 'Xu H', 'Wang S', 'Liu Y']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/10/22 06:00']	20190523	20180818	2018 Nov	2018/10/22 06:00		['Miao, Shumei', 'Xu, Tingyu', 'Wu, Yonghui', 'Xie, Hui', 'Wang, Jingqi', 'Jing, Shenqi', 'Zhang, Yaoyun', 'Zhang, Xiaoliang', 'Yang, Yinshuang', 'Zhang, Xin', 'Shan, Tao', 'Wang, Li', 'Xu, Hua', 'Wang, Shui', 'Liu, Yun']					1872-8243 (Electronic) 1386-5056 (Linking)	9711057	International journal of medical informatics	['eng']	S1386-5056(18)30922-5 [pii] 10.1016/j.ijmedinf.2018.08.009 [doi]	20190523	['*Algorithms', 'Breast Neoplasms/*diagnostic imaging', 'China', '*Deep Learning', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', '*Radiology Information Systems', 'Ultrasonography, Mammary/*methods']	2019/05/24 06:00		['*Clinical natural language processing', '*Deep learning', '*Named entity recognition']	['NOTNLM']	NLM	17-21	['2017/11/13 00:00 [received]', '2018/08/14 00:00 [revised]', '2018/08/16 00:00 [accepted]', '2018/10/22 06:00 [entrez]', '2018/10/22 06:00 [pubmed]', '2019/05/24 06:00 [medline]']	Ireland			30342682	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Int J Med Inform. 2018 Nov;119:17-21. doi: 10.1016/j.ijmedinf.2018.08.009. Epub 2018 Aug 18.	MEDLINE	Int J Med Inform	Extraction of BI-RADS findings from breast ultrasound reports in Chinese using deep learning approaches.		119	Extraction of BI-RADS findings from breast ultrasound reports in Chinese using deep learning approaches.
Machine learning based on artificial neural networks has emerged as an efficient means to develop empirical models of complex systems. Cold atomic ensembles have become commonplace in laboratories around the world, however, many-body interactions give rise to complex dynamics that preclude precise analytic optimisation of the cooling and trapping process. Here, we implement a deep artificial neural network to optimise the magneto-optic cooling and trapping of neutral atomic ensembles. The solution identified by machine learning is radically different to the smoothly varying adiabatic solutions currently used. Despite this, the solutions outperform best known solutions producing higher optical densities.	['Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'School of Engineering and Information Technology, University of New South Wales, Canberra, 2600, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia. ben.buchler@anu.edu.au.', 'Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia.']	['10.1038/s41467-018-06847-1 [doi]', '10.1038/s41467-018-06847-1 [pii]']	['Tranter AD', 'Slatyer HJ', 'Hush MR', 'Leung AC', 'Everett JL', 'Paul KV', 'Vernaz-Gris P', 'Lam PK', 'Buchler BC', 'Campbell GT']	['ORCID: http://orcid.org/0000-0002-2523-3439']						['2018/10/21 06:00']	20190108	20181019	2018 Oct 19	2018/10/21 06:00		['Tranter, A D', 'Slatyer, H J', 'Hush, M R', 'Leung, A C', 'Everett, J L', 'Paul, K V', 'Vernaz-Gris, P', 'Lam, P K', 'Buchler, B C', 'Campbell, G T']		['CE170100012/Australian Research Council (ARC)/International']	1		2041-1723 (Electronic) 2041-1723 (Linking)	101528555	Nature communications	['eng']	10.1038/s41467-018-06847-1 [doi]	20191019	['Algorithms', '*Deep Learning', '*Magnetics', 'Neural Networks (Computer)', '*Optics and Photonics']	2019/01/09 06:00				NLM	4360	['2018/04/30 00:00 [received]', '2018/09/21 00:00 [accepted]', '2018/10/21 06:00 [entrez]', '2018/10/21 06:00 [pubmed]', '2019/01/09 06:00 [medline]']	England	PMC6195564		30341301	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Commun. 2018 Oct 19;9(1):4360. doi: 10.1038/s41467-018-06847-1.	MEDLINE	Nat Commun	Multiparameter optimisation of a magneto-optical trap using deep learning.		9	Multiparameter optimisation of a magneto-optical trap using deep learning.
Alzheimer's disease (AD) is an irreversible neurodegenerative disorder with progressive impairment of memory and cognitive functions. Structural magnetic resonance images (MRI) play important role to evaluate the brain anatomical changes for AD Diagnosis. Machine learning technologies have been widely studied on MRI computation and analysis for quantitative evaluation and computer-aided-diagnosis of AD. Most existing methods extract the hand-craft features after image processing such as registration and segmentation, and then train a classifier to distinguish AD subjects from other groups. Motivated by the success of deep learning in image classification, this paper proposes a classification method based on multiple cluster dense convolutional neural networks (DenseNets) to learn the various local features of MR brain images, which are combined for AD classification. First, we partition the whole brain image into different local regions and extract a number of 3D patches from each region. Second, the patches from each region are grouped into different clusters with the K-Means clustering method. Third, we construct a DenseNet to learn the patch features for each cluster and the features learned from the discriminative clusters of each region are ensembled for classification. Finally, the classification results from different local regions are combined to enhance final image classification. The proposed method can gradually learn the MRI features from the local patches to global image level for the classification task. There are no rigid registration and segmentation required for preprocessing MRI images. Our method is evaluated using T1-weighted MRIs of 831 subjects including 199 AD patients, 403 mild cognitive impairment (MCI) and 229 normal control (NC) subjects from Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an accuracy of 89.5% and an AUC (area under the ROC curve) of 92.4% for AD vs. NC classification, and an accuracy of 73.8% and an AUC of 77.5% for MCI vs. NC classification, demonstrating the promising classification performances.	['Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China.', 'Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China; Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, 200240, China. Electronic address: mhliu@sjtu.edu.cn.']	['S0895-6111(18)30199-X [pii]', '10.1016/j.compmedimag.2018.09.009 [doi]']	['Li F', 'Liu M']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']		"[""Alzheimer's Disease Neuroimaging Initiative""]"			['2018/10/20 06:00']	20191029	20181002	2018 Dec	2018/10/20 06:00		['Li, Fan', 'Liu, Manhua']					1879-0771 (Electronic) 0895-6111 (Linking)	8806104	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	['eng']	S0895-6111(18)30199-X [pii] 10.1016/j.compmedimag.2018.09.009 [doi]	20191029	['Algorithms', 'Alzheimer Disease/*diagnostic imaging/pathology', 'Diagnosis, Computer-Assisted/*methods', 'Humans', '*Neural Networks (Computer)']	2019/10/30 06:00		"[""*Alzheimer's disease"", '*Dense convolutional network', '*K-Means clustering', '*Patch features', '*Structural magnetic resonance image']"	['NOTNLM']	NLM	101-110	['2018/04/05 00:00 [received]', '2018/07/12 00:00 [revised]', '2018/09/26 00:00 [accepted]', '2018/10/20 06:00 [pubmed]', '2019/10/30 06:00 [medline]', '2018/10/20 06:00 [entrez]']	United States			30340094	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Med Imaging Graph. 2018 Dec;70:101-110. doi: 10.1016/j.compmedimag.2018.09.009. Epub 2018 Oct 2.	MEDLINE	Comput Med Imaging Graph	Alzheimer's disease diagnosis based on multiple cluster dense convolutional networks.		70	Alzheimer's disease diagnosis based on multiple cluster dense convolutional networks.
BACKGROUND AND OBJECTIVE: Automatic classification of healthy tissues and organs based on histology images is an open problem, mainly due to the lack of automated tools. Solutions in this regard have potential in educational medicine and medical practices. Some preliminary advances have been made using image processing techniques and classical supervised learning. Due to the breakthrough performance of deep learning in various areas, we present an approach to recognise and classify, automatically, fundamental tissues and organs using Convolutional Neural Networks (CNN). METHODS: We adapt four popular CNNs architectures - ResNet, VGG19, VGG16 and Inception - to this problem through transfer learning. The resulting models are evaluated at three stages. Firstly, all the transferred networks are compared to each other. Secondly, the best resulting fine-tuned model is compared to an ad-hoc 2D multi-path model to outline the importance of transfer learning. Thirdly, the same model is evaluated against the state-of-the-art method, a cascade SVM using LBP-based descriptors, to contrast a traditional machine learning approach and a representation learning one. The evaluation task consists of separating six classes accurately: smooth muscle of the elastic artery, smooth muscle of the large vein, smooth muscle of the muscular artery, cardiac muscle, loose connective tissue, and light regions. The different networks are tuned on 6000 blocks of 100x100 pixels and tested on 7500. RESULTS: Our proposal yields F-score values between 0.717 and 0.928. The highest and lowest performances are for cardiac muscle and smooth muscle of the large vein, respectively. The main issue leading to limited classification scores for the latter class is its similarity with the elastic artery. However, this confusion is evidenced during manual annotation as well. Our algorithm reached improvements in F-score between 0.080 and 0.220 compared to the state-of-the-art machine learning approach. CONCLUSIONS: We conclude that it is possible to classify healthy cardiovascular tissues and organs automatically using CNNs and that deep learning holds great promise to improve tissue and organs classification. We left our training and test sets, models and source code publicly available to the research community.	['University College Dublin, CeADAR: Centre for Applied Data Analytics Research, School of Computer Science, Dublin, Ireland. Electronic address: claudia.mazovargas@ucd.ie.', 'Universitat de Girona, Institute of Computer Vision and Robotics, Girona, Spain.', 'Universidad del Valle, Computer and Systems Engineering School, Cali, Colombia.', 'Universidad de Leon, Industrial and Informatics Engineering School, Leon, Spain.']	['S0169-2607(18)30529-7 [pii]', '10.1016/j.cmpb.2018.08.006 [doi]']	['Mazo C', 'Bernal J', 'Trujillo M', 'Alegre E']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/10/20 06:00']	20190204	20180816	2018 Oct	2018/10/20 06:00		['Mazo, Claudia', 'Bernal, Jose', 'Trujillo, Maria', 'Alegre, Enrique']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30529-7 [pii] 10.1016/j.cmpb.2018.08.006 [doi]	20190215	['Algorithms', 'Cardiovascular System/*anatomy & histology', 'Deep Learning', 'Histological Techniques', 'Humans', 'Image Processing, Computer-Assisted/*methods/statistics & numerical data', '*Machine Learning', 'Models, Anatomic', 'Models, Cardiovascular', '*Neural Networks (Computer)', 'Reference Values', 'Support Vector Machine']	2019/02/05 06:00		['Cardiovascular system', 'Fundamental tissues', 'Histological images', 'Organs', 'SVM', 'Transfer learning']	['NOTNLM']	NLM	69-76	['2018/04/16 00:00 [received]', '2018/07/27 00:00 [revised]', '2018/08/08 00:00 [accepted]', '2018/10/20 06:00 [entrez]', '2018/10/20 06:00 [pubmed]', '2019/02/05 06:00 [medline]']	Ireland			30337082	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Oct;165:69-76. doi: 10.1016/j.cmpb.2018.08.006. Epub 2018 Aug 16.	MEDLINE	Comput Methods Programs Biomed	Transfer learning for classification of cardiovascular tissues in histological images.		165	Transfer learning for classification of cardiovascular tissues in histological images.
BACKGROUND AND OBJECTIVES: Retinal fundus image analysis without manual intervention has been rising as an imperative analytical approach for early detection of eye-related diseases such as glaucoma and diabetic retinopathy. For analysis and detection of Glaucoma and some other disease from retinal image, there is a significant role of predicting the bounding box coordinates of Optic Disc (OD) that acts as a Region of Interest (ROI). METHODS: We reframe ROI detection as a solitary regression predicament, from image pixel values to ROI coordinates including class probabilities. A Convolution Neural Network (CNN) has trained on full images to predict bounding boxes along with their analogous probabilities and confidence scores. The publically available MESSIDOR and Kaggle datasets have been used to train the network. We adopted various data augmentation techniques to amplify our dataset so that our network becomes less sensitive to noise. From a very high-level perspective, every image is divided into a 13x13 grid. Every grid cell envisages 5 bounding boxes along with the corresponding class probability and a confidence score. Before training, the network and the bounding box priors or anchors are initialized using k-means clustering on the original dataset using a distance metric based on Intersection of the Union (IOU) over ground-truth bounding boxes. During training in fact, a sum-squared loss function is used as the prediction's error function. Finally, Non-maximum suppression is applied by the proposed methodology to reach the concluding prediction. RESULTS: The following projected method accomplish an accuracy of 99.05% and 98.78% on the Kaggle and MESSIDOR test sets for ROI detection. Results of proposed methodology indicates that proposed network is able to perceive ROI in fundus images in 0.0045 s at 25 ms of latency, which is far better than the recent-time and using no handcrafted features. CONCLUSIONS: The network predicts accurate results even on low-quality images without being biased towards any particular type of image. The network prepared to see more summed up depiction rather than past works in the field. Going by the results, our novel method has better diagnosis of eye diseases in the future in a faster and reliable way.	['Department of Computer Science and Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata 700098, India; Department of Computer Science and Engineering, Academy of Technology, Adisaptagram 712121, West Bengal, India.', 'Department of Computer Science and Engineering, Academy of Technology, Adisaptagram 712121, West Bengal, India.', 'Department of Computer Science and Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata 700098, India; Mallinckrodt Institute of Radiology Department (MIR), Washington University School of Medicine, Campus Box 8225, 510 South Kingshighway Boulevard, Saint Louis, MO 63110-1076, USA. Electronic address: sudiptaroy01@yahoo.com.', 'Department of Computer Science and Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata 700098, India.', 'Department of Computer Science and Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata 700098, India.']	['S0169-2607(18)30838-1 [pii]', '10.1016/j.cmpb.2018.08.003 [doi]']	['Mitra A', 'Banerjee PS', 'Roy S', 'Roy S', 'Setua SK']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/10/20 06:00']	20190204	20180808	2018 Oct	2018/10/20 06:00		['Mitra, Anirban', 'Banerjee, Priya Shankar', 'Roy, Sudipta', 'Roy, Somasis', 'Setua, Sanjit Kumar']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30838-1 [pii] 10.1016/j.cmpb.2018.08.003 [doi]	20190215	['Algorithms', 'Databases, Factual', 'Deep Learning', 'Diagnosis, Computer-Assisted/methods', 'Diagnostic Techniques, Ophthalmological', 'Fundus Oculi', 'Glaucoma/*diagnostic imaging/pathology', 'Humans', 'Image Enhancement/methods', 'Image Interpretation, Computer-Assisted/methods', 'Neural Networks (Computer)', 'Optic Disk/diagnostic imaging/pathology']	2019/02/05 06:00		['Anchor Boxes', 'Batch Normalization', 'Convolution Neural Networks', 'Intersection over Union', 'K-means clustering', 'Leaky ReLU, Max Pooling', 'Non-maximum suppression', 'Optic Disc Localization']	['NOTNLM']	NLM	25-35	['2018/06/04 00:00 [received]', '2018/07/14 00:00 [revised]', '2018/08/07 00:00 [accepted]', '2018/10/20 06:00 [entrez]', '2018/10/20 06:00 [pubmed]', '2019/02/05 06:00 [medline]']	Ireland			30337079	ppublish	['Evaluation Studies', 'Journal Article']			IM		Comput Methods Programs Biomed. 2018 Oct;165:25-35. doi: 10.1016/j.cmpb.2018.08.003. Epub 2018 Aug 8.	MEDLINE	Comput Methods Programs Biomed	The region of interest localization for glaucoma analysis from retinal fundus image using deep learning.		165	The region of interest localization for glaucoma analysis from retinal fundus image using deep learning.
BACKGROUND AND OBJECTIVES: Glaucoma is an eye condition which leads to permanent blindness when the disease progresses to an advanced stage. It occurs due to inappropriate intraocular pressure within the eye, resulting in damage to the optic nerve. Glaucoma does not exhibit any symptoms in its nascent stage and thus, it is important to diagnose early to prevent blindness. Fundus photography is widely used by ophthalmologists to assist in diagnosis of glaucoma and is cost-effective. METHODS: The morphological features of the disc that is characteristic of glaucoma are clearly seen in the fundus images. However, manual inspection of the acquired fundus images may be prone to inter-observer variation. Therefore, a computer-aided detection (CAD) system is proposed to make an accurate, reliable and fast diagnosis of glaucoma based on the optic nerve features of fundus imaging. In this paper, we reviewed existing techniques to automatically diagnose glaucoma. RESULTS: The use of CAD is very effective in the diagnosis of glaucoma and can assist the clinicians to alleviate their workload significantly. We have also discussed the advantages of employing state-of-art techniques, including deep learning (DL), when developing the automated system. The DL methods are effective in glaucoma diagnosis. CONCLUSIONS: Novel DL algorithms with big data availability are required to develop a reliable CAD system. Such techniques can be employed to diagnose other eye diseases accurately.	"['Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 599489, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 599489, Singapore.', 'National University of Singapore, Institute of System Science.', 'Department of Ophthalmology, Kasturba Medical College, Manipal, India.', 'National Healthcare Group Eye Institute, Tan Tock Seng Hospital, Singapore; Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore.', 'Department of Medicine, Columbia University, New York, USA.', 'Ocular Surface Research Group, Singapore Eye Research Institute, Singapore; Cornea and External Eye Disease Service, Singapore National Eye Center, Singapore; Eye Academic Clinical Program, Duke-NUS Medical School, Singapore; Department of Ophthalmology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore.', ""Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 599489, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore School of Social Sciences, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, Subang Jaya, Malaysia. Electronic address: aru@np.edu.sg.""]"	['S0169-2607(18)30549-2 [pii]', '10.1016/j.cmpb.2018.07.012 [doi]']	['Hagiwara Y', 'Koh JEW', 'Tan JH', 'Bhandary SV', 'Laude A', 'Ciaccio EJ', 'Tong L', 'Acharya UR']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/10/20 06:00']	20190204	20180726	2018 Oct	2018/10/20 06:00		['Hagiwara, Yuki', 'Koh, Joel En Wei', 'Tan, Jen Hong', 'Bhandary, Sulatha V', 'Laude, Augustinus', 'Ciaccio, Edward J', 'Tong, Louis', 'Acharya, U Rajendra']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30549-2 [pii] 10.1016/j.cmpb.2018.07.012 [doi]	20190215	['Algorithms', 'Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Diagnostic Techniques, Ophthalmological', 'Fundus Oculi', 'Glaucoma/*diagnostic imaging/pathology', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Microscopy, Confocal/methods', 'Neural Networks (Computer)', 'Ophthalmoscopy/methods', 'Photography', 'Risk Factors']	2019/02/05 06:00		['Computer-aided detection system', 'Deep learning', 'Glaucoma', 'Machine learning', 'Optic disc', 'Segmentation']	['NOTNLM']	NLM	1-12	['2018/04/20 00:00 [received]', '2018/07/02 00:00 [revised]', '2018/07/25 00:00 [accepted]', '2018/10/20 06:00 [entrez]', '2018/10/20 06:00 [pubmed]', '2019/02/05 06:00 [medline]']	Ireland			30337064	ppublish	['Journal Article', 'Review']			IM		Comput Methods Programs Biomed. 2018 Oct;165:1-12. doi: 10.1016/j.cmpb.2018.07.012. Epub 2018 Jul 26.	MEDLINE	Comput Methods Programs Biomed	Computer-aided diagnosis of glaucoma using fundus images: A review.		165	Computer-aided diagnosis of glaucoma using fundus images: A review.
The detection of Adverse Medical Events (AMEs) plays an important role in disease management in ensuring efficient treatment delivery and quality improvement of health services. Recently, with the rapid development of hospital information systems, a large volume of Electronic Health Records (EHRs) have been produced, in which AMEs are regularly documented in a free-text manner. In this study, we are concerned with the problem of AME detection by utilizing a large volume of unstructured EHR data. To address this challenge, we propose a neural attention network-based model to incorporate the contextual information of words into AME detection. Specifically, we develop a context-aware attention mechanism to locate salient words with respect to the target AMEs in patient medical records. And then we combine the proposed context attention mechanism with the deep learning tactic to boost the performance of AME detection. We validate our proposed model on a real clinical dataset that consists of 8845 medical records of patients with cardiovascular diseases. The experimental results show that our proposed model advances state-of-the-art models and achieves competitive performance in terms of AME detection.	['College of Biomedical Engineering and Instrument Science, Zhejiang University, PR China.', 'Department of Cardiology, Chinese PLA General Hospital, PR China.', 'Department of Cardiology, Chinese PLA General Hospital, PR China.', 'College of Biomedical Engineering and Instrument Science, Zhejiang University, PR China.', 'College of Biomedical Engineering and Instrument Science, Zhejiang University, PR China. Electronic address: zhengxinghuang@zju.edu.cn.']	['S1532-0464(18)30198-9 [pii]', '10.1016/j.jbi.2018.10.002 [doi]']	['Chu J', 'Dong W', 'He K', 'Duan H', 'Huang Z']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/10/19 06:00']	20191119	20181015	2018 Nov	2018/10/20 06:00		['Chu, Jiebin', 'Dong, Wei', 'He, Kunlun', 'Duan, Huilong', 'Huang, Zhengxing']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30198-9 [pii] 10.1016/j.jbi.2018.10.002 [doi]	20191119	['Algorithms', 'Area Under Curve', 'Cardiovascular Diseases/diagnosis/epidemiology', 'China', 'Databases, Factual', '*Deep Learning', 'Electronic Health Records/*standards', 'Hemorrhage', 'Hospital Information Systems', 'Hospitals', 'Humans', 'Medical Informatics/*methods', 'Myocardial Ischemia/diagnosis', 'Myocardial Revascularization', '*Neural Networks (Computer)']	2019/11/20 06:00		['*Adverse medical event', '*Cardiovascular disease', '*Deep learning', '*Electronic health record', '*Neural attention network']	['NOTNLM']	NLM	118-130	['2018/04/25 00:00 [received]', '2018/10/10 00:00 [revised]', '2018/10/12 00:00 [accepted]', '2018/10/20 06:00 [pubmed]', '2019/11/20 06:00 [medline]', '2018/10/19 06:00 [entrez]']	United States			30336262	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Nov;87:118-130. doi: 10.1016/j.jbi.2018.10.002. Epub 2018 Oct 15.	MEDLINE	J Biomed Inform	Using neural attention networks to detect adverse medical events from electronic health records.		87	Using neural attention networks to detect adverse medical events from electronic health records.
"Enlarged perivascular spaces (PVS) are structural brain changes visible in MRI, are common in aging, and are considered a reflection of cerebral small vessel disease. As such, assessing the burden of PVS has promise as a brain imaging marker. Visual and manual scoring of PVS is a tedious and observer-dependent task. Automated methods would advance research into the etiology of PVS, could aid to assess what a ""normal"" burden is in aging, and could evaluate the potential of PVS as a biomarker of cerebral small vessel disease. In this work, we propose and evaluate an automated method to quantify PVS in the midbrain, hippocampi, basal ganglia and centrum semiovale. We also compare associations between (earlier established) determinants of PVS and visual PVS scores versus the automated PVS scores, to verify whether automated PVS scores could replace visual scoring of PVS in epidemiological and clinical studies. Our approach is a deep learning algorithm based on convolutional neural network regression, and is contingent on successful brain structure segmentation. In our work we used FreeSurfer segmentations. We trained and validated our method on T2-contrast MR images acquired from 2115 subjects participating in a population-based study. These scans were visually scored by an expert rater, who counted the number of PVS in each brain region. Agreement between visual and automated scores was found to be excellent for all four regions, with intraclass correlation coefficients (ICCs) between 0.75 and 0.88. These values were higher than the inter-observer agreement of visual scoring (ICCs between 0.62 and 0.80). Scan-rescan reproducibility was high (ICCs between 0.82 and 0.93). The association between 20 determinants of PVS, including aging, and the automated scores were similar to those between the same 20 determinants of PVS and visual scores. We conclude that this method may replace visual scoring and facilitate large epidemiological and clinical studies of PVS."	['Biomedical Imaging Group Rotterdam, Department of Radiology, Department of Medical Informatics, Erasmus MC - University Medical Center Rotterdam, the Netherlands. Electronic address: floriandubost1@gmail.com.', 'Department of Radiology, Department of Nuclear Medicine, Department of Epidemiology, Erasmus MC - University Medical Center Rotterdam, the Netherlands.', 'Department of Radiology, Department of Nuclear Medicine, Department of Epidemiology, Erasmus MC - University Medical Center Rotterdam, the Netherlands.', 'Biomedical Imaging Group Rotterdam, Department of Radiology, Department of Medical Informatics, Erasmus MC - University Medical Center Rotterdam, the Netherlands.', 'Department of Radiology, Department of Epidemiology, Department of Neurology, Erasmus MC - University Medical Center Rotterdam, the Netherlands.', 'Biomedical Imaging Group Rotterdam, Department of Radiology, Department of Medical Informatics, Erasmus MC - University Medical Center Rotterdam, the Netherlands; Department of Imaging Physics, Faculty of Applied Science, TU Delft, Delft, the Netherlands.', 'Department of Radiology, Department of Nuclear Medicine, Department of Epidemiology, Erasmus MC - University Medical Center Rotterdam, the Netherlands.', 'Biomedical Imaging Group Rotterdam, Department of Radiology, Department of Medical Informatics, Erasmus MC - University Medical Center Rotterdam, the Netherlands; Department of Computer Science, University of Copenhagen, Copenhagen, Denmark. Electronic address: marleen.debruijne@erasmusmc.nl.']	['S1053-8119(18)31985-2 [pii]', '10.1016/j.neuroimage.2018.10.026 [doi]']	['Dubost F', 'Yilmaz P', 'Adams H', 'Bortsova G', 'Ikram MA', 'Niessen W', 'Vernooij M', 'de Bruijne M']		['Copyright (c) 2018 The Authors. Published by Elsevier Inc. All rights reserved.']					['2018/10/17 06:00']	20190307	20181013	2019 Jan 15	2018/10/17 06:00		['Dubost, Florian', 'Yilmaz, Pinar', 'Adams, Hieab', 'Bortsova, Gerda', 'Ikram, M Arfan', 'Niessen, Wiro', 'Vernooij, Meike', 'de Bruijne, Marleen']					1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(18)31985-2 [pii] 10.1016/j.neuroimage.2018.10.026 [doi]	20190307	['Aged', 'Brain/*diagnostic imaging/pathology', 'Cerebral Small Vessel Diseases/*diagnostic imaging/pathology', '*Deep Learning', 'Female', 'Glymphatic System/*diagnostic imaging/pathology', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/methods', 'Male', 'Neuroimaging/*methods']	2019/03/08 06:00		['*Deep learning', '*Dementia', '*Enlarged perivascular spaces', '*Machine learning', '*Perivascular spaces', '*Virchow-Robin spaces']	['NOTNLM']	NLM	534-544	['2018/07/28 00:00 [received]', '2018/09/20 00:00 [revised]', '2018/10/09 00:00 [accepted]', '2018/10/17 06:00 [pubmed]', '2019/03/08 06:00 [medline]', '2018/10/17 06:00 [entrez]']	United States			30326293	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroimage. 2019 Jan 15;185:534-544. doi: 10.1016/j.neuroimage.2018.10.026. Epub 2018 Oct 13.	MEDLINE	Neuroimage	Enlarged perivascular spaces in brain MRI: Automated quantification in four regions.		185	Enlarged perivascular spaces in brain MRI: Automated quantification in four regions.
There have been tremendous advances in artificial intelligence (AI) and machine learning (ML) within the past decade, especially in the application of deep learning to various challenges. These include advanced competitive games (such as Chess and Go), self-driving cars, speech recognition, and intelligent personal assistants. Rapid advances in computer vision for recognition of objects in pictures have led some individuals, including computer science experts and health care system experts in machine learning, to make predictions that ML algorithms will soon lead to the replacement of the radiologist. However, there are complex technological, regulatory, and medicolegal obstacles facing the implementation of machine learning in radiology that will definitely preclude replacement of the radiologist by these algorithms within the next two decades and beyond. While not a comprehensive review of machine learning, this article is intended to highlight specific features of machine learning which face significant technological and health care systems challenges. Rather than replacing radiologists, machine learning will provide quantitative tools that will increase the value of diagnostic imaging as a biomarker, increase image quality with decreased acquisition times, and improve workflow, communication, and patient safety. In the foreseeable future, we predict that today's generation of radiologists will be replaced not by ML algorithms, but by a new breed of data science-savvy radiologists who have embraced and harnessed the incredible potential that machine learning has to advance our ability to care for our patients. In this way, radiology will remain a viable medical specialty for years to come.	['1 Department of Radiology, Harlem Hospital Center and Columbia University , New York, NY , USA.', '2 Department of Diagnostic Radiology and Nuclear Medicine, VA Maryland Health Care System , Baltimore, MD , USA.']	['10.1259/bjr.20180416 [doi]']	['Chan S', 'Siegel EL']	['ORCID: http://orcid.org/0000-0002-1410-7998']						['2018/10/17 06:00']	20190208	20181101	2019 Feb	2018/10/17 06:00		['Chan, Stephen', 'Siegel, Eliot L']			1094		1748-880X (Electronic) 0007-1285 (Linking)	0373125	The British journal of radiology	['eng']	10.1259/bjr.20180416 [doi]	20190312	['Algorithms', 'Artificial Intelligence', 'Humans', '*Image Interpretation, Computer-Assisted', '*Machine Learning', 'Pattern Recognition, Automated']	2019/02/09 06:00				NLM	20180416	['2020/02/01 00:00 [pmc-release]', '2018/10/17 06:00 [pubmed]', '2019/02/09 06:00 [medline]', '2018/10/17 06:00 [entrez]']	England	PMC6404816	['2020/02/01 00:00']	30325645	ppublish	['Journal Article']			AIM IM		Br J Radiol. 2019 Feb;92(1094):20180416. doi: 10.1259/bjr.20180416. Epub 2018 Nov 1.	MEDLINE	Br J Radiol	Will machine learning end the viability of radiology as a thriving medical specialty?		92	Will machine learning end the viability of radiology as a thriving medical specialty?
Learning in physical neural systems must rely on learning rules that are local in both space and time. Optimal learning in deep neural architectures requires that non-local information be available to the deep synapses. Thus, in general, optimal learning in physical neural systems requires the presence of a deep learning channel to communicate non-local information to deep synapses, in a direction opposite to the forward propagation of the activities. Theoretical arguments suggest that for circular autoencoders, an important class of neural architectures where the output layer is identical to the input layer, alternative algorithms may exist that enable local learning without the need for additional learning channels, by using the forward activation channel as the deep learning channel. Here we systematically identify, classify, and study several such local learning algorithms, based on the general idea of recirculating information from the output layer to the hidden layers. We show through simulations and mathematical derivations that these algorithms are robust and converge to critical points of the global error function. In most cases, we show that these recirculation algorithms are very similar to an adaptive form of random backpropagation, where each hidden layer receives a linearly transformed, slowly-varying, version of the output error.	['Department of Computer Science, University of California, Irvine, Irvine, CA 92697, United States. Electronic address: pfbaldi@uci.edu.', 'Department of Computer Science, University of California, Irvine, Irvine, CA 92697, United States. Electronic address: psadowsk@uci.edu.']	['S0893-6080(18)30268-5 [pii]', '10.1016/j.neunet.2018.09.006 [doi]']	['Baldi P', 'Sadowski P']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/10/15 06:00']	20190109	20180927	2018 Dec	2018/10/15 06:00		['Baldi, P', 'Sadowski, P']		['R01 GM123558/GM/NIGMS NIH HHS/United States']			1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30268-5 [pii] 10.1016/j.neunet.2018.09.006 [doi]	20191201	['*Algorithms', '*Deep Learning/trends', 'Machine Learning/trends', 'Neural Networks (Computer)']	2019/01/10 06:00	['NIHMS1508281']	['Autoencoders', 'Backpropagation', 'Convergence', 'Random backpropagation', 'Recirculation', 'Unsupervised learning']	['NOTNLM']	NLM	479-494	['2018/05/10 00:00 [received]', '2018/08/12 00:00 [revised]', '2018/09/11 00:00 [accepted]', '2018/10/15 06:00 [pubmed]', '2019/01/10 06:00 [medline]', '2018/10/15 06:00 [entrez]']	United States	PMC6246787		30317133	ppublish	['Journal Article']			IM		Neural Netw. 2018 Dec;108:479-494. doi: 10.1016/j.neunet.2018.09.006. Epub 2018 Sep 27.	MEDLINE	Neural Netw	Learning in the machine: Recirculation is random backpropagation.		108	Learning in the machine: Recirculation is random backpropagation.
In the past two decades, significant advances have been made on automated electroencephalogram (EEG)-based diagnosis of epilepsy and seizure detection. A number of innovative algorithms have been introduced that can aid in epilepsy diagnosis with a high degree of accuracy. In recent years, the frontiers of computational epilepsy research have moved to seizure prediction, a more challenging problem. While antiepileptic medication can result in complete seizure freedom in many patients with epilepsy, up to one-third of patients living with epilepsy will have medically intractable epilepsy, where medications reduce seizure frequency but do not completely control seizures. If a seizure can be predicted prior to its clinical manifestation, then there is potential for abortive treatment to be given, either self-administered or via an implanted device administering medication or electrical stimulation. This will have a far-reaching impact on the treatment of epilepsy and patient's quality of life. This paper presents a state-of-the-art review of recent efforts and journal articles on seizure prediction. The technologies developed for epilepsy diagnosis and seizure detection are being adapted and extended for seizure prediction. The paper ends with some novel ideas for seizure prediction using the increasingly ubiquitous machine learning technology, particularly deep neural network machine learning.	['Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore University of Social Sciences, Singapore; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Neuroscience, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, United States; Department of Neurology, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, United States; Department of Biomedical Informatics, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, United States. Electronic address: adeli.1@osu.edu.']	['S1525-5050(18)30579-1 [pii]', '10.1016/j.yebeh.2018.09.030 [doi]']	['Acharya UR', 'Hagiwara Y', 'Adeli H']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/10/15 06:00']	20190425	20181011	2018 Nov	2018/10/15 06:00		['Acharya, U Rajendra', 'Hagiwara, Yuki', 'Adeli, Hojjat']					1525-5069 (Electronic) 1525-5050 (Linking)	100892858	Epilepsy & behavior : E&B	['eng']	S1525-5050(18)30579-1 [pii] 10.1016/j.yebeh.2018.09.030 [doi]	20190425	['Algorithms', 'Electroencephalography', 'Epilepsy/diagnosis/physiopathology/psychology', 'Humans', 'Machine Learning/*trends', '*Neural Networks (Computer)', 'Predictive Value of Tests', 'Quality of Life/psychology', 'Seizures/*diagnosis/physiopathology/*psychology']	2019/04/26 06:00		['*Electroencephalogram', '*Epilepsy', '*Machine learning', '*Seizure prediction']	['NOTNLM']	NLM	251-261	['2018/07/16 00:00 [received]', '2018/09/16 00:00 [revised]', '2018/09/22 00:00 [accepted]', '2018/10/15 06:00 [pubmed]', '2019/04/26 06:00 [medline]', '2018/10/15 06:00 [entrez]']	United States			30317059	ppublish	['Journal Article', 'Review']			IM		Epilepsy Behav. 2018 Nov;88:251-261. doi: 10.1016/j.yebeh.2018.09.030. Epub 2018 Oct 11.	MEDLINE	Epilepsy Behav	Automated seizure prediction.		88	Automated seizure prediction.
Technological advances in artificial intelligence (AI) represent an enticing opportunity to benefit gastroenterological practice. Moreover, AI, through machine or deep learning, permits the ability to develop predictive models from large datasets. Possibilities of predictive model development in machine learning are numerous dependent on the clinical question. For example, binary classifiers aim to stratify allocation to a categorical outcome, such as the presence or absence of a gastrointestinal disease. In addition, continuous variable fitting techniques can be used to predict quantity of a therapeutic response, thus offering a tool to predict which therapeutic intervention may be most beneficial to the given patient. Namely, this permits an important opportunity for personalization of medicine, including a movement from guideline-specific treatment algorithms to patient-specific ones, providing both clinician and patient the capacity for data-driven decision making. Furthermore, such analyses could predict the development of GI disease prior to the manifestation of symptoms, raising the possibility of prevention or pre-treatment. In addition, computer vision additionally provides an exciting opportunity in endoscopy to automatically detect lesions. In this review, we overview the recent developments in healthcare-based AI and machine learning and describe promises and pitfalls for its application to gastroenterology.	['Centre for Neuroscience and Trauma, Blizard Institute, Wingate Institute of Neurogastroenterology, Barts and the London School of Medicine & Dentistry, Queen Mary University of London, 26 Ashfield Street, London, E1 2AJ, UK.', 'Centre for Neuroscience and Trauma, Blizard Institute, Wingate Institute of Neurogastroenterology, Barts and the London School of Medicine & Dentistry, Queen Mary University of London, 26 Ashfield Street, London, E1 2AJ, UK.', 'Institute of Applied Clinical Science, University of Keele, Staffordshire, ST5 5BG, UK.', 'Centre for Neuroscience and Trauma, Blizard Institute, Wingate Institute of Neurogastroenterology, Barts and the London School of Medicine & Dentistry, Queen Mary University of London, 26 Ashfield Street, London, E1 2AJ, UK.']	['10.1038/s41395-018-0268-4 [doi]', '10.1038/s41395-018-0268-4 [pii]']	['Ruffle JK', 'Farmer AD', 'Aziz Q']							['2018/10/14 06:00']			2019 Mar	2018/10/14 06:00		['Ruffle, James K', 'Farmer, Adam D', 'Aziz, Qasim']			3		1572-0241 (Electronic) 0002-9270 (Linking)	0421030	The American journal of gastroenterology	['eng']	10.1038/s41395-018-0268-4 [doi]	20191120		2018/10/14 06:00				NLM	422-428	['2018/10/14 06:00 [pubmed]', '2018/10/14 06:00 [medline]', '2018/10/14 06:00 [entrez]']	United States			30315284	ppublish	['Journal Article']			IM		Am J Gastroenterol. 2019 Mar;114(3):422-428. doi: 10.1038/s41395-018-0268-4.	In-Data-Review	Am J Gastroenterol	Artificial Intelligence-Assisted Gastroenterology- Promises and Pitfalls.		114	Artificial Intelligence-Assisted Gastroenterology- Promises and Pitfalls.
BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine. METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls. RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS). CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.	['Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu, Sichuan, China.', 'Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu, Sichuan, China. zhangjunran@126.com.', 'Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu, Sichuan, China.', 'Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu, Sichuan, China.']	['10.1186/s12938-018-0587-0 [doi]', '10.1186/s12938-018-0587-0 [pii]']	['Yang H', 'Zhang J', 'Liu Q', 'Wang Y']							['2018/10/14 06:00']	20181231	20181011	2018 Oct 11	2018/10/14 06:00		['Yang, Hao', 'Zhang, Junran', 'Liu, Qihong', 'Wang, Yi']		['2015HH0036/Sichuan Science and Technology Plan Project', '2015HM0100561SF/Chengdu Science and Technology Plan Project', '2017CDLZ-G2/Sichuan University-Luzhou Science and Technology Plan Project']	1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-018-0587-0 [doi]	20181231	['Adolescent', 'Adult', 'Case-Control Studies', '*Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Magnetic Resonance Imaging', 'Male', 'Middle Aged', 'Migraine Disorders/*diagnostic imaging', 'Multimodal Imaging', 'Young Adult']	2019/01/01 06:00		['Convolutional neural networks', 'Deep learning', 'Diagnosis', 'Migraine', 'Resting-state functional MRI']	['NOTNLM']	NLM	138	['2018/05/15 00:00 [received]', '2018/10/04 00:00 [accepted]', '2018/10/14 06:00 [entrez]', '2018/10/14 06:00 [pubmed]', '2019/01/01 06:00 [medline]']	England	PMC6186044		30314437	epublish	['Journal Article']			IM		Biomed Eng Online. 2018 Oct 11;17(1):138. doi: 10.1186/s12938-018-0587-0.	MEDLINE	Biomed Eng Online	Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.		17	Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.
OBJECTIVE: Accurate detection and segmentation of organs at risks (OARs) in CT image is the key step for efficient planning of radiation therapy for nasopharyngeal carcinoma (NPC) treatment. We develop a fully automated deep-learning-based method (termed organs-at-risk detection and segmentation network (ODS net)) on CT images and investigate ODS net performance in automated detection and segmentation of OARs. METHODS: The ODS net consists of two convolutional neural networks (CNNs). The first CNN proposes organ bounding boxes along with their scores, and then a second CNN utilizes the proposed bounding boxes to predict segmentation masks for each organ. A total of 185 subjects were included in this study for statistical comparison. Sensitivity and specificity were performed to determine the performance of the detection and the Dice coefficient was used to quantitatively measure the overlap between automated segmentation results and manual segmentation. Paired samples t tests and analysis of variance were employed for statistical analysis. RESULTS: ODS net provides an accurate detection result with a sensitivity of 0.997 to 1 for most organs and a specificity of 0.983 to 0.999. Furthermore, segmentation results from ODS net correlated strongly with manual segmentation with a Dice coefficient of more than 0.85 in most organs. A significantly higher Dice coefficient for all organs together (p = 0.0003 < 0.01) was obtained in ODS net (0.861 +/- 0.07) than in fully convolutional neural network (FCN) (0.8 +/- 0.07). The Dice coefficients of each OAR did not differ significantly between different T-staging patients. CONCLUSION: The ODS net yielded accurate automated detection and segmentation of OARs in CT images and thereby may improve and facilitate radiotherapy planning for NPC. KEY POINTS: * A fully automated deep-learning method (ODS net) is developed to detect and segment OARs in clinical CT images. * This deep-learning-based framework produces reliable detection and segmentation results and thus can be useful in delineating OARs in NPC radiotherapy planning. * This deep-learning-based framework delineating a single image requires approximately 30 s, which is suitable for clinical workflows.	['Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Department of Radiation Oncology, Nanfang Hospital, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Department of Medical Imaging Center, Nanfang Hospital, Southern Medical University, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China.', 'Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, No. 1838 Guangzhou Northern Avenue, Baiyun District, Guangzhou, 510515, Guangdong, China. yuzhang@smu.edu.cn.']	['10.1007/s00330-018-5748-9 [doi]', '10.1007/s00330-018-5748-9 [pii]']	['Liang S', 'Tang F', 'Huang X', 'Yang K', 'Zhong T', 'Hu R', 'Liu S', 'Yuan X', 'Zhang Y']							['2018/10/11 06:00']	20190506	20181009	2019 Apr	2018/10/12 06:00		['Liang, Shujun', 'Tang, Fan', 'Huang, Xia', 'Yang, Kaifan', 'Zhong, Tao', 'Hu, Runyue', 'Liu, Shangqing', 'Yuan, Xinrui', 'Zhang, Yu']		['61671230/National Natural Science Foundation of China', '31271067/National Natural Science Foundation of China', '2017A020211012/The Science and Technology Program of Guangdong Province', '2014B030301042/The Guangdong Provincial Key Laboratory of Medical Image', 'Processing', '201607010097/The Science and Technology Program of Guangzhou']	4		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-018-5748-9 [doi]	20190506	['Adolescent', 'Adult', 'Aged', '*Deep Learning', 'Female', 'Humans', 'Male', 'Middle Aged', 'Nasopharyngeal Carcinoma/diagnostic imaging/*radiotherapy', 'Neural Networks (Computer)', 'Organ Sparing Treatments/*methods', 'Organs at Risk/*diagnostic imaging', 'Patient Care Planning', 'Sensitivity and Specificity', 'Tomography, X-Ray Computed', 'Young Adult']	2019/05/07 06:00		['Head and neck neoplasms', 'Image processing', 'Organs at risk', 'Radiotherapy', 'Tomography, x-ray computed']	['NOTNLM']	NLM	1961-1967	['2018/06/04 00:00 [received]', '2018/09/10 00:00 [accepted]', '2018/08/16 00:00 [revised]', '2018/10/12 06:00 [pubmed]', '2019/05/07 06:00 [medline]', '2018/10/11 06:00 [entrez]']	Germany			30302589	ppublish	['Evaluation Studies', 'Journal Article']			IM		Eur Radiol. 2019 Apr;29(4):1961-1967. doi: 10.1007/s00330-018-5748-9. Epub 2018 Oct 9.	MEDLINE	Eur Radiol	Deep-learning-based detection and segmentation of organs at risk in nasopharyngeal carcinoma computed tomographic images for radiotherapy planning.		29	Deep-learning-based detection and segmentation of organs at risk in nasopharyngeal carcinoma computed tomographic images for radiotherapy planning.
Click-through rate prediction is critical in Internet advertising and affects web publisher's profits and advertiser's payment. The traditional method of obtaining features using feature extraction did not consider the sparseness of advertising data and the highly nonlinear association between features. To reduce the sparseness of data and to mine the hidden features in advertising data, a method that learns the sparse features is proposed. Our method exploits dimension reduction based on decomposition, takes advantage of the attention mechanism in neural network modelling, and improves FM to make feature interactions contribute differently to the prediction. We utilize stack autoencoder to explore high-order feature interactions and use improved FM for low-order feature interactions to portray the nonlinear associated relationship of features. The experiment shows that our method improves the effect of CTR prediction and produces economic benefits in Internet advertising.	['School of Information Science and Engineering, Shandong Normal University, Jinan, China.', 'School of Information Science and Engineering, Shandong Normal University, Jinan, China.', 'School of Information Science and Engineering, Shandong Normal University, Jinan, China.', 'School of Mathematical Science, Shandong Normal University, Jinan, China.']	['10.1155/2018/8056541 [doi]']	['Wang Q', 'Liu F', 'Xing S', 'Zhao X']	['ORCID: 0000-0002-0399-7905', 'ORCID: 0000-0003-4023-3979']						['2018/10/11 06:00']	20190211	20180913	2018	2018/10/12 06:00		"['Wang, Qianqian', ""Liu, Fang'ai"", 'Xing, Shuning', 'Zhao, Xiaohui']"					1748-6718 (Electronic) 1748-670X (Linking)	101277751	Computational and mathematical methods in medicine	['eng']	10.1155/2018/8056541 [doi]	20190215	['*Advertising as Topic', 'Algorithms', 'Area Under Curve', 'Attention', 'Humans', 'Informatics', '*Internet', '*Machine Learning', 'Models, Statistical', '*Neural Networks (Computer)', 'Reproducibility of Results']	2019/02/12 06:00				NLM	8056541	['2018/03/29 00:00 [received]', '2018/08/01 00:00 [accepted]', '2018/10/11 06:00 [entrez]', '2018/10/12 06:00 [pubmed]', '2019/02/12 06:00 [medline]']	United States	PMC6158939		30302123	epublish	['Journal Article']			IM		Comput Math Methods Med. 2018 Sep 13;2018:8056541. doi: 10.1155/2018/8056541. eCollection 2018.	MEDLINE	Comput Math Methods Med	A New Approach for Advertising CTR Prediction Based on Deep Neural Network via Attention Mechanism.		2018	A New Approach for Advertising CTR Prediction Based on Deep Neural Network via Attention Mechanism.
Purpose To develop a deep learning-based method for fully automated quantification of left ventricular (LV) function from short-axis cine MR images and to evaluate its performance in a multivendor and multicenter setting. Materials and Methods This retrospective study included cine MRI data sets obtained from three major MRI vendors in four medical centers from 2008 to 2016. Three convolutional neural networks (CNNs) with the U-NET architecture were trained on data sets of increasing variability: (a) a single-vendor, single-center, homogeneous cohort of 100 patients (CNN1); (b) a single-vendor, multicenter, heterogeneous cohort of 200 patients (CNN2); and (c) a multivendor, multicenter, heterogeneous cohort of 400 patients (CNN3). All CNNs were tested on an independent multivendor, multicenter data set of 196 patients. CNN performance was evaluated with respect to the manual annotations from three experienced observers in terms of (a) LV detection accuracy, (b) LV segmentation accuracy, and (c) LV functional parameter accuracy. Automatic and manual results were compared with the paired Wilcoxon test, Pearson correlation, and Bland-Altman analysis. Results CNN3 achieved the highest performance on the independent testing data set. The average perpendicular distance compared with manual analysis was 1.1 mm +/- 0.3 for CNN3, compared with 1.5 mm +/- 1.0 for CNN1 (P < .05) and 1.3 mm +/- 0.6 for CNN2 (P < .05). The LV function parameters derived from CNN3 showed a high correlation (r(2) >/= 0.98) and agreement with those obtained by experts for data sets from different vendors and centers. Conclusion A deep learning-based method trained on a data set with high variability can achieve fully automated and accurate cine MRI analysis on multivendor, multicenter cine MRI data. (c) RSNA, 2018 See also the editorial by Colletti in this issue.	['From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.', 'From the Department of Radiology, Leiden University Medical Center, Albinusdreef 2, 2333 ZA Leiden, the Netherlands (Q.T., E.H.M.P., D.P.S., A.d.R., H.J.L., R.J.v.d.G.); Department of Electrical Engineering, Fudan University, Shanghai, China (W.Y., Y.W.); Multidisciplinary Cardiovascular Research Centre & Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, England (P.G., S.P.); Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China (L.H., L.X.); and Departments of Cardiology (M.S.) and Radiology (J.T.), Institute for Clinical and Experimental Medicine, Prague, Czech Republic.']	['10.1148/radiol.2018180513 [doi]']	['Tao Q', 'Yan W', 'Wang Y', 'Paiman EHM', 'Shamonin DP', 'Garg P', 'Plein S', 'Huang L', 'Xia L', 'Sramko M', 'Tintera J', 'de Roos A', 'Lamb HJ', 'van der Geest RJ']	['ORCID: 0000-0001-7480-0703']		['Radiology. 2019 Jan;290(1):89. PMID: 30299235']				['2018/10/10 06:00']	20191011	20181009	2019 Jan	2018/10/10 06:00		['Tao, Qian', 'Yan, Wenjun', 'Wang, Yuanyuan', 'Paiman, Elisabeth H M', 'Shamonin, Denis P', 'Garg, Pankaj', 'Plein, Sven', 'Huang, Lu', 'Xia, Liming', 'Sramko, Marek', 'Tintera, Jarsolav', 'de Roos, Albert', 'Lamb, Hildo J', 'van der Geest, Rob J']			1		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2018180513 [doi]	20191011	['*Deep Learning', 'Heart Ventricles/*diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Magnetic Resonance Imaging, Cine/*methods', 'Retrospective Studies', 'Ventricular Function/*physiology']	2019/10/12 06:00				NLM	81-88	['2018/10/10 06:00 [pubmed]', '2019/10/12 06:00 [medline]', '2018/10/10 06:00 [entrez]']	United States			30299231	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			AIM IM		Radiology. 2019 Jan;290(1):81-88. doi: 10.1148/radiol.2018180513. Epub 2018 Oct 9.	MEDLINE	Radiology	Deep Learning-based Method for Fully Automatic Quantification of Left Ventricle Function from Cine MR Images: A Multivendor, Multicenter Study.		290	Deep Learning-based Method for Fully Automatic Quantification of Left Ventricle Function from Cine MR Images: A Multivendor, Multicenter Study.
The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.	['Department of Software Engineering, University of Engineering and Technology Taxila, Taxila, 47050, Pakistan.', 'Department of Computer Engineering, University of Engineering and Technology Taxila, Taxila, 47050, Pakistan. m.majid@uettaxila.edu.pk.', 'Department of Computer Engineering, University of Engineering and Technology Taxila, Taxila, 47050, Pakistan.', 'Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, Guildford, UK.', 'Department of Nuclear Engineering, King Abdul Aziz University, Jeddah, Saudi Arabia.', 'Center of Excellence in Information Assurance (CoEIA), King Saud University, Riyadh, 11653, Saudi Arabia.']	['10.1007/s10916-018-1088-1 [doi]', '10.1007/s10916-018-1088-1 [pii]']	['Anwar SM', 'Majid M', 'Qayyum A', 'Awais M', 'Alnowami M', 'Khan MK']	['ORCID: http://orcid.org/0000-0002-8179-3959']						['2018/10/10 06:00']	20190204	20181008	2018 Oct 8	2018/10/10 06:00		['Anwar, Syed Muhammad', 'Majid, Muhammad', 'Qayyum, Adnan', 'Awais, Muhammad', 'Alnowami, Majdi', 'Khan, Muhammad Khurram']			11		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-018-1088-1 [doi]	20190215	['Algorithms', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Image Processing, Computer-Assisted/*methods', 'Information Storage and Retrieval', 'Neural Networks (Computer)']	2019/02/05 06:00		['Classification', 'Computer aided diagnosis', 'Convolutional neural network', 'Medical image analysis', 'Segmentation']	['NOTNLM']	NLM	226	['2018/05/09 00:00 [received]', '2018/09/25 00:00 [accepted]', '2018/10/10 06:00 [entrez]', '2018/10/10 06:00 [pubmed]', '2019/02/05 06:00 [medline]']	United States			30298337	epublish	['Journal Article', 'Review']			IM		J Med Syst. 2018 Oct 8;42(11):226. doi: 10.1007/s10916-018-1088-1.	MEDLINE	J Med Syst	Medical Image Analysis using Convolutional Neural Networks: A Review.		42	Medical Image Analysis using Convolutional Neural Networks: A Review.
Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.	['Department of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.', 'Department of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.']	['10.1155/2018/2061516 [doi]']	['Lai Z', 'Deng H']	['ORCID: 0000-0003-3998-7466']						['2018/10/10 06:00']	20181211	20180912	2018	2018/10/10 06:00		['Lai, ZhiFei', 'Deng, HuiFang']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2018/2061516 [doi]	20181211	['Connective Tissue/pathology', 'Diagnosis, Computer-Assisted/*methods', 'Epithelium/pathology', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Keratosis, Seborrheic/pathology', 'Machine Learning', 'Melanoma/pathology', 'Muscles/pathology', 'Nerve Tissue/pathology', 'Neural Networks (Computer)', 'Nevus/pathology', 'Statistics as Topic']	2018/12/12 06:00				NLM	2061516	['2018/03/03 00:00 [received]', '2018/08/09 00:00 [accepted]', '2018/10/10 06:00 [entrez]', '2018/10/10 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	United States	PMC6157177		30298088	epublish	['Evaluation Studies', 'Journal Article']			IM		Comput Intell Neurosci. 2018 Sep 12;2018:2061516. doi: 10.1155/2018/2061516. eCollection 2018.	MEDLINE	Comput Intell Neurosci	Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron().		2018	Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron().
Relation extraction between medical concepts from electronic medical records has pervasive applications as well as significance. However, previous researches utilizing machine learning algorithms judge the semantic types of medical concept pair mentions independently. In fact, different concept pair mentions in the same context are of dependencies which can provide beneficial evidences for identifying their relation types. To the best of our knowledge, only one study has considered such dependencies in discharge summaries. However, its hard constraints are not applied effectively to the History of Present Illness (HPI) in electronic Medical Records. According to the writing characteristics of HPI records, we generalize two regularities of dependencies among concept pairs mentioned in an HPI record to enhance the performance of relation extraction. We incorporate the two soft constraints corresponding to the regularities and the posterior probabilities returned by a local classifier into a joint inference process which applies Integer Quadratic Programming method to carry out collective classification for all concept pair mentions in an HPI record. We implement four local classification models including support vector machine, logistics regression, random forest and piecewise convolutional neural networks to examine the performance of our approach. A series of experimental results demonstrate that our collective classification method has made a principal improvement and outperforms the other state-of-the-art methods.	['Department of Computer Science, Sichuan University, Chengdu, China. Electronic address: cl@scu.edu.cn.', 'Department of Computer Science, Sichuan University, Chengdu, China.', 'Department of Computer Science, Sichuan University, Chengdu, China.', 'School of Basic Medicine, Chengdu University of TCM, Chengdu, China.', 'Department of Computer Science, Sichuan University, Chengdu, China. Electronic address: yuzhonghua@scu.edu.cn.', 'Department of Computer Science, Sichuan University, Chengdu, China.']	['S1532-0464(18)30186-2 [pii]', '10.1016/j.jbi.2018.09.013 [doi]']	['Chen L', 'Li Y', 'Chen W', 'Liu X', 'Yu Z', 'Zhang S']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/10/08 06:00']	20191119	20181004	2018 Nov	2018/10/08 06:00		['Chen, Li', 'Li, Yuanju', 'Chen, Weipeng', 'Liu, Xinglong', 'Yu, Zhonghua', 'Zhang, Siyuan']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30186-2 [pii] 10.1016/j.jbi.2018.09.013 [doi]	20191119	['Algorithms', 'China', 'Deep Learning', '*Electronic Health Records', 'Humans', 'Medical Informatics/*methods', 'Models, Statistical', 'Probability', 'Regression Analysis', 'Reproducibility of Results', '*Support Vector Machine']	2019/11/20 06:00		['*Electronic medical record', '*History of present illness', '*Integer quadratic programming', '*Relation extraction', '*Soft constraints']	['NOTNLM']	NLM	108-117	['2017/12/13 00:00 [received]', '2018/09/05 00:00 [revised]', '2018/09/24 00:00 [accepted]', '2018/10/08 06:00 [pubmed]', '2019/11/20 06:00 [medline]', '2018/10/08 06:00 [entrez]']	United States			30292854	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Nov;87:108-117. doi: 10.1016/j.jbi.2018.09.013. Epub 2018 Oct 4.	MEDLINE	J Biomed Inform	Utilizing soft constraints to enhance medical relation extraction from the history of present illness in electronic medical records.		87	Utilizing soft constraints to enhance medical relation extraction from the history of present illness in electronic medical records.
OBJECTIVE: This study was carried out with the purpose of testing the ability of deep learning machine vision to identify microscopic objects and geometries found in chemical crystal structures. RESULTS: A database of 6994 images taken with a light microscope showing microscopic crystal details of selected chemical compounds along with 180 images of an unknown chemical was created to train and test, respectively the deep learning models. The models used were GoogLeNet (22 layers deep network) and VGG-16 (16 layers deep network), based on the Caffe framework (University of California, Berkeley, CA) of the DIGITS platform (NVIDIA Corporation, Santa Clara, CA). The two models were successfully trained with the images, having validation accuracy values of 97.38% and 99.65% respectively. Finally, both models were able to correctly identify the unknown chemical sample with a high probability score of 93.34% (GoogLeNet) and 99.41% (VGG-16). The positive results found in this study can be further applied to other unknown sample identification tasks using light microscopy coupled with deep learning machine vision.	['Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, FL, 33850, USA.', 'Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, FL, 33850, USA. schumaw@ufl.edu.', 'Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, FL, 33850, USA.']	['10.1186/s13104-018-3813-8 [doi]', '10.1186/s13104-018-3813-8 [pii]']	['Mungofa P', 'Schumann A', 'Waldo L']							['2018/10/07 06:00']	20190118	20181005	2018 Oct 5	2018/10/07 06:00		['Mungofa, Perseveranca', 'Schumann, Arnold', 'Waldo, Laura']		['2018-70016-27387/National Institute of Food and Agriculture']	1		1756-0500 (Electronic) 1756-0500 (Linking)	101462768	BMC research notes	['eng']	10.1186/s13104-018-3813-8 [doi]	20190118	['Agrochemicals', '*Deep Learning', '*Image Processing, Computer-Assisted', '*Microscopy', '*Pattern Recognition, Automated']	2019/01/19 06:00		['Chemical crystals', 'Deep learning', 'GoogLeNet', 'Image classification', 'Microscopic objects', 'VGG-16']	['NOTNLM']	NLM	703	['2018/07/29 00:00 [received]', '2018/10/03 00:00 [accepted]', '2018/10/07 06:00 [entrez]', '2018/10/07 06:00 [pubmed]', '2019/01/19 06:00 [medline]']	England	PMC6173923		30290837	epublish	['Journal Article']		['0 (Agrochemicals)']	IM		BMC Res Notes. 2018 Oct 5;11(1):703. doi: 10.1186/s13104-018-3813-8.	MEDLINE	BMC Res Notes	Chemical crystal identification with deep learning machine vision.		11	Chemical crystal identification with deep learning machine vision.
BACKGROUND: To develop a deep neural network able to differentiate glaucoma from non-glaucoma visual fields based on visual filed (VF) test results, we collected VF tests from 3 different ophthalmic centers in mainland China. METHODS: Visual fields obtained by both Humphrey 30-2 and 24-2 tests were collected. Reliability criteria were established as fixation losses less than 2/13, false positive and false negative rates of less than 15%. RESULTS: We split a total of 4012 PD images from 1352 patients into two sets, 3712 for training and another 300 for validation. There is no significant difference between left to right ratio (P = 0.6211), while age (P = 0.0022), VFI (P = 0.0001), MD (P = 0.0039) and PSD (P = 0.0001) exhibited obvious statistical differences. On the validation set of 300 VFs, CNN achieves the accuracy of 0.876, while the specificity and sensitivity are 0.826 and 0.932, respectively. For ophthalmologists, the average accuracies are 0.607, 0.585 and 0.626 for resident ophthalmologists, attending ophthalmologists and glaucoma experts, respectively. AGIS and GSS2 achieved accuracy of 0.459 and 0.523 respectively. Three traditional machine learning algorithms, namely support vector machine (SVM), random forest (RF), and k-nearest neighbor (k-NN) were also implemented and evaluated in the experiments, which achieved accuracy of 0.670, 0.644, and 0.591 respectively. CONCLUSIONS: Our algorithm based on CNN has achieved higher accuracy compared to human ophthalmologists and traditional rules (AGIS and GSS2) in differentiation of glaucoma and non-glaucoma VFs.	['Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Sun Yat-sen University, Guangzhou, China.', 'SenseTime Group Limited, Hong Kong, China.', 'Guangdong key lab of Computer Vision & Virtual Reality, Multimedia Research Center, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.', 'Guangdong key lab of Computer Vision & Virtual Reality, Multimedia Research Center, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.', 'Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Sun Yat-sen University, Guangzhou, China.', 'C-MER Dennis Lam Eye Hospital, Shenzhen, China.', 'Department of Ophthalmology, the First Affiliated Hospital of Kunming Medical University, Kunming, China.', 'Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Sun Yat-sen University, Guangzhou, China.', 'Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Sun Yat-sen University, Guangzhou, China.', 'Guangdong key lab of Computer Vision & Virtual Reality, Multimedia Research Center, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.', 'C-MER Dennis Lam Eye Hospital, Shenzhen, China.', 'Department of Ophthalmology, the First Affiliated Hospital of Kunming Medical University, Kunming, China. zhoculist@163.com.', 'Guangdong key lab of Computer Vision & Virtual Reality, Multimedia Research Center, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China. yu.qiao@siat.ac.cn.', 'Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Sun Yat-sen University, Guangzhou, China. zhangxl2@mail.sysu.edu.cn.']	['10.1186/s12880-018-0273-5 [doi]', '10.1186/s12880-018-0273-5 [pii]']	['Li F', 'Wang Z', 'Qu G', 'Song D', 'Yuan Y', 'Xu Y', 'Gao K', 'Luo G', 'Xiao Z', 'Lam DSC', 'Zhong H', 'Qiao Y', 'Zhang X']							['2018/10/06 06:00']	20190219	20181004	2018 Oct 4	2018/10/06 06:00	['BMC Med Imaging. 2019 May 21;19(1):40. PMID: 31113391']	['Li, Fei', 'Wang, Zhe', 'Qu, Guoxiang', 'Song, Diping', 'Yuan, Ye', 'Xu, Yang', 'Gao, Kai', 'Luo, Guangwei', 'Xiao, Zegu', 'Lam, Dennis S C', 'Zhong, Hua', 'Qiao, Yu', 'Zhang, Xiulan']		['2018YFC010302/National Key Research and Development Project/International', '201803010066/Science and Technology Program of Guangzhou,China/International', 'U1613211, 81460085, 81760170/National Natural Science Foundation of', 'China/International']	1		1471-2342 (Electronic) 1471-2342 (Linking)	100968553	BMC medical imaging	['eng']	10.1186/s12880-018-0273-5 [doi]	20190320	['Adult', 'Aged', 'Female', 'Glaucoma/*diagnosis', 'Humans', 'Machine Learning', 'Middle Aged', 'Reproducibility of Results', 'Visual Field Tests/*methods']	2019/03/21 06:00		['*Deep learning', '*Glaucoma', '*Visual field']	['NOTNLM']	NLM	35	['2018/07/13 00:00 [received]', '2018/08/30 00:00 [accepted]', '2018/10/06 06:00 [entrez]', '2018/10/06 06:00 [pubmed]', '2019/03/21 06:00 [medline]']	England	PMC6172715		30286740	epublish	"['Clinical Trial', 'Journal Article', 'Multicenter Study', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Imaging. 2018 Oct 4;18(1):35. doi: 10.1186/s12880-018-0273-5.	MEDLINE	BMC Med Imaging	Automatic differentiation of Glaucoma visual field from non-glaucoma visual filed using deep convolutional neural network.		18	Automatic differentiation of Glaucoma visual field from non-glaucoma visual filed using deep convolutional neural network.
BACKGROUND: Deep convolutional neural networks have become a widespread tool for the detection of nuclei in histopathology images. Many implementations share a basic approach that includes generation of an intermediate map indicating the presence of a nucleus center, which we refer to as PMap. Nevertheless, these implementations often still differ in several parameters, resulting in different detection qualities. METHODS: We identified several essential parameters and configured the basic PMap approach using combinations of them. We thoroughly evaluated and compared various configurations on multiple datasets with respect to detection quality, efficiency and training effort. RESULTS: Post-processing of the PMap was found to have the largest impact on detection quality. Also, two different network architectures were identified that improve either detection quality or runtime performance. The best-performing configuration yields f1-measures of 0.816 on H&E stained images of colorectal adenocarcinomas and 0.819 on Ki-67 stained images of breast tumor tissue. On average, it was fully trained in less than 15,000 iterations and processed 4.15 megapixels per second at prediction time. CONCLUSIONS: The basic PMap approach is greatly affected by certain parameters. Our evaluation provides guidance on their impact and best settings. When configured properly, this simple and efficient approach can yield equal detection quality as more complex and time-consuming state-of-the-art approaches.	['Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany. Electronic address: henning.hoefener@mevis.fraunhofer.de.', 'Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany. Electronic address: andre.homeyer@mevis.fraunhofer.de.', 'Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany. Electronic address: nick.weiss@mevis.fraunhofer.de.', 'Sectra AB, Teknikringen 20, 58330, Linkoping, Sweden. Electronic address: Jesper.Molin@sectra.com.', 'Sectra AB, Teknikringen 20, 58330, Linkoping, Sweden; Center for Medical Image Science and Visualization, Linkoping University, 58183, Linkoping, Sweden. Electronic address: claes.lundstrom@liu.se.', 'Fraunhofer MEVIS, Am Fallturm 1, 28359, Bremen, Germany; Jacobs University, Campus Ring 1, 28759, Bremen, Germany. Electronic address: horst.hahn@mevis.fraunhofer.de.']	['S0895-6111(18)30080-6 [pii]', '10.1016/j.compmedimag.2018.08.010 [doi]']	['Hofener H', 'Homeyer A', 'Weiss N', 'Molin J', 'Lundstrom CF', 'Hahn HK']		['Copyright (c) 2018 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2018/10/05 06:00']	20191029	20180917	2018 Dec	2018/10/05 06:00		['Hofener, Henning', 'Homeyer, Andre', 'Weiss, Nick', 'Molin, Jesper', 'Lundstrom, Claes F', 'Hahn, Horst K']					1879-0771 (Electronic) 0895-6111 (Linking)	8806104	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	['eng']	S0895-6111(18)30080-6 [pii] 10.1016/j.compmedimag.2018.08.010 [doi]	20191029	['Algorithms', '*Cell Nucleus', '*Deep Learning', 'Histology', 'Image Interpretation, Computer-Assisted/*methods']	2019/10/30 06:00		['*Deep learning', '*Histology', '*Image analysis', '*Nuclei detection', '*PMap']	['NOTNLM']	NLM	43-52	['2018/02/08 00:00 [received]', '2018/07/13 00:00 [revised]', '2018/08/23 00:00 [accepted]', '2018/10/05 06:00 [pubmed]', '2019/10/30 06:00 [medline]', '2018/10/05 06:00 [entrez]']	United States			30286333	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Med Imaging Graph. 2018 Dec;70:43-52. doi: 10.1016/j.compmedimag.2018.08.010. Epub 2018 Sep 17.	MEDLINE	Comput Med Imaging Graph	Deep learning nuclei detection: A simple approach can deliver state-of-the-art results.		70	Deep learning nuclei detection: A simple approach can deliver state-of-the-art results.
The Purpose of the study was to develop a deep residual learning algorithm to screen for glaucoma from fundus photography and measure its diagnostic performance compared to Residents in Ophthalmology. A training dataset consisted of 1,364 color fundus photographs with glaucomatous indications and 1,768 color fundus photographs without glaucomatous features. A testing dataset consisted of 60 eyes of 60 glaucoma patients and 50 eyes of 50 normal subjects. Using the training dataset, a deep learning algorithm known as Deep Residual Learning for Image Recognition (ResNet) was developed to discriminate glaucoma, and its diagnostic accuracy was validated in the testing dataset, using the area under the receiver operating characteristic curve (AROC). The Deep Residual Learning for Image Recognition was constructed using the training dataset and validated using the testing dataset. The presence of glaucoma in the testing dataset was also confirmed by three Residents in Ophthalmology. The deep learning algorithm achieved significantly higher diagnostic performance compared to Residents in Ophthalmology; with ResNet, the AROC from all testing data was 96.5 (95% confidence interval [CI]: 93.5 to 99.6)% while the AROCs obtained by the three Residents were between 72.6% and 91.2%.	['Queue inc, Tokyo, Japan.', 'Division of Ophthalmology, Matsue Red Cross Hospital, Shimane, Japan.', 'Department of Ophthalmology, Shimane University Faculty of Medicine, Shimane, Japan.', 'Queue inc, Tokyo, Japan.', 'Department of Ophthalmology, The University of Tokyo, Tokyo, Japan.', 'Department of Ophthalmology, Graduate School of Medical Science, Kitasato University, Sagamihara Kanagawa, Japan.', 'Department of Ophthalmology, The University of Tokyo, Tokyo, Japan.', 'Department of Ophthalmology, Graduate School of Medical Science, Kitasato University, Sagamihara Kanagawa, Japan.', 'Department of Ophthalmology, The University of Tokyo, Tokyo, Japan.', 'Department of Ophthalmology, The University of Tokyo, Tokyo, Japan. rasaoka-tky@umin.ac.jp.']	['10.1038/s41598-018-33013-w [doi]', '10.1038/s41598-018-33013-w [pii]']	['Shibata N', 'Tanito M', 'Mitsuhashi K', 'Fujino Y', 'Matsuura M', 'Murata H', 'Asaoka R']	['ORCID: http://orcid.org/0000-0001-6082-0738']						['2018/10/04 06:00']	20191113	20181002	2018 Oct 2	2018/10/04 06:00		['Shibata, Naoto', 'Tanito, Masaki', 'Mitsuhashi, Keita', 'Fujino, Yuri', 'Matsuura, Masato', 'Murata, Hiroshi', 'Asaoka, Ryo']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-33013-w [doi]	20191115	['Adult', 'Aged', 'Datasets as Topic', '*Deep Learning', 'Female', '*Fundus Oculi', 'Glaucoma/*diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Male', 'Middle Aged', 'Ophthalmoscopy', 'Photography', 'ROC Curve']	2019/11/14 06:00				NLM	14665	['2018/04/24 00:00 [received]', '2018/09/20 00:00 [accepted]', '2018/10/04 06:00 [entrez]', '2018/10/04 06:00 [pubmed]', '2019/11/14 06:00 [medline]']	England	PMC6168579		30279554	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			IM		Sci Rep. 2018 Oct 2;8(1):14665. doi: 10.1038/s41598-018-33013-w.	MEDLINE	Sci Rep	Development of a deep residual learning algorithm to screen for glaucoma from fundus photography.		8	Development of a deep residual learning algorithm to screen for glaucoma from fundus photography.
Traditional laboratory experiments, rehabilitation clinics, and wearable sensors offer biomechanists a wealth of data on healthy and pathological movement. To harness the power of these data and make research more efficient, modern machine learning techniques are starting to complement traditional statistical tools. This survey summarizes the current usage of machine learning methods in human movement biomechanics and highlights best practices that will enable critical evaluation of the literature. We carried out a PubMed/Medline database search for original research articles that used machine learning to study movement biomechanics in patients with musculoskeletal and neuromuscular diseases. Most studies that met our inclusion criteria focused on classifying pathological movement, predicting risk of developing a disease, estimating the effect of an intervention, or automatically recognizing activities to facilitate out-of-clinic patient monitoring. We found that research studies build and evaluate models inconsistently, which motivated our discussion of best practices. We provide recommendations for training and evaluating machine learning models and discuss the potential of several underutilized approaches, such as deep learning, to generate new knowledge about human movement. We believe that cross-training biomechanists in data science and a cultural shift toward sharing of data and tools are essential to maximize the impact of biomechanics research.	['Department of Mechanical Engineering, Carnegie Mellon University, United States. Electronic address: ehalilaj@andrew.cmu.edu.', 'Department of Mechanical Engineering, Stanford University, United States.', 'Department of Computer Science, Stanford University, United States.', 'Department of Bioengineering, Stanford University, United States.', 'Department of Statistics, Stanford University, United States; Department of Health Research and Policy, Stanford University, United States.', 'Department of Mechanical Engineering, Stanford University, United States; Department of Bioengineering, Stanford University, United States; Department of Orthopaedic Surgery, Stanford University, United States.']	['S0021-9290(18)30730-9 [pii]', '10.1016/j.jbiomech.2018.09.009 [doi]']	['Halilaj E', 'Rajagopal A', 'Fiterau M', 'Hicks JL', 'Hastie TJ', 'Delp SL']		['Copyright (c) 2018. Published by Elsevier Ltd.']					['2018/10/04 06:00']	20190605	20180913	2018 Nov 16	2018/10/04 06:00		['Halilaj, Eni', 'Rajagopal, Apoorva', 'Fiterau, Madalina', 'Hicks, Jennifer L', 'Hastie, Trevor J', 'Delp, Scott L']		['U54 EB020405/EB/NIBIB NIH HHS/United States']			1873-2380 (Electronic) 0021-9290 (Linking)	0157375	Journal of biomechanics	['eng']	S0021-9290(18)30730-9 [pii] 10.1016/j.jbiomech.2018.09.009 [doi]	20191128	['Biomechanical Phenomena', 'Humans', '*Machine Learning', 'Movement/*physiology']	2019/06/06 06:00	['NIHMS1020529']	['*Data science', '*Machine learning', '*Musculoskeletal', '*Neuromuscular']	['NOTNLM']	NLM	1-11	['2018/08/10 00:00 [received]', '2018/09/08 00:00 [accepted]', '2018/10/04 06:00 [pubmed]', '2019/06/06 06:00 [medline]', '2018/10/04 06:00 [entrez]']	United States	PMC6879187		30279002	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural', 'Review']			IM		J Biomech. 2018 Nov 16;81:1-11. doi: 10.1016/j.jbiomech.2018.09.009. Epub 2018 Sep 13.	MEDLINE	J Biomech	Machine learning in human movement biomechanics: Best practices, common pitfalls, and new opportunities.		81	Machine learning in human movement biomechanics: Best practices, common pitfalls, and new opportunities.
BACKGROUND: The large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery. METHODS: We used deep learning methods (recurrent neural networks) to predict several severe complications (mortality, renal failure with a need for renal replacement therapy, and postoperative bleeding leading to operative revision) in post cardiosurgical care in real time. Adult patients who underwent major open heart surgery from Jan 1, 2000, to Dec 31, 2016, in a German tertiary care centre for cardiovascular diseases formed the main derivation dataset. We measured the accuracy and timeliness of the deep learning model's forecasts and compared predictive quality to that of established standard-of-care clinical reference tools (clinical rule for postoperative bleeding, Simplified Acute Physiology Score II for mortality, and the Kidney Disease: Improving Global Outcomes staging criteria for acute renal failure) using positive predictive value (PPV), negative predictive value, sensitivity, specificity, area under the curve (AUC), and the F1 measure (which computes a harmonic mean of sensitivity and PPV). Results were externally retrospectively validated with 5898 cases from the published MIMIC-III dataset. FINDINGS: Of 47 559 intensive care admissions (corresponding to 42 007 patients), we included 11 492 (corresponding to 9269 patients). The deep learning models yielded accurate predictions with the following PPV and sensitivity scores: PPV 0.90 and sensitivity 0.85 for mortality, 0.87 and 0.94 for renal failure, and 0.84 and 0.74 for bleeding. The predictions significantly outperformed the standard clinical reference tools, improving the absolute complication prediction AUC by 0.29 (95% CI 0.23-0.35) for bleeding, by 0.24 (0.19-0.29) for mortality, and by 0.24 (0.13-0.35) for renal failure (p<0.0001 for all three analyses). The deep learning methods showed accurate predictions immediately after patient admission to the intensive care unit. We also observed an increase in performance in our validation cohort when the machine learning approach was tested against clinical reference tools, with absolute improvements in AUC of 0.09 (95% CI 0.03-0.15; p=0.0026) for bleeding, of 0.18 (0.07-0.29; p=0.0013) for mortality, and of 0.25 (0.18-0.32; p<0.0001) for renal failure. INTERPRETATION: The observed improvements in prediction for all three investigated clinical outcomes have the potential to improve critical care. These findings are noteworthy in that they use routinely collected clinical data exclusively, without the need for any manual processing. The deep machine learning method showed AUC scores that significantly surpass those of clinical reference tools, especially soon after admission. Taken together, these properties are encouraging for prospective deployment in critical care settings to direct the staff's attention towards patients who are most at risk. FUNDING: No specific funding.	['Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany; Berlin Institute of Health, Berlin, Germany. Electronic address: meyera@dhzb.de.', 'Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Department of Computer Science, ETH Zurich, Zurich, Switzerland.', 'Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Berlin Institute of Health, Berlin, Germany.', 'Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany.', 'Institute of Imaging Science and Computational Modelling, Charite - Universitatsmedizin Berlin, Berlin, Germany.', 'Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Department of Cardiovascular Surgery, Charite - Universitatsmedizin Berlin, Berlin, Germany.', 'Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Berlin Center for Regenerative Therapies, Charite - Universitatsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany.', 'Department of Computer Science, ETH Zurich, Zurich, Switzerland.', 'Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Department of Cardiovascular Surgery, Charite - Universitatsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany.', 'Department of Computer Science, ETH Zurich, Zurich, Switzerland; Center for Biomedical Informatics, Brown University, Providence, RI, USA.']	['S2213-2600(18)30300-X [pii]', '10.1016/S2213-2600(18)30300-X [doi]']	['Meyer A', 'Zverinski D', 'Pfahringer B', 'Kempfert J', 'Kuehne T', 'Sundermann SH', 'Stamm C', 'Hofmann T', 'Falk V', 'Eickhoff C']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']	['Lancet Respir Med. 2018 Dec;6(12):886-888. PMID: 30416082']				['2018/10/03 06:00']	20190710	20180928	2018 Dec	2018/10/03 06:00		['Meyer, Alexander', 'Zverinski, Dina', 'Pfahringer, Boris', 'Kempfert, Jorg', 'Kuehne, Titus', 'Sundermann, Simon H', 'Stamm, Christof', 'Hofmann, Thomas', 'Falk, Volkmar', 'Eickhoff, Carsten']			12		2213-2619 (Electronic) 2213-2600 (Linking)	101605555	The Lancet. Respiratory medicine	['eng']	S2213-2600(18)30300-X [pii] 10.1016/S2213-2600(18)30300-X [doi]	20190710	['Aged', 'Cardiac Surgical Procedures/*adverse effects/mortality', '*Deep Learning', 'Female', 'Humans', 'Intensive Care Units/statistics & numerical data', 'Male', 'Middle Aged', 'Outcome Assessment (Health Care)', 'Postoperative Hemorrhage/*diagnosis/epidemiology', 'Predictive Value of Tests', 'ROC Curve', 'Renal Insufficiency/*diagnosis/epidemiology', 'Retrospective Studies']	2019/07/11 06:00				NLM	905-914	['2018/01/30 00:00 [received]', '2018/06/29 00:00 [revised]', '2018/07/09 00:00 [accepted]', '2018/10/03 06:00 [pubmed]', '2019/07/11 06:00 [medline]', '2018/10/03 06:00 [entrez]']	England			30274956	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			IM		Lancet Respir Med. 2018 Dec;6(12):905-914. doi: 10.1016/S2213-2600(18)30300-X. Epub 2018 Sep 28.	MEDLINE	Lancet Respir Med	Machine learning for real-time prediction of complications in critical care: a retrospective study.		6	Machine learning for real-time prediction of complications in critical care: a retrospective study.
Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.	['State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China.', 'Department of Bioinformatics & Systems Biology, MOE Key Laboratory of Molecular Biophysics, College of Life Science and Technology and the Collaborative Innovation Center for Biomedical Engineering, Huazhong University of Science and Technology, Wuhan 430074, China.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China. Electronic address: zuozhx@sysucc.org.cn.', 'State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou 510060, China. Electronic address: renjian@sysucc.org.cn.']	['S1672-0229(18)30347-4 [pii]', '10.1016/j.gpb.2018.04.007 [doi]']	['Xie Y', 'Luo X', 'Li Y', 'Chen L', 'Ma W', 'Huang J', 'Cui J', 'Zhao Y', 'Xue Y', 'Zuo Z', 'Ren J']		['Copyright (c) 2018. Production and hosting by Elsevier B.V.']					['2018/10/01 06:00']	20181211	20180927	2018 Aug	2018/10/01 06:00		['Xie, Yubin', 'Luo, Xiaotong', 'Li, Yupeng', 'Chen, Li', 'Ma, Wenbin', 'Huang, Junjiu', 'Cui, Jun', 'Zhao, Yong', 'Xue, Yu', 'Zuo, Zhixiang', 'Ren, Jian']			4		2210-3244 (Electronic) 1672-0229 (Linking)	101197608	Genomics, proteomics & bioinformatics	['eng']	S1672-0229(18)30347-4 [pii] 10.1016/j.gpb.2018.04.007 [doi]	20190122	['Amino Acid Sequence', 'Amino Acids/metabolism', '*Deep Learning', 'Humans', 'Internet', 'Neural Networks (Computer)', 'Nitrosation', 'Proteins/chemistry/*metabolism', 'Reproducibility of Results', '*Software']	2018/12/12 06:00		['*Deep learning', '*Feature extraction', '*Functional site prediction', '*Protein nitration and nitrosylation', '*Web service']	['NOTNLM']	NLM	294-306	['2018/01/07 00:00 [received]', '2018/04/12 00:00 [revised]', '2018/04/27 00:00 [accepted]', '2018/10/01 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2018/10/01 06:00 [entrez]']	China	PMC6205083		30268931	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Amino Acids)', '0 (Proteins)']	IM		Genomics Proteomics Bioinformatics. 2018 Aug;16(4):294-306. doi: 10.1016/j.gpb.2018.04.007. Epub 2018 Sep 27.	MEDLINE	Genomics Proteomics Bioinformatics	DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.		16	DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.
BACKGROUND: Small interfering RNA (siRNA) can be used to post-transcriptional gene regulation by knocking down targeted genes. In functional genomics, biomedical research and cancer therapeutics, siRNA design is a critical research topic. Various computational algorithms have been developed to select the most effective siRNA, whereas the efficacy prediction accuracy is not so satisfactory. Many existing computational methods are based on feature engineering, which may lead to biased and incomplete features. Deep learning utilizes non-linear mapping operations to detect potential feature pattern and has been considered perform better than existing machine learning method. RESULTS: In this paper, to further improve the prediction accuracy and facilitate gene functional studies, we developed a new powerful siRNA efficacy predictor based on a deep architecture. First, we extracted hidden feature patterns from two modalities, including sequence context features and thermodynamic property. Then, we constructed a deep architecture to implement the prediction. On the available largest siRNA database, the performance of our proposed method was measured with 0.725 PCC and 0.903 AUC value. The comparative experiment showed that our proposed architecture outperformed several siRNA prediction methods. CONCLUSIONS: The results demonstrate that our deep architecture is stable and efficient to predict siRNA silencing efficacy. The method could help select candidate siRNA for targeted mRNA, and further promote the development of RNA interference.	['School of Information Technology, Jilin Agricultural University, Changchun, China.', 'School of Information Science and Technology, Northeast Normal University, Changchun, China.', 'Institute of Computational Biology, Northeast Normal University, Changchun, China.', 'School of Information Science and Technology, Northeast Normal University, Changchun, China.', 'Institute of Computational Biology, Northeast Normal University, Changchun, China.', 'Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China.', 'College of Computer Science and Technology, Jilin University, Changchun, China.', 'School of Information Technology, Jilin Agricultural University, Changchun, China. 264496469@qq.com.']	['10.1186/s12864-018-5028-8 [doi]', '10.1186/s12864-018-5028-8 [pii]']	['Han Y', 'He F', 'Chen Y', 'Liu Y', 'Yu H']							['2018/09/27 06:00']	20181114	20180924	2018 Sep 24	2018/09/27 06:00		['Han, Ye', 'He, Fei', 'Chen, Yongbing', 'Liu, Yuanning', 'Yu, Helong']			Suppl 7		1471-2164 (Electronic) 1471-2164 (Linking)	100965258	BMC genomics	['eng']	10.1186/s12864-018-5028-8 [doi]	20181114	['*Algorithms', 'Computational Biology/*methods', '*Gene Silencing', 'Gene Targeting/*methods', 'Humans', 'Machine Learning', '*Neural Networks (Computer)', 'RNA, Messenger/genetics', 'RNA, Small Interfering/chemistry/*genetics']	2018/11/15 06:00		['Deep learning', 'RNAi', 'siRNA']	['NOTNLM']	NLM	669	['2018/09/27 06:00 [entrez]', '2018/09/27 06:00 [pubmed]', '2018/11/15 06:00 [medline]']	England	PMC6157246		30255786	epublish	['Journal Article']		['0 (RNA, Messenger)', '0 (RNA, Small Interfering)']	IM		BMC Genomics. 2018 Sep 24;19(Suppl 7):669. doi: 10.1186/s12864-018-5028-8.	MEDLINE	BMC Genomics	SiRNA silencing efficacy prediction based on a deep architecture.		19	SiRNA silencing efficacy prediction based on a deep architecture.
PURPOSE: With the advent of robot-assisted surgery, the role of data-driven approaches to integrate statistics and machine learning is growing rapidly with prominent interests in objective surgical skill assessment. However, most existing work requires translating robot motion kinematics into intermediate features or gesture segments that are expensive to extract, lack efficiency, and require significant domain-specific knowledge. METHODS: We propose an analytical deep learning framework for skill assessment in surgical training. A deep convolutional neural network is implemented to map multivariate time series data of the motion kinematics to individual skill levels. RESULTS: We perform experiments on the public minimally invasive surgical robotic dataset, JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our proposed learning model achieved competitive accuracies of 92.5%, 95.4%, and 91.3%, in the standard training tasks: Suturing, Needle-passing, and Knot-tying, respectively. Without the need of engineered features or carefully tuned gesture segmentation, our model can successfully decode skill information from raw motion profiles via end-to-end learning. Meanwhile, the proposed model is able to reliably interpret skills within a 1-3 second window, without needing an observation of entire training trial. CONCLUSION: This study highlights the potential of deep architectures for efficient online skill assessment in modern surgical training.	['Department of Mechanical Engineering, University of Texas at Dallas, Richardson, TX, 75080, USA. zihengwang@utdallas.edu.', 'Department of Mechanical Engineering, University of Texas at Dallas, Richardson, TX, 75080, USA.', 'Department of Surgery, UT Southwestern Medical Center, Dallas, TX, 75390, USA.']	['10.1007/s11548-018-1860-1 [doi]', '10.1007/s11548-018-1860-1 [pii]']	['Wang Z', 'Majewicz Fey A']	['ORCID: http://orcid.org/0000-0003-1099-3141']						['2018/09/27 06:00']	20190108	20180925	2018 Dec	2018/09/27 06:00		['Wang, Ziheng', 'Majewicz Fey, Ann']		['1464432/National Science Foundation']	12		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-018-1860-1 [doi]	20190108	['Biomechanical Phenomena', '*Clinical Competence', '*Deep Learning', 'Gestures', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', 'Robotics/*education']	2019/01/09 06:00		['Convolutional neural network', 'Deep learning', 'Motion analysis', 'Surgical robotics', 'Surgical skill evaluation']	['NOTNLM']	NLM	1959-1970	['2018/01/11 00:00 [received]', '2018/09/11 00:00 [accepted]', '2018/09/27 06:00 [pubmed]', '2019/01/09 06:00 [medline]', '2018/09/27 06:00 [entrez]']	Germany			30255463	ppublish	['Journal Article', 'Review']			IM		Int J Comput Assist Radiol Surg. 2018 Dec;13(12):1959-1970. doi: 10.1007/s11548-018-1860-1. Epub 2018 Sep 25.	MEDLINE	Int J Comput Assist Radiol Surg	Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery.		13	Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery.
Manual ultrasound (US)-based methods are adapted for lumen diameter (LD) measurement to estimate the risk of stroke but they are tedious, error prone, and subjective causing variability. We propose an automated deep learning (DL)-based system for lumen detection. The system consists of a combination of two DL systems: encoder and decoder for lumen segmentation. The encoder employs a 13-layer convolution neural network model (CNN) for rich feature extraction. The decoder employs three up-sample layers of fully convolution network (FCN) for lumen segmentation. Three sets of manual tracings were used during the training paradigm leading to the design of three DL systems. Cross-validation protocol was implemented for all three DL systems. Using the polyline distance metric, the precision of merit for three DL systems over 407 US scans was 99.61%, 97.75%, and 99.89%, respectively. The Jaccard index and Dice similarity of DL lumen segmented region against three ground truth (GT) regions were 0.94, 0.94, and 0.93 and 0.97, 0.97, and 0.97, respectively. The corresponding AUC for three DL systems was 0.95, 0.91, and 0.93. The experimental results demonstrated superior performance of proposed deep learning system over conventional methods in literature. Graphical abstract .	['Department of Computer Science and Engineering, NIT Goa, Ponda, India.', 'Department of Computer Science and Engineering, NIT Goa, Ponda, India.', 'Department of Radiology, A.O.U. Cagliari, Cagliari, Italy.', 'Department of Computer Science and Engineering, NIT Goa, Ponda, India.', 'Brown University, Providence, RI, USA.', 'Monitoring and Diagnostic Division, AtheroPoint, Roseville, CA, USA.', 'Cardiovascular Division, University of Virginia, Charlottesville, VA, USA.', 'Dept. of Neurology, IMIM - Hospital del Mar, Passeig Maritim 25-29, Barcelona, Spain.', 'Helena Hospital, St. Helena, CA, USA.', 'Vascular Screening and Diagnostic Centre, London, UK.', 'Department of Biological Sciences, University of Cyprus, Nicosia, Cyprus.', 'Monitoring and Diagnostic Division, AtheroPoint, Roseville, CA, USA. Jasjit.Suri@AtheroPoint.com.']	['10.1007/s11517-018-1897-x [doi]', '10.1007/s11517-018-1897-x [pii]']	['Biswas M', 'Kuppili V', 'Saba L', 'Edla DR', 'Suri HS', 'Sharma A', 'Cuadrado-Godia E', 'Laird JR', 'Nicolaides A', 'Suri JS']							['2018/09/27 06:00']	20190509	20180926	2019 Feb	2018/09/27 06:00		['Biswas, Mainak', 'Kuppili, Venkatanareshbabu', 'Saba, Luca', 'Edla, Damodar Reddy', 'Suri, Harman S', 'Sharma, Aditya', 'Cuadrado-Godia, Elisa', 'Laird, John R', 'Nicolaides, Andrew', 'Suri, Jasjit S']			2		1741-0444 (Electronic) 0140-0118 (Linking)	7704869	Medical & biological engineering & computing	['eng']	10.1007/s11517-018-1897-x [doi]	20190509	['Aged', 'Carotid Arteries/*physiopathology', 'Deep Learning', 'Diabetes Mellitus/*physiopathology', 'Female', 'Humans', 'Machine Learning', 'Male', 'Neural Networks (Computer)', 'Retrospective Studies', 'Risk Assessment/methods', 'Stroke/*physiopathology', 'Ultrasonography/methods']	2019/05/10 06:00		['CNN', 'Carotid', 'Deep learning', 'Lumen diameter', 'Performance', 'Stroke', 'Ultrasound']	['NOTNLM']	NLM	543-564	['2018/02/17 00:00 [received]', '2018/09/06 00:00 [accepted]', '2018/09/27 06:00 [pubmed]', '2019/05/10 06:00 [medline]', '2018/09/27 06:00 [entrez]']	United States			30255236	ppublish	['Journal Article']			IM		Med Biol Eng Comput. 2019 Feb;57(2):543-564. doi: 10.1007/s11517-018-1897-x. Epub 2018 Sep 26.	MEDLINE	Med Biol Eng Comput	Deep learning fully convolution network for lumen characterization in diabetic patients using carotid ultrasound: a tool for stroke risk.		57	Deep learning fully convolution network for lumen characterization in diabetic patients using carotid ultrasound: a tool for stroke risk.
Parkinson's disease (PD) is a neurodegenerative disease of the central nervous system caused due to the loss of dopaminergic neurons. It is classified under movement disorder as patients with PD present with tremor, rigidity, postural changes, and a decrease in spontaneous movements. Comorbidities including anxiety, depression, fatigue, and sleep disorders are observed prior to the diagnosis of PD. Gene mutations, exposure to toxic substances, and aging are considered as the causative factors of PD even though its genesis is unknown. This paper reviews PD etiologies, progression, and in particular measurable indicators of PD such as neuroimaging and electrophysiology modalities. In addition to gene therapy, neuroprotective, pharmacological, and neural transplantation treatments, researchers are actively aiming at identifying biological markers of PD with the goal of early diagnosis. Neuroimaging modalities used together with advanced machine learning techniques offer a promising path for the early detection and intervention in PD patients.	"['Department of Biomedical Engineering, Manipal Institute of Technology, Manipal, 576104, India.', ""Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 599489, Singapore; Department of Biomedical Engineering, School of Science and Technology, SUSS University, 599491, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, Subang Jaya, Malaysia. Electronic address: aru@np.edu.sg."", 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 599489, Singapore.', 'Board-certified Neurologist, Columbus, OH, United States.', 'Departments of Biomedical Informatics, Neurology, and Neuroscience, The Ohio State University, United States.']"	['S0010-4825(18)30270-1 [pii]', '10.1016/j.compbiomed.2018.09.008 [doi]']	['Bhat S', 'Acharya UR', 'Hagiwara Y', 'Dadmehr N', 'Adeli H']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/09/27 06:00']	20191028	20180920	2018 Nov 1	2018/09/27 06:00		['Bhat, Shreya', 'Acharya, U Rajendra', 'Hagiwara, Yuki', 'Dadmehr, Nahid', 'Adeli, Hojjat']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30270-1 [pii] 10.1016/j.compbiomed.2018.09.008 [doi]	20191028	['Brain/diagnostic imaging', 'Comorbidity', 'Deep Learning', 'Disease Progression', 'Dopaminergic Neurons/physiology', 'Early Diagnosis', 'Electrophysiological Phenomena', 'Humans', 'Machine Learning', 'Movement Disorders/physiopathology', 'Mutation', 'Neuroimaging', 'Parkinson Disease/*diagnosis/*etiology/*therapy', 'Sleep Wake Disorders/physiopathology']	2019/10/29 06:00		"['*GBA', '*Genes', '*LRRK2', '*Neuroimaging', '*PINK1', ""*Parkinson's disease"", '*Substantia nigra']"	['NOTNLM']	NLM	234-241	['2018/07/24 00:00 [received]', '2018/09/12 00:00 [revised]', '2018/09/12 00:00 [accepted]', '2018/09/27 06:00 [pubmed]', '2019/10/29 06:00 [medline]', '2018/09/27 06:00 [entrez]']	United States			30253869	ppublish	['Journal Article', 'Review']			IM		Comput Biol Med. 2018 Nov 1;102:234-241. doi: 10.1016/j.compbiomed.2018.09.008. Epub 2018 Sep 20.	MEDLINE	Comput Biol Med	Parkinson's disease: Cause factors, measurable indicators, and early diagnosis.		102	Parkinson's disease: Cause factors, measurable indicators, and early diagnosis.
BACKGROUND: Due to the occult anatomic location of the nasopharynx and frequent presence of adenoid hyperplasia, the positive rate for malignancy identification during biopsy is low, thus leading to delayed or missed diagnosis for nasopharyngeal malignancies upon initial attempt. Here, we aimed to develop an artificial intelligence tool to detect nasopharyngeal malignancies under endoscopic examination based on deep learning. METHODS: An endoscopic images-based nasopharyngeal malignancy detection model (eNPM-DM) consisting of a fully convolutional network based on the inception architecture was developed and fine-tuned using separate training and validation sets for both classification and segmentation. Briefly, a total of 28,966 qualified images were collected. Among these images, 27,536 biopsy-proven images from 7951 individuals obtained from January 1st, 2008, to December 31st, 2016, were split into the training, validation and test sets at a ratio of 7:1:2 using simple randomization. Additionally, 1430 images obtained from January 1st, 2017, to March 31st, 2017, were used as a prospective test set to compare the performance of the established model against oncologist evaluation. The dice similarity coefficient (DSC) was used to evaluate the efficiency of eNPM-DM in automatic segmentation of malignant area from the background of nasopharyngeal endoscopic images, by comparing automatic segmentation with manual segmentation performed by the experts. RESULTS: All images were histopathologically confirmed, and included 5713 (19.7%) normal control, 19,107 (66.0%) nasopharyngeal carcinoma (NPC), 335 (1.2%) NPC and 3811 (13.2%) benign diseases. The eNPM-DM attained an overall accuracy of 88.7% (95% confidence interval (CI) 87.8%-89.5%) in detecting malignancies in the test set. In the prospective comparison phase, eNPM-DM outperformed the experts: the overall accuracy was 88.0% (95% CI 86.1%-89.6%) vs. 80.5% (95% CI 77.0%-84.0%). The eNPM-DM required less time (40 s vs. 110.0 +/- 5.8 min) and exhibited encouraging performance in automatic segmentation of nasopharyngeal malignant area from the background, with an average DSC of 0.78 +/- 0.24 and 0.75 +/- 0.26 in the test and prospective test sets, respectively. CONCLUSIONS: The eNPM-DM outperformed oncologist evaluation in diagnostic classification of nasopharyngeal mass into benign versus malignant, and realized automatic segmentation of malignant area from the background of nasopharyngeal endoscopic images.	['State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Information, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'Precision Medicine Center, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Information, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Radiology, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Information, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Information, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China.', 'Department of Radiotherapy, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China. guoxiang@sysucc.org.cn.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China. guoxiang@sysucc.org.cn.', 'Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, 510060, P. R. China. guoxiang@sysucc.org.cn.', 'State Key Laboratory of Oncology in South China, Collaborative Innovation Center of Cancer Medicine, Guangzhou, 510060, P. R. China. lvxing@sysucc.org.cn.', 'Department of Nasopharyngeal Carcinoma, Sun Yat-Sen University Cancer Center, Guangzhou, 510060, P. R. China. lvxing@sysucc.org.cn.', 'Guangdong Key Laboratory of Nasopharyngeal Carcinoma Diagnosis and Therapy, Guangzhou, 510060, P. R. China. lvxing@sysucc.org.cn.']	['10.1186/s40880-018-0325-9 [doi]', '10.1186/s40880-018-0325-9 [pii]']	['Li C', 'Jing B', 'Ke L', 'Li B', 'Xia W', 'He C', 'Qian C', 'Zhao C', 'Mai H', 'Chen M', 'Cao K', 'Mo H', 'Guo L', 'Chen Q', 'Tang L', 'Qiu W', 'Yu Y', 'Liang H', 'Huang X', 'Liu G', 'Li W', 'Wang L', 'Sun R', 'Zou X', 'Guo S', 'Huang P', 'Luo D', 'Qiu F', 'Wu Y', 'Hua Y', 'Liu K', 'Lv S', 'Miao J', 'Xiang Y', 'Sun Y', 'Guo X', 'Lv X']							['2018/09/27 06:00']	20190305	20180925	2018 Sep 25	2018/09/27 06:00		['Li, Chaofeng', 'Jing, Bingzhong', 'Ke, Liangru', 'Li, Bin', 'Xia, Weixiong', 'He, Caisheng', 'Qian, Chaonan', 'Zhao, Chong', 'Mai, Haiqiang', 'Chen, Mingyuan', 'Cao, Kajia', 'Mo, Haoyuan', 'Guo, Ling', 'Chen, Qiuyan', 'Tang, Linquan', 'Qiu, Wenze', 'Yu, Yahui', 'Liang, Hu', 'Huang, Xinjun', 'Liu, Guoying', 'Li, Wangzhong', 'Wang, Lin', 'Sun, Rui', 'Zou, Xiong', 'Guo, Shanshan', 'Huang, Peiyu', 'Luo, Donghua', 'Qiu, Fang', 'Wu, Yishan', 'Hua, Yijun', 'Liu, Kuiyuan', 'Lv, Shuhui', 'Miao, Jingjing', 'Xiang, Yanqun', 'Sun, Ying', 'Guo, Xiang', 'Lv, Xing']		['8170110801/National Natural Science Foundation of China/International', '81572665/National Natural Science Foundation of China/International', '81672680/National Natural Science Foundation of China/International', '81472525/National Natural Science Foundation of China/International', '2016A050502011/the International Cooperation Project of Science and Technology', 'Plan of Guangdong Province/International']	1		2523-3548 (Electronic) 2523-3548 (Linking)	101723675	Cancer communications (London, England)	['eng']	10.1186/s40880-018-0325-9 [doi]	20190305	['Deep Learning/*trends', 'Endoscopy/*methods', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'Middle Aged', 'Nasopharyngeal Neoplasms/*diagnostic imaging/pathology']	2019/03/06 06:00		['*Automatic segmentation', '*Deep learning', '*Differential diagnosis', '*Nasopharyngeal malignancy']	['NOTNLM']	NLM	59	['2018/01/28 00:00 [received]', '2018/09/04 00:00 [accepted]', '2018/09/27 06:00 [entrez]', '2018/09/27 06:00 [pubmed]', '2019/03/06 06:00 [medline]']	England	PMC6156962		30253801	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Cancer Commun (Lond). 2018 Sep 25;38(1):59. doi: 10.1186/s40880-018-0325-9.	MEDLINE	Cancer Commun (Lond)	Development and validation of an endoscopic images-based deep learning model for detection with nasopharyngeal malignancies.		38	Development and validation of an endoscopic images-based deep learning model for detection with nasopharyngeal malignancies.
Purpose To develop and validate a deep learning-based automatic detection algorithm (DLAD) for malignant pulmonary nodules on chest radiographs and to compare its performance with physicians including thoracic radiologists. Materials and Methods For this retrospective study, DLAD was developed by using 43 292 chest radiographs (normal radiograph-to-nodule radiograph ratio, 34 067:9225) in 34 676 patients (healthy-to-nodule ratio, 30 784:3892; 19 230 men [mean age, 52.8 years; age range, 18-99 years]; 15 446 women [mean age, 52.3 years; age range, 18-98 years]) obtained between 2010 and 2015, which were labeled and partially annotated by 13 board-certified radiologists, in a convolutional neural network. Radiograph classification and nodule detection performances of DLAD were validated by using one internal and four external data sets from three South Korean hospitals and one U.S. hospital. For internal and external validation, radiograph classification and nodule detection performances of DLAD were evaluated by using the area under the receiver operating characteristic curve (AUROC) and jackknife alternative free-response receiver-operating characteristic (JAFROC) figure of merit (FOM), respectively. An observer performance test involving 18 physicians, including nine board-certified radiologists, was conducted by using one of the four external validation data sets. Performances of DLAD, physicians, and physicians assisted with DLAD were evaluated and compared. Results According to one internal and four external validation data sets, radiograph classification and nodule detection performances of DLAD were a range of 0.92-0.99 (AUROC) and 0.831-0.924 (JAFROC FOM), respectively. DLAD showed a higher AUROC and JAFROC FOM at the observer performance test than 17 of 18 and 15 of 18 physicians, respectively (P < .05), and all physicians showed improved nodule detection performances with DLAD (mean JAFROC FOM improvement, 0.043; range, 0.006-0.190; P < .05). Conclusion This deep learning-based automatic detection algorithm outperformed physicians in radiograph classification and nodule detection performance for malignant pulmonary nodules on chest radiographs, and it enhanced physicians' performances when used as a second reader. (c) RSNA, 2018 Online supplemental material is available for this article.	['From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).', 'From the Department of Radiology and Institute of Radiation Medicine, Seoul National University Hospital and College of Medicine, 101 Daehak-ro, Jongno-gu, Seoul 03080, Republic of Korea (J.G.N., E.J.H., J.M.G., C.M.P.); Lunit Incorporated, Seoul, Republic of Korea (S.P.); Department of Radiology, Armed Forces Seoul Hospital, Seoul, Republic of Korea (J.H.L.); Department of Radiology, Seoul National University Boramae Medical Center, Seoul, Republic of Korea (K.N.J.); Department of Radiology, National Cancer Center, Goyang, Republic of Korea (K.Y.L.); Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, Calif (T.H.V., J.H.S.); and Department of Industrial & Information Systems Engineering, Seoul National University of Science and Technology, Seoul, Republic of Korea (S.H.).']	['10.1148/radiol.2018180237 [doi]']	['Nam JG', 'Park S', 'Hwang EJ', 'Lee JH', 'Jin KN', 'Lim KY', 'Vu TH', 'Sohn JH', 'Hwang S', 'Goo JM', 'Park CM']	['ORCID: 0000-0003-3991-4523', 'ORCID: 0000-0002-6733-7551', 'ORCID: 0000-0003-1791-7942']		['Radiology. 2019 Jan;290(1):272-273. PMID: 30511912']				['2018/09/26 06:00']	20191011	20180925	2019 Jan	2018/09/27 06:00		['Nam, Ju Gang', 'Park, Sunggyun', 'Hwang, Eui Jin', 'Lee, Jong Hyuk', 'Jin, Kwang-Nam', 'Lim, Kun Young', 'Vu, Thienkai Huy', 'Sohn, Jae Ho', 'Hwang, Sangheum', 'Goo, Jin Mo', 'Park, Chang Min']			1		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2018180237 [doi]	20191011	['Adolescent', 'Adult', 'Aged', 'Aged, 80 and over', 'Algorithms', '*Deep Learning', 'Female', 'Humans', 'Lung Neoplasms/*diagnostic imaging', 'Male', 'Middle Aged', 'Multiple Pulmonary Nodules/*diagnostic imaging', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Radiography, Thoracic/*methods', 'Reproducibility of Results', 'Retrospective Studies', 'Young Adult']	2019/10/12 06:00				NLM	218-228	['2018/09/27 06:00 [pubmed]', '2019/10/12 06:00 [medline]', '2018/09/26 06:00 [entrez]']	United States			30251934	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			AIM IM		Radiology. 2019 Jan;290(1):218-228. doi: 10.1148/radiol.2018180237. Epub 2018 Sep 25.	MEDLINE	Radiology	Development and Validation of Deep Learning-based Automatic Detection Algorithm for Malignant Pulmonary Nodules on Chest Radiographs.		290	Development and Validation of Deep Learning-based Automatic Detection Algorithm for Malignant Pulmonary Nodules on Chest Radiographs.
Artificial intelligence (AI) is a branch of computer science that deals with the development of algorithms that seek to simulate human intelligence. We provide an overview of the basic principles in AI that are essential to the understanding of AI and its application in health care. We also present a descriptive analysis of the current state of AI in various fields of medicine, especially ophthalmology. Finally, we review the potential limitations and challenges that come along with the development and implementation of this new technology that will likely play a major role in clinical medicine in the near future.	['Columbia University Medical Center, Harkness Eye Institute, New York, New York, USA.', 'Columbia University Medical Center, Harkness Eye Institute, New York, New York, USA.', 'Columbia University Medical Center, Harkness Eye Institute, New York, New York, USA. Electronic address: laa2003@cumc.columbia.edu.']	['S0039-6257(18)30088-2 [pii]', '10.1016/j.survophthal.2018.09.002 [doi]']	['Kapoor R', 'Walters SP', 'Al-Aswad LA']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/09/25 06:00']	20190225	20180922	2019 Mar - Apr	2018/09/25 06:00		['Kapoor, Rahul', 'Walters, Stephen P', 'Al-Aswad, Lama A']			2		1879-3304 (Electronic) 0039-6257 (Linking)	0404551	Survey of ophthalmology	['eng']	S0039-6257(18)30088-2 [pii] 10.1016/j.survophthal.2018.09.002 [doi]	20190225	['Artificial Intelligence/*trends', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', 'Ophthalmology/*trends', '*Telemedicine']	2019/02/26 06:00		['*artificial intelligence', '*convolutional neural network', '*deep learning', '*deep reinforcement learning', '*machine learning', '*natural language processing', '*neural network', '*ophthalmology', '*teleophthalmology']	['NOTNLM']	NLM	233-240	['2018/03/21 00:00 [received]', '2018/08/22 00:00 [revised]', '2018/09/07 00:00 [accepted]', '2018/09/25 06:00 [pubmed]', '2019/02/26 06:00 [medline]', '2018/09/25 06:00 [entrez]']	United States			30248307	ppublish	['Journal Article', 'Review']			IM		Surv Ophthalmol. 2019 Mar - Apr;64(2):233-240. doi: 10.1016/j.survophthal.2018.09.002. Epub 2018 Sep 22.	MEDLINE	Surv Ophthalmol	The current state of artificial intelligence in ophthalmology.		64	The current state of artificial intelligence in ophthalmology.
This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing.	"['Department of Computer Engineering, Munzur University, Tunceli, Turkey. Electronic address: oyildirim@munzur.edu.tr.', 'Institute of Telecomputing, Faculty of Physics, Mathematics and Computer Science Cracow University of Technology, Krakow, Poland.', 'Department of Cardiology, National Heart Centre Singapore, Singapore; Duke-NUS Medical School, Singapore.', ""Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore School of Social Sciences, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, 47500 Subang Jaya, Malaysia.""]"	['S0010-4825(18)30271-3 [pii]', '10.1016/j.compbiomed.2018.09.009 [doi]']	['Yildirim O', 'Plawiak P', 'Tan RS', 'Acharya UR']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/09/25 06:00']	20191028	20180915	2018 Nov 1	2018/09/25 06:00		['Yildirim, Ozal', 'Plawiak, Pawel', 'Tan, Ru-San', 'Acharya, U Rajendra']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30271-3 [pii] 10.1016/j.compbiomed.2018.09.009 [doi]	20191028	['Adult', 'Aged', 'Aged, 80 and over', 'Algorithms', 'Arrhythmias, Cardiac/*diagnosis/*therapy', 'Cardiovascular Diseases/diagnosis', 'Cloud Computing', 'Deep Learning', 'Diagnosis, Computer-Assisted/*methods', '*Electrocardiography', 'Electronic Data Processing', 'Female', 'Humans', 'Machine Learning', 'Male', 'Middle Aged', 'Neural Networks (Computer)', '*Pacemaker, Artificial', 'Reproducibility of Results', '*Signal Processing, Computer-Assisted', 'Software', 'Telemedicine', 'Young Adult']	2019/10/29 06:00		['*Convolutional neural networks', '*Deep learning', '*ECG classification', '*cardiac arrhythmias']	['NOTNLM']	NLM	411-420	['2018/08/10 00:00 [received]', '2018/09/11 00:00 [revised]', '2018/09/12 00:00 [accepted]', '2018/09/25 06:00 [pubmed]', '2019/10/29 06:00 [medline]', '2018/09/25 06:00 [entrez]']	United States			30245122	ppublish	['Journal Article']			IM		Comput Biol Med. 2018 Nov 1;102:411-420. doi: 10.1016/j.compbiomed.2018.09.009. Epub 2018 Sep 15.	MEDLINE	Comput Biol Med	Arrhythmia detection using deep convolutional neural network with long duration ECG signals.		102	Arrhythmia detection using deep convolutional neural network with long duration ECG signals.
A novel framework for the classification of lung nodules using computed tomography scans is proposed in this article. To get an accurate diagnosis of the detected lung nodules, the proposed framework integrates the following 2 groups of features: (1) appearance features modeled using the higher order Markov Gibbs random field model that has the ability to describe the spatial inhomogeneities inside the lung nodule and (2) geometric features that describe the shape geometry of the lung nodules. The novelty of this article is to accurately model the appearance of the detected lung nodules using a new developed seventh-order Markov Gibbs random field model that has the ability to model the existing spatial inhomogeneities for both small and large detected lung nodules, in addition to the integration with the extracted geometric features. Finally, a deep autoencoder classifier is fed by the above 2 feature groups to distinguish between the malignant and benign nodules. To evaluate the proposed framework, we used the publicly available data from the Lung Image Database Consortium. We used a total of 727 nodules that were collected from 467 patients. The proposed system demonstrates the promise to be a valuable tool for the detection of lung cancer evidenced by achieving a nodule classification accuracy of 91.20%.	['1 Bioengineering Department, University of Louisville, Louisville, KY, USA.', '2 Computer Engineering and Computer Science Department, University of Louisville, Louisville, KY, USA.', '1 Bioengineering Department, University of Louisville, Louisville, KY, USA.', '3 Department of Electrical and Computer Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates.', '1 Bioengineering Department, University of Louisville, Louisville, KY, USA.', '3 Department of Electrical and Computer Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates.', '4 College of Technological Innovation, Zayed University, Dubai, United Arab Emirates.', '5 Department of Radiation Oncology, University of Louisville, Louisville, KY, USA.', '5 Department of Radiation Oncology, University of Louisville, Louisville, KY, USA.', '6 Department of Cardiovascular and Thoracic Surgery, University of Louisville, Louisville, KY, USA.', '1 Bioengineering Department, University of Louisville, Louisville, KY, USA.', '2 Computer Engineering and Computer Science Department, University of Louisville, Louisville, KY, USA.', '1 Bioengineering Department, University of Louisville, Louisville, KY, USA.']	['10.1177/1533033818798800 [doi]']	['Shaffie A', 'Soliman A', 'Fraiwan L', 'Ghazal M', 'Taher F', 'Dunlap N', 'Wang B', 'van Berkel V', 'Keynton R', 'Elmaghraby A', 'El-Baz A']	['ORCID: 0000-0001-7264-1323']						['2018/09/25 06:00']	20190117		2018 Jan 1	2018/09/25 06:00		['Shaffie, Ahmed', 'Soliman, Ahmed', 'Fraiwan, Luay', 'Ghazal, Mohammed', 'Taher, Fatma', 'Dunlap, Neal', 'Wang, Brian', 'van Berkel, Victor', 'Keynton, Robert', 'Elmaghraby, Adel', 'El-Baz, Ayman']					1533-0338 (Electronic) 1533-0338 (Linking)	101140941	Technology in cancer research & treatment	['eng']	10.1177/1533033818798800 [doi]	20190117	['Aged', 'Aged, 80 and over', 'Algorithms', 'Databases, Factual', 'Deep Learning', 'Diagnosis, Computer-Assisted/methods', '*Early Detection of Cancer', 'Female', 'Humans', 'Imaging, Three-Dimensional', 'Lung/*diagnostic imaging/pathology', 'Lung Neoplasms/*diagnosis/diagnostic imaging/pathology', 'Male', 'Multiple Pulmonary Nodules/*diagnosis/diagnostic imaging', 'Radiographic Image Interpretation, Computer-Assisted', 'Tomography, X-Ray Computed']	2019/01/18 06:00		['*autoencoder', '*computed tomography', '*computer-aided diagnosis', '*higher order MGRF', '*lung cancer', '*pulmonary nodule']	['NOTNLM']	NLM	1533033818798800	['2018/09/25 06:00 [entrez]', '2018/09/25 06:00 [pubmed]', '2019/01/18 06:00 [medline]']	United States	PMC6153532		30244648	ppublish	['Journal Article']			IM		Technol Cancer Res Treat. 2018 Jan 1;17:1533033818798800. doi: 10.1177/1533033818798800.	MEDLINE	Technol Cancer Res Treat	A Generalized Deep Learning-Based Diagnostic System for Early Diagnosis of Various Types of Pulmonary Nodules.		17	A Generalized Deep Learning-Based Diagnostic System for Early Diagnosis of Various Types of Pulmonary Nodules.
Recently, snake-like robots are proposed to assist experts during medical procedures on internal organs via natural orifices. Despite their well-spelt advantages, applications in radiosurgery is still hindered by absence of suitable designs required for spatial navigations within clustered and confined parts of human body, and inexistence of precise and fast inverse kinematics (IK) models. In this study, a deeply-learnt damped least squares method is proposed for solving IK of spatial snake-like robot. The robot's model consists of several modules, and each module has a pair of serial-links connected with orthogonal twists. For precise control of the robot's end-effector, damped least-squares approach is used to minimize error magnitude in a function modeled over analytical Jacobian of the robot. This is iteratively done until an apt joint vector needed to converge the robot to desired positions is obtained. For fast control and singularity avoidance, a deep network is built for prediction of unique damping factor required for each target point in the robot's workspace. The deep network consists of 11 x 15 array of neurons at the hidden layer, and deeply-learnt with a huge dataset of 877,500 data points generated from workspace of the snake robot. Implementation results for both simulated and actual prototype of an eight-link model of the robot show the effectiveness of the proposed IK method. With error tolerance of 0.01 mm, the proposed method has a very high reachability measure of 91.59% and faster mean execution time of 9.20 (+/-16.92) ms for convergence. In addition, the method requires an average of 33.02 (+/-39.60) iterations to solve the IK problem. Hence, approximately 3.6 iterations can be executed in 1 ms. Evaluation against popularly used IK methods shows that the proposed method has very good performance in terms of accuracy and speed, simultaneously.	['Research Centre for Medical Robotics and Minimally Invasive Surgical Devices, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Avenue, Shenzhen 518055, China; Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen 518055, China; CAS Key Laboratory for Health Informatics, Shenzhen Institutes of Advanced Technology, Shenzhen 518055, China. Electronic address: omisore@siat.ac.cn.', 'Research Centre for Medical Robotics and Minimally Invasive Surgical Devices, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Avenue, Shenzhen 518055, China. Electronic address: sp.han@siat.ac.cn.', 'Research Centre for Medical Robotics and Minimally Invasive Surgical Devices, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Avenue, Shenzhen 518055, China. Electronic address: lx.ren@siat.ac.cn.', 'Computer Science Department, Misr Higher Institute for Commerce and Computers, Mansoura City, Egypt; School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen 518060, China. Electronic address: ahmedelazab@szu.edu.cn.', 'Research Centre for Medical Robotics and Minimally Invasive Surgical Devices, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Avenue, Shenzhen 518055, China. Electronic address: hui.li1@siat.ac.cn.', 'Physics and Mathematical Engineering Department, Faculty of Electronic Engineering, Menoufiya University, Menouf 32952, Egypt. Electronic address: talaat@siat.ac.cn.', 'School of Computer Science and Information, North-West University, Vaal Triangle Campus, South Africa; Department of Computer Sciences, University of Lagos, Akoka, Lagos State, Nigeria. Electronic address: 30041708@nwu.ac.za.', 'Research Centre for Medical Robotics and Minimally Invasive Surgical Devices, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Avenue, Shenzhen 518055, China; CAS Key Laboratory for Health Informatics, Shenzhen Institutes of Advanced Technology, Shenzhen 518055, China. Electronic address: wang.lei@siat.ac.cn.']	['S0893-6080(18)30218-1 [pii]', '10.1016/j.neunet.2018.06.018 [doi]']	['Omisore OM', 'Han S', 'Ren L', 'Elazab A', 'Hui L', 'Abdelhamid T', 'Azeez NA', 'Wang L']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/09/23 06:00']	20181211	20180823	2018 Nov	2018/09/23 06:00		['Omisore, Olatunji Mumini', 'Han, Shipeng', 'Ren, Lingxue', 'Elazab, Ahmed', 'Hui, Li', 'Abdelhamid, Talaat', 'Azeez, Nureni Ayofe', 'Wang, Lei']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30218-1 [pii] 10.1016/j.neunet.2018.06.018 [doi]	20181211	['Biomechanical Phenomena', '*Deep Learning', 'Robotics/*methods', 'Stereotaxic Techniques/*instrumentation']	2018/12/12 06:00		['DLS methods', 'Deep neural network', 'Inverse kinematics', 'Jacobian matrix', 'Radiosurgical robots', 'Snake-like robots']	['NOTNLM']	NLM	34-47	['2017/07/15 00:00 [received]', '2018/02/20 00:00 [revised]', '2018/06/28 00:00 [accepted]', '2018/09/23 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2018/09/23 06:00 [entrez]']	United States			30241968	ppublish	['Journal Article']			IM		Neural Netw. 2018 Nov;107:34-47. doi: 10.1016/j.neunet.2018.06.018. Epub 2018 Aug 23.	MEDLINE	Neural Netw	Deeply-learnt damped least-squares (DL-DLS) method for inverse kinematics of snake-like robots.		107	Deeply-learnt damped least-squares (DL-DLS) method for inverse kinematics of snake-like robots.
In online health expert question-answering (HQA) services, it is significant to automatically determine the quality of the answers. There are two prominent challenges in this task. First, the answers are usually written in short text, which makes it difficult to absorb the text semantic information. Second, it usually lacks sufficient labeled data but contains a huge amount of unlabeled data. To tackle these challenges, we propose a novel deep co-training framework based on factorization machines (FM) and deep textual views to intelligently and automatically identify the quality of HQA systems. More specifically, we exploit additional domain-specific semantic information from domain-specific word embeddings to expand the semantic space of short text and apply FM to excavate the non-independent interaction relationships among diverse features within individual views for improving the performance of the base classifier via co-training. Our learned deep textual views, the convolutional neural networks (CNN) view which focuses on extracting local features using convolution filters to locally model short text and the dependency-sensitive convolutional neural networks (DSCNN) view which focuses on capturing long-distance dependency information within the text to globally model short text, can then overcome the challenge of feature sparseness in the short text answers from the doctors. The developed co-training framework can effectively mine the highly non-linear semantic information embedded in the unlabeled data and expose the highly non-linear relationships between different views, which minimizes the labeling effort. Finally, we conduct extensive empirical evaluations and demonstrate that our proposed method can significantly improve the predictive performance of the answer quality in the context of HQA services.	['School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China. Electronic address: huze171@163.com.', 'Department of Computing, Hang Seng Management College, Hong Kong; MTdata, Meitu, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China. Electronic address: zuodc_hit@163.com.']	['S1532-0464(18)30185-0 [pii]', '10.1016/j.jbi.2018.09.011 [doi]']	['Zhang Z', 'Hu Z', 'Yang H', 'Zhu R', 'Zuo D']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/09/22 06:00']	20191119	20180918	2018 Nov	2018/09/22 06:00		['Zhang, Zhan', 'Hu, Ze', 'Yang, Haiqin', 'Zhu, Rong', 'Zuo, Decheng']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30185-0 [pii] 10.1016/j.jbi.2018.09.011 [doi]	20191119	['Algorithms', 'Communication', 'Humans', '*Internet', 'Machine Learning', '*Neural Networks (Computer)', 'Predictive Value of Tests', 'Semantics', '*Software', 'Telemedicine/*methods']	2019/11/20 06:00		['*Answer quality predicting', '*Convolutional neural networks', '*Deep co-training', '*Deep views', '*Factorization machines', '*Online health expert question-answering services']	['NOTNLM']	NLM	21-36	['2018/05/17 00:00 [received]', '2018/08/27 00:00 [revised]', '2018/09/17 00:00 [accepted]', '2018/09/22 06:00 [pubmed]', '2019/11/20 06:00 [medline]', '2018/09/22 06:00 [entrez]']	United States			30240803	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Nov;87:21-36. doi: 10.1016/j.jbi.2018.09.011. Epub 2018 Sep 18.	MEDLINE	J Biomed Inform	Factorization machines and deep views-based co-training for improving answer quality prediction in online health expert question-answering services.		87	Factorization machines and deep views-based co-training for improving answer quality prediction in online health expert question-answering services.
The BioCreative VI Track IV (mining protein interactions and mutations for precision medicine) challenge was organized in 2017 with the goal of applying biomedical text mining methods to support advancements in precision medicine approaches. As part of the challenge, a new dataset was introduced for the purpose of building a supervised relation extraction model capable of taking a test article and returning a list of interacting protein pairs identified by their Entrez Gene IDs. Specifically, such pairs represent proteins participating in a binary protein-protein interaction relation where the interaction is additionally affected by a genetic mutation-referred to as a PPIm relation. In this study, we explore an end-to-end approach for PPIm relation extraction by deploying a three-component pipeline involving deep learning-based named-entity recognition and relation classification models along with a knowledge-based approach for gene normalization. We propose several recall-focused improvements to our original challenge entry that placed second when matching on Entrez Gene ID (exact matching) and on HomoloGene ID. On exact matching, the improved system achieved new competitive test results of 37.78% micro-F1 with a precision of 38.22% and recall of 37.34% that corresponds to an improvement from the prior best system by approximately three micro-F1 points. When matching on HomoloGene IDs, we report similarly competitive test results at 46.17% micro-F1 with a precision and recall of 46.67 and 45.59%, respectively, corresponding to an improvement of more than eight micro-F1 points over the prior best result. The code for our deep learning system is made publicly available at https://github.com/bionlproc/biocppi_extraction.	['Department of Computer Science, University of Kentucky, Lexington, KY, USA.', 'Department of Computer Science, University of Kentucky, Lexington, KY, USA.', 'Division of Biomedical Informatics, Department of Internal Medicine, University of Kentucky, Lexington, KY, USA.']	['5096687 [pii]', '10.1093/database/bay092 [doi]']	['Tran T', 'Kavuluru R']							['2018/09/22 06:00']	20181126	20180101	2018 Jan 1	2018/09/22 06:00		['Tran, Tung', 'Kavuluru, Ramakanth']		['R21 LM012274/LM/NLM NIH HHS/United States']			1758-0463 (Electronic) 1758-0463 (Linking)	101517697	Database : the journal of biological databases and curation	['eng']	10.1093/database/bay092 [doi]	20190109	['Algorithms', 'Databases, Protein', '*Machine Learning', 'Mutation/*genetics', 'Neural Networks (Computer)', 'Protein Interaction Maps/*genetics']	2018/11/27 06:00				NLM	1-13	['2018/02/28 00:00 [received]', '2018/08/13 00:00 [accepted]', '2018/09/22 06:00 [entrez]', '2018/09/22 06:00 [pubmed]', '2018/11/27 06:00 [medline]']	England	PMC6146129		30239680	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Database (Oxford). 2018 Jan 1;2018:1-13. doi: 10.1093/database/bay092.	MEDLINE	Database (Oxford)	An end-to-end deep learning architecture for extracting protein-protein interactions affected by genetic mutations.		2018	An end-to-end deep learning architecture for extracting protein-protein interactions affected by genetic mutations.
PURPOSE: This paper proposes a sinogram-consistency learning method to deal with beam hardening-related artifacts in polychromatic computerized tomography (CT). The presence of highly attenuating materials in the scan field causes an inconsistent sinogram that does not match the range space of the Radon transform. When the mismatched data are entered into the range space during CT reconstruction, streaking and shading artifacts are generated owing to the inherent nature of the inverse Radon transform METHODS: The proposed learning method aims to repair inconsistent sinogram by removing the primary metal-induced beam hardening factors along the metal trace in the sinogram. Taking account of the fundamental difficulty in obtaining sufficient training data in a medical environment, the learning method is designed to use simulated training data and a patient's implant type-specific learning model is used to simplify the learning process. RESULTS: The feasibility of the proposed method is investigated using a dataset, consisting of real CT scans of pelvises containing simulated hip prostheses. The anatomical areas in training and test data are different, in order to demonstrate that the proposed method extracts the beam hardening features, selectively. The results show that our method successfully corrects sinogram inconsistency by extracting beam hardening sources by means of deep learning. CONCLUSION: This paper proposed a deep learning method of sinogram correction for beam hardening reduction in CT for the first time. Conventional methods for beam hardening reduction are based on regularizations, and have the fundamental drawback of being not easily able to use manifold CT images, while a deep learning approach has the potential to do so.	['Division of Integrated Mathematics, National Institute for Mathematical Sciences, Daejeon, 34047, Korea.', 'Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, Korea.', 'Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, Korea.', 'Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, Korea.', 'Department of Radiology, Yonsei University College of Medicine, Seoul, 03722, Korea.']	['10.1002/mp.13199 [doi]']	['Park HS', 'Lee SM', 'Kim HP', 'Seo JK', 'Chung YE']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/09/22 06:00']	20190107	20181108	2018 Dec	2018/09/22 06:00		['Park, Hyoung Suk', 'Lee, Sung Min', 'Kim, Hwa Pyung', 'Seo, Jin Keun', 'Chung, Yong Eun']			12		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13199 [doi]	20190107	['*Artifacts', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', '*Metals', 'Pelvis/diagnostic imaging', '*Tomography, X-Ray Computed']	2019/01/08 06:00		['computerized tomography', 'deep learning', 'metal artifact reduction', 'tomographic image reconstruction']	['NOTNLM']	NLM	5376-5384	['2017/12/22 00:00 [received]', '2018/09/04 00:00 [revised]', '2018/09/08 00:00 [accepted]', '2018/09/22 06:00 [pubmed]', '2019/01/08 06:00 [medline]', '2018/09/22 06:00 [entrez]']	United States			30238586	ppublish	['Journal Article']		['0 (Metals)']	IM		Med Phys. 2018 Dec;45(12):5376-5384. doi: 10.1002/mp.13199. Epub 2018 Nov 8.	MEDLINE	Med Phys	CT sinogram-consistency learning for metal-induced beam hardening correction.		45	CT sinogram-consistency learning for metal-induced beam hardening correction.
Faster Region-based Convolutional Network (Faster R-CNN) is a state-of-the-art object detection method. However, the object detection effect of Faster R-CNN is not good based on the Region Proposal Network (RPN). Inspired by RPN of Faster R-CNN, we propose a novel proposal generation method called Enhanced Region Proposal Network (ERPN). Four improvements are presented in ERPN. Firstly, our proposed deconvolutional feature pyramid network (DFPN) is introduced to improve the quality of region proposals. Secondly, novel anchor boxes are designed with interspersed scales and adaptive aspect ratios. Thereafter, the capability of object localization is increased. Thirdly, a particle swarm optimization (PSO) based support vector machine (SVM), termed PSO-SVM, is developed to distinguish the positive and negative anchor boxes. Fourthly, the classification part of multi-task loss function in RPN is improved. Consequently, the effect of classification loss is strengthened. In this study, our proposed ERPN is compared with five object detection methods on both PASCAL VOC and COCO data sets. For the VGG-16 model, our ERPN obtains 78.6% mAP on VOC 2007 data set, 74.4% mAP on VOC 2012 data set and 31.7% on COCO data set. The performance of ERPN is the best among the comparison object detection methods. Furthermore, the detection speed of ERPN is 5.8 fps. Additionally, ERPN obtains good effect on small object detection.	"[""College of Computer Science and Technology, Jilin University, Changchun, People's Republic of China."", ""Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, People's Republic of China."", ""College of Computer Science and Technology, Jilin University, Changchun, People's Republic of China."", ""Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, People's Republic of China."", ""College of Computer Science and Technology, Jilin University, Changchun, People's Republic of China."", ""Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, People's Republic of China.""]"	['10.1371/journal.pone.0203897 [doi]', 'PONE-D-18-16729 [pii]']	['Chen YP', 'Li Y', 'Wang G']	['ORCID: 0000-0001-9696-3546']				['The authors have declared that no competing interests exist.']		['2018/09/21 06:00']	20190305	20180920	2018	2018/09/21 06:00		['Chen, Yu Peng', 'Li, Ying', 'Wang, Gang']			9		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0203897 [doi]	20190305	['Algorithms', '*Deep Learning', '*Neural Networks (Computer)', '*Support Vector Machine']	2019/03/06 06:00				NLM	e0203897	['2018/06/04 00:00 [received]', '2018/08/29 00:00 [accepted]', '2018/09/21 06:00 [entrez]', '2018/09/21 06:00 [pubmed]', '2019/03/06 06:00 [medline]']	United States	PMC6147513		30235238	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Sep 20;13(9):e0203897. doi: 10.1371/journal.pone.0203897. eCollection 2018.	MEDLINE	PLoS One	An Enhanced Region Proposal Network for object detection using deep learning method.		13	An Enhanced Region Proposal Network for object detection using deep learning method.
BACKGROUND: Fundus fluorescein angiography (FFA) imaging is a standard diagnostic tool for many retinal diseases such as age-related macular degeneration and diabetic retinopathy. High-resolution FFA images facilitate the detection of small lesions such as microaneurysms, and other landmark changes, in the early stages; this can help an ophthalmologist improve a patient's cure rate. However, only low-resolution images are available in most clinical cases. Super-resolution (SR), which is a method to improve the resolution of an image, has been successfully employed for natural and remote sensing images. To the best of our knowledge, no one has applied SR techniques to FFA imaging so far. METHODS: In this work, we propose a SR method-based pipeline for FFA imaging. The aim of this pipeline is to enhance the image quality of FFA by using SR techniques. Several SR frameworks including neighborhood embedding, sparsity-based, locally-linear regression and deep learning-based approaches are investigated. Based on a clinical FFA dataset collected from Second Affiliated Hospital to Xuzhou Medical University, each SR method is implemented and evaluated for the pipeline to improve the resolution of FFA images. RESULTS AND CONCLUSION: As shown in our results, most SR algorithms have a positive impact on the enhancement of FFA images. Super-resolution forests (SRF), a random forest-based SR method has displayed remarkable high effectiveness and outperformed other methods. Hence, SRF should be one potential way to benefit ophthalmologists by obtaining high-resolution FFA images in a clinical setting.	['Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China.', 'Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China.', 'Hospital Affiliated to Xuzhou Medical University, Xuzhou, 221006, China.', 'Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China.', 'School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, 100044, China.', 'Hospital Affiliated to Xuzhou Medical University, Xuzhou, 221006, China. guojianxin_724@126.com.', 'Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China.', 'Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, 91058, Erlangen, Germany. yanye.lu@pku.edu.cn.']	['10.1186/s12938-018-0556-7 [doi]', '10.1186/s12938-018-0556-7 [pii]']	['Jiang Z', 'Yu Z', 'Feng S', 'Huang Z', 'Peng Y', 'Guo J', 'Ren Q', 'Lu Y']	['ORCID: http://orcid.org/0000-0002-3063-8051']						['2018/09/21 06:00']	20181231	20180919	2018 Sep 19	2018/09/21 06:00		['Jiang, Zhe', 'Yu, Zekuan', 'Feng, Shouxin', 'Huang, Zhiyu', 'Peng, Yahui', 'Guo, Jianxin', 'Ren, Qiushi', 'Lu, Yanye']		['2017YFE0104200/The National Key Research and Development Program of China', '81421004/The National Natural Science Foundation of China', '2013YQ030651/The National Key Instrumentation Development Project of China']	1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-018-0556-7 [doi]	20181231	['Deep Learning', 'Eye/*diagnostic imaging', 'Fluorescein Angiography/*methods', '*Fundus Oculi', 'Humans', 'Image Processing, Computer-Assisted', 'Linear Models']	2019/01/01 06:00		['Convolutional network', 'Fundus fluorescein angiography imaging', 'Machine learning', 'Random forest', 'Super-resolution']	['NOTNLM']	NLM	125	['2018/07/18 00:00 [received]', '2018/09/06 00:00 [accepted]', '2018/09/21 06:00 [entrez]', '2018/09/21 06:00 [pubmed]', '2019/01/01 06:00 [medline]']	England	PMC6146678		30231879	epublish	['Journal Article']			IM		Biomed Eng Online. 2018 Sep 19;17(1):125. doi: 10.1186/s12938-018-0556-7.	MEDLINE	Biomed Eng Online	A super-resolution method-based pipeline for fundus fluorescein angiography imaging.		17	A super-resolution method-based pipeline for fundus fluorescein angiography imaging.
Protein hydroxylation is one type of post-translational modifications (PTMs) playing critical roles in human diseases. It is known that protein sequence contains many uncharacterized residues of proline and lysine. The question that needs to be answered is: which residue can be hydroxylated, and which one cannot. The answer will not only help understand the mechanism of hydroxylation but can also benefit the development of new drugs. In this paper, we proposed a novel approach for predicting hydroxylation using a hybrid deep learning model integrating the convolutional neural network (CNN) and long short-term memory network (LSTM). We employed a pseudo amino acid composition (PseAAC) method to construct valid benchmark datasets based on a sliding window strategy and used the position-specific scoring matrix (PSSM) to represent samples as inputs to the deep learning model. In addition, we compared our method with popular predictors including CNN, iHyd-PseAAC, and iHyd-PseCp. The results for 5-fold cross-validations all demonstrated that our method significantly outperforms the other methods in prediction accuracy.	['Department of Information Science and Technology, Hainan Normal University, Haikou 571158, China. myresearch_hainnu@163.com.', 'Department of Mathematics and Statistics, Hainan Normal University, Haikou 571158, China. dragonbw@163.com.', 'College of Life Sciences, Zhejiang Sci-Tech University, Hangzhou 310018, China. xingyuxu821@163.com.', 'Department of Mathematics and Statistics, Hainan Normal University, Haikou 571158, China. jialiang.yang@mssm.edu.', 'Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai, New York, NY 10029, USA. jialiang.yang@mssm.edu.']	['ijms19092817 [pii]', '10.3390/ijms19092817 [doi]']	['Long H', 'Liao B', 'Xu X', 'Yang J']	['ORCID: 0000-0003-2202-3820', 'ORCID: 0000-0003-4689-8672']						['2018/09/21 06:00']	20190121	20180918	2018 Sep 18	2018/09/21 06:00		['Long, Haixia', 'Liao, Bo', 'Xu, Xingyu', 'Yang, Jialiang']		['61762034/National Natural Science Foundation of China', '618MS057/Hainan Provincial Natural Science Foundation of China', 'ZDKJ2017012/Hainan Provincial major scientific and technological plans']	9		1422-0067 (Electronic) 1422-0067 (Linking)	101092791	International journal of molecular sciences	['eng']	E2817 [pii] 10.3390/ijms19092817 [doi]	20190121	['*Deep Learning', 'Humans', 'Hydroxylation', 'Hydroxylysine/*chemistry/metabolism', 'Hydroxyproline/*chemistry/metabolism', 'Models, Biological', 'Neural Networks (Computer)', 'Protein Processing, Post-Translational', 'Proteins/*chemistry/metabolism']	2019/01/22 06:00		['convolutional neural network (CNN)', 'hydroxylation sites', 'iHyd-PseAAC', 'iHyd-PseCp', 'long short-term memory network (LSTM)', 'protein post-translational modification (PTM)']	['NOTNLM']	NLM		['2018/08/19 00:00 [received]', '2018/09/12 00:00 [revised]', '2018/09/15 00:00 [accepted]', '2018/09/21 06:00 [entrez]', '2018/09/21 06:00 [pubmed]', '2019/01/22 06:00 [medline]']	Switzerland	PMC6164125		30231550	epublish	['Journal Article']		['0 (Proteins)', '2GQB349IUB (Hydroxylysine)', 'RMB44WO89X (Hydroxyproline)']	IM		Int J Mol Sci. 2018 Sep 18;19(9). pii: ijms19092817. doi: 10.3390/ijms19092817.	MEDLINE	Int J Mol Sci	A Hybrid Deep Learning Model for Predicting Protein Hydroxylation Sites.		19	A Hybrid Deep Learning Model for Predicting Protein Hydroxylation Sites.
In this study, a multi-stage optimization procedure is proposed to develop deep neural network models which results in a powerful deep learning pipeline called intelligent deep learning (iDeepLe). The proposed pipeline is then evaluated by a challenging real-world problem, the modeling of the spectral acceleration experienced by a particle during earthquakes. This approach has three main stages to optimize the deep model topology, the hyper-parameters, and its performance, respectively. This pipeline optimizes the deep model via adaptive learning rate optimization algorithms for both accuracy and complexity in multiple stages, while simultaneously solving the unknown parameters of the regression model. Among the seven adaptive learning rate optimization algorithms, Nadam optimization algorithm has shown the best performance results in the current study. The proposed approach is shown to be a suitable tool to generate solid models for this complex real-world system. The results also show that the parallel pipeline of iDeepLe has the capacity to handle big data problems as well.	['Department of Scientific Computing, Florida State University, Tallahassee, Florida 32306-4120, United States of America.', 'School of Business, Stevens Institute of Technology, Hoboken, New Jersey 07030, United States of America.', 'Department of Computer Science and Information Science, University of Macau, Taipa, Macau.', 'Department of Scientific Computing, Florida State University, Tallahassee, Florida 32306-4120, United States of America.', 'Department of Electrical and Computer Engineering, FAMU-FSU College of Engineering, Tallahassee, Florida 32310-6046, United States of America.']	['10.1371/journal.pone.0203829 [doi]', 'PONE-D-18-08965 [pii]']	['Tahmassebi A', 'Gandomi AH', 'Fong S', 'Meyer-Baese A', 'Foo SY']	['ORCID: 0000-0003-4677-6907', 'ORCID: 0000-0002-2798-0104']				['The authors have declared that no competing interests exist.']		['2018/09/20 06:00']	20190322	20180919	2018	2018/09/20 06:00		['Tahmassebi, Amirhessam', 'Gandomi, Amir H', 'Fong, Simon', 'Meyer-Baese, Anke', 'Foo, Simon Y']			9		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0203829 [doi]	20190322	['Algorithms', 'Computer Simulation', 'Data Analysis', 'Deep Learning', 'Machine Learning', 'Motion', '*Neural Networks (Computer)']	2019/03/23 06:00				NLM	e0203829	['2018/03/24 00:00 [received]', '2018/08/28 00:00 [accepted]', '2018/09/20 06:00 [entrez]', '2018/09/20 06:00 [pubmed]', '2019/03/23 06:00 [medline]']	United States	PMC6145533		30231077	epublish	['Journal Article']			IM	['figshare/10.6084/m9.figshare.7037609.v1']	PLoS One. 2018 Sep 19;13(9):e0203829. doi: 10.1371/journal.pone.0203829. eCollection 2018.	MEDLINE	PLoS One	Multi-stage optimization of a deep model: A case study on ground motion modeling.		13	Multi-stage optimization of a deep model: A case study on ground motion modeling.
Several computer aided diagnosis (CAD) systems have been developed for mammography. They are widely used in certain countries such as the U.S. where mammography studies are conducted more frequently; however, they are not yet globally employed for clinical use due to their inconsistent performance, which can be attributed to their reliance on hand-crafted features. It is difficult to use hand-crafted features for mammogram images that vary due to factors such as the breast density of patients and differences in imaging devices. To address these problems, several studies have leveraged a deep convolutional neural network that does not require hand-crafted features. Among the recent object detectors, RetinaNet is particularly promising as it is a simpler one-stage object detector that is fast and efficient while achieving state-of-the-art performance. RetinaNet has been proven to perform conventional object detection tasks but has not been tested on detecting masses in mammograms. Thus, we propose a mass detection model based on RetinaNet. To validate its performance in diverse use cases, we construct several experimental setups using the public dataset INbreast and the in-house dataset GURO. In addition to training and testing on the same dataset (i.e., training and testing on INbreast), we evaluate our mass detection model in setups using additional training data (i.e., training on INbreast + GURO and testing on INbreast). We also evaluate our model in setups using pre-trained weights (i.e., using weights pre-trained on GURO, training and testing on INbreast). In all the experiments, our mass detection model achieves comparable or better performance than more complex state-of-the-art models including the two-stage object detector. Also, the results show that using the weights pre-trained on datasets achieves similar performance as directly using datasets in the training phase. Therefore, we make our mass detection model's weights pre-trained on both GURO and INbreast publicly available. We expect that researchers who train RetinaNet on their in-house dataset for the mass detection task can use our pre-trained weights to leverage the features extracted from the datasets.	['Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Department of Radiology, Kangbuk Samsung Medical Center, Seoul, Republic of Korea.', 'Department of Radiology, Korea University Guro Hospital, Seoul, Republic of Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, Republic of Korea.']	['10.1371/journal.pone.0203355 [doi]', 'PONE-D-18-09938 [pii]']	['Jung H', 'Kim B', 'Lee I', 'Yoo M', 'Lee J', 'Ham S', 'Woo O', 'Kang J']	['ORCID: 0000-0001-5886-7836', 'ORCID: 0000-0002-5333-9839']				['The authors have declared that no competing interests exist.']		['2018/09/19 06:00']	20190226	20180918	2018	2018/09/19 06:00		['Jung, Hwejin', 'Kim, Bumsoo', 'Lee, Inyeop', 'Yoo, Minhwan', 'Lee, Junhyun', 'Ham, Sooyoun', 'Woo, Okhee', 'Kang, Jaewoo']			9		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0203355 [doi]	20190226	['Breast Neoplasms/*diagnostic imaging', 'Databases, Factual', 'Decision Support Techniques', 'Deep Learning', 'Diagnosis, Computer-Assisted/*methods/*statistics & numerical data', 'Female', 'Humans', 'Mammography/*methods/*statistics & numerical data', '*Neural Networks (Computer)', 'Radiographic Image Interpretation, Computer-Assisted/methods/statistics & numerical data']	2019/02/27 06:00				NLM	e0203355	['2018/04/14 00:00 [received]', '2018/08/20 00:00 [accepted]', '2018/09/19 06:00 [entrez]', '2018/09/19 06:00 [pubmed]', '2019/02/27 06:00 [medline]']	United States	PMC6143189		30226841	epublish	"['Evaluation Studies', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Sep 18;13(9):e0203355. doi: 10.1371/journal.pone.0203355. eCollection 2018.	MEDLINE	PLoS One	Detection of masses in mammograms using a one-stage object detector based on a deep convolutional neural network.		13	Detection of masses in mammograms using a one-stage object detector based on a deep convolutional neural network.
Visual inspection of histopathology slides is one of the main methods used by pathologists to assess the stage, type and subtype of lung tumors. Adenocarcinoma (LUAD) and squamous cell carcinoma (LUSC) are the most prevalent subtypes of lung cancer, and their distinction requires visual inspection by an experienced pathologist. In this study, we trained a deep convolutional neural network (inception v3) on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue. The performance of our method is comparable to that of pathologists, with an average area under the curve (AUC) of 0.97. Our model was validated on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues and biopsies. Furthermore, we trained the network to predict the ten most commonly mutated genes in LUAD. We found that six of them-STK11, EGFR, FAT1, SETBP1, KRAS and TP53-can be predicted from pathology images, with AUCs from 0.733 to 0.856 as measured on a held-out population. These findings suggest that deep-learning models can assist pathologists in the detection of cancer subtype or gene mutations. Our approach can be applied to any cancer type, and the code is available at https://github.com/ncoudray/DeepPATH .	['Applied Bioinformatics Laboratories, New York University School of Medicine, New York, NY, USA.', 'Skirball Institute, Department of Cell Biology, New York University School of Medicine, New York, NY, USA.', 'Department of Pathology, New York University School of Medicine, New York, NY, USA.', 'School of Mechanical Engineering, National Technical University of Athens, Zografou, Greece.', 'Department of Pathology, New York University School of Medicine, New York, NY, USA.', 'Department of Pathology, New York University School of Medicine, New York, NY, USA.', 'Institute for Systems Genetics, New York University School of Medicine, New York, NY, USA.', 'Department of Biochemistry and Molecular Pharmacology, New York University School of Medicine, New York, NY, USA.', 'Department of Pathology, New York University School of Medicine, New York, NY, USA.', 'Center for Biospecimen Research and Development, New York University, New York, NY, USA.', 'Department of Population Health and the Center for Healthcare Innovation and Delivery Science, New York University School of Medicine, New York, NY, USA. narges.razavian@nyumc.org.', 'Applied Bioinformatics Laboratories, New York University School of Medicine, New York, NY, USA. aristotelis.tsirigos@nyumc.org.', 'Department of Pathology, New York University School of Medicine, New York, NY, USA. aristotelis.tsirigos@nyumc.org.']	['10.1038/s41591-018-0177-5 [doi]', '10.1038/s41591-018-0177-5 [pii]']	['Coudray N', 'Ocampo PS', 'Sakellaropoulos T', 'Narula N', 'Snuderl M', 'Fenyo D', 'Moreira AL', 'Razavian N', 'Tsirigos A']	['ORCID: http://orcid.org/0000-0002-6050-2219', 'ORCID: http://orcid.org/0000-0002-9922-6370', 'ORCID: http://orcid.org/0000-0002-7512-8477']		['Nat Rev Clin Oncol. 2018 Dec;15(12):724. PMID: 30266916', 'J Thorac Dis. 2019 Feb;11(2):369-372. PMID: 30962976']				['2018/09/19 06:00']	20190510	20180917	2018 Oct	2018/09/19 06:00		['Coudray, Nicolas', 'Ocampo, Paolo Santiago', 'Sakellaropoulos, Theodore', 'Narula, Navneet', 'Snuderl, Matija', 'Fenyo, David', 'Moreira, Andre L', 'Razavian, Narges', 'Tsirigos, Aristotelis']			10		1546-170X (Electronic) 1078-8956 (Linking)	9502015	Nature medicine	['eng']	10.1038/s41591-018-0177-5 [doi]	20190716	['Adenocarcinoma/classification/diagnosis/*genetics/pathology', 'Carcinoma, Non-Small-Cell Lung/classification/diagnosis/*genetics/pathology', 'Carcinoma, Squamous Cell/classification/diagnosis/*genetics/pathology', 'Deep Learning', 'Gene Expression Regulation, Neoplastic', 'Humans', 'Mutation/genetics', 'Neoplasm Proteins/classification/*genetics', 'Neural Networks (Computer)']	2019/05/11 06:00				NLM	1559-1567	['2017/11/22 00:00 [received]', '2018/07/06 00:00 [accepted]', '2018/09/19 06:00 [pubmed]', '2019/05/11 06:00 [medline]', '2018/09/19 06:00 [entrez]']	United States			30224757	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Neoplasm Proteins)']	IM		Nat Med. 2018 Oct;24(10):1559-1567. doi: 10.1038/s41591-018-0177-5. Epub 2018 Sep 17.	MEDLINE	Nat Med	Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning.		24	Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning.
Experimental detection of RNA splicing branchpoints is difficult. To date, high-confidence experimental annotations exist for 18% of 3' splice sites in the human genome. We develop a deep-learning-based branchpoint predictor, LaBranchoR, which predicts a correct branchpoint for at least 75% of 3' splice sites genome-wide. Detailed analysis of cases in which our predicted branchpoint deviates from experimental data suggests a correct branchpoint is predicted in over 90% of cases. We use our predicted branchpoints to identify a novel sequence element upstream of branchpoints consistent with extended U2 snRNA base-pairing, show an association between weak branchpoints and alternative splicing, and explore the effects of genetic variants on branchpoints. We provide genome-wide branchpoint annotations and in silico mutagenesis scores at http://bejerano.stanford.edu/labranchor.	['Department of Computer Science, Stanford University, Stanford, California 94305, USA.', 'Department of Computer Science, Stanford University, Stanford, California 94305, USA.', 'Department of Developmental Biology, Stanford University, Stanford, California 94305, USA.', 'Department of Pediatrics, Stanford University, Stanford, California 94305, USA.', 'Department of Biomedical Data Science, Stanford University, Stanford, California 94305, USA.']	['rna.066290.118 [pii]', '10.1261/rna.066290.118 [doi]']	['Paggi JM', 'Bejerano G']		['(c) 2018 Paggi and Bejerano; Published by Cold Spring Harbor Laboratory Press for', 'the RNA Society.']					['2018/09/19 06:00']	20190107	20180917	2018 Dec	2018/09/19 06:00		['Paggi, Joseph M', 'Bejerano, Gill']		['U01 MH105949/MH/NIMH NIH HHS/United States', 'U01MH105949 /NH/NIH HHS/United States']	12		1469-9001 (Electronic) 1355-8382 (Linking)	9509184	RNA (New York, N.Y.)	['eng']	10.1261/rna.066290.118 [doi]	20191202	['Alternative Splicing/*genetics', 'Computer Simulation', 'Deep Learning', 'Exons/genetics', 'Genome, Human/*genetics', 'Humans', 'Introns/genetics', 'Molecular Sequence Annotation', 'Mutagenesis/genetics', 'RNA Splice Sites/genetics', 'RNA Splicing/*genetics', 'RNA, Small Nuclear/*genetics']	2019/01/08 06:00		['*RNA splicing', '*RNA splicing branchpoints', '*alternative splicing', '*deep learning']	['NOTNLM']	NLM	1647-1658	['2018/03/14 00:00 [received]', '2018/09/10 00:00 [accepted]', '2018/09/19 06:00 [pubmed]', '2019/01/08 06:00 [medline]', '2018/09/19 06:00 [entrez]']	United States	PMC6239175		30224349	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA Splice Sites)', '0 (RNA, Small Nuclear)', '0 (U2 small nuclear RNA)']	IM		RNA. 2018 Dec;24(12):1647-1658. doi: 10.1261/rna.066290.118. Epub 2018 Sep 17.	MEDLINE	RNA	A sequence-based, deep learning model accurately predicts RNA splicing branchpoints.		24	A sequence-based, deep learning model accurately predicts RNA splicing branchpoints.
PURPOSE: In this study, we compared deep learning (DL) with support vector machine (SVM), both of which use three-dimensional optical coherence tomography (3D-OCT) images for detecting epiretinal membrane (ERM). METHODS: In total, 529 3D-OCT images from the Tsukazaki hospital ophthalmology database (184 non-ERM subjects and 205 ERM patients) were assessed; 80% of the images were divided for training, and 20% for test as follows: 423 training (non-ERM 245, ERM 178) and 106 test (non-ERM 59, ERM 47) images. Using the 423 training images, a model was created with deep convolutional neural network and SVM, and the test data were evaluated. RESULTS: The DL model's sensitivity was 97.6% [95% confidence interval (CI), 87.7-99.9%] and specificity was 98.0% (95% CI, 89.7-99.9%), and the area under the curve (AUC) was 0.993 (95% CI, 0.993-0.994). In contrast, the SVM model's sensitivity was 97.6% (95% CI, 87.7-99.9%), specificity was 94.2% (95% CI, 84.0-98.7%), and AUC was 0.988 (95% CI, 0.987-0.988). CONCLUSION: DL model is better than SVM model in detecting ERM by using 3D-OCT images.	['Department of Ophthalmology, Tsukazaki Hospital, 68-1 Waku, Aboshi-ku, Himeji, 671-1227, Japan. t.sonobe@tsukazaki-eye.net.', 'Department of Ophthalmology, Tsukazaki Hospital, 68-1 Waku, Aboshi-ku, Himeji, 671-1227, Japan.', 'Department of Ophthalmology, Tsukazaki Hospital, 68-1 Waku, Aboshi-ku, Himeji, 671-1227, Japan.', 'Department of Ophthalmology, Tsukazaki Hospital, 68-1 Waku, Aboshi-ku, Himeji, 671-1227, Japan.', 'Department of Ophthalmology, Tsukazaki Hospital, 68-1 Waku, Aboshi-ku, Himeji, 671-1227, Japan.', 'Research Group of Intelligent Cybernetics and Computer Science Graduate School of Engineering, University of Hyogo, Himeji, Japan.', 'Rist Inc, Tokyo, Japan.', 'Department of Ophthalmology, Tsukazaki Hospital, 68-1 Waku, Aboshi-ku, Himeji, 671-1227, Japan.']	['10.1007/s10792-018-1016-x [doi]', '10.1007/s10792-018-1016-x [pii]']	['Sonobe T', 'Tabuchi H', 'Ohsugi H', 'Masumoto H', 'Ishitobi N', 'Morita S', 'Enno H', 'Nagasato D']	['ORCID: http://orcid.org/0000-0001-9366-6394']						['2018/09/16 06:00']	20190812	20180914	2019 Aug	2018/09/16 06:00		['Sonobe, Tomoaki', 'Tabuchi, Hitoshi', 'Ohsugi, Hideharu', 'Masumoto, Hiroki', 'Ishitobi, Naohumi', 'Morita, Shoji', 'Enno, Hiroki', 'Nagasato, Daisuke']			8		1573-2630 (Electronic) 0165-5701 (Linking)	7904294	International ophthalmology	['eng']	10.1007/s10792-018-1016-x [doi]	20190812	['Aged', 'Deep Learning', 'Early Diagnosis', 'Epiretinal Membrane/*diagnosis', 'Female', 'Humans', 'Imaging, Three-Dimensional/*methods', '*Machine Learning', 'Male', 'Retina/*diagnostic imaging', '*Support Vector Machine', 'Tomography, Optical Coherence/*methods', '*Visual Acuity']	2019/08/14 06:00		['Deep learning', 'Epiretinal membrane', 'Optical coherence tomography', 'Support vector machine']	['NOTNLM']	NLM	1871-1877	['2018/04/06 00:00 [received]', '2018/09/01 00:00 [accepted]', '2018/09/16 06:00 [pubmed]', '2019/08/14 06:00 [medline]', '2018/09/16 06:00 [entrez]']	Netherlands			30218173	ppublish	['Comparative Study', 'Journal Article']			IM		Int Ophthalmol. 2019 Aug;39(8):1871-1877. doi: 10.1007/s10792-018-1016-x. Epub 2018 Sep 14.	MEDLINE	Int Ophthalmol	Comparison between support vector machine and deep learning, machine-learning technologies for detecting epiretinal membrane using 3D-OCT.		39	Comparison between support vector machine and deep learning, machine-learning technologies for detecting epiretinal membrane using 3D-OCT.
PURPOSE: Magnetic resonance imaging (MRI)-guided radiation therapy (RT) treatment planning is limited by the fact that the electron density distribution required for dose calculation is not readily provided by MR imaging. We compare a selection of novel synthetic CT generation algorithms recently reported in the literature, including segmentation-based, atlas-based and machine learning techniques, using the same cohort of patients and quantitative evaluation metrics. METHODS: Six MRI-guided synthetic CT generation algorithms were evaluated: one segmentation technique into a single tissue class (water-only), four atlas-based techniques, namely, median value of atlas images (ALMedian), atlas-based local weighted voting (ALWV), bone enhanced atlas-based local weighted voting (ALWV-Bone), iterative atlas-based local weighted voting (ALWV-Iter), and a machine learning technique using deep convolution neural network (DCNN). RESULTS: Organ auto-contouring from MR images was evaluated for bladder, rectum, bones, and body boundary. Overall, DCNN exhibited higher segmentation accuracy resulting in Dice indices (DSC) of 0.93 +/- 0.17, 0.90 +/- 0.04, and 0.93 +/- 0.02 for bladder, rectum, and bones, respectively. On the other hand, ALMedian showed the lowest accuracy with DSC of 0.82 +/- 0.20, 0.81 +/- 0.08, and 0.88 +/- 0.04, respectively. DCNN reached the best performance in terms of accurate derivation of synthetic CT values within each organ, with a mean absolute error within the body contour of 32.7 +/- 7.9 HU, followed by the advanced atlas-based methods (ALWV: 40.5 +/- 8.2 HU, ALWV-Iter: 42.4 +/- 8.1 HU, ALWV-Bone: 44.0 +/- 8.9 HU). ALMedian led to the highest error (52.1 +/- 11.1 HU). Considering the dosimetric evaluation results, ALWV-Iter, ALWV, DCNN and ALWV-Bone led to similar mean dose estimation within each organ at risk and target volume with less than 1% dose discrepancy. However, the two-dimensional gamma analysis demonstrated higher pass rates for ALWV-Bone, DCNN, ALMedian and ALWV-Iter at 1%/1 mm criterion with 94.99 +/- 5.15%, 94.59 +/- 5.65%, 93.68 +/- 5.53% and 93.10 +/- 5.99% success, respectively, while ALWV and water-only resulted in 86.91 +/- 13.50% and 80.77 +/- 12.10%, respectively. CONCLUSIONS: Overall, machine learning and advanced atlas-based methods exhibited promising performance by achieving reliable organ segmentation and synthetic CT generation. DCNN appears to have slightly better performance by achieving accurate automated organ segmentation and relatively small dosimetric errors (followed closely by advanced atlas-based methods, which in some cases achieved similar performance). However, the DCNN approach showed higher vulnerability to anatomical variation, where a greater number of outliers was observed with this method. Considering the dosimetric results obtained from the evaluated methods, the challenge of electron density estimation from MR images can be resolved with a clinically tolerable error.	['Division of Nuclear Medicine and Molecular Imaging, Geneva University Hospital, Geneva, CH-1211, Switzerland.', 'CSIRO Australian e-Health Research Centre, Herston, QLD, Australia.', 'Inria Paris, Aramis Project-Team, Institut du Cerveau et de la Moelle epiniere, ICM, Inserm U 1127, CNRS, UMR 7225, Sorbonne Universite, Paris, F-75013, France.', 'Elekta Inc., Maryland Heights, MO, 63043, USA.', 'Calvary Mater Newcastle Hospital, Waratah, NSW, Australia.', 'University of Newcastle, Callaghan, NSW, Australia.', 'Division of Radiation Oncology, Geneva University Hospital, Geneva, CH-1211, Switzerland.', 'Division of Nuclear Medicine and Molecular Imaging, Geneva University Hospital, Geneva, CH-1211, Switzerland.', 'Geneva University Neurocenter, University of Geneva, Geneva, 1205, Switzerland.', 'Department of Nuclear Medicine and Molecular Imaging, University of Groningen, Groningen, the Netherlands.', 'Department of Nuclear Medicine, University of Southern Denmark, Odense, DK-500, Denmark.']	['10.1002/mp.13187 [doi]']	['Arabi H', 'Dowling JA', 'Burgos N', 'Han X', 'Greer PB', 'Koutsouvelis N', 'Zaidi H']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/09/15 06:00']	20181211	20181010	2018 Nov	2018/09/15 06:00		['Arabi, Hossein', 'Dowling, Jason A', 'Burgos, Ninon', 'Han, Xiao', 'Greer, Peter B', 'Koutsouvelis, Nikolaos', 'Zaidi, Habib']		"['SNSF 320030_176052/Swiss National Science Foundation', 'KFS-3855-02-2016/Swiss Cancer Research Foundation', ""FP7/2007-2013/European Union's Seventh Framework Programme"", 'PCOFUND-GA-2013-609102/REA']"	11		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.13187 [doi]	20181211	['*Algorithms', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', '*Magnetic Resonance Imaging', 'Neural Networks (Computer)', 'Pelvis/*diagnostic imaging', '*Tomography, X-Ray Computed']	2018/12/12 06:00		['CT synthesis', 'MRI-guided radiotherapy planning', 'atlas-based', 'machine learning', 'segmentation']	['NOTNLM']	NLM	5218-5233	['2018/06/07 00:00 [received]', '2018/07/29 00:00 [revised]', '2018/09/06 00:00 [accepted]', '2018/09/15 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2018/09/15 06:00 [entrez]']	United States			30216462	ppublish	['Comparative Study', 'Journal Article']			IM		Med Phys. 2018 Nov;45(11):5218-5233. doi: 10.1002/mp.13187. Epub 2018 Oct 10.	MEDLINE	Med Phys	Comparative study of algorithms for synthetic CT generation from MRI: Consequences for MRI-guided radiation planning in the pelvic region.		45	Comparative study of algorithms for synthetic CT generation from MRI: Consequences for MRI-guided radiation planning in the pelvic region.
Identification of cancer prognostic genes is important in that it can lead to accurate outcome prediction and better therapeutic trials for cancer patients. Many computational approaches have been proposed to achieve this goal; however, there is room for improvement. Recent developments in deep learning techniques can aid in the identification of better prognostic genes and more accurate outcome prediction, but one of the main problems in the adoption of deep learning for this purpose is that data from cancer patients have too many dimensions, while the number of samples is relatively small. In this study, we propose a novel network-based deep learning method to identify prognostic gene signatures via distributed gene representations generated by G2Vec, which is a modified Word2Vec model originally used for natural language processing. We applied the proposed method to five cancer types including liver cancer and showed that G2Vec outperformed extant feature selection methods, especially for small number of samples. Moreover, biomarkers identified by G2Vec was useful to find significant prognostic gene modules associated with hepatocellular carcinoma.	['Department of Computer Science & Engineering, Incheon National University, Incheon, South Korea.', 'Department of Computer Science & Engineering, Incheon National University, Incheon, South Korea.', 'Department of Computer Science & Engineering, Incheon National University, Incheon, South Korea.', 'Department of Computer Science & Engineering, Incheon National University, Incheon, South Korea. jgahn@inu.ac.kr.']	['10.1038/s41598-018-32180-0 [doi]', '10.1038/s41598-018-32180-0 [pii]']	['Choi J', 'Oh I', 'Seo S', 'Ahn J']							['2018/09/15 06:00']	20191104	20180913	2018 Sep 13	2018/09/15 06:00		['Choi, Jonghwan', 'Oh, Ilhwan', 'Seo, Sangmin', 'Ahn, Jaegyoon']		['NRF-2016R1D1A1B03934135/National Research Foundation of Korea (NRF)/International']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-32180-0 [doi]	20191104	['Algorithms', 'Biomarkers, Tumor/*genetics', 'Carcinoma, Hepatocellular/epidemiology/*genetics', 'Computational Biology/methods', '*Deep Learning', 'Gene Expression Profiling', 'Gene Regulatory Networks', 'Humans', 'Neoplasms/epidemiology/*genetics', 'Oncogenes/genetics', 'Prognosis']	2019/11/05 06:00				NLM	13729	['2018/05/11 00:00 [received]', '2018/09/03 00:00 [accepted]', '2018/09/15 06:00 [entrez]', '2018/09/15 06:00 [pubmed]', '2019/11/05 06:00 [medline]']	England	PMC6137174		30213980	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Biomarkers, Tumor)']	IM		Sci Rep. 2018 Sep 13;8(1):13729. doi: 10.1038/s41598-018-32180-0.	MEDLINE	Sci Rep	G2Vec: Distributed gene representations for identification of cancer prognostic genes.		8	G2Vec: Distributed gene representations for identification of cancer prognostic genes.
MOTIVATION: Knowledge of the correct protein subcellular localization is necessary for understanding the function of a protein and revealing the mechanism of many human diseases due to protein subcellular mislocalization, which is required before approaching gene therapy to treat a disease. In addition, it is well-known that the gene therapy is an effective way to overcome disease by targeting a gene therapy product to a specific subcellular compartment. Deep neural networks to predict protein function have become increasingly popular due to large increases in the available genomics data due to its strong superiority in the non-linear classification ability. However, they still have some drawbacks such as too many hyper-parameters and sufficient amount of labeled data. RESULTS: We present a deep forest-based protein location algorithm relying on sequence information. The prediction model uses a random forest network with a multi-layered structure to identify the subcellular regions of protein. The model was trained and tested on a latest UniProt releases protein dataset, and we demonstrate that our deep forest predict the subcellular location of proteins given only the protein sequence with high accuracy, outperforming the current state-of-art algorithms. Meanwhile, unlike the deep neural networks, it has a significantly smaller number of parameters and is much easier to train.	['School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China.', 'Department of Rehabilitation, Heilongjiang Province Land Reclamation Headquarters General Hospital, Harbin, China.']	['CGT-EPUB-93031 [pii]', '10.2174/1566523218666180913110949 [doi]']	['Zhao L', 'Wang J', 'Nabil MM', 'Zhang J']		['Copyright(c) Bentham Science Publishers; For any queries, please email at', 'epub@benthamscience.org.']					['2018/09/14 06:00']	20191009		2018	2018/09/14 06:00		['Zhao, Lingling', 'Wang, Junjie', 'Nabil, Mahieddine Mohammed', 'Zhang, Jun']			5		1875-5631 (Electronic) 1566-5232 (Linking)	101125446	Current gene therapy	['eng']	10.2174/1566523218666180913110949 [doi]	20191010	['*Algorithms', 'Computational Biology/*methods', '*Deep Learning', 'Genetic Therapy/methods', 'Humans', 'Intracellular Space/metabolism', '*Neural Networks (Computer)', 'Protein Transport', 'Proteins/*analysis/genetics/metabolism', 'Reproducibility of Results']	2019/10/11 06:00		"[""*Algorithm's"", '*Deep forest', '*Machine learning', '*Protein subcellular location', '*Sequence information', '*UniProt.']"	['NOTNLM']	NLM	268-274	['2018/03/03 00:00 [received]', '2018/05/26 00:00 [revised]', '2018/06/02 00:00 [accepted]', '2018/09/14 06:00 [pubmed]', '2019/10/11 06:00 [medline]', '2018/09/14 06:00 [entrez]']	United Arab Emirates			30209998	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		Curr Gene Ther. 2018;18(5):268-274. doi: 10.2174/1566523218666180913110949.	MEDLINE	Curr Gene Ther	Deep Forest-based Prediction of Protein Subcellular Localization.		18	Deep Forest-based Prediction of Protein Subcellular Localization.
We present a study of multiple sclerosis segmentation algorithms conducted at the international MICCAI 2016 challenge. This challenge was operated using a new open-science computing infrastructure. This allowed for the automatic and independent evaluation of a large range of algorithms in a fair and completely automatic manner. This computing infrastructure was used to evaluate thirteen methods of MS lesions segmentation, exploring a broad range of state-of-theart algorithms, against a high-quality database of 53 MS cases coming from four centers following a common definition of the acquisition protocol. Each case was annotated manually by an unprecedented number of seven different experts. Results of the challenge highlighted that automatic algorithms, including the recent machine learning methods (random forests, deep learning, ...), are still trailing human expertise on both detection and delineation criteria. In addition, we demonstrate that computing a statistically robust consensus of the algorithms performs closer to human expertise on one score (segmentation) although still trailing on detection scores.	"['VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France. Olivier.Commowick@inria.fr.', 'Department of Radiology, Lyon Sud Hospital, Hospices Civils de Lyon, Lyon, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'LaTIM, INSERM, UMR 1101, University of Brest, IBSAM, Brest, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'Univ Lyon, INSA-Lyon, Universite Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1206, F-69621, Lyon, France.', 'Univ Lyon, INSA-Lyon, Universite Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1206, F-69621, Lyon, France.', 'Department of Radiology, Lyon Sud Hospital, Hospices Civils de Lyon, Lyon, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'CHU Rennes, Department of Neuroradiology, F-35033, Rennes, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'CHU Rennes, Department of Neurology, F-35033, Rennes, France.', 'CHU de Bordeaux, Service de Neuro-Imagerie, Bordeaux, France.', 'Univ Lyon, INSA-Lyon, Universite Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1206, F-69621, Lyon, France.', 'Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'Pixyl Medical, Grenoble, France.', 'Pixyl Medical, Grenoble, France.', 'Inria Grenoble Rhone-Alpes, Grenoble, France.', 'Image Analysis in Medicine Lab, School of Engineering, University of Guelph, Guelph, Canada.', 'Image Analysis in Medicine Lab (IAMLAB), Ryerson University, Toronto, Canada.', 'School of Technology and Health, KTH Royal Institute of Technology, Stockholm, Sweden.', 'School of Technology and Health, KTH Royal Institute of Technology, Stockholm, Sweden.', 'Department of Diagnostic and Interventional Neuroradiology, Inselspital, University of Bern, Bern, Switzerland.', 'Department of Diagnostic and Interventional Neuroradiology, Inselspital, University of Bern, Bern, Switzerland.', 'Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, USA.', 'Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, USA.', 'Research institute of Computer Vision and Robotics (VICOROB), University of Girona, Girona, Spain.', 'Research institute of Computer Vision and Robotics (VICOROB), University of Girona, Girona, Spain.', 'Centro de Informatica, Universidade Federal de Pernambuco, Pernambuco, Brazil.', 'Depto. de Eng. Biomedica, Universidade Federal de Pernambuco, Pernambuco, Brazil.', 'Centro de Informatica, Universidade Federal de Pernambuco, Pernambuco, Brazil.', ""Computational Radiology Laboratory, Department of Radiology, Children's Hospital, 300 Longwood Avenue, Boston, MA, USA."", 'LTCI, Telecom ParisTech, Universite Paris-Saclay, Paris, France.', 'LTCI, Telecom ParisTech, Universite Paris-Saclay, Paris, France.', 'Research institute of Computer Vision and Robotics (VICOROB), University of Girona, Girona, Spain.', 'Research institute of Computer Vision and Robotics (VICOROB), University of Girona, Girona, Spain.', 'Medical Image Analysis Lab, Universidad Rey Juan Carlos, Madrid, Spain.', 'Medical Image Analysis Lab, Universidad Rey Juan Carlos, Madrid, Spain.', ""Center for Neurological Imaging, Department of Radiology, Brigham and Women's Hospital, Boston, MA, USA."", 'Department of Radiology, Lyon Sud Hospital, Hospices Civils de Lyon, Lyon, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.', 'CHU Rennes, Department of Neurology, F-35033, Rennes, France.', 'Inserm U1216, University Grenoble Alpes, CHU Grenoble, GIN, Grenoble, France.', 'Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA.', ""Computational Radiology Laboratory, Department of Radiology, Children's Hospital, 300 Longwood Avenue, Boston, MA, USA."", 'Department of Radiology, Lyon Sud Hospital, Hospices Civils de Lyon, Lyon, France.', 'VISAGES: INSERM U1228 - CNRS UMR6074 - Inria, University of Rennes I, Rennes, France.']"	['10.1038/s41598-018-31911-7 [doi]', '10.1038/s41598-018-31911-7 [pii]']	['Commowick O', 'Istace A', 'Kain M', 'Laurent B', 'Leray F', 'Simon M', 'Pop SC', 'Girard P', 'Ameli R', 'Ferre JC', 'Kerbrat A', 'Tourdias T', 'Cervenansky F', 'Glatard T', 'Beaumont J', 'Doyle S', 'Forbes F', 'Knight J', 'Khademi A', 'Mahbod A', 'Wang C', 'McKinley R', 'Wagner F', 'Muschelli J', 'Sweeney E', 'Roura E', 'Llado X', 'Santos MM', 'Santos WP', 'Silva-Filho AG', 'Tomas-Fernandez X', 'Urien H', 'Bloch I', 'Valverde S', 'Cabezas M', 'Vera-Olmos FJ', 'Malpica N', 'Guttmann C', 'Vukusic S', 'Edan G', 'Dojat M', 'Styner M', 'Warfield SK', 'Cotton F', 'Barillot C']	['ORCID: 0000-0002-7923-5069', 'ORCID: 0000-0002-0455-5455', 'ORCID: 0000-0002-4932-0385', 'ORCID: 0000-0001-5042-1442', 'ORCID: 0000-0001-6469-1750', 'ORCID: 0000-0003-4618-7459', 'ORCID: 0000-0003-0046-2478']						['2018/09/14 06:00']	20191031	20180912	2018 Sep 12	2018/09/14 06:00		['Commowick, Olivier', 'Istace, Audrey', 'Kain, Michael', 'Laurent, Baptiste', 'Leray, Florent', 'Simon, Mathieu', 'Pop, Sorina Camarasu', 'Girard, Pascal', 'Ameli, Roxana', 'Ferre, Jean-Christophe', 'Kerbrat, Anne', 'Tourdias, Thomas', 'Cervenansky, Frederic', 'Glatard, Tristan', 'Beaumont, Jeremy', 'Doyle, Senan', 'Forbes, Florence', 'Knight, Jesse', 'Khademi, April', 'Mahbod, Amirreza', 'Wang, Chunliang', 'McKinley, Richard', 'Wagner, Franca', 'Muschelli, John', 'Sweeney, Elizabeth', 'Roura, Eloy', 'Llado, Xavier', 'Santos, Michel M', 'Santos, Wellington P', 'Silva-Filho, Abel G', 'Tomas-Fernandez, Xavier', 'Urien, Helene', 'Bloch, Isabelle', 'Valverde, Sergi', 'Cabezas, Mariano', 'Vera-Olmos, Francisco Javier', 'Malpica, Norberto', 'Guttmann, Charles', 'Vukusic, Sandra', 'Edan, Gilles', 'Dojat, Michel', 'Styner, Martin', 'Warfield, Simon K', 'Cotton, Francois', 'Barillot, Christian']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-31911-7 [doi]	20191031	['*Algorithms', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Image Processing, Computer-Assisted/methods', 'Machine Learning', 'Magnetic Resonance Imaging/*methods', 'Male', 'Multiple Sclerosis/*diagnosis/*diagnostic imaging/pathology', 'Neural Networks (Computer)', 'Parenchymal Tissue/*diagnostic imaging/pathology', 'Retrospective Studies']	2019/11/02 06:00				NLM	13650	['2018/04/20 00:00 [received]', '2018/08/06 00:00 [accepted]', '2018/09/14 06:00 [entrez]', '2018/09/14 06:00 [pubmed]', '2019/11/02 06:00 [medline]']	England	PMC6135867		30209345	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Sep 12;8(1):13650. doi: 10.1038/s41598-018-31911-7.	MEDLINE	Sci Rep	Objective Evaluation of Multiple Sclerosis Lesion Segmentation using a Data Management and Processing Infrastructure.		8	Objective Evaluation of Multiple Sclerosis Lesion Segmentation using a Data Management and Processing Infrastructure.
BACKGROUND AND OBJECTIVE: There is a huge amount of rare diseases, many of which have associated important disabilities. It is paramount to know in advance the evolution of the disease in order to limit and prevent the appearance of disabilities and to prepare the patient to manage the future difficulties. Rare disease associations are making an effort to manually collect this information, but it is a long process. A lot of information about the consequences of rare diseases is published in scientific papers, and our goal is to automatically extract disabilities associated with diseases from them. METHODS: This work presents a new corpus of abstracts from scientific papers related to rare diseases, which has been manually annotated with disabilities. This corpus allows to train machine and deep learning systems that can automatically process other papers, thus extracting new information about the relations between rare diseases and disabilities. The corpus is also annotated with negation and speculation when they appear affecting disabilities. The corpus has been made publicly accessible. RESULTS: We have devised some experiments using deep learning techniques to show the usefulness of the developed corpus. Specifically, we have designed a long short-term memory based architecture for disabilities identification, as well as a convolutional neural network for detecting their relationships to diseases. The systems designed do not need any preprocessing of the data, but only low dimensional vectors representing the words. CONCLUSIONS: The developed corpus will allow to train systems to identify disabilities in biomedical documents, which the current annotation systems are not able to detect. The system could also be trained to detect relationships between them and diseases, as well as negation and speculation, that can change the meaning of the language. The deep learning models designed for identifying disabilities and their relationships to diseases in new documents show that the corpus allows obtaining an F-measure of around 81% for the disability recognition and 75% for relation extraction.	['Department of Computer Science, Universidad Nacional de Educacion a Distancia (UNED), Juan del Rosal 16, Madrid 28040, Spain. Electronic address: gildo.fabregat@lsi.uned.es.', 'Department of Computer Science, Universidad Nacional de Educacion a Distancia (UNED), Juan del Rosal 16, Madrid 28040, Spain; IMIENS: Instituto Mixto de Investigacion, Escuela Nacional de Sanidad, Monforte de Lemos 5, Madrid 28019, Spain. Electronic address: lurdes@lsi.uned.es.', 'Department of Computer Science, Universidad Nacional de Educacion a Distancia (UNED), Juan del Rosal 16, Madrid 28040, Spain; IMIENS: Instituto Mixto de Investigacion, Escuela Nacional de Sanidad, Monforte de Lemos 5, Madrid 28019, Spain. Electronic address: juaner@lsi.uned.es.']	['S0169-2607(18)30133-0 [pii]', '10.1016/j.cmpb.2018.07.007 [doi]']	['Fabregat H', 'Araujo L', 'Martinez-Romo J']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/09/10 06:00']	20190107	20180720	2018 Oct	2018/09/10 06:00		['Fabregat, Hermenegildo', 'Araujo, Lourdes', 'Martinez-Romo, Juan']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30133-0 [pii] 10.1016/j.cmpb.2018.07.007 [doi]	20190107	['Data Mining', 'Databases, Factual/statistics & numerical data', 'Deep Learning', 'Disabled Persons/*statistics & numerical data', 'Humans', 'Natural Language Processing', '*Neural Networks (Computer)', 'Rare Diseases/*etiology', 'Semantics']	2019/01/08 06:00		['Biomedical corpora', 'Deep neural networks', 'Disabilities', 'Entity recognition', 'Rare diseases', 'Relationship classification']	['NOTNLM']	NLM	121-129	['2018/01/30 00:00 [received]', '2018/06/20 00:00 [revised]', '2018/07/16 00:00 [accepted]', '2018/09/10 06:00 [entrez]', '2018/09/10 06:00 [pubmed]', '2019/01/08 06:00 [medline]']	Ireland			30195420	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Oct;164:121-129. doi: 10.1016/j.cmpb.2018.07.007. Epub 2018 Jul 20.	MEDLINE	Comput Methods Programs Biomed	Deep neural models for extracting entities and relationships in the new RDD corpus relating disabilities and rare diseases.		164	Deep neural models for extracting entities and relationships in the new RDD corpus relating disabilities and rare diseases.
Hospital readmission is one of the critical metrics used for measuring the performance of hospitals. The HITECH Act imposes penalties when patients are readmitted to hospitals if they are diagnosed with one of the six conditions mentioned in the Act. However, patients diagnosed with lupus are the sixth highest in terms of rehospitalization. The heterogeneity in the disease and patient characteristics makes it very hard to predict rehospitalization. This research utilizes deep learning methods to predict rehospitalization within 30 days by extracting the temporal relationships in the longitudinal EHR clinical data. Prediction results from deep learning methods such as LSTM are evaluated and compared with traditional classification methods such as penalized logistic regression and artificial neural networks. The simple recurrent neural network method and its variant, gated recurrent unit network, are also developed and validated to compare their performance against the proposed LSTM model. The results indicated that the deep learning method RNN-LSTM has a significantly better performance (with an AUC of .70) compared to traditional classification methods such as ANN (with an AUC of 0.66) and penalized logistic regression (with an AUC of 0.63). The rationale for the better performance of the deep learning method may be due to its ability to leverage the temporal relationships of the disease state in patients over time and to capture the progression of the disease-relevant clinical information from patients' prior visits is carried forward in the memory, which may have enabled the higher predictability for the deep learning methods.	['UCB Biosciences, Inc., 8010 Arco Corporate Drive, Suite 100, Raleigh, NC, 27617, USA. Electronic address: Bhargava.Reddy@ucb.com.', 'Department of Management Science and Information Systems, Spears School of Business, Oklahoma State University, Tulsa, OK, 74106, USA. Electronic address: dursun.delen@okstate.edu.']	['S0010-4825(18)30256-7 [pii]', '10.1016/j.compbiomed.2018.08.029 [doi]']	['Reddy BK', 'Delen D']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/09/09 06:00']	20190925	20180831	2018 Oct 1	2018/09/09 06:00		['Reddy, Bhargava K', 'Delen, Dursun']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30256-7 [pii] 10.1016/j.compbiomed.2018.08.029 [doi]	20190925	['*Deep Learning', 'Female', 'Humans', 'Lupus Erythematosus, Systemic/epidemiology/*therapy', 'Male', '*Models, Biological', '*Neural Networks (Computer)', '*Patient Readmission', 'Predictive Value of Tests']	2019/09/26 06:00		['*Deep learning', '*LSTM', '*Lupus', '*Machine learning', '*Predictive analytics', '*Readmission']	['NOTNLM']	NLM	199-209	['2018/05/16 00:00 [received]', '2018/08/29 00:00 [revised]', '2018/08/30 00:00 [accepted]', '2018/09/09 06:00 [pubmed]', '2019/09/26 06:00 [medline]', '2018/09/09 06:00 [entrez]']	United States			30195164	ppublish	['Journal Article']			IM		Comput Biol Med. 2018 Oct 1;101:199-209. doi: 10.1016/j.compbiomed.2018.08.029. Epub 2018 Aug 31.	MEDLINE	Comput Biol Med	Predicting hospital readmission for lupus patients: An RNN-LSTM-based deep-learning methodology.		101	Predicting hospital readmission for lupus patients: An RNN-LSTM-based deep-learning methodology.
	['Applied Physics Laboratory, Johns Hopkins University, Baltimore, Maryland.', 'Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, Baltimore, Maryland.', 'Department of Computer Science, Malone Center for Engineering in Healthcare, Johns Hopkins University, Baltimore, Maryland.', 'Applied Physics Laboratory, Johns Hopkins University, Baltimore, Maryland.', 'Retina Division, Department of Ophthalmology, Brazilian Center of Vision Eye Hospital, Brasilia, Brazil.', 'Applied Physics Laboratory, Johns Hopkins University, Baltimore, Maryland.', 'Department of Ophthalmology, The Fourth Affiliated Hospital of China Medical University, Eye Hospital of China Medical University, Shenyang, China.', 'Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, Baltimore, Maryland.', 'Editor.']	['2698945 [pii]', '10.1001/jamaophthalmol.2018.3799 [doi]']	['Burlina P', 'Joshi N', 'Pacheco KD', 'Freund DE', 'Kong J', 'Bressler NM']							['2018/09/08 06:00']	20191011		2018 Nov 1	2018/09/08 06:00		['Burlina, Phillippe', 'Joshi, Neil', 'Pacheco, Katia D', 'Freund, David E', 'Kong, Jun', 'Bressler, Neil M']		['R21 EY024310/EY/NEI NIH HHS/United States']	11		2168-6173 (Electronic) 2168-6165 (Linking)	101589539	JAMA ophthalmology	['eng']	10.1001/jamaophthalmol.2018.3799 [doi]	20191011	['Aged', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'False Positive Reactions', 'Humans', 'Macular Degeneration/*classification', 'Neural Networks (Computer)', 'Ophthalmologists/standards', 'Predictive Value of Tests', 'Reproducibility of Results', 'Sensitivity and Specificity']	2019/10/12 06:00				NLM	1305-1307	['2018/09/08 06:00 [pubmed]', '2019/10/12 06:00 [medline]', '2018/09/08 06:00 [entrez]']	United States	PMC6248178		30193354	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			AIM IM		JAMA Ophthalmol. 2018 Nov 1;136(11):1305-1307. doi: 10.1001/jamaophthalmol.2018.3799.	MEDLINE	JAMA Ophthalmol	Utility of Deep Learning Methods for Referability Classification of Age-Related Macular Degeneration.		136	Utility of Deep Learning Methods for Referability Classification of Age-Related Macular Degeneration.
Deep learning is beginning to impact biological research and biomedical applications as a result of its ability to integrate vast datasets, learn arbitrarily complex relationships and incorporate existing knowledge. Already, deep learning models can predict, with varying degrees of success, how genetic variation alters cellular processes involved in pathogenesis, which small molecules will modulate the activity of therapeutically relevant proteins, and whether radiographic images are indicative of disease. However, the flexibility of deep learning creates new challenges in guaranteeing the performance of deployed systems and in establishing trust with stakeholders, clinicians and regulators, who require a rationale for decision making. We argue that these challenges will be overcome using the same flexibility that created them; for example, by training deep models so that they can output a rationale for their predictions. Significant research in this direction will be needed to realize the full potential of deep learning in biomedicine.	['Deep Genomics Inc., MaRS Discovery District, Toronto, Ontario, Canada.', 'Department of Computer Science, Stanford University, Stanford, California, USA.', 'Deep Genomics Inc., MaRS Discovery District, Toronto, Ontario, Canada.', 'Deep Genomics Inc., MaRS Discovery District, Toronto, Ontario, Canada.', 'Deep Genomics Inc., MaRS Discovery District, Toronto, Ontario, Canada.']	['nbt.4233 [pii]', '10.1038/nbt.4233 [doi]']	['Wainberg M', 'Merico D', 'Delong A', 'Frey BJ']							['2018/09/07 06:00']	20190429	20180906	2018 Oct	2018/09/07 06:00		['Wainberg, Michael', 'Merico, Daniele', 'Delong, Andrew', 'Frey, Brendan J']			9		1546-1696 (Electronic) 1087-0156 (Linking)	9604648	Nature biotechnology	['eng']	10.1038/nbt.4233 [doi]	20190429	['Algorithms', '*Deep Learning', 'Humans']	2019/04/30 06:00				NLM	829-838	['2017/10/12 00:00 [received]', '2018/08/01 00:00 [accepted]', '2018/09/07 06:00 [entrez]', '2018/09/07 06:00 [pubmed]', '2019/04/30 06:00 [medline]']	United States			30188539	ppublish	['Journal Article']			IM		Nat Biotechnol. 2018 Oct;36(9):829-838. doi: 10.1038/nbt.4233. Epub 2018 Sep 6.	MEDLINE	Nat Biotechnol	Deep learning in biomedicine.		36	Deep learning in biomedicine.
Purpose To develop and validate a deep learning system (DLS) for staging liver fibrosis by using CT images in the liver. Materials and Methods DLS for CT-based staging of liver fibrosis was created by using a development data set that included portal venous phase CT images in 7461 patients with pathologically confirmed liver fibrosis. The diagnostic performance of the DLS was evaluated in separate test data sets for 891 patients. The influence of patient characteristics and CT techniques on the staging accuracy of the DLS was evaluated by logistic regression analysis. In a subset of 421 patients, the diagnostic performance of the DLS was compared with that of the radiologist's assessment, aminotransferase-to-platelet ratio index (APRI), and fibrosis-4 index by using the area under the receiver operating characteristic curve (AUROC) and Obuchowski index. Results In the test data sets, the DLS had a staging accuracy of 79.4% (707 of 891) and an AUROC of 0.96, 0.97, and 0.95 for diagnosing significant fibrosis (F2-4), advanced fibrosis (F3-4), and cirrhosis (F4), respectively. At multivariable analysis, only pathologic fibrosis stage significantly affected the staging accuracy of the DLS (P = .016 and .013 for F1 and F2, respectively, compared with F4), whereas etiology of liver disease and CT technique did not. The DLS (Obuchowski index, 0.94) outperformed the radiologist's interpretation, APRI, and fibrosis-4 index (Obuchowski index range, 0.71-0.81; P < .001) for staging liver fibrosis. Conclusion The deep learning system allows for accurate staging of liver fibrosis by using CT images. (c) RSNA, 2018 Online supplemental material is available for this article.	['From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).', 'From the Department of Computer Science, Hanyang University, Seoul, Republic of Korea (K.J.C.); Department of Radiology and Research Institute of Radiology (J.K.J., S.S.L., Y.S.S., W.H.S., H.S.K., J.Y., J.H.K., S.Y.K.) and Department of Diagnostic Pathology (E.S.Y.), Asan Medical Center, University of Ulsan College of Medicine, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, South Korea; Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Seoul, Korea (J.Y.C.); Department of Radiology, Haeundae Paik Hospital, Inje University College of Medicine, Busan, Korea (Y.L.); and Department of Radiology, Hanyang University Medical Center, Hanyang University School of Medicine, Seoul, Korea (B.K.K.).']	['10.1148/radiol.2018180763 [doi]']	['Choi KJ', 'Jang JK', 'Lee SS', 'Sung YS', 'Shim WH', 'Kim HS', 'Yun J', 'Choi JY', 'Lee Y', 'Kang BK', 'Kim JH', 'Kim SY', 'Yu ES']	['ORCID: 0000-0002-9477-7421']		['Radiology. 2018 Dec;289(3):708-709. PMID: 30179103']				['2018/09/05 06:00']	20190903	20180904	2018 Dec	2018/09/05 06:00		['Choi, Kyu Jin', 'Jang, Jong Keon', 'Lee, Seung Soo', 'Sung, Yu Sub', 'Shim, Woo Hyun', 'Kim, Ho Sung', 'Yun, Jessica', 'Choi, Jin-Young', 'Lee, Yedaun', 'Kang, Bo-Kyeong', 'Kim, Jin Hee', 'Kim, So Yeon', 'Yu, Eun Sil']			3		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2018180763 [doi]	20190903	['Adult', '*Contrast Media', 'Deep Learning/*standards', 'Female', 'Humans', 'Liver/diagnostic imaging/pathology', 'Liver Cirrhosis/*diagnostic imaging/*pathology', 'Male', 'Middle Aged', 'Radiographic Image Enhancement/*methods', 'Reproducibility of Results', 'Severity of Illness Index', 'Tomography, X-Ray Computed/*methods']	2019/09/04 06:00				NLM	688-697	['2018/09/05 06:00 [pubmed]', '2019/09/04 06:00 [medline]', '2018/09/05 06:00 [entrez]']	United States			30179104	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"		['0 (Contrast Media)']	AIM IM		Radiology. 2018 Dec;289(3):688-697. doi: 10.1148/radiol.2018180763. Epub 2018 Sep 4.	MEDLINE	Radiology	Development and Validation of a Deep Learning System for Staging Liver Fibrosis by Using Contrast Agent-enhanced CT Images in the Liver.		289	Development and Validation of a Deep Learning System for Staging Liver Fibrosis by Using Contrast Agent-enhanced CT Images in the Liver.
	['Google Brain Team and Department of Computer Science, University of Toronto, Ontario, Canada.']	['2701666 [pii]', '10.1001/jama.2018.11100 [doi]']	['Hinton G']			['JAMA. 2018 Sep 18;320(11):1107-1108. PMID: 30178025']				['2018/09/05 06:00']	20181010		2018 Sep 18	2018/09/05 06:00		['Hinton, Geoffrey']			11		1538-3598 (Electronic) 0098-7484 (Linking)	7501160	JAMA	['eng']	10.1001/jama.2018.11100 [doi]	20181010	['Diagnosis, Differential', 'History, 20th Century', 'History, 21st Century', 'Humans', '*Machine Learning/history', '*Neural Networks (Computer)']	2018/10/12 06:00				NLM	1101-1102	['2018/09/05 06:00 [pubmed]', '2018/10/12 06:00 [medline]', '2018/09/05 06:00 [entrez]']	United States			30178065	ppublish	['Historical Article', 'Journal Article']			AIM IM		JAMA. 2018 Sep 18;320(11):1101-1102. doi: 10.1001/jama.2018.11100.	MEDLINE	JAMA	Deep Learning-A Technology With the Potential to Transform Health Care.		320	Deep Learning-A Technology With the Potential to Transform Health Care.
The purpose of this study was to evaluate the performance of the deep convolutional neural network (DCNN) in differentiating between tuberculous and pyogenic spondylitis on magnetic resonance (MR) imaging, compared to the performance of three skilled radiologists. This clinical retrospective study used spine MR images of 80 patients with tuberculous spondylitis and 81 patients with pyogenic spondylitis that was bacteriologically and/or histologically confirmed from January 2007 to December 2016. Supervised training and validation of the DCNN classifier was performed with four-fold cross validation on a patient-level independent split. The object detection and classification model was implemented as a DCNN and was designed to calculate the deep-learning scores of individual patients to reach a conclusion. Three musculoskeletal radiologists blindly interpreted the images. The diagnostic performances of the DCNN classifier and of the three radiologists were expressed as receiver operating characteristic (ROC) curves, and the areas under the ROC curves (AUCs) were compared using a bootstrap resampling procedure. When comparing the AUC value of the DCNN classifier (0.802) with the pooled AUC value of the three readers (0.729), there was no significant difference (P = 0.079). In differentiating between tuberculous and pyogenic spondylitis using MR images, the performance of the DCNN classifier was comparable to that of three skilled radiologists.	['Department of Radiology, Gangnam Severance Hospital, Yonsei University College of Medicine, Research Institute of Radiological Science, Center for Clinical Imaging Data Science, Seoul, South Korea.', 'Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Research Institute of Radiological Science, Center for Clinical Imaging Data Science, Seoul, South Korea.', 'Department of Radiology, Severance Hospital, Yonsei University College of Medicine, Research Institute of Radiological Science, Center for Clinical Imaging Data Science, Seoul, South Korea.', 'Department of Radiology, National Health Insurance Service Ilsan Hospital, Goyang-si, Gyeonggi-do, South Korea.', 'Biostatistics Collaboration Unit, Research Center for Future Medicine, Yonsei University College of Medicine, Seoul, South Korea.', 'Department of Radiology, Gangnam Severance Hospital, Yonsei University College of Medicine, Research Institute of Radiological Science, Center for Clinical Imaging Data Science, Seoul, South Korea. AGN70@yuhs.ac.']	['10.1038/s41598-018-31486-3 [doi]', '10.1038/s41598-018-31486-3 [pii]']	['Kim K', 'Kim S', 'Lee YH', 'Lee SH', 'Lee HS', 'Kim S']	['ORCID: 0000-0002-8798-5038', 'ORCID: 0000-0001-6328-6948', 'ORCID: 0000-0002-7876-7901']						['2018/09/05 06:00']	20191025	20180903	2018 Sep 3	2018/09/05 06:00		['Kim, Kiwook', 'Kim, Sungwon', 'Lee, Young Han', 'Lee, Seung Hyun', 'Lee, Hye Sun', 'Kim, Sungjun']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-31486-3 [doi]	20191025	['Adult', 'Aged', '*Algorithms', 'Area Under Curve', 'Diagnosis, Differential', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*statistics & numerical data', 'Magnetic Resonance Imaging', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'ROC Curve', 'Retrospective Studies', 'Spine/*diagnostic imaging/pathology', 'Spondylitis/*diagnostic imaging/pathology', 'Supervised Machine Learning', 'Tuberculosis, Osteoarticular/*diagnostic imaging/pathology']	2019/10/28 06:00				NLM	13124	['2018/06/06 00:00 [received]', '2018/08/20 00:00 [accepted]', '2018/09/05 06:00 [entrez]', '2018/09/05 06:00 [pubmed]', '2019/10/28 06:00 [medline]']	England	PMC6120953		30177857	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Sep 3;8(1):13124. doi: 10.1038/s41598-018-31486-3.	MEDLINE	Sci Rep	Performance of the deep convolutional neural network based magnetic resonance image scoring algorithm for differentiating between tuberculous and pyogenic spondylitis.		8	Performance of the deep convolutional neural network based magnetic resonance image scoring algorithm for differentiating between tuberculous and pyogenic spondylitis.
During seizures, a myriad of clinical manifestations may occur. The analysis of these signs, known as seizure semiology, gives clues to the underlying cerebral networks involved. When patients with drug-resistant epilepsy are monitored to assess their suitability for epilepsy surgery, semiology is a vital component to the presurgical evaluation. Specific patterns of facial movements, head motions, limb posturing and articulations, and hand and finger automatisms may be useful in distinguishing between mesial temporal lobe epilepsy (MTLE) and extratemporal lobe epilepsy (ETLE). However, this analysis is time-consuming and dependent on clinical experience and training. Given this limitation, an automated analysis of semiological patterns, i.e., detection, quantification, and recognition of body movement patterns, has the potential to help increase the diagnostic precision of localization. While a few single modal quantitative approaches are available to assess seizure semiology, the automated quantification of patients' behavior across multiple modalities has seen limited advances in the literature. This is largely due to multiple complicated variables commonly encountered in the clinical setting, such as analyzing subtle physical movements when the patient is covered or room lighting is inadequate. Semiology encompasses the stepwise/temporal progression of signs that is reflective of the integration of connected neuronal networks. Thus, single signs in isolation are far less informative. Taking this into account, here, we describe a novel modular, hierarchical, multimodal system that aims to detect and quantify semiologic signs recorded in 2D monitoring videos. Our approach can jointly learn semiologic features from facial, body, and hand motions based on computer vision and deep learning architectures. A dataset collected from an Australian quaternary referral epilepsy unit analyzing 161 seizures arising from the temporal (n=90) and extratemporal (n=71) brain regions has been used in our system to quantitatively classify these types of epilepsy according to the semiology detected. A leave-one-subject-out (LOSO) cross-validation of semiological patterns from the face, body, and hands reached classification accuracies ranging between 12% and 83.4%, 41.2% and 80.1%, and 32.8% and 69.3%, respectively. The proposed hierarchical multimodal system is a potential stepping-stone towards developing a fully automated semiology analysis system to support the assessment of epilepsy.	['The Speech, Audio, Image and Video Technologies (SAIVT) research group, School of Electrical Engineering & Computer Science, Queensland University of Technology, Australia. Electronic address: david.aristizabal@hdr.qut.edu.au.', 'The Speech, Audio, Image and Video Technologies (SAIVT) research group, School of Electrical Engineering & Computer Science, Queensland University of Technology, Australia.', 'The Speech, Audio, Image and Video Technologies (SAIVT) research group, School of Electrical Engineering & Computer Science, Queensland University of Technology, Australia.', 'The Speech, Audio, Image and Video Technologies (SAIVT) research group, School of Electrical Engineering & Computer Science, Queensland University of Technology, Australia.', 'The Speech, Audio, Image and Video Technologies (SAIVT) research group, School of Electrical Engineering & Computer Science, Queensland University of Technology, Australia.', 'The Speech, Audio, Image and Video Technologies (SAIVT) research group, School of Electrical Engineering & Computer Science, Queensland University of Technology, Australia.', 'Department of Mater Advanced Epilepsy Unit, Mater Centre for Neurosciences, Brisbane, Australia.']	['S1525-5050(18)30431-1 [pii]', '10.1016/j.yebeh.2018.07.028 [doi]']	['Ahmedt-Aristizabal D', 'Fookes C', 'Denman S', 'Nguyen K', 'Fernando T', 'Sridharan S', 'Dionisio S']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/09/03 06:00']	20190415	20180831	2018 Oct	2018/09/03 06:00		['Ahmedt-Aristizabal, David', 'Fookes, Clinton', 'Denman, Simon', 'Nguyen, Kien', 'Fernando, Tharindu', 'Sridharan, Sridha', 'Dionisio, Sasha']					1525-5069 (Electronic) 1525-5050 (Linking)	100892858	Epilepsy & behavior : E&B	['eng']	S1525-5050(18)30431-1 [pii] 10.1016/j.yebeh.2018.07.028 [doi]	20190415	['Automatism/*physiopathology', 'Biomechanical Phenomena', 'Datasets as Topic', '*Deep Learning', 'Epilepsy/*diagnosis', 'Epilepsy, Temporal Lobe/*diagnosis', 'Face/*physiopathology', 'Hand/*physiopathology', 'Humans', 'Movement/*physiology', 'Neurophysiological Monitoring/*methods', 'Seizures/*diagnosis']	2019/04/16 06:00		['*Computer vision', '*Deep learning', '*Facial movements', '*Hand automatisms', '*Quantitative movement analysis', '*Seizure semiology']	['NOTNLM']	NLM	46-58	['2018/05/21 00:00 [received]', '2018/07/30 00:00 [revised]', '2018/07/30 00:00 [accepted]', '2018/09/03 06:00 [pubmed]', '2019/04/16 06:00 [medline]', '2018/09/03 06:00 [entrez]']	United States			30173017	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Epilepsy Behav. 2018 Oct;87:46-58. doi: 10.1016/j.yebeh.2018.07.028. Epub 2018 Aug 31.	MEDLINE	Epilepsy Behav	A hierarchical multimodal system for motion analysis in patients with epilepsy.		87	A hierarchical multimodal system for motion analysis in patients with epilepsy.
Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95% of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications.	['Department Electronic Systems at Norwegian University of Science and Technology (NTNU), Trondheim, Norway. Electronic address: shinyh0919@gmail.com.', 'Intervention Centre, Oslo University Hospital, Oslo NO-0027, Norway; Institute of Clinical Medicine, University of Oslo, and the Norwegian University of Science and Technology (NTNU), Norway. Electronic address: ilangkob@medisin.uio.no.']	['S0895-6111(18)30092-2 [pii]', '10.1016/j.compmedimag.2018.08.001 [doi]']	['Shin Y', 'Balasingham I']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/09/02 06:00']	20191024	20180822	2018 Nov	2018/09/02 06:00		['Shin, Younghak', 'Balasingham, Ilangko']					1879-0771 (Electronic) 0895-6111 (Linking)	8806104	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	['eng']	S0895-6111(18)30092-2 [pii] 10.1016/j.compmedimag.2018.08.001 [doi]	20191024	['Algorithms', 'Brain/*diagnostic imaging', 'Early Detection of Cancer', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Magnetic Resonance Imaging', 'Male', 'Prostate/diagnostic imaging', 'Support Vector Machine', 'Urinary Bladder/diagnostic imaging']	2019/10/28 06:00		['*Colonoscopy', '*Computer-aided detection', '*Dictionary learning', '*Polyp classification', '*Shape and color feature', '*Sparse coding']	['NOTNLM']	NLM	33-42	['2018/02/14 00:00 [received]', '2018/07/29 00:00 [revised]', '2018/08/13 00:00 [accepted]', '2018/09/02 06:00 [pubmed]', '2019/10/28 06:00 [medline]', '2018/09/02 06:00 [entrez]']	United States			30172091	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Med Imaging Graph. 2018 Nov;69:33-42. doi: 10.1016/j.compmedimag.2018.08.001. Epub 2018 Aug 22.	MEDLINE	Comput Med Imaging Graph	Automatic polyp frame screening using patch based combined feature and dictionary learning.		69	Automatic polyp frame screening using patch based combined feature and dictionary learning.
The adoption of enterprise digital imaging, along with the development of quantitative imaging methods and the re-emergence of statistical learning, has opened the opportunity for more personalized cancer treatments through transformative data science research. In the last 5 years, accumulating evidence has indicated that noninvasive advanced imaging analytics (i.e., radiomics) can reveal key components of tumor phenotype for multiple lesions at multiple time points over the course of treatment. Many groups using homegrown software have extracted engineered and deep quantitative features on 3-dimensional medical images for better spatial and longitudinal understanding of tumor biology and for the prediction of diverse outcomes. These developments could augment patient stratification and prognostication, buttressing emerging targeted therapeutic approaches. Unfortunately, the rapid growth in popularity of this immature scientific discipline has resulted in many early publications that miss key information or use underpowered patient data sets, without production of generalizable results. Quantitative imaging research is complex, and key principles should be followed to realize its full potential. The fields of quantitative imaging and radiomics in particular require a renewed focus on optimal study design and reporting practices, standardization, interpretability, data sharing, and clinical trials. Standardization of image acquisition, feature calculation, and statistical analysis (i.e., machine learning) are required for the field to move forward. A new data-sharing paradigm enacted among open and diverse participants (medical institutions, vendors and associations) should be embraced for faster development and comprehensive clinical validation of imaging biomarkers. In this review and critique of the field, we propose working principles and fundamental changes to the current scientific approach, with the goal of high-impact research and development of actionable prediction models that will yield more meaningful applications of precision cancer medicine.	['Department of Radiation Oncology, University of California San Francisco, San Francisco, California. Electronic address: olivier.morin@ucsf.edu.', 'Medical Physics Unit, McGill University, Montreal, Canada.', 'The D-Lab, Grow Research Institute for Oncology, Maastricht University, Maastricht, The Netherlands.', 'The D-Lab, Grow Research Institute for Oncology, Maastricht University, Maastricht, The Netherlands.', 'Department of Radiation Oncology, University of California San Francisco, San Francisco, California.', 'Department of Radiation Oncology, University of California San Francisco, San Francisco, California.', 'Department of Radiology and Nuclear Medicine, Maastricht University Medical Center, Maastricht, The Netherlands.', 'Department of Radiology, University of California San Francisco, San Francisco, California.', 'Department of Radiation Oncology, University of California San Francisco, San Francisco, California.', 'Department of Radiation Oncology, University of California San Francisco, San Francisco, California.', 'Department of Radiation Oncology, University of California San Francisco, San Francisco, California.', 'The D-Lab, Grow Research Institute for Oncology, Maastricht University, Maastricht, The Netherlands.']	['S0360-3016(18)33638-1 [pii]', '10.1016/j.ijrobp.2018.08.032 [doi]']	['Morin O', 'Vallieres M', 'Jochems A', 'Woodruff HC', 'Valdes G', 'Braunstein SE', 'Wildberger JE', 'Villanueva-Meyer JE', 'Kearney V', 'Yom SS', 'Solberg TD', 'Lambin P']		['Copyright (c) 2018. Published by Elsevier Inc.']					['2018/09/01 06:00']	20190529	20180828	2018 Nov 15	2018/09/01 06:00		['Morin, Olivier', 'Vallieres, Martin', 'Jochems, Arthur', 'Woodruff, Henry C', 'Valdes, Gilmer', 'Braunstein, Steve E', 'Wildberger, Joachim E', 'Villanueva-Meyer, Javier E', 'Kearney, Vasant', 'Yom, Sue S', 'Solberg, Timothy D', 'Lambin, Philippe']			4		1879-355X (Electronic) 0360-3016 (Linking)	7603616	International journal of radiation oncology, biology, physics	['eng']	S0360-3016(18)33638-1 [pii] 10.1016/j.ijrobp.2018.08.032 [doi]	20190529	['Deep Learning', 'Diagnostic Imaging/*methods', 'Humans', 'Image Processing, Computer-Assisted', 'Information Dissemination', 'Neoplasms/*diagnostic imaging']	2019/05/30 06:00				NLM	1074-1082	['2018/04/27 00:00 [received]', '2018/08/21 00:00 [revised]', '2018/08/21 00:00 [accepted]', '2018/09/01 06:00 [pubmed]', '2019/05/30 06:00 [medline]', '2018/09/01 06:00 [entrez]']	United States			30170101	ppublish	['Journal Article', 'Review']			IM		Int J Radiat Oncol Biol Phys. 2018 Nov 15;102(4):1074-1082. doi: 10.1016/j.ijrobp.2018.08.032. Epub 2018 Aug 28.	MEDLINE	Int J Radiat Oncol Biol Phys	A Deep Look Into the Future of Quantitative Imaging in Oncology: A Statement of Working Principles and Proposal for Change.		102	A Deep Look Into the Future of Quantitative Imaging in Oncology: A Statement of Working Principles and Proposal for Change.
BACKGROUND: Retinopathy of prematurity (ROP) is the leading cause of childhood blindness worldwide. Automated ROP detection system is urgent and it appears to be a safe, reliable, and cost-effective complement to human experts. METHODS: An automated ROP detection system called DeepROP was developed by using Deep Neural Networks (DNNs). ROP detection was divided into ROP identification and grading tasks. Two specific DNN models, i.e., Id-Net and Gr-Net, were designed for identification and grading tasks, respectively. To develop the DNNs, large-scale datasets of retinal fundus images were constructed by labeling the images of ROP screenings by clinical ophthalmologists. FINDINGS: On the test dataset, the Id-Net achieved a sensitivity of 96.62%(95%CI, 92.29%-98.89%) and a specificity of 99.32% (95%CI, 96.29%-9.98%) for ROP identification while the Gr-Net attained sensitivity and specificity values of 88.46% (95%CI, 96.29%-99.98%) and 92.31% (95%CI, 81.46%-97.86%), respectively, on the ROP grading task. On another 552 cases, the developed DNNs outperformed some human experts. In a clinical setting, the sensitivity and specificity values of DeepROP for ROP identification were 84.91% (95%CI, 76.65%-91.12%) and 96.90% (95%CI, 95.49%-97.96%), respectively, whereas the corresponding measures for ROP grading were 93.33%(95%CI, 68.05%-99.83%) and 73.63%(95%CI, 68.05%-99.83%), respectively. INTERPRETATION: We constructed large-scale ROP datasets with adequate clinical labels and proposed novel DNN models. The DNN models can directly learn ROP features from big data. The developed DeepROP is potential to be an efficient and effective system for automated ROP screening. FUND: National Natural Science Foundation of China under Grant 61432012 and U1435213.	"['Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, PR China.', ""Department of Neonatology, Chengdu Women & Children's Central Hospital, Chengdu, PR China."", 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, PR China.', 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, PR China.', 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, PR China.', 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, PR China.', ""Department of Ophthalmology, Sichuan Academy of Medical Sciences and Sichuan Provincial People's Hospital, Chengdu, PR China."", ""Department of Ophthalmology, Sichuan Academy of Medical Sciences and Sichuan Provincial People's Hospital, Chengdu, PR China. Electronic address: zjllxx1968@163.com."", 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, PR China. Electronic address: zhangyi@scu.edu.cn.']"	['S2352-3964(18)30325-6 [pii]', '10.1016/j.ebiom.2018.08.033 [doi]']	['Wang J', 'Ju R', 'Chen Y', 'Zhang L', 'Hu J', 'Wu Y', 'Dong W', 'Zhong J', 'Yi Z']		['Copyright (c) 2018 The Authors. Published by Elsevier B.V. All rights reserved.']					['2018/09/01 06:00']	20190122	20180827	2018 Sep	2018/09/01 06:00		['Wang, Jianyong', 'Ju, Rong', 'Chen, Yuanyuan', 'Zhang, Lei', 'Hu, Junjie', 'Wu, Yu', 'Dong, Wentao', 'Zhong, Jie', 'Yi, Zhang']					2352-3964 (Electronic) 2352-3964 (Linking)	101647039	EBioMedicine	['eng']	S2352-3964(18)30325-6 [pii] 10.1016/j.ebiom.2018.08.033 [doi]	20190122	['Algorithms', '*Automation', 'Birth Weight', 'Databases as Topic', '*Deep Learning', 'Gestational Age', 'Humans', 'Image Processing, Computer-Assisted', 'Infant', 'Internet', '*Mass Screening', '*Neural Networks (Computer)', 'ROC Curve', 'Retinopathy of Prematurity/*diagnosis']	2019/01/23 06:00				NLM	361-368	['2018/05/31 00:00 [received]', '2018/07/30 00:00 [revised]', '2018/08/14 00:00 [accepted]', '2018/09/01 06:00 [pubmed]', '2019/01/23 06:00 [medline]', '2018/09/01 06:00 [entrez]']	Netherlands	PMC6156692		30166272	ppublish	['Journal Article']			IM		EBioMedicine. 2018 Sep;35:361-368. doi: 10.1016/j.ebiom.2018.08.033. Epub 2018 Aug 27.	MEDLINE	EBioMedicine	Automated retinopathy of prematurity screening using deep neural networks.		35	Automated retinopathy of prematurity screening using deep neural networks.
A fundamental challenge of biology is to understand the vast heterogeneity of cells, particularly how cellular composition, structure, and morphology are linked to cellular physiology. Unfortunately, conventional technologies are limited in uncovering these relations. We present a machine-intelligence technology based on a radically different architecture that realizes real-time image-based intelligent cell sorting at an unprecedented rate. This technology, which we refer to as intelligent image-activated cell sorting, integrates high-throughput cell microscopy, focusing, and sorting on a hybrid software-hardware data-management infrastructure, enabling real-time automated operation for data acquisition, data processing, decision-making, and actuation. We use it to demonstrate real-time sorting of microalgal and blood cells based on intracellular protein localization and cell-cell interaction from large heterogeneous populations for studying photosynthesis and atherothrombosis, respectively. The technology is highly versatile and expected to enable machine-based scientific discovery in biological, pharmaceutical, and medical sciences.	['Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan; Japan Science and Technology Agency, Saitama 332-0012, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan; Japan Science and Technology Agency, Saitama 332-0012, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya 464-8603, Japan.', 'Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo 113-8656, Japan.', 'Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya 464-8603, Japan.', 'Center for Advanced Intelligence Project, RIKEN, Tokyo 103-0027, Japan; ExaWizards Inc., Tokyo 105-0013, Japan.', 'Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo 113-8656, Japan.', 'Graduate School of Biostudies, Kyoto University, Kyoto 606-8502, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Precision Mechanics, Chuo University, Tokyo 112-8551, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Chemical Engineering, Kyushu University, Fukuoka 819-0395, Japan.', 'Department of Creative Informatics, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan; Japan Science and Technology Agency, Saitama 332-0012, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya 464-8603, Japan.', 'Department of Creative Informatics, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Bioengineering, University of California, Los Angeles, Los Angeles, CA 90095, USA.', 'Institute of Medical Science, The University of Tokyo, Tokyo 108-8639, Japan.', 'Department of Gastroenterology, Cancer Institute Hospital, Japanese Foundation for Cancer Research, Tokyo 135-8550, Japan.', 'Department of Creative Informatics, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Neurosurgery, Graduate School of Medicine, Tohoku University, Sendai 980-8577, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo 113-0033, Japan.', 'Science and Technology Unit, Natural Sciences Cluster, Kochi University, Kochi 780-8520, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan.', 'Division of Protein Engineering, Cancer Institute, Japanese Foundation for Cancer Research, Tokyo 135-8550, Japan.', 'Department of Micro Engineering, Kyoto University, Kyoto 606-8501, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo 113-0033, Japan.', 'Division of Protein Engineering, Cancer Institute, Japanese Foundation for Cancer Research, Tokyo 135-8550, Japan.', 'Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo 113-8656, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo 113-0033, Japan.', 'Center for Biosystems Dynamics Research, RIKEN, Osaka 565-0871, Japan.', 'Department of Creative Informatics, The University of Tokyo, Tokyo 113-0033, Japan.', 'Graduate School of Biostudies, Kyoto University, Kyoto 606-8502, Japan.', 'Center for Biosystems Dynamics Research, RIKEN, Osaka 565-0871, Japan.', 'Center for Advanced Intelligence Project, RIKEN, Tokyo 103-0027, Japan; Graduate School of Informatics, Kyoto University, Kyoto 606-8501, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo 113-0033, Japan.', 'Graduate School of Biostudies, Kyoto University, Kyoto 606-8502, Japan.', 'Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Rehabilitation and Regenerative Medicine, Pharmacology, Columbia University, New York, NY 10032, USA.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan; Department of Bioengineering, University of California, Los Angeles, Los Angeles, CA 90095, USA; Department of Mechanical Engineering, University of California, Los Angeles, Los Angeles, CA 90095, USA; California NanoSystems Institute, University of California, Los Angeles, Los Angeles, CA 90095, USA.', 'Graduate School of Materials Science, Nara Institute of Science and Technology, Ikoma 630-0192, Japan.', 'Department of Biological Sciences, The University of Tokyo, Tokyo 113-0033, Japan.', 'Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo 113-8656, Japan.', 'Department of Chemistry, The University of Tokyo, Tokyo 113-0033, Japan; Japan Science and Technology Agency, Saitama 332-0012, Japan; Department of Electrical Engineering, University of California, Los Angeles, Los Angeles, CA 90095, USA. Electronic address: goda@chem.s.u-tokyo.ac.jp.']	['S0092-8674(18)31044-4 [pii]', '10.1016/j.cell.2018.08.028 [doi]']	['Nitta N', 'Sugimura T', 'Isozaki A', 'Mikami H', 'Hiraki K', 'Sakuma S', 'Iino T', 'Arai F', 'Endo T', 'Fujiwaki Y', 'Fukuzawa H', 'Hase M', 'Hayakawa T', 'Hiramatsu K', 'Hoshino Y', 'Inaba M', 'Ito T', 'Karakawa H', 'Kasai Y', 'Koizumi K', 'Lee S', 'Lei C', 'Li M', 'Maeno T', 'Matsusaka S', 'Murakami D', 'Nakagawa A', 'Oguchi Y', 'Oikawa M', 'Ota T', 'Shiba K', 'Shintaku H', 'Shirasaki Y', 'Suga K', 'Suzuki Y', 'Suzuki N', 'Tanaka Y', 'Tezuka H', 'Toyokawa C', 'Yalikun Y', 'Yamada M', 'Yamagishi M', 'Yamano T', 'Yasumoto A', 'Yatomi Y', 'Yazawa M', 'Di Carlo D', 'Hosokawa Y', 'Uemura S', 'Ozeki Y', 'Goda K']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']	['Nat Methods. 2018 Nov;15(11):859. PMID: 30377354']				['2018/09/01 06:00']	20190617	20180827	2018 Sep 20	2018/09/01 06:00		['Nitta, Nao', 'Sugimura, Takeaki', 'Isozaki, Akihiro', 'Mikami, Hideharu', 'Hiraki, Kei', 'Sakuma, Shinya', 'Iino, Takanori', 'Arai, Fumihito', 'Endo, Taichiro', 'Fujiwaki, Yasuhiro', 'Fukuzawa, Hideya', 'Hase, Misa', 'Hayakawa, Takeshi', 'Hiramatsu, Kotaro', 'Hoshino, Yu', 'Inaba, Mary', 'Ito, Takuro', 'Karakawa, Hiroshi', 'Kasai, Yusuke', 'Koizumi, Kenichi', 'Lee, SangWook', 'Lei, Cheng', 'Li, Ming', 'Maeno, Takanori', 'Matsusaka, Satoshi', 'Murakami, Daichi', 'Nakagawa, Atsuhiro', 'Oguchi, Yusuke', 'Oikawa, Minoru', 'Ota, Tadataka', 'Shiba, Kiyotaka', 'Shintaku, Hirofumi', 'Shirasaki, Yoshitaka', 'Suga, Kanako', 'Suzuki, Yuta', 'Suzuki, Nobutake', 'Tanaka, Yo', 'Tezuka, Hiroshi', 'Toyokawa, Chihana', 'Yalikun, Yaxiaer', 'Yamada, Makoto', 'Yamagishi, Mai', 'Yamano, Takashi', 'Yasumoto, Atsushi', 'Yatomi, Yutaka', 'Yazawa, Masayuki', 'Di Carlo, Dino', 'Hosokawa, Yoichiroh', 'Uemura, Sotaro', 'Ozeki, Yasuyuki', 'Goda, Keisuke']			1		1097-4172 (Electronic) 0092-8674 (Linking)	0413066	Cell	['eng']	S0092-8674(18)31044-4 [pii] 10.1016/j.cell.2018.08.028 [doi]	20190617	['Animals', 'Deep Learning', 'Flow Cytometry/*methods', 'High-Throughput Screening Assays/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods']	2019/06/18 06:00		['*cellular heterogeneity', '*cellular morphology', '*convolutional neural network', '*deep learning', '*high-throughput microscopy', '*high-throughput screening', '*image-activated cell sorting', '*machine intelligence']	['NOTNLM']	NLM	266-276.e13	['2018/06/10 00:00 [received]', '2018/08/09 00:00 [revised]', '2018/08/15 00:00 [accepted]', '2018/09/01 06:00 [pubmed]', '2019/06/18 06:00 [medline]', '2018/09/01 06:00 [entrez]']	United States			30166209	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Cell. 2018 Sep 20;175(1):266-276.e13. doi: 10.1016/j.cell.2018.08.028. Epub 2018 Aug 27.	MEDLINE	Cell	Intelligent Image-Activated Cell Sorting.		175	Intelligent Image-Activated Cell Sorting.
		['10.1038/d41586-018-06030-y [doi]', '10.1038/d41586-018-06030-y [pii]']	['Beroza GC']						['Nature. 2018 Aug;560(7720):632-634. PMID: 30158606']	['2018/08/31 06:00']	20181224		2018 Aug	2018/08/31 06:00		['Beroza, Gregory C']			7720		1476-4687 (Electronic) 0028-0836 (Linking)	0410462	Nature	['eng']	10.1038/d41586-018-06030-y [doi]	20181224	['Algorithms', '*Deep Learning', '*Earthquakes', 'Forecasting', 'Machine Learning']	2018/12/26 06:00		['*Computer science', '*Geophysics', '*Solid Earth sciences']	['NOTNLM']	NLM	556-557	['2018/08/31 06:00 [entrez]', '2018/08/31 06:00 [pubmed]', '2018/12/26 06:00 [medline]']	England			30158611	ppublish	['Journal Article', 'Comment']			IM		Nature. 2018 Aug;560(7720):556-557. doi: 10.1038/d41586-018-06030-y.	MEDLINE	Nature	Machine learning improves forecasts of aftershock locations.		560	Machine learning improves forecasts of aftershock locations.
BACKGROUND: Targeting critical viral-host Protein-Protein Interactions (PPIs) has enormous application prospects for therapeutics. Using experimental methods to evaluate all possible virus-host PPIs is labor-intensive and time-consuming. Recent growth in computational identification of virus-host PPIs provides new opportunities for gaining biological insights, including applications in disease control. We provide an overview of recent computational approaches for studying virus-host PPI interactions. METHODS: In this review, a variety of computational methods for virus-host PPIs prediction have been surveyed. These methods are categorized based on the features they utilize and different machine learning algorithms including classical and novel methods. RESULTS: We describe the pivotal and representative features extracted from relevant sources of biological data, mainly include sequence signatures, known domain interactions, protein motifs and protein structure information. We focus on state-of-the-art machine learning algorithms that are used to build binary prediction models for the classification of virus-host protein pairs and discuss their abilities, weakness and future directions. CONCLUSION: The findings of this review confirm the importance of computational methods for finding the potential protein-protein interactions between virus and host. Although there has been significant progress in the prediction of virus-host PPIs in recent years, there is a lot of room for improvement in virus-host PPI prediction.	['School of Software, Central South University, Changsha, 410075, China.', 'School of Software, Central South University, Changsha, 410075, China.', 'School of Electronics and Computer Science, Zhejiang Wanli University, Ningbo 315100, China.', 'School of Software, Central South University, Changsha, 410075, China.', 'Shanghai Key Lab of Intelligent Information Processing, Shanghai 200433, China.']	['CDM-EPUB-92676 [pii]', '10.2174/1389200219666180829121038 [doi]']	['Zheng N', 'Wang K', 'Zhan W', 'Deng L']		['Copyright(c) Bentham Science Publishers; For any queries, please email at', 'epub@benthamscience.net.']					['2018/08/30 06:00']	20191127		2019	2018/08/30 06:00		['Zheng, Nantao', 'Wang, Kairou', 'Zhan, Weihua', 'Deng, Lei']			3		1875-5453 (Electronic) 1389-2002 (Linking)	100960533	Current drug metabolism	['eng']	10.2174/1389200219666180829121038 [doi]	20191127	['Algorithms', 'Host-Pathogen Interactions', 'Humans', '*Machine Learning', '*Protein Interaction Mapping', 'Proteins/*metabolism', '*Viruses']	2019/11/28 06:00		['Virus-host protein-protein interactions', 'computational methods', 'deep learning', 'feature extraction', 'feature representation', 'machine learning.']	['NOTNLM']	NLM	177-184	['2018/01/19 00:00 [received]', '2018/05/21 00:00 [revised]', '2018/08/02 00:00 [accepted]', '2018/08/30 06:00 [pubmed]', '2019/11/28 06:00 [medline]', '2018/08/30 06:00 [entrez]']	Netherlands			30156155	ppublish	['Journal Article', 'Review']		['0 (Proteins)']	IM		Curr Drug Metab. 2019;20(3):177-184. doi: 10.2174/1389200219666180829121038.	MEDLINE	Curr Drug Metab	Targeting Virus-host Protein Interactions: Feature Extraction and Machine Learning Approaches.		20	Targeting Virus-host Protein Interactions: Feature Extraction and Machine Learning Approaches.
Artificial intelligence (AI) has emerged as a major frontier in computer science research. Although AI has broad application across many medical fields, it will have particular utility in ophthalmology and will dramatically change the diagnostic and treatment pathways for many eye conditions such as corneal ectasias, glaucoma, age-related macular degeneration and diabetic retinopathy. However, given that AI has primarily been driven as a computer science, its concepts and terminology are unfamiliar to many medical professionals. Important key terms such as machine learning and deep learning are often misunderstood and incorrectly used interchangeably. This article presents an overview of AI and new developments relevant to ophthalmology.	['Centre for Eye Research Australia, Royal Victorian Eye and Ear Hospital, University of Melbourne, Melbourne, Victoria, Australia.', 'Centre for Eye Research Australia, Royal Victorian Eye and Ear Hospital, University of Melbourne, Melbourne, Victoria, Australia.', 'Lions Eye Institute, Centre for Vision Sciences, University of Western Australia, Perth, Western Australia, Australia.', 'Menzies Institute for Medical Research, University of Tasmania, Hobart, Tasmania, Australia.', 'Centre for Eye Research Australia, Royal Victorian Eye and Ear Hospital, University of Melbourne, Melbourne, Victoria, Australia.', 'Lions Eye Institute, Centre for Vision Sciences, University of Western Australia, Perth, Western Australia, Australia.', 'Menzies Institute for Medical Research, University of Tasmania, Hobart, Tasmania, Australia.']	['10.1111/ceo.13381 [doi]']	['Hogarty DT', 'Mackey DA', 'Hewitt AW']	['ORCID: 0000-0003-3206-6496']	['(c) 2018 Royal Australian and New Zealand College of Ophthalmologists.']	['Clin Exp Ophthalmol. 2019 Jan;47(1):5-6. PMID: 30485615']				['2018/08/30 06:00']		20180930	2019 Jan	2018/08/30 06:00		['Hogarty, Daniel T', 'Mackey, David A', 'Hewitt, Alex W']			1		1442-9071 (Electronic) 1442-6404 (Linking)	100896531	Clinical & experimental ophthalmology	['eng']	10.1111/ceo.13381 [doi]	20191120		2018/08/30 06:00		['*artificial intelligence', '*deep learning', '*diabetic retinopathy', '*machine learning', '*ophthalmology']	['NOTNLM']	NLM	128-139	['2018/08/15 00:00 [received]', '2018/08/25 00:00 [accepted]', '2018/08/30 06:00 [pubmed]', '2018/08/30 06:00 [medline]', '2018/08/30 06:00 [entrez]']	Australia			30155978	ppublish	['Journal Article', 'Review']			IM		Clin Exp Ophthalmol. 2019 Jan;47(1):128-139. doi: 10.1111/ceo.13381. Epub 2018 Sep 30.	In-Process	Clin Exp Ophthalmol	Current state and future prospects of artificial intelligence in ophthalmology: a review.		47	Current state and future prospects of artificial intelligence in ophthalmology: a review.
Astrocytes are involved in various brain pathologies including trauma, stroke, neurodegenerative disorders such as Alzheimer's and Parkinson's diseases, or chronic pain. Determining cell density in a complex tissue environment in microscopy images and elucidating the temporal characteristics of morphological and biochemical changes is essential to understand the role of astrocytes in physiological and pathological conditions. Nowadays, manual stereological cell counting or semi-automatic segmentation techniques are widely used for the quantitative analysis of microscopy images. Detecting astrocytes automatically is a highly challenging computational task, for which we currently lack efficient image analysis tools. We have developed a fast and fully automated software that assesses the number of astrocytes using Deep Convolutional Neural Networks (DCNN). The method highly outperforms state-of-the-art image analysis and machine learning methods and provides precision comparable to those of human experts. Additionally, the runtime of cell detection is significantly less than that of other three computational methods analysed, and it is faster than human observers by orders of magnitude. We applied our DCNN-based method to examine the number of astrocytes in different brain regions of rats with opioid-induced hyperalgesia/tolerance (OIH/OIT), as morphine tolerance is believed to activate glia. We have demonstrated a strong positive correlation between manual and DCNN-based quantification of astrocytes in rat brain.	['Laboratory of Molecular Neuroscience, Research Program in Developmental Biology, Institute of Biotechnology (HiLIFE), University of Helsinki, Viikinkaari 5D, FI-00014, Helsinki, Finland.', 'Synthetic and Systems Biology Unit, Hungarian Academy of Sciences, Biological Research Centre (BRC), Temesvari korut 62, 6726, Szeged, Hungary.', 'Research Program Unit, Helsinki Institute of Life Science (HiLIFE), Faculty of Medicine, University of Helsinki, Haartmaninkatu 8, 00014, Helsinki, Finland.', 'Synthetic and Systems Biology Unit, Hungarian Academy of Sciences, Biological Research Centre (BRC), Temesvari korut 62, 6726, Szeged, Hungary.', 'Laboratory of Molecular Neuroscience, Research Program in Developmental Biology, Institute of Biotechnology (HiLIFE), University of Helsinki, Viikinkaari 5D, FI-00014, Helsinki, Finland.', 'Laboratory of Molecular Neuroscience, Research Program in Developmental Biology, Institute of Biotechnology (HiLIFE), University of Helsinki, Viikinkaari 5D, FI-00014, Helsinki, Finland.', 'Synthetic and Systems Biology Unit, Hungarian Academy of Sciences, Biological Research Centre (BRC), Temesvari korut 62, 6726, Szeged, Hungary. horvath.peter@brc.mta.hu.', 'Institute for Molecular Medicine Finland (FIMM), University of Helsinki, Tukholmankatu 8, 00014, Helsinki, Finland. horvath.peter@brc.mta.hu.']	['10.1038/s41598-018-31284-x [doi]', '10.1038/s41598-018-31284-x [pii]']	['Suleymanova I', 'Balassa T', 'Tripathi S', 'Molnar C', 'Saarma M', 'Sidorova Y', 'Horvath P']							['2018/08/29 06:00']	20191029	20180827	2018 Aug 27	2018/08/29 06:00		['Suleymanova, Ilida', 'Balassa, Tamas', 'Tripathi, Sushil', 'Molnar, Csaba', 'Saarma, Mart', 'Sidorova, Yulia', 'Horvath, Peter']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-31284-x [doi]	20191029	['Animals', 'Area Under Curve', 'Astrocytes/*physiology', 'Humans', 'Image Processing, Computer-Assisted', 'Machine Learning', '*Models, Biological', '*Neural Networks (Computer)', 'Rats', 'Software']	2019/10/30 06:00				NLM	12878	['2018/01/19 00:00 [received]', '2018/08/10 00:00 [accepted]', '2018/08/29 06:00 [entrez]', '2018/08/29 06:00 [pubmed]', '2019/10/30 06:00 [medline]']	England	PMC6110828		30150631	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Aug 27;8(1):12878. doi: 10.1038/s41598-018-31284-x.	MEDLINE	Sci Rep	A deep convolutional neural network approach for astrocyte detection.		8	A deep convolutional neural network approach for astrocyte detection.
Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, but markers are intrusive, and the number and location of the markers must be determined a priori. Here we present an efficient method for markerless pose estimation based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in multiple species across a broad collection of behaviors. Remarkably, even when only a small number of frames are labeled (~200), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy.	['Institute for Theoretical Physics and Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls Universitat Tubingen, Tubingen, Germany.', 'Department of Molecular & Cellular Biology and Center for Brain Science, Harvard University, Cambridge, MA, USA.', 'Institute for Theoretical Physics and Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls Universitat Tubingen, Tubingen, Germany.', 'Department of Neuroscience and the Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA.', 'Department of Neuroscience and the Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA.', 'Department of Molecular & Cellular Biology and Center for Brain Science, Harvard University, Cambridge, MA, USA.', 'Institute for Theoretical Physics and Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls Universitat Tubingen, Tubingen, Germany. mackenzie@post.harvard.edu.', 'The Rowland Institute at Harvard, Harvard University, Cambridge, MA, USA. mackenzie@post.harvard.edu.', 'Institute for Theoretical Physics and Werner Reichardt Centre for Integrative Neuroscience, Eberhard Karls Universitat Tubingen, Tubingen, Germany.', 'Max Planck Institute for Biological Cybernetics, Tubingen, Germany.', 'Bernstein Center for Computational Neuroscience, Tubingen, Germany.', 'Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine, Houston, TX, USA.']	['10.1038/s41593-018-0209-y [doi]', '10.1038/s41593-018-0209-y [pii]']	['Mathis A', 'Mamidanna P', 'Cury KM', 'Abe T', 'Murthy VN', 'Mathis MW', 'Bethge M']	['ORCID: http://orcid.org/0000-0002-3777-2202', 'ORCID: http://orcid.org/0000-0003-2443-4252', 'ORCID: http://orcid.org/0000-0001-7368-4456']		['Nat Neurosci. 2018 Sep;21(9):1146-1147. PMID: 30127429', 'Lab Anim (NY). 2018 Oct;47(10):268. PMID: 30250093']				['2018/08/22 06:00']	20190515	20180820	2018 Sep	2018/08/22 06:00		['Mathis, Alexander', 'Mamidanna, Pranav', 'Cury, Kevin M', 'Abe, Taiga', 'Murthy, Venkatesh N', 'Mathis, Mackenzie Weygandt', 'Bethge, Matthias']			9		1546-1726 (Electronic) 1097-6256 (Linking)	9809671	Nature neuroscience	['eng']	10.1038/s41593-018-0209-y [doi]	20190606	['Algorithms', 'Animals', '*Behavior', '*Behavior, Animal', '*Deep Learning', 'Drosophila melanogaster', 'Humans', 'Male', 'Mice', 'Mice, Inbred C57BL', 'Nerve Net/physiology', 'Neural Networks (Computer)', 'Odorants', 'Posture', 'Psychomotor Performance/physiology', 'Transfer (Psychology)', 'Video Recording/*methods']	2019/05/16 06:00				NLM	1281-1289	['2018/04/08 00:00 [received]', '2018/06/27 00:00 [accepted]', '2018/08/22 06:00 [pubmed]', '2019/05/16 06:00 [medline]', '2018/08/22 06:00 [entrez]']	United States			30127430	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Neurosci. 2018 Sep;21(9):1281-1289. doi: 10.1038/s41593-018-0209-y. Epub 2018 Aug 20.	MEDLINE	Nat Neurosci	DeepLabCut: markerless pose estimation of user-defined body parts with deep learning.		21	DeepLabCut: markerless pose estimation of user-defined body parts with deep learning.
Pattern recognition and classification of images are key challenges throughout the life sciences. We combined two approaches for large-scale classification of fluorescence microscopy images. First, using the publicly available data set from the Cell Atlas of the Human Protein Atlas (HPA), we integrated an image-classification task into a mainstream video game (EVE Online) as a mini-game, named Project Discovery. Participation by 322,006 gamers over 1 year provided nearly 33 million classifications of subcellular localization patterns, including patterns that were not previously annotated by the HPA. Second, we used deep learning to build an automated Localization Cellular Annotation Tool (Loc-CAT). This tool classifies proteins into 29 subcellular localization patterns and can deal efficiently with multi-localization proteins, performing robustly across different cell types. Combining the annotations of gamers and deep learning, we applied transfer learning to create a boosted learner that can characterize subcellular protein distribution with F1 score of 0.72. We found that engaging players of commercial computer games provided data that augmented deep learning and enabled scalable and readily improved image classification.	['Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'CCP hf, Reyjkavik, Iceland.', 'CCP hf, Reyjkavik, Iceland.', 'CCP hf, Reyjkavik, Iceland.', 'CCP hf, Reyjkavik, Iceland.', 'Science for Life Laboratory, School of Computer Science and Communication, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'MMOS Sarl, Monthey, Switzerland.', 'CCP hf, Reyjkavik, Iceland.', 'MMOS Sarl, Monthey, Switzerland.', 'Science for Life Laboratory, School of Engineering Sciences in Chemistry, Biotechnology and Health, KTH - Royal Institute of Technology, Stockholm, Sweden.', 'Department of Genetics, Stanford University, Stanford, California, USA.', 'Chan Zuckerberg Biohub, San Francisco, San Francisco, California, USA.']	['nbt.4225 [pii]', '10.1038/nbt.4225 [doi]']	['Sullivan DP', 'Winsnes CF', 'Akesson L', 'Hjelmare M', 'Wiking M', 'Schutten R', 'Campbell L', 'Leifsson H', 'Rhodes S', 'Nordgren A', 'Smith K', 'Revaz B', 'Finnbogason B', 'Szantner A', 'Lundberg E']	['ORCID: 0000-0001-6176-108X', 'ORCID: 0000-0002-0028-5865']						['2018/08/21 06:00']	20190429	20180820	2018 Oct	2018/08/21 06:00		['Sullivan, Devin P', 'Winsnes, Casper F', 'Akesson, Lovisa', 'Hjelmare, Martin', 'Wiking, Mikaela', 'Schutten, Rutger', 'Campbell, Linzi', 'Leifsson, Hjalti', 'Rhodes, Scott', 'Nordgren, Andie', 'Smith, Kevin', 'Revaz, Bernard', 'Finnbogason, Bergur', 'Szantner, Attila', 'Lundberg, Emma']			9		1546-1696 (Electronic) 1087-0156 (Linking)	9604648	Nature biotechnology	['eng']	10.1038/nbt.4225 [doi]	20190429	['*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Microscopy, Fluorescence', 'Subcellular Fractions/metabolism']	2019/04/30 06:00				NLM	820-828	['2017/12/24 00:00 [received]', '2018/07/19 00:00 [accepted]', '2018/08/21 06:00 [pubmed]', '2019/04/30 06:00 [medline]', '2018/08/21 06:00 [entrez]']	United States			30125267	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Biotechnol. 2018 Oct;36(9):820-828. doi: 10.1038/nbt.4225. Epub 2018 Aug 20.	MEDLINE	Nat Biotechnol	Deep learning is combined with massive-scale citizen science to improve large-scale image classification.		36	Deep learning is combined with massive-scale citizen science to improve large-scale image classification.
BACKGROUND: Drug discovery, which is the process of discovering new candidate medications, is very important for pharmaceutical industries. At its current stage, discovering new drugs is still a very expensive and time-consuming process, requiring Phases I, II and III for clinical trials. Recently, machine learning techniques in Artificial Intelligence (AI), especially the deep learning techniques which allow a computational model to generate multiple layers, have been widely applied and achieved state-of-the-art performance in different fields, such as speech recognition, image classification, bioinformatics, etc. One very important application of these AI techniques is in the field of drug discovery. METHODS: We did a large-scale literature search on existing scientific websites (e.g, ScienceDirect, Arxiv) and startup companies to understand current status of machine learning techniques in drug discovery. RESULTS: Our experiments demonstrated that there are different patterns in machine learning fields and drug discovery fields. For example, keywords like prediction, brain, discovery, and treatment are usually in drug discovery fields. Also, the total number of papers published in drug discovery fields with machine learning techniques is increasing every year. CONCLUSION: The main focus of this survey is to understand the current status of machine learning techniques in the drug discovery field within both academic and industrial settings, and discuss its potential future applications. Several interesting patterns for machine learning techniques in drug discovery fields are discussed in this survey.	['Department of Computer Science, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Department of Computer Science, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Department of Computer Science, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Department of Computer Science, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Department of Computer Science, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Department of Mathematics, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Key Laboratory of Hebei Province for Plant Physiology and Molecular Pathology, College of Life Sciences, Hebei Agricultural University, Baoding, China.', 'School of Business, Pacific Lutheran University, Tacoma, WA 98447, United States.', 'Department of Computer Science, Pacific Lutheran University, Tacoma, WA 98447, United States.']	['CDM-EPUB-92486 [pii]', '10.2174/1389200219666180820112457 [doi]']	['Stephenson N', 'Shane E', 'Chase J', 'Rowland J', 'Ries D', 'Justice N', 'Zhang J', 'Chan L', 'Cao R']		['Copyright(c) Bentham Science Publishers; For any queries, please email at', 'epub@benthamscience.net.']					['2018/08/21 06:00']	20191127		2019	2018/08/21 06:00		['Stephenson, Natalie', 'Shane, Emily', 'Chase, Jessica', 'Rowland, Jason', 'Ries, David', 'Justice, Nicola', 'Zhang, Jie', 'Chan, Leong', 'Cao, Renzhi']			3		1875-5453 (Electronic) 1389-2002 (Linking)	100960533	Current drug metabolism	['eng']	10.2174/1389200219666180820112457 [doi]	20191127	['Computational Biology/methods', '*Drug Discovery', 'Drug Industry', 'Humans', '*Machine Learning', 'Surveys and Questionnaires']	2019/11/28 06:00		['Drug discovery', 'artificial intelligence', 'deep learning', 'drug development', 'machine learning', 'pharmacology.']	['NOTNLM']	NLM	185-193	['2017/09/06 00:00 [received]', '2018/01/01 00:00 [revised]', '2018/03/19 00:00 [accepted]', '2018/08/21 06:00 [pubmed]', '2019/11/28 06:00 [medline]', '2018/08/21 06:00 [entrez]']	Netherlands			30124147	ppublish	['Journal Article', 'Review']			IM		Curr Drug Metab. 2019;20(3):185-193. doi: 10.2174/1389200219666180820112457.	MEDLINE	Curr Drug Metab	Survey of Machine Learning Techniques in Drug Discovery.		20	Survey of Machine Learning Techniques in Drug Discovery.
In recent decades, artificial intelligence and machine learning have played a significant role in increasing the efficiency of processes across a wide spectrum of industries. When it comes to the pharmaceutical and biotechnology sectors, numerous tools enabled by advancement of computer science have been developed and are now routinely utilized. However, there are many aspects of the drug discovery process, which can further benefit from refinement of computational methods and tools, as well as improvement of accessibility of these new technologies. In this review, examples of recent developments in machine learning application are described, which have the potential to impact different parts of the drug discovery and development flow scheme. Notably, new deep learning-based approaches across compound design and synthesis, prediction of binding, activity and ADMET properties, as well as applications of genetic algorithms are highlighted.	['Amgen Discovery Research, 360 Binney St., Cambridge, MA 02141, USA.', 'Amgen Discovery Research, 360 Binney St., Cambridge, MA 02141, USA.', 'Amgen Discovery Research, One Amgen Center Dr., Thousand Oaks, CA 91320, USA. Electronic address: ljia@amgen.com.']	['S0960-894X(18)30547-X [pii]', '10.1016/j.bmcl.2018.06.046 [doi]']	['Panteleev J', 'Gao H', 'Jia L']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/08/21 06:00']	20190311	20180628	2018 Sep 15	2018/08/21 06:00		['Panteleev, Jane', 'Gao, Hua', 'Jia, Lei']			17		1464-3405 (Electronic) 0960-894X (Linking)	9107377	Bioorganic & medicinal chemistry letters	['eng']	S0960-894X(18)30547-X [pii] 10.1016/j.bmcl.2018.06.046 [doi]	20190311	['Animals', 'Chemistry, Pharmaceutical', 'Humans', '*Machine Learning', 'Models, Molecular', 'Quantitative Structure-Activity Relationship']	2019/03/12 06:00				NLM	2807-2815	['2018/04/10 00:00 [received]', '2018/06/24 00:00 [revised]', '2018/06/26 00:00 [accepted]', '2018/08/21 06:00 [entrez]', '2018/08/21 06:00 [pubmed]', '2019/03/12 06:00 [medline]']	England			30122222	ppublish	['Journal Article', 'Review']			IM		Bioorg Med Chem Lett. 2018 Sep 15;28(17):2807-2815. doi: 10.1016/j.bmcl.2018.06.046. Epub 2018 Jun 28.	MEDLINE	Bioorg Med Chem Lett	Recent applications of machine learning in medicinal chemistry.		28	Recent applications of machine learning in medicinal chemistry.
The displacement of the hyoid bone is one of the key components evaluated in the swallow study, as its motion during swallowing is related to overall swallowing integrity. In daily research settings, experts visually detect the hyoid bone in the video frames and manually plot hyoid bone position frame by frame. This study aims to develop an automatic method to localize the location of the hyoid bone in the video sequence. To automatically detect the location of the hyoid bone in a frame, we proposed a single shot multibox detector, a deep convolutional neural network, which is employed to detect and classify the location of the hyoid bone. We also evaluated the performance of two other state-of-art detection methods for comparison. The experimental results clearly showed that the single shot multibox detector can detect the hyoid bone with an average precision of 89.14% and outperform other auto-detection algorithms. We conclude that this automatic hyoid bone tracking system is accurate enough to be widely applied as a pre-processing step for image processing in dysphagia research, as well as a promising development that may be useful in the diagnosis of dysphagia.	['Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA, 15261, USA.', 'Department of Communication Science and Disorders, University of Pittsburgh, Pittsburgh, PA, 15260, USA.', 'Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA, 15261, USA. esejdic@ieee.org.']	['10.1038/s41598-018-30182-6 [doi]', '10.1038/s41598-018-30182-6 [pii]']	['Zhang Z', 'Coyle JL', 'Sejdic E']	['ORCID: 0000-0001-7215-0858']						['2018/08/19 06:00']	20191018	20180817	2018 Aug 17	2018/08/19 06:00		['Zhang, Zhenwei', 'Coyle, James L', 'Sejdic, Ervin']		['R01 HD074819/HD/NICHD NIH HHS/United States', 'R01 HD092239/HD/NICHD NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-30182-6 [doi]	20191018	['Adult', 'Aged', 'Aged, 80 and over', '*Deep Learning', 'Female', 'Fluoroscopy/*methods', 'Humans', 'Hyoid Bone/*diagnostic imaging', 'Image Processing, Computer-Assisted', 'Male', 'Middle Aged', 'Models, Theoretical', 'Young Adult']	2019/10/19 06:00				NLM	12310	['2018/02/15 00:00 [received]', '2018/07/25 00:00 [accepted]', '2018/08/19 06:00 [entrez]', '2018/08/19 06:00 [pubmed]', '2019/10/19 06:00 [medline]']	England	PMC6097989		30120314	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Sci Rep. 2018 Aug 17;8(1):12310. doi: 10.1038/s41598-018-30182-6.	MEDLINE	Sci Rep	Automatic hyoid bone detection in fluoroscopic images using deep learning.		8	Automatic hyoid bone detection in fluoroscopic images using deep learning.
BACKGROUND AND OBJECTIVE: Congenital anomalies are seen at 1-3% of the population, probabilities of which are tried to be found out primarily through double, triple and quad tests during pregnancy. Also, ultrasonographical evaluations of fetuses enhance detecting and defining these abnormalities. About 60-70% of the anomalies can be diagnosed via ultrasonography, while the remaining 30-40% can be diagnosed after childbirth. Medical diagnosis and prediction is a topic that is closely related with e-Health and machine learning. e-Health applications are critically important especially for the patients unable to see a doctor or any health professional. Our objective is to help clinicians and families to better predict fetal congenital anomalies besides the traditional pregnancy tests using machine learning techniques and e-Health applications. METHODS: In this work, we developed a prediction system with assistive e-Health applications which both the pregnant women and practitioners can make use of. A performance comparison (considering Accuracy, F1-Score, AUC measures) was made between 9 binary classification models (Averaged Perceptron, Boosted Decision Tree, Bayes Point Machine, Decision Forest, Decision Jungle, Locally-Deep Support Vector Machine, Logistic Regression, Neural Network, Support Vector Machine) which were trained with the clinical dataset of 96 pregnant women and used to process data to predict fetal anomaly status based on the maternal and clinical data. The dataset was obtained through maternal questionnaire and detailed evaluations of 3 clinicians from RadyoEmar radiodiagnostics center in Istanbul, Turkey. Our e-Health applications are used to get pregnant women's health status and clinical history parameters as inputs, recommend them physical activities to perform during pregnancy, and inform the practitioners and finally the patients about possible risks of fetal anomalies as the output. RESULTS: In this paper, the highest accuracy of prediction was displayed as 89.5% during the development tests with Decision Forest model. In real life testing with 16 users, the performance was 87.5%. This estimate is sufficient to give an idea of fetal health before the patient visits the physician. CONCLUSIONS: The proposed work aims to provide assistive services to pregnant women and clinicians via an online system consisting of a mobile side for the patients, a web application side for their clinicians and a prediction system. In addition, we showed the impact of certain clinical data parameters of pregnant on the fetal health status, statistically correlated the parameters with the existence of fetal anomalies and showed guidelines for future researches.	['Department of Computer Science, North Carolina State University, Raleigh, NC 27606, USA; Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul 34156, Turkey. Electronic address: aakbulu@ncsu.edu.', 'Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul 34156, Turkey. Electronic address: 1401020030@stu.iku.edu.tr.', 'Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul 34156, Turkey. Electronic address: 1600006916@stu.iku.edu.tr.']	['S0169-2607(18)30238-4 [pii]', '10.1016/j.cmpb.2018.06.010 [doi]']	['Akbulut A', 'Ertugrul E', 'Topcu V']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/08/19 06:00']	20181127	20180614	2018 Sep	2018/08/19 06:00		['Akbulut, Akhan', 'Ertugrul, Egemen', 'Topcu, Varol']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30238-4 [pii] 10.1016/j.cmpb.2018.06.010 [doi]	20181127	['Algorithms', 'Area Under Curve', 'Bayes Theorem', 'Congenital Abnormalities/*diagnosis', 'Decision Trees', 'Diagnosis, Computer-Assisted/*methods', 'Female', 'Fetus/*physiology', 'Health Status', 'Humans', 'Internet', 'Logistic Models', '*Machine Learning', 'Mobile Applications', 'Perception', 'Pregnancy', 'ROC Curve', 'Regression Analysis', 'Reproducibility of Results', 'Support Vector Machine', 'Telemedicine', 'Ultrasonography, Prenatal']	2018/11/28 06:00		['Fetal health', 'Machine learning', 'Medical diagnosis', 'Pregnancy', 'Prognosis', 'Risk prediction', 'm-Health']	['NOTNLM']	NLM	87-100	['2018/02/18 00:00 [received]', '2018/05/19 00:00 [revised]', '2018/06/08 00:00 [accepted]', '2018/08/19 06:00 [entrez]', '2018/08/19 06:00 [pubmed]', '2018/11/28 06:00 [medline]']	Ireland			30119860	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Sep;163:87-100. doi: 10.1016/j.cmpb.2018.06.010. Epub 2018 Jun 14.	MEDLINE	Comput Methods Programs Biomed	Fetal health status prediction based on maternal clinical history using machine learning techniques.		163	Fetal health status prediction based on maternal clinical history using machine learning techniques.
It has been long established that cis conformations of amino acid residues play many biologically important roles despite their rare occurrence in protein structure. Because of this rarity, few methods have been developed for predicting cis isomers from protein sequences, most of which are based on outdated datasets and lack the means for independent testing. In this work, using a database of >10000 high-resolution protein structures, we update the statistics of cis isomers and develop a sequence-based prediction technique using an ensemble of residual convolutional and long short-term memory bidirectional recurrent neural networks that allow learning from the whole protein sequence. We show that ensembling eight neural network models yields maximum Matthews correlation coefficient values of approximately 0.35 for cis-Pro isomers and 0.1 for cis-nonPro residues. The method should be useful for prioritizing functionally important residues in cis isomers for experimental validations and improving the sampling of rare protein conformations for ab initio protein structure prediction.	['Signal Processing Laboratory , Griffith University , Brisbane , QLD 4122 , Australia.', 'Signal Processing Laboratory , Griffith University , Brisbane , QLD 4122 , Australia.', 'Signal Processing Laboratory , Griffith University , Brisbane , QLD 4122 , Australia.', 'Signal Processing Laboratory , Griffith University , Brisbane , QLD 4122 , Australia.', 'Institute for Glycomics and School of Information and Communication Technology , Griffith University , Southport , QLD 4222 , Australia.', 'School of Data and Computer Science , Sun Yat-Sen University , Guangzhou , Guangdong 510006 , China.', 'Institute for Glycomics and School of Information and Communication Technology , Griffith University , Southport , QLD 4222 , Australia.']	['10.1021/acs.jcim.8b00442 [doi]']	['Singh J', 'Hanson J', 'Heffernan R', 'Paliwal K', 'Yang Y', 'Zhou Y']	['ORCID: 0000-0001-6956-6748', 'ORCID: 0000-0002-9958-5699']						['2018/08/18 06:00']	20191021	20180829	2018 Sep 24	2018/08/18 06:00		['Singh, Jaswinder', 'Hanson, Jack', 'Heffernan, Rhys', 'Paliwal, Kuldip', 'Yang, Yuedong', 'Zhou, Yaoqi']			9		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.8b00442 [doi]	20191022	['Amino Acid Sequence', '*Machine Learning', 'Proline/*chemistry', 'Proteins/*chemistry']	2019/10/23 06:00				NLM	2033-2042	['2018/08/18 06:00 [pubmed]', '2019/10/23 06:00 [medline]', '2018/08/18 06:00 [entrez]']	United States			30118602	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)', '9DLQ4CIU6V (Proline)']	IM		J Chem Inf Model. 2018 Sep 24;58(9):2033-2042. doi: 10.1021/acs.jcim.8b00442. Epub 2018 Aug 29.	MEDLINE	J Chem Inf Model	Detecting Proline and Non-Proline Cis Isomers in Protein Structures from Sequences Using Deep Residual Ensemble Learning.		58	Detecting Proline and Non-Proline Cis Isomers in Protein Structures from Sequences Using Deep Residual Ensemble Learning.
The global burden of cancer, severe diagnostic bottlenecks in underserved regions, and underfunded health care systems are fueling the need for inexpensive, rapid, and treatment-informative diagnostics. On the basis of advances in computational optics and deep learning, we have developed a low-cost digital system, termed AIDA (artificial intelligence diffraction analysis), for breast cancer diagnosis of fine needle aspirates. Here, we show high accuracy (>90%) in (i) recognizing cells directly from diffraction patterns and (ii) classifying breast cancer types using deep-learning-based analysis of sample aspirates. The image algorithm is fast, enabling cellular analyses at high throughput ( approximately 3 s per 1000 cells), and the unsupervised processing allows use by lower skill health care workers. AIDA can perform quantitative molecular profiling on individual cells, revealing intratumor molecular heterogeneity, and has the potential to improve cancer diagnosis and treatment. The system could be further developed for other cancers and thus find widespread use in global health.	['Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Department of Radiology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Department of Electrical Engineering and Computer Science , Massachusetts Institute of Technology , Cambridge , Massachusetts 02139 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Department of Systems Biology , Harvard Medical School , Boston , Massachusetts 02115 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'BreastCare Center, Division of Hematology Oncology , Beth Israel Deaconess Medical Center , Boston , Massachusetts 02115 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Massachusetts General Hospital Cancer Center , Boston , Massachusetts 02114 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Department of Radiology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Department of Systems Biology , Harvard Medical School , Boston , Massachusetts 02115 , United States.', 'Center for Systems Biology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.', 'Department of Radiology , Massachusetts General Hospital , Boston , Massachusetts 02114 , United States.']	['10.1021/acsnano.8b03029 [doi]']	['Min J', 'Im H', 'Allen M', 'McFarland PJ', 'Degani I', 'Yu H', 'Normandin E', 'Pathania D', 'Patel JM', 'Castro CM', 'Weissleder R', 'Lee H']	['ORCID: 0000-0002-6737-7254', 'ORCID: 0000-0002-0626-1346', 'ORCID: 0000-0003-0828-4143', 'ORCID: 0000-0002-0087-0909']						['2018/08/17 06:00']	20191007	20180820	2018 Sep 25	2018/08/17 06:00		['Min, Jouha', 'Im, Hyungsoon', 'Allen, Matthew', 'McFarland, Phillip J', 'Degani, Ismail', 'Yu, Hojeong', 'Normandin, Erica', 'Pathania, Divya', 'Patel, Jaymin M', 'Castro, Cesar M', 'Weissleder, Ralph', 'Lee, Hakho']		['UH2 CA202637/CA/NCI NIH HHS/United States', 'T32 CA079443/CA/NCI NIH HHS/United States', 'R21 CA205322/CA/NCI NIH HHS/United States', 'R01 CA229777/CA/NCI NIH HHS/United States', 'R00 CA201248/CA/NCI NIH HHS/United States', 'UH3 CA202637/CA/NCI NIH HHS/United States', 'R01 HL113156/HL/NHLBI NIH HHS/United States', 'U01 CA233360/CA/NCI NIH HHS/United States']	9		1936-086X (Electronic) 1936-0851 (Linking)	101313589	ACS nano	['eng']	10.1021/acsnano.8b03029 [doi]	20191007	['Algorithms', 'Biopsy, Fine-Needle', 'Breast Neoplasms/*diagnostic imaging', 'Cell Line, Tumor', '*Deep Learning', 'Female', 'Humans', '*Image Processing, Computer-Assisted', '*Point-of-Care Systems']	2019/10/08 06:00	['NIHMS1022952']	['*artificial intelligence', '*breast cancer', '*deep learning', '*diagnostics', '*global health']	['NOTNLM']	NLM	9081-9090	['2018/08/17 06:00 [pubmed]', '2019/10/08 06:00 [medline]', '2018/08/17 06:00 [entrez]']	United States	PMC6519708		30113824	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		ACS Nano. 2018 Sep 25;12(9):9081-9090. doi: 10.1021/acsnano.8b03029. Epub 2018 Aug 20.	MEDLINE	ACS Nano	Computational Optics Enables Breast Cancer Profiling in Point-of-Care Settings.		12	Computational Optics Enables Breast Cancer Profiling in Point-of-Care Settings.
"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by persistent difficulties including repetitive patterns of behavior known as stereotypical motor movements (SMM). So far, several techniques have been implemented to track and identify SMMs. In this context, we propose a deep learning approach for SMM recognition, namely, convolutional neural networks (CNN) in time and frequency-domains. To solve the intrasubject SMM variability, we propose a robust CNN model for SMM detection within subjects, whose parameters are set according to a proper analysis of SMM signals, thereby outperforming state-of-the-art SMM classification works. And, to solve the intersubject variability, we propose a global, fast, and light-weight framework for SMM detection across subjects which combines a knowledge transfer technique with an SVM classifier, therefore resolving the ""real-life"" medical issue associated with the lack of supervised SMMs per testing subject in particular. We further show that applying transfer learning across domains instead of transfer learning within the same domain also generalizes to the SMM target domain, thus alleviating the problem of the lack of supervised SMMs in general."	['Faculty of Science and Technology, University Hassan 1, Settat, Morocco.', 'Faculty of Science and Technology, University Hassan 1, Settat, Morocco.', 'Faculty of Science and Technology, University Hassan 1, Settat, Morocco.']	['10.1155/2018/7186762 [doi]']	['Sadouk L', 'Gadi T', 'Essoufi EH']	['ORCID: 0000-0001-6545-3412']						['2018/08/17 06:00']	20181025	20180710	2018	2018/08/17 06:00		['Sadouk, Lamyaa', 'Gadi, Taoufiq', 'Essoufi, El Hassan']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2018/7186762 [doi]	20181114	['Accelerometry/instrumentation/methods', 'Autism Spectrum Disorder/*diagnosis/physiopathology', 'Biomechanical Phenomena', 'Diagnosis, Computer-Assisted/*methods', 'Humans', '*Movement', 'Neural Networks (Computer)', 'Pattern Recognition, Automated/methods', 'Periodicity', '*Stereotyped Behavior', 'Support Vector Machine', 'Wireless Technology']	2018/10/26 06:00				NLM	7186762	['2018/03/28 00:00 [received]', '2018/06/10 00:00 [accepted]', '2018/08/17 06:00 [entrez]', '2018/08/17 06:00 [pubmed]', '2018/10/26 06:00 [medline]']	United States	PMC6077579		30111994	epublish	['Journal Article']			IM		Comput Intell Neurosci. 2018 Jul 10;2018:7186762. doi: 10.1155/2018/7186762. eCollection 2018.	MEDLINE	Comput Intell Neurosci	A Novel Deep Learning Approach for Recognizing Stereotypical Motor Movements within and across Subjects on the Autism Spectrum Disorder.		2018	A Novel Deep Learning Approach for Recognizing Stereotypical Motor Movements within and across Subjects on the Autism Spectrum Disorder.
The recent explosion of 'big data' has ushered in a new era of artificial intelligence (AI) algorithms in every sphere of technological activity, including medicine, and in particular radiology. However, the recent success of AI in certain flagship applications has, to some extent, masked decades-long advances in computational technology development for medical image analysis. In this article, we provide an overview of the history of AI methods for radiological image analysis in order to provide a context for the latest developments. We review the functioning, strengths and limitations of more classical methods as well as of the more recent deep learning techniques. We discuss the unique characteristics of medical data and medical science that set medicine apart from other technological domains in order to highlight not only the potential of AI in radiology but also the very real and often overlooked constraints that may limit the applicability of certain AI methods. Finally, we provide a comprehensive perspective on the potential impact of AI on radiology and on how to evaluate it not only from a technical point of view but also from a clinical one, so that patients can ultimately benefit from it. KEY POINTS: * Artificial intelligence (AI) research in medical imaging has a long history * The functioning, strengths and limitations of more classical AI methods is reviewed, together with that of more recent deep learning methods. * A perspective is provided on the potential impact of AI on radiology and on its evaluation from both technical and clinical points of view.	['Department of Diagnostic Radiology, McGill University, Montreal, QC, Canada.', 'Department of Diagnostic Radiology, McGill University, Montreal, QC, Canada.', 'Department of Diagnostic Radiology, McGill University Health Centre, Montreal, QC, Canada.', 'Department of Diagnostic Radiology, McGill University, Montreal, QC, Canada.', 'Department of Diagnostic Radiology, McGill University Health Centre, Montreal, QC, Canada.', 'Department of Body & Interventional Imaging, Hopital Lariboisiere-AP-HP, Universite Diderot-Paris 7 and INSERM U965, 75475, Paris Cedex 10, France.', 'Ecole CentraleSupelec, 91190, Gif-sur-Yvette, France.', 'Inria Saclay/Ile-de-France, 91120, Palaiseau, France.', 'Department of Diagnostic Radiology, McGill University, Montreal, QC, Canada.', 'Department of Diagnostic Radiology, McGill University Health Centre, Montreal, QC, Canada.', 'Ecole CentraleSupelec, 91190, Gif-sur-Yvette, France.', 'TheraPanacea, 75014, Paris, France.', 'Department of Diagnostic Radiology, McGill University, Montreal, QC, Canada. benoit.gallix@mcgill.ca.', 'Department of Diagnostic Radiology, McGill University Health Centre, Montreal, QC, Canada. benoit.gallix@mcgill.ca.']	['10.1007/s00330-018-5674-x [doi]', '10.1007/s00330-018-5674-x [pii]']	['Savadjiev P', 'Chong J', 'Dohan A', 'Vakalopoulou M', 'Reinhold C', 'Paragios N', 'Gallix B']							['2018/08/15 06:00']	20190325	20180813	2019 Mar	2018/08/15 06:00		['Savadjiev, Peter', 'Chong, Jaron', 'Dohan, Anthony', 'Vakalopoulou, Maria', 'Reinhold, Caroline', 'Paragios, Nikos', 'Gallix, Benoit']			3		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-018-5674-x [doi]	20190325	['Algorithms', 'Artificial Intelligence/*trends', 'Deep Learning', 'Forecasting', 'Humans', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Technology, Radiologic/*trends']	2019/03/26 06:00		['Artificial intelligence (AI)', 'Computer-assisted image interpretation', 'Computer-assisted image processing', 'Diagnostic imaging', 'Machine learning']	['NOTNLM']	NLM	1616-1624	['2018/06/15 00:00 [received]', '2018/07/17 00:00 [accepted]', '2018/07/05 00:00 [revised]', '2018/08/15 06:00 [pubmed]', '2019/03/26 06:00 [medline]', '2018/08/15 06:00 [entrez]']	Germany			30105410	ppublish	['Journal Article', 'Review']			IM		Eur Radiol. 2019 Mar;29(3):1616-1624. doi: 10.1007/s00330-018-5674-x. Epub 2018 Aug 13.	MEDLINE	Eur Radiol	Demystification of AI-driven medical image interpretation: past, present and future.		29	Demystification of AI-driven medical image interpretation: past, present and future.
MAIN CONCLUSION: Deep learning is a promising technology to accurately select individuals with high phenotypic values based on genotypic data. Genomic selection (GS) is a promising breeding strategy by which the phenotypes of plant individuals are usually predicted based on genome-wide markers of genotypes. In this study, we present a deep learning method, named DeepGS, to predict phenotypes from genotypes. Using a deep convolutional neural network, DeepGS uses hidden variables that jointly represent features in genotypes when making predictions; it also employs convolution, sampling and dropout strategies to reduce the complexity of high-dimensional genotypic data. We used a large GS dataset to train DeepGS and compared its performance with other methods. The experimental results indicate that DeepGS can be used as a complement to the commonly used RR-BLUP in the prediction of phenotypes from genotypes. The complementarity between DeepGS and RR-BLUP can be utilized using an ensemble learning approach for more accurately selecting individuals with high phenotypic values, even for the absence of outlier individuals and subsets of genotypic markers. The source codes of DeepGS and the ensemble learning approach have been packaged into Docker images for facilitating their applications in different GS programs.	['State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China.', 'State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China.', 'State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China.', 'State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China.', 'State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China. cma@nwafu.edu.cn.', 'Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China. cma@nwafu.edu.cn.']	['10.1007/s00425-018-2976-9 [doi]', '10.1007/s00425-018-2976-9 [pii]']	['Ma W', 'Qiu Z', 'Song J', 'Li J', 'Cheng Q', 'Zhai J', 'Ma C']	['ORCID: http://orcid.org/0000-0001-9612-7898']						['2018/08/14 06:00']	20181025	20180812	2018 Nov	2018/08/14 06:00		['Ma, Wenlong', 'Qiu, Zhixu', 'Song, Jie', 'Li, Jiajia', 'Cheng, Qian', 'Zhai, Jingjing', 'Ma, Chuang']		['31570371/National Natural Science Foundation of China', '2015NY011/the Agricultural Science and Technology Innovation and Research Project', 'of Shaanxi Province, China', '2017KJXX-67/the Innovative Talents Promotion Project of Shaanxi Province of China']	5		1432-2048 (Electronic) 0032-0935 (Linking)	1250576	Planta	['eng']	10.1007/s00425-018-2976-9 [doi]	20181114	['Genetic Association Studies/*methods', 'Genome-Wide Association Study/methods', 'Machine Learning', 'Models, Genetic', '*Neural Networks (Computer)', 'Plants/*genetics', 'Selection, Genetic']	2018/10/26 06:00		['Deep learning', 'Ensemble learning', 'Genomic selection', 'Genotypic marker', 'High phenotypic values', 'Machine learning']	['NOTNLM']	NLM	1307-1318	['2018/04/09 00:00 [received]', '2018/07/11 00:00 [accepted]', '2018/08/14 06:00 [pubmed]', '2018/10/26 06:00 [medline]', '2018/08/14 06:00 [entrez]']	Germany			30101399	ppublish	['Journal Article']			IM		Planta. 2018 Nov;248(5):1307-1318. doi: 10.1007/s00425-018-2976-9. Epub 2018 Aug 12.	MEDLINE	Planta	A deep convolutional neural network approach for predicting phenotypes from genotypes.		248	A deep convolutional neural network approach for predicting phenotypes from genotypes.
OBJECTIVE: We evaluated whether deep learning applied to whole-brain presurgical structural connectomes could be used to predict postoperative seizure outcome more accurately than inference from clinical variables in patients with mesial temporal lobe epilepsy (TLE). METHODS: Fifty patients with unilateral TLE were classified either as having persistent disabling seizures (SZ) or becoming seizure-free (SZF) at least 1 year after epilepsy surgery. Their presurgical structural connectomes were reconstructed from whole-brain diffusion tensor imaging. A deep network was trained based on connectome data to classify seizure outcome using 5-fold cross-validation. RESULTS: Classification accuracy of our trained neural network showed positive predictive value (PPV; seizure freedom) of 88 +/- 7% and mean negative predictive value (NPV; seizure refractoriness) of 79 +/- 8%. Conversely, a classification model based on clinical variables alone yielded <50% accuracy. The specific features that contributed to high accuracy classification of the neural network were located not only in the ipsilateral temporal and extratemporal regions, but also in the contralateral hemisphere. SIGNIFICANCE: Deep learning demonstrated to be a powerful statistical approach capable of isolating abnormal individualized patterns from complex datasets to provide a highly accurate prediction of seizure outcomes after surgery. Features involved in this predictive model were both ipsilateral and contralateral to the clinical foci and spanned across limbic and extralimbic networks.	['Department of Neurology, Medical University of South Carolina, Charleston, South Carolina.', 'Department of Computer Science, College of Charleston, Charleston, South Carolina.', 'Department of Neurology, Medical University of South Carolina, Charleston, South Carolina.', 'Department of Neurosurgery, Medical University of South Carolina, Charleston, South Carolina.', 'Department of Psychology, University of South Carolina, Columbia, South Carolina.', 'Department of Psychology, University of California, San Diego, San Diego, California.', 'Department of Neurology, Medical University of South Carolina, Charleston, South Carolina.', 'Department of Neurology, Hofstra Northwell School of Medicine, Great Neck, New York.', 'Department of Neurology, Medical University of South Carolina, Charleston, South Carolina.']	['10.1111/epi.14528 [doi]']	['Gleichgerrcht E', 'Munsell B', 'Bhatia S', 'Vandergrift WA 3rd', 'Rorden C', 'McDonald C', 'Edwards J', 'Kuzniecky R', 'Bonilha L']	['ORCID: 0000-0002-4212-4146']	['Wiley Periodicals, Inc. (c) 2018 International League Against Epilepsy.']					['2018/08/12 06:00']	20190215	20180810	2018 Sep	2018/08/12 06:00		['Gleichgerrcht, Ezequiel', 'Munsell, Brent', 'Bhatia, Sonal', 'Vandergrift, William A 3rd', 'Rorden, Chris', 'McDonald, Carrie', 'Edwards, Jonathan', 'Kuzniecky, Ruben', 'Bonilha, Leonardo']			9		1528-1167 (Electronic) 0013-9580 (Linking)	2983306R	Epilepsia	['eng']	10.1111/epi.14528 [doi]	20190215	['Adult', 'Brain/diagnostic imaging/*physiopathology/surgery', 'Connectome/*methods', '*Deep Learning', 'Electroencephalography', 'Epilepsy/*surgery', 'Female', 'Humans', 'Image Processing, Computer-Assisted', 'Magnetic Resonance Imaging', 'Male', 'Middle Aged', 'Neural Pathways', 'Outcome Assessment (Health Care)/classification/*methods', 'Retrospective Studies', 'Young Adult']	2019/02/16 06:00		['*connectome', '*deep learning', '*diffusion tensor imaging', '*neural networks', '*structural connectivity', '*temporal lobe epilepsy']	['NOTNLM']	NLM	1643-1654	['2018/04/09 00:00 [received]', '2018/07/14 00:00 [revised]', '2018/07/15 00:00 [accepted]', '2018/08/12 06:00 [pubmed]', '2019/02/16 06:00 [medline]', '2018/08/12 06:00 [entrez]']	United States			30098002	ppublish	['Journal Article']			IM		Epilepsia. 2018 Sep;59(9):1643-1654. doi: 10.1111/epi.14528. Epub 2018 Aug 10.	MEDLINE	Epilepsia	Deep learning applied to whole-brain connectome to determine seizure control after epilepsy surgery.		59	Deep learning applied to whole-brain connectome to determine seizure control after epilepsy surgery.
In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.	['Department of Radiology, Duke University School of Medicine, Durham, NC, USA; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden. Electronic address: buda@kth.se.', 'School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden. Electronic address: atsuto@kth.se.', 'Department of Radiology, Duke University School of Medicine, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA. Electronic address: maciej.mazurowski@duke.edu.']	['S0893-6080(18)30210-7 [pii]', '10.1016/j.neunet.2018.07.011 [doi]']	['Buda M', 'Maki A', 'Mazurowski MA']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/08/10 06:00']	20181211	20180729	2018 Oct	2018/08/10 06:00		['Buda, Mateusz', 'Maki, Atsuto', 'Mazurowski, Maciej A']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30210-7 [pii] 10.1016/j.neunet.2018.07.011 [doi]	20181211	['Humans', '*Machine Learning/trends', '*Neural Networks (Computer)', 'Probability', 'ROC Curve']	2018/12/12 06:00		['Class imbalance', 'Convolutional neural networks', 'Deep learning', 'Image classification']	['NOTNLM']	NLM	249-259	['2018/01/17 00:00 [received]', '2018/05/26 00:00 [revised]', '2018/07/20 00:00 [accepted]', '2018/08/10 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2018/08/10 06:00 [entrez]']	United States			30092410	ppublish	['Journal Article']			IM		Neural Netw. 2018 Oct;106:249-259. doi: 10.1016/j.neunet.2018.07.011. Epub 2018 Jul 29.	MEDLINE	Neural Netw	A systematic study of the class imbalance problem in convolutional neural networks.		106	A systematic study of the class imbalance problem in convolutional neural networks.
BACKGROUND: For the functional control of prosthetic hand, it is insufficient to obtain only the motion pattern information. As far as practicality is concerned, the control of the prosthetic hand force is indispensable. The application value of prosthetic hand will be greatly improved if the stable grip of prosthetic hand can be achieved. To address this problem, in this study, a bio-signal control method for grasping control of a prosthetic hand is proposed to improve patient's sense of using prosthetic hand and the thus improving the quality of life. METHODS: A MYO gesture control armband is used to collect the surface electromyographic (sEMG) signals from the upper limb. The overlapping sliding window scheme are applied for data segmentation and the correlated features are extracted from each segmented data. Principal component analysis (PCA) methods are then deployed for dimension reduction. Deep neural network is used to generate sEMG-force regression model for force prediction at different levels. The predicted force values are input to a fuzzy controller for the grasping control of a prosthetic hand. A vibration feedback device is used to feed grasping force value back to patient's arm to improve patient's sense of using prosthetic hand and realize accurate grasping. To test the effectiveness of the scheme, 15 able-bodied subjects participated in the experiments. RESULTS: The classification results indicated that 8-channel sEMG applying all four time-domain features, with PCA reduction from 32 to 8 dimensions results in the highest classification accuracy. Based on the experimental results from 15 participants, the average recognition rate is over 95%. On the other hand, from the statistical results of standard deviation, the between-subject variations ranges from 3.58 to 1.25%, proving that the robustness and stability of the proposed approach. CONCLUSIONS: The method proposed hereto control grasping power through the patient's own sEMG signal, which achieves a high recognition rate to improve the success rate of grip and increases the sense of operation and also brings the gospel for upper extremity amputation patients.	['The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, 201418, China. licj@shnu.edu.cn.', 'The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, 201418, China.', 'EPFL, 2002, Neuchatel, Switzerland.', 'BFH, 2502, Biel, Switzerland.', 'The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, 201418, China.', 'The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, 201418, China.', 'School of Computer Science & Electronic Engineering, University of Essex, Colchester, CO4 3SQ, UK.']	['10.1186/s12938-018-0539-8 [doi]', '10.1186/s12938-018-0539-8 [pii]']	['Li C', 'Ren J', 'Huang H', 'Wang B', 'Zhu Y', 'Hu H']	['ORCID: http://orcid.org/0000-0001-8552-9349']						['2018/08/08 06:00']	20181105	20180806	2018 Aug 6	2018/08/08 06:00		['Li, Chuanjiang', 'Ren, Jian', 'Huang, Huaiqi', 'Wang, Bin', 'Zhu, Yanfei', 'Hu, Huosheng']		['16070502900/Research Project of Science and Technology Commission of Shanghai', 'Municipality', 'A-7001-15-001005/The Innovation Team Program of Shanghai Normal University', '18ZR1428000/Natural Science Foundation of Shanghai (CN)']	1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-018-0539-8 [doi]	20181114	['*Artificial Limbs', '*Electromyography', 'Feasibility Studies', 'Female', 'Hand/*physiology', '*Hand Strength', 'Humans', '*Machine Learning', 'Male', 'Muscles/*physiology', '*Principal Component Analysis']	2018/11/06 06:00		['DNN', 'Fuzzy controller', 'Grasp control', 'PCA', 'Prosthetic hand', 'Vibration feedback device', 'sEMG-force']	['NOTNLM']	NLM	107	['2018/05/15 00:00 [received]', '2018/07/30 00:00 [accepted]', '2018/08/08 06:00 [entrez]', '2018/08/08 06:00 [pubmed]', '2018/11/06 06:00 [medline]']	England	PMC6080221		30081927	epublish	['Journal Article']			IM		Biomed Eng Online. 2018 Aug 6;17(1):107. doi: 10.1186/s12938-018-0539-8.	MEDLINE	Biomed Eng Online	PCA and deep learning based myoelectric grasping control of a prosthetic hand.		17	PCA and deep learning based myoelectric grasping control of a prosthetic hand.
PURPOSE: Probe-based confocal laser endomicroscopy (pCLE) is a subcellular in vivo imaging technique capable of producing images that enable diagnosis of malign structural modifications in epithelial tissue. Images acquired with pCLE are, however, often tainted by significant artifacts that impair diagnosis. This is especially detrimental for automated image analysis, which is why said images are often excluded from recognition pipelines. METHODS: We present an approach for the automatic detection of motion artifacts in pCLE images and apply this methodology to a data set of 15 thousand images of epithelial tissue acquired in the oral cavity and the vocal folds. The approach is based on transfer learning from intermediate endpoints within a pre-trained Inception v3 network with tailored preprocessing. For detection within the non-rectangular pCLE images, we perform pooling within the activation maps of the network and evaluate this at different network depths. RESULTS: We achieved area under the ROC curve values of 0.92 with the proposed method, compared to 0.80 for the best feature-based machine learning approach. Our overall accuracy with the presented approach is 94.8%. CONCLUSION: Over traditional machine learning approaches with state-of-the-art features, we achieved significantly improved overall performance.	['Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany. marc.aubreville@fau.de.', 'Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Department of Oral and Maxillofacial Surgery, University Hospital Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Department of Oral and Maxillofacial Surgery, University Medical Center Hamburg-Eppendorf, Universitat Hamburg, Hamburg, Germany.', 'First Department of Internal Medicine, University Hospital Mainz, Johannes Gutenberg-Universitat Mainz, Mainz, Germany.', 'Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital, Universitat Regensburg, Regensburg, Germany.', 'Department of Oral and Maxillofacial Surgery, University Hospital Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.']	['10.1007/s11548-018-1836-1 [doi]', '10.1007/s11548-018-1836-1 [pii]']	['Aubreville M', 'Stoeve M', 'Oetter N', 'Goncalves M', 'Knipfer C', 'Neumann H', 'Bohr C', 'Stelzle F', 'Maier A']	['ORCID: http://orcid.org/0000-0002-5294-5247']						['2018/08/06 06:00']	20190325	20180804	2019 Jan	2018/08/06 06:00		['Aubreville, Marc', 'Stoeve, Maike', 'Oetter, Nicolai', 'Goncalves, Miguel', 'Knipfer, Christian', 'Neumann, Helmut', 'Bohr, Christopher', 'Stelzle, Florian', 'Maier, Andreas']			1		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-018-1836-1 [doi]	20190325	['Artifacts', '*Deep Learning', 'Endoscopy/*methods', 'Humans', 'Microscopy, Confocal/*methods', 'Motion']	2019/03/26 06:00		['Confocal laser endomicroscopy', 'Deep convolutional neural networks', 'Motion artifact detection']	['NOTNLM']	NLM	31-42	['2018/04/04 00:00 [received]', '2018/07/26 00:00 [accepted]', '2018/08/06 06:00 [pubmed]', '2019/03/26 06:00 [medline]', '2018/08/06 06:00 [entrez]']	Germany			30078151	ppublish	['Journal Article']			IM		Int J Comput Assist Radiol Surg. 2019 Jan;14(1):31-42. doi: 10.1007/s11548-018-1836-1. Epub 2018 Aug 4.	MEDLINE	Int J Comput Assist Radiol Surg	Deep learning-based detection of motion artifacts in probe-based confocal laser endomicroscopy images.		14	Deep learning-based detection of motion artifacts in probe-based confocal laser endomicroscopy images.
BACKGROUND: Protein secondary structure can be regarded as an information bridge that links the primary sequence and tertiary structure. Accurate 8-state secondary structure prediction can significantly give more precise and high resolution on structure-based properties analysis. RESULTS: We present a novel deep learning architecture which exploits an integrative synergy of prediction by a convolutional neural network, residual network, and bidirectional recurrent neural network to improve the performance of protein secondary structure prediction. A local block comprised of convolutional filters and original input is designed for capturing local sequence features. The subsequent bidirectional recurrent neural network consisting of gated recurrent units can capture global context features. Furthermore, the residual network can improve the information flow between the hidden layers and the cascaded recurrent neural network. Our proposed deep network achieved 71.4% accuracy on the benchmark CB513 dataset for the 8-state prediction; and the ensemble learning by our model achieved 74% accuracy. Our model generalization capability is also evaluated on other three independent datasets CASP10, CASP11 and CASP12 for both 8- and 3-state prediction. These prediction performances are superior to the state-of-the-art methods. CONCLUSION: Our experiment demonstrates that it is a valuable method for predicting protein secondary structure, and capturing local and global features concurrently is very useful in deep learning.	['School of Computer Science and Technology, Soochow University, Suzhou, China.', 'School of Computer and Information, and the University Key Laboratory of Intelligent Perception and Computing of Anhui Province, Anqing Normal University, Anqing, 246011, China.', 'Advanced Analytics Institute, Faculty of Engineering and IT, University of Technology Sydney, Broadway, NSW 2007, Sydney, PO Box 123, Australia.', 'School of Computer Science and Technology, Soochow University, Suzhou, China. qiang@suda.edu.cn.']	['10.1186/s12859-018-2280-5 [doi]', '10.1186/s12859-018-2280-5 [pii]']	['Zhang B', 'Li J', 'Lu Q']							['2018/08/05 06:00']	20190422	20180803	2018 Aug 3	2018/08/05 06:00		['Zhang, Buzhong', 'Li, Jinyan', 'Lu, Qiang']			1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2280-5 [doi]	20190422	['Algorithms', 'Computational Biology/*methods', 'Databases, Protein', '*Deep Learning', 'Neural Networks (Computer)', '*Protein Structure, Secondary']	2019/04/23 06:00		['*Deep learning', '*Local block', '*Protein secondary structures', '*Q8 prediction']	['NOTNLM']	NLM	293	['2018/04/19 00:00 [received]', '2018/07/09 00:00 [accepted]', '2018/08/05 06:00 [entrez]', '2018/08/05 06:00 [pubmed]', '2019/04/23 06:00 [medline]']	England	PMC6090794		30075707	epublish	['Journal Article']			IM		BMC Bioinformatics. 2018 Aug 3;19(1):293. doi: 10.1186/s12859-018-2280-5.	MEDLINE	BMC Bioinformatics	Prediction of 8-state protein secondary structures by a novel deep learning architecture.		19	Prediction of 8-state protein secondary structures by a novel deep learning architecture.
Machine learning based predictions of protein(-)protein interactions (PPIs) could provide valuable insights into protein functions, disease occurrence, and therapy design on a large scale. The intensive feature engineering in most of these methods makes the prediction task more tedious and trivial. The emerging deep learning technology enabling automatic feature engineering is gaining great success in various fields. However, the over-fitting and generalization of its models are not yet well investigated in most scenarios. Here, we present a deep neural network framework (DNN-PPI) for predicting PPIs using features learned automatically only from protein primary sequences. Within the framework, the sequences of two interacting proteins are sequentially fed into the encoding, embedding, convolution neural network (CNN), and long short-term memory (LSTM) neural network layers. Then, a concatenated vector of the two outputs from the previous layer is wired as the input of the fully connected neural network. Finally, the Adam optimizer is applied to learn the network weights in a back-propagation fashion. The different types of features, including semantic associations between amino acids, position-related sequence segments (motif), and their long- and short-term dependencies, are captured in the embedding, CNN and LSTM layers, respectively. When the model was trained on Pan's human PPI dataset, it achieved a prediction accuracy of 98.78% at the Matthew's correlation coefficient (MCC) of 97.57%. The prediction accuracies for six external datasets ranged from 92.80% to 97.89%, making them superior to those achieved with previous methods. When performed on Escherichia coli, Drosophila, and Caenorhabditis elegans datasets, DNN-PPI obtained prediction accuracies of 95.949%, 98.389%, and 98.669%, respectively. The performances in cross-species testing among the four species above coincided in their evolutionary distances. However, when testing Mus Musculus using the models from those species, they all obtained prediction accuracies of over 92.43%, which is difficult to achieve and worthy of note for further study. These results suggest that DNN-PPI has remarkable generalization and is a promising tool for identifying protein interactions.	['School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin 300072, China. lihang2499@126.com.', 'Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin 300072, China. lihang2499@126.com.', 'School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin 300072, China. gongxj@tju.edu.cn.', 'Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin 300072, China. gongxj@tju.edu.cn.', 'School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin 300072, China. yuhua@tju.edu.cn.', 'Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin 300072, China. yuhua@tju.edu.cn.', 'School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin 300072, China. fujisyu@163.com.', 'Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin 300072, China. fujisyu@163.com.']	['molecules23081923 [pii]', '10.3390/molecules23081923 [doi]']	['Li H', 'Gong XJ', 'Yu H', 'Zhou C']	['ORCID: 0000-0001-9591-2237']						['2018/08/04 06:00']	20181105	20180801	2018 Aug 1	2018/08/04 06:00		['Li, Hang', 'Gong, Xiu-Jun', 'Yu, Hua', 'Zhou, Chang']			8		1420-3049 (Electronic) 1420-3049 (Linking)	100964009	Molecules (Basel, Switzerland)	['eng']	E1923 [pii] 10.3390/molecules23081923 [doi]	20181207	['Amino Acid Sequence', 'Animals', 'Humans', 'Memory, Short-Term', '*Neural Networks (Computer)', 'Protein Binding', '*Protein Interaction Mapping']	2018/11/06 06:00		['convolution neural networks', 'long short-term memory neural networks', 'model generalization', 'protein-protein interaction']	['NOTNLM']	NLM		['2018/06/13 00:00 [received]', '2018/07/16 00:00 [revised]', '2018/07/28 00:00 [accepted]', '2018/08/04 06:00 [entrez]', '2018/08/04 06:00 [pubmed]', '2018/11/06 06:00 [medline]']	Switzerland	PMC6222503		30071670	epublish	['Journal Article']			IM		Molecules. 2018 Aug 1;23(8). pii: molecules23081923. doi: 10.3390/molecules23081923.	MEDLINE	Molecules	Deep Neural Network Based Predictions of Protein Interactions Using Primary Sequences.		23	Deep Neural Network Based Predictions of Protein Interactions Using Primary Sequences.
BACKGROUND: Suicide has been one of the leading causes of deaths in the United States. One major cause of suicide is psychiatric stressors. The detection of psychiatric stressors in an at risk population will facilitate the early prevention of suicidal behaviors and suicide. In recent years, the widespread popularity and real-time information sharing flow of social media allow potential early intervention in a large-scale population. However, few automated approaches have been proposed to extract psychiatric stressors from Twitter. The goal of this study was to investigate techniques for recognizing suicide related psychiatric stressors from Twitter using deep learning based methods and transfer learning strategy which leverages an existing annotation dataset from clinical text. METHODS: First, a dataset of suicide-related tweets was collected from Twitter streaming data with a multiple-step pipeline including keyword-based retrieving, filtering and further refining using an automated binary classifier. Specifically, a convolutional neural networks (CNN) based algorithm was used to build the binary classifier. Next, psychiatric stressors were annotated in the suicide-related tweets. The stressor recognition problem is conceptualized as a typical named entity recognition (NER) task and tackled using recurrent neural networks (RNN) based methods. Moreover, to reduce the annotation cost and improve the performance, transfer learning strategy was adopted by leveraging existing annotation from clinical text. RESULTS & CONCLUSIONS: To our best knowledge, this is the first effort to extract psychiatric stressors from Twitter data using deep learning based approaches. Comparison to traditional machine learning algorithms shows the superiority of deep learning based approaches. CNN is leading the performance at identifying suicide-related tweets with a precision of 78% and an F-1 measure of 83%, outperforming Support Vector Machine (SVM), Extra Trees (ET), etc. RNN based psychiatric stressors recognition obtains the best F-1 measure of 53.25% by exact match and 67.94% by inexact match, outperforming Conditional Random Fields (CRF). Moreover, transfer learning from clinical notes for the Twitter corpus outperforms the training with Twitter corpus only with an F-1 measure of 54.9% by exact match. The results indicate the advantages of deep learning based methods for the automated stressors recognition from social media.	['The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA.', 'The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA.', 'The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA.', 'Department of Management Science and Engineering, Zhejiang Sci-Tech University, Hangzhou, 310018, China.', 'The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA.', 'Department of Medical Informatics, School of Public Health, Jilin University, Changchun, 130021, Jilin, China.', 'The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA.', 'The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA.', 'The University of Texas School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, TX, 77030, USA. hua.xu@uth.tmc.edu.']	['10.1186/s12911-018-0632-8 [doi]', '10.1186/s12911-018-0632-8 [pii]']	['Du J', 'Zhang Y', 'Luo J', 'Jia Y', 'Wei Q', 'Tao C', 'Xu H']							['2018/08/02 06:00']	20190627	20180723	2018 Jul 23	2018/08/02 06:00		['Du, Jingcheng', 'Zhang, Yaoyun', 'Luo, Jianhong', 'Jia, Yuxi', 'Wei, Qiang', 'Tao, Cui', 'Xu, Hua']		['R01 AI130460/AI/NIAID NIH HHS/United States', 'R01 LM011829/LM/NLM NIH HHS/United States', 'R01 LM010681/LM/NLM NIH HHS/United States', 'U01 CA180940/CA/NCI NIH HHS/United States']	Suppl 2		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-018-0632-8 [doi]	20190714	['Algorithms', '*Deep Learning', 'Humans', 'Neural Networks (Computer)', '*Social Media', '*Stress, Psychological', '*Suicide/prevention & control']	2019/06/30 06:00		['*Deep learning', '*Mental health', '*Named entity recognition', '*Psychiatric stressors', '*Social media', '*Suicide']	['NOTNLM']	NLM	43	['2018/08/02 06:00 [entrez]', '2018/08/02 06:00 [pubmed]', '2019/06/30 06:00 [medline]']	England	PMC6069295		30066665	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Inform Decis Mak. 2018 Jul 23;18(Suppl 2):43. doi: 10.1186/s12911-018-0632-8.	MEDLINE	BMC Med Inform Decis Mak	Extracting psychiatric stressors for suicide from social media using deep learning.		18	Extracting psychiatric stressors for suicide from social media using deep learning.
BACKGROUND: The emergence of the deep convolutional neural network (CNN) greatly improves the quality of computer-aided supporting systems. However, due to the challenges of generating reliable and timely results, clinical adoption of computer-aided diagnosis systems is still limited. Recent informatics research indicates that machine learning algorithms need to be combined with sufficient clinical expertise in order to achieve an optimal result. METHODS: In this research, we used deep learning algorithms to help diagnose four common cutaneous diseases based on dermoscopic images. In order to facilitate decision-making and improve the accuracy of our algorithm, we summarized classification/diagnosis scenarios based on domain expert knowledge and semantically represented them in a hierarchical structure. RESULTS: Our algorithm achieved an accuracy of 87.25 +/- 2.24% in our test dataset with 1067 images. The semantic summarization of diagnosis scenarios can help further improve the algorithm to facilitate future computer-aided decision support. CONCLUSIONS: In this paper, we applied deep neural network algorithm to classify dermoscopic images of four common skin diseases and archived promising results. Based on the results, we further summarized the diagnosis/classification scenarios, which reflect the importance of combining the efforts of both human expertise and computer algorithms in dermatologic diagnoses.	['School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Huston, TX, USA.', 'Department of Dermatology, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, China.', 'Department of Dermatology, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, China. liujie04672@pumch.cn.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Huston, TX, USA. cui.tao@uth.tmc.edu.']	['10.1186/s12911-018-0631-9 [doi]', '10.1186/s12911-018-0631-9 [pii]']	['Zhang X', 'Wang S', 'Liu J', 'Tao C']							['2018/08/02 06:00']	20190627	20180723	2018 Jul 23	2018/08/02 06:00		['Zhang, Xinyuan', 'Wang, Shiqi', 'Liu, Jie', 'Tao, Cui']		['R01 LM011829/LM/NLM NIH HHS/United States']	Suppl 2		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-018-0631-9 [doi]	20190627	['Algorithms', '*Deep Learning', 'Diagnosis, Computer-Assisted/methods', 'Humans', 'Machine Learning', '*Neural Networks (Computer)', '*Quality Improvement', 'Skin Diseases/*diagnosis']	2019/06/30 06:00		['*Deep learning', '*Dermatology', '*Image classification', '*Semantic data analytics']	['NOTNLM']	NLM	59	['2018/08/02 06:00 [entrez]', '2018/08/02 06:00 [pubmed]', '2019/06/30 06:00 [medline]']	England	PMC6069289		30066649	epublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		BMC Med Inform Decis Mak. 2018 Jul 23;18(Suppl 2):59. doi: 10.1186/s12911-018-0631-9.	MEDLINE	BMC Med Inform Decis Mak	Towards improving diagnosis of skin diseases by combining deep neural network and human knowledge.		18	Towards improving diagnosis of skin diseases by combining deep neural network and human knowledge.
Designing a new drug is a lengthy and expensive process. As the space of potential molecules is very large ( Polishchuk , P. G. ; Madzhidov , T. I. ; Varnek , A. Estimation of the size of drug-like chemical space based on GDB-17 data . J. Comput.-Aided Mol. Des. 2013 , 27 , 675 -679 10.1007/s10822-013-9672-4 ), a common technique during drug discovery is to start from a molecule which already has some of the desired properties. An interdisciplinary team of scientists generates hypothesis about the required changes to the prototype. In this work, we develop a deep-learning unsupervised-approach that automatically generates potential drug molecules given a prototype drug. We show that the molecules generated by the system are valid molecules and significantly different from the prototype drug. Out of the compounds generated by the system, we identified 35 known FDA-approved drugs. As an example, our system generated isoniazid, one of the main drugs for tuberculosis. We suggest several ranking functions for the generated molecules and present results that the top ten generated molecules per prototype drug contained in our retrospective experiments 23 known FDA-approved drugs.	['Department of Computer Science , Technion - Israel Institute of Technology , Haifa 3200003 , Israel.', 'Department of Computer Science , Technion - Israel Institute of Technology , Haifa 3200003 , Israel.']	['10.1021/acs.molpharmaceut.8b00474 [doi]']	['Harel S', 'Radinsky K']	['ORCID: 0000-0001-8175-5031']						['2018/08/01 06:00']	20190819	20180816	2018 Oct 1	2018/08/01 06:00		['Harel, Shahar', 'Radinsky, Kira']			10		1543-8392 (Electronic) 1543-8384 (Linking)	101197791	Molecular pharmaceutics	['eng']	10.1021/acs.molpharmaceut.8b00474 [doi]	20190819	['*Deep Learning', 'Drug Discovery', 'Isoniazid/*chemistry', 'Quantitative Structure-Activity Relationship']	2019/08/20 06:00		['*compound design', '*deep learning for medicine', '*generative models', '*prototype-based drug discovery']	['NOTNLM']	NLM	4406-4416	['2018/08/01 06:00 [pubmed]', '2019/08/20 06:00 [medline]', '2018/08/01 06:00 [entrez]']	United States			30063142	ppublish	['Journal Article']		['V83O1VOZ8L (Isoniazid)']			Mol Pharm. 2018 Oct 1;15(10):4406-4416. doi: 10.1021/acs.molpharmaceut.8b00474. Epub 2018 Aug 16.	MEDLINE	Mol Pharm	Prototype-Based Compound Discovery Using Deep Generative Models.		15	Prototype-Based Compound Discovery Using Deep Generative Models.
The decision-making process for estimating the optimal dosage is critical in clinical settings. In the neonatal intensive care unit (NICU), preterm neonates suffering from apnea of prematurity, optimum drug dosage can make a difference between life and death. To improve clinical decision making in the NICU, we have developed prediction models using machine learning algorithms. We have used optimized Support Vector Machine (SVM), decision trees with ensembles created using Bagging, Boosting, Random Forest, optimized Multi Layer Perceptron (MLP) and Deep Learning to predict adequacy of caffeine, a methylxanthine used to prevent the development of recurrent apneas, to reduce the need for mechanical ventilation. The respective models developed were evaluated using 100 clinical caffeine cases collected from the Neonatal Intensive Care Unit (NICU) of Kasturba Medical College, Manipal. Our results indicate that a deep belief network (DBN) having an area under curve (AUC) of 0.91, followed by an optimized MLP with the Score for Neonatal Acute Physiology I (SNAP I) as an input feature, outperform other models for assessing the drug effectiveness. Furthermore, the optimized MLP followed by a DBN, with SNAP I as an input feature is a more accurate model for predicting the therapeutic concentration of caffeine. These results suggest that the proposed SNAP I (illness severity score) acts as a critical input variable to enhance the performance of the prediction model. The machine learning approach is very useful for building decision support systems in the NICU in general, and it provides specific solutions to optimize the administration of lifesaving drugs to neonates who are very sensitive to dosages. Using our method, physicians can assess the adequacy and efficacy of caffeine on the study population in a NICU before administering it to neonates.	['Departments of Computer Science and Engineering, Manipal Institute of Technology.']	['6b7afd80398dbd73,65a2875a3bb42d85 [pii]', '10.1615/CritRevBiomedEng.2018025933 [doi]']	['Shirwaikar RD']							['2018/07/30 06:00']	20190424		2018	2018/07/30 06:00		['Shirwaikar, Rudresh Deepak']			2		1943-619X (Electronic) 0278-940X (Linking)	8208627	Critical reviews in biomedical engineering	['eng']	10.1615/CritRevBiomedEng.2018025933 [doi]	20190424	['Caffeine/*administration & dosage/pharmacokinetics', 'Clinical Decision-Making/*methods', '*Decision Making, Computer-Assisted', 'Decision Trees', 'Drug Dosage Calculations', 'Gestational Age', 'Humans', 'Infant, Newborn', 'Infant, Newborn, Diseases/*drug therapy/metabolism', '*Intensive Care Units, Neonatal', 'Machine Learning', 'Statistics as Topic/methods', 'Support Vector Machine']	2019/04/25 06:00				NLM	93-115	['2018/07/30 06:00 [entrez]', '2018/07/30 06:00 [pubmed]', '2019/04/25 06:00 [medline]']	United States			30055527	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['3G6A5W338E (Caffeine)']	IM		Crit Rev Biomed Eng. 2018;46(2):93-115. doi: 10.1615/CritRevBiomedEng.2018025933.	MEDLINE	Crit Rev Biomed Eng	Estimation of Caffeine Regimens: A Machine Learning Approach for Enhanced Clinical Decision Making at a Neonatal Intensive Care Unit (NICU).		46	Estimation of Caffeine Regimens: A Machine Learning Approach for Enhanced Clinical Decision Making at a Neonatal Intensive Care Unit (NICU).
"This work presents a novel approach to finding linkage/association between multimodal brain imaging data, such as structural MRI (sMRI) and functional MRI (fMRI). Motivated by the machine translation domain, we employ a deep learning model, and consider two different imaging views of the same brain like two different languages conveying some common facts. That analogy enables finding linkages between two modalities. The proposed translation-based fusion model contains a computing layer that learns ""alignments"" (or links) between dynamic connectivity features from fMRI data and static gray matter patterns from sMRI data. The approach is evaluated on a multi-site dataset consisting of eyes-closed resting state imaging data collected from 298 subjects (age- and gender matched 154 healthy controls and 144 patients with schizophrenia). Results are further confirmed on an independent dataset consisting of eyes-open resting state imaging data from 189 subjects (age- and gender matched 91 healthy controls and 98 patients with schizophrenia). We used dynamic functional connectivity (dFNC) states as the functional features and ICA-based sources from gray matter densities as the structural features. The dFNC states characterized by weakly correlated intrinsic connectivity networks (ICNs) were found to have stronger association with putamen and insular gray matter pattern, while the dFNC states of profuse strongly correlated ICNs exhibited stronger links with the gray matter pattern in precuneus, posterior cingulate cortex (PCC), and temporal cortex. Further investigation with the estimated link strength (or alignment score) showed significant group differences between healthy controls and patients with schizophrenia in several key regions including temporal lobe, and linked these to connectivity states showing less occupancy in healthy controls. Moreover, this novel approach revealed significant correlation between a cognitive score (attention/vigilance) and the function/structure alignment score that was not detected when data modalities were considered separately."	['The Mind Research Network, 1101 Yale Blvd, Albuquerque, NM, 87106, USA. Electronic address: s.m.plis@gmail.com.', 'The Mind Research Network, 1101 Yale Blvd, Albuquerque, NM, 87106, USA; Intel Corporation, 5000 W Chandler Blvd, Chandler, AZ, 85226, USA.', 'Human Neuroscience Laboratory, Yale University, New Haven, CT, 06520, USA.', 'The Mind Research Network, 1101 Yale Blvd, Albuquerque, NM, 87106, USA.', 'The Mind Research Network, 1101 Yale Blvd, Albuquerque, NM, 87106, USA.', 'Division of Computer Science and Engineering, CAIIT, Chonbuk National University, Jeonju, South Korea.', 'Department of Psychiatry and Neurosciences, University of New Mexico, Albuquerque, NM, 87131, USA.', 'Courant Institute & Center for Data Science, New York University, New York, NY, 10012, USA.', 'Olin Neuropsychiatry Research Center, Hartford Hospital (IOL Campus), Hartford, CT, USA; Department of Psychiatry and Neurobiology, Yale University School of Medicine, New Haven, CT, USA.', 'The Mind Research Network, 1101 Yale Blvd, Albuquerque, NM, 87106, USA; Department of Psychiatry and Neurosciences, University of New Mexico, Albuquerque, NM, 87131, USA; Dept. of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, 87131, USA.']	['S1053-8119(18)30661-X [pii]', '10.1016/j.neuroimage.2018.07.047 [doi]']	['Plis SM', 'Amin MF', 'Chekroud A', 'Hjelm D', 'Damaraju E', 'Lee HJ', 'Bustillo JR', 'Cho K', 'Pearlson GD', 'Calhoun VD']		['Copyright (c) 2018. Published by Elsevier Inc.']					['2018/07/29 06:00']	20190204	20180725	2018 Nov 1	2018/07/29 06:00		['Plis, Sergey M', 'Amin, Md Faijul', 'Chekroud, Adam', 'Hjelm, Devon', 'Damaraju, Eswar', 'Lee, Hyo Jong', 'Bustillo, Juan R', 'Cho, KyungHyun', 'Pearlson, Godfrey D', 'Calhoun, Vince D']		['P20 GM103472/GM/NIGMS NIH HHS/United States', 'P30 GM122734/GM/NIGMS NIH HHS/United States', 'R01 EB006841/EB/NIBIB NIH HHS/United States', 'P20GM103472/NH/NIH HHS/United States', 'R01EB005846 /NH/NIH HHS/United States', 'R01EB020407/NH/NIH HHS/United States', 'R01 EB020407/EB/NIBIB NIH HHS/United States']			1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(18)30661-X [pii] 10.1016/j.neuroimage.2018.07.047 [doi]	20190610	['Adult', 'Connectome/*methods', '*Deep Learning', 'Female', 'Gray Matter/diagnostic imaging/*physiology', 'Humans', 'Magnetic Resonance Imaging', 'Male', 'Middle Aged', 'Nerve Net/diagnostic imaging/*physiopathology', 'Psychotic Disorders/diagnostic imaging/*physiopathology', 'Schizophrenia/diagnostic imaging/*physiopathology']	2019/02/05 06:00	['NIHMS1004056']	['*Deep learning', '*Multimodal fusion', '*Psychosis', '*Schizophrenia']	['NOTNLM']	NLM	734-747	['2017/06/25 00:00 [received]', '2018/07/16 00:00 [revised]', '2018/07/18 00:00 [accepted]', '2018/07/29 06:00 [pubmed]', '2019/02/05 06:00 [medline]', '2018/07/29 06:00 [entrez]']	United States	PMC6321628		30055372	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Neuroimage. 2018 Nov 1;181:734-747. doi: 10.1016/j.neuroimage.2018.07.047. Epub 2018 Jul 25.	MEDLINE	Neuroimage	Reading the (functional) writing on the (structural) wall: Multimodal fusion of brain structure and function via a deep neural network based translation approach reveals novel impairments in schizophrenia.		181	Reading the (functional) writing on the (structural) wall: Multimodal fusion of brain structure and function via a deep neural network based translation approach reveals novel impairments in schizophrenia.
Thanks to the fast improvement of the computing power and the rapid development of the computational chemistry and biology, the computer-aided drug design techniques have been successfully applied in almost every stage of the drug discovery and development pipeline to speed up the process of research and reduce the cost and risk related to preclinical and clinical trials. Owing to the development of machine learning theory and the accumulation of pharmacological data, the artificial intelligence (AI) technology, as a powerful data mining tool, has cut a figure in various fields of the drug design, such as virtual screening, activity scoring, quantitative structure-activity relationship (QSAR) analysis, de novo drug design, and in silico evaluation of absorption, distribution, metabolism, excretion and toxicity (ADME/T) properties. Although it is still challenging to provide a physical explanation of the AI-based models, it indeed has been acting as a great power to help manipulating the drug discovery through the versatile frameworks. Recently, due to the strong generalization ability and powerful feature extraction capability, deep learning methods have been employed in predicting the molecular properties as well as generating the desired molecules, which will further promote the application of AI technologies in the field of drug design.	['Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Life Science and Technology, ShanghaiTech University, Shanghai, 200031, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Life Science and Technology, ShanghaiTech University, Shanghai, 200031, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Pharmacy, University of Chinese Academy of Sciences, Beijing, 100049, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'Department of Chemistry, College of Sciences, Shanghai University, Shanghai, 200444, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Information Management, Dezhou University, Shandong, 253023, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China.', 'School of Life Science and Technology, ShanghaiTech University, Shanghai, 200031, China.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China. myzheng@simm.ac.cn.', 'Drug Discovery and Design Center, State Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai, 201203, China. hljiang@simm.ac.cn.', 'School of Life Science and Technology, ShanghaiTech University, Shanghai, 200031, China. hljiang@simm.ac.cn.']	['10.1007/s11427-018-9342-2 [doi]', '10.1007/s11427-018-9342-2 [pii]']	['Zhong F', 'Xing J', 'Li X', 'Liu X', 'Fu Z', 'Xiong Z', 'Lu D', 'Wu X', 'Zhao J', 'Tan X', 'Li F', 'Luo X', 'Li Z', 'Chen K', 'Zheng M', 'Jiang H']							['2018/07/29 06:00']	20190107	20180718	2018 Oct	2018/07/29 06:00		['Zhong, Feisheng', 'Xing, Jing', 'Li, Xutong', 'Liu, Xiaohong', 'Fu, Zunyun', 'Xiong, Zhaoping', 'Lu, Dong', 'Wu, Xiaolong', 'Zhao, Jihui', 'Tan, Xiaoqin', 'Li, Fei', 'Luo, Xiaomin', 'Li, Zhaojun', 'Chen, Kaixian', 'Zheng, Mingyue', 'Jiang, Hualiang']			10		1869-1889 (Electronic) 1674-7305 (Linking)	101529880	Science China. Life sciences	['eng']	10.1007/s11427-018-9342-2 [doi]	20190107	['*Artificial Intelligence', 'Computational Biology/methods', 'Computer Simulation', '*Computer-Aided Design', '*Drug Design', 'Drug Discovery/*methods', 'Humans', 'Pharmaceutical Preparations/administration & dosage/chemistry/metabolism', 'Pharmacokinetics', 'Structure-Activity Relationship']	2019/01/08 06:00		['ADME/T', 'QSAR', 'artificial intelligence', 'deep learning', 'drug design']	['NOTNLM']	NLM	1191-1204	['2018/04/24 00:00 [received]', '2018/05/22 00:00 [accepted]', '2018/07/29 06:00 [pubmed]', '2019/01/08 06:00 [medline]', '2018/07/29 06:00 [entrez]']	China			30054833	ppublish	['Journal Article', 'Review']		['0 (Pharmaceutical Preparations)']	IM		Sci China Life Sci. 2018 Oct;61(10):1191-1204. doi: 10.1007/s11427-018-9342-2. Epub 2018 Jul 18.	MEDLINE	Sci China Life Sci	Artificial intelligence in drug design.		61	Artificial intelligence in drug design.
Feature extraction and classification is a vital part in motor imagery-based brain-computer interface (BCI) system. Traditional deep learning (DL) methods usually perform better with more labeled training samples. Unfortunately, the labeled samples are usually scarce for electroencephalography (EEG) data, while unlabeled samples are available in large quantity and easy to collect. In addition, traditional DL algorithms are notoriously time-consuming for the training process. To address these issues, a novel method of hierarchical semi-supervised extreme learning machine (HSS-ELM) is proposed in this paper and applied for motor imagery (MI) task classification. Firstly, the deep architecture of hierarchical ELM (H-ELM) approach is employed for feature learning automatically, and then these new high-level features are classified using the semi-supervised ELM (SS-ELM) algorithm which can exploit the information from both labeled and unlabeled data. Extensive experiments were conducted on some benchmark datasets and EEG datasets to evaluate the effectiveness of the proposed method. Compared with several state-of-the-art methods, including SVM, ELM, SAE, H-ELM, and SS-ELM, our HSS-ELM method can achieve better classification accuracy, a mean kappa value of 0.7945 and 0.5701 across all subjects in the training and evaluation sessions of BCI Competition IV Dataset 2a, respectively. Finally, it comes to the conclusion that the proposed method has achieved superior performance for feature extraction and classification of EEG signals. Graphical abstract The schematic of the proposed HSS-ELM algorithm.	['Institute of Intelligent Control and Robotics, Hangzhou Dianzi University, Zhejiang, Hangzhou, 310018, China. qsshe@hdu.edu.cn.', 'Institute of Intelligent Control and Robotics, Hangzhou Dianzi University, Zhejiang, Hangzhou, 310018, China.', 'Institute of Intelligent Control and Robotics, Hangzhou Dianzi University, Zhejiang, Hangzhou, 310018, China.', 'Department of Biomedical Engineering, University of Houston, Houston, TX, 77204, USA.', 'Institute of Intelligent Control and Robotics, Hangzhou Dianzi University, Zhejiang, Hangzhou, 310018, China. yingchun.umn@gmail.com.', 'Department of Biomedical Engineering, University of Houston, Houston, TX, 77204, USA. yingchun.umn@gmail.com.']	['10.1007/s11517-018-1875-3 [doi]', '10.1007/s11517-018-1875-3 [pii]']	['She Q', 'Hu B', 'Luo Z', 'Nguyen T', 'Zhang Y']	['ORCID: http://orcid.org/0000-0002-1927-4103']						['2018/07/29 06:00']	20190318	20180728	2019 Jan	2018/07/29 06:00		['She, Qingshan', 'Hu, Bo', 'Luo, Zhizeng', 'Nguyen, Thinh', 'Zhang, Yingchun']		['61201302/National Nature Science Foundation', '61671197/National Nature Science Foundation', 'LY15F010009/Natural Science Foundation of Zhejiang Province (CN)']	1		1741-0444 (Electronic) 0140-0118 (Linking)	7704869	Medical & biological engineering & computing	['eng']	10.1007/s11517-018-1875-3 [doi]	20190318	['Algorithms', 'Benchmarking', 'Brain-Computer Interfaces', 'Electroencephalography/*methods', 'Humans', '*Machine Learning']	2019/03/19 06:00		['Deep learning', 'Extreme learning machines', 'Hierarchical', 'Motor imagery electroencephalography', 'Semi-supervised learning']	['NOTNLM']	NLM	147-157	['2017/06/12 00:00 [received]', '2017/12/22 00:00 [accepted]', '2018/07/29 06:00 [pubmed]', '2019/03/19 06:00 [medline]', '2018/07/29 06:00 [entrez]']	United States			30054779	ppublish	['Journal Article']			IM		Med Biol Eng Comput. 2019 Jan;57(1):147-157. doi: 10.1007/s11517-018-1875-3. Epub 2018 Jul 28.	MEDLINE	Med Biol Eng Comput	A hierarchical semi-supervised extreme learning machine method for EEG recognition.		57	A hierarchical semi-supervised extreme learning machine method for EEG recognition.
The tumor-stroma ratio (TSR) reflected on hematoxylin and eosin (H&E)-stained histological images is a potential prognostic factor for survival. Automatic image processing techniques that allow for high-throughput and precise discrimination of tumor epithelium and stroma are required to elevate the prognostic significance of the TSR. As a variant of deep learning techniques, transfer learning leverages nature-images features learned by deep convolutional neural networks (CNNs) to relieve the requirement of deep CNNs for immense sample size when handling biomedical classification problems. Herein we studied different transfer learning strategies for accurately distinguishing epithelial and stromal regions of H&E-stained histological images acquired from either breast or ovarian cancer tissue. We compared the performance of important deep CNNs as either a feature extractor or as an architecture for fine-tuning with target images. Moreover, we addressed the current contradictory issue about whether the higher-level features would generalize worse than lower-level ones because they are more specific to the source-image domain. Under our experimental setting, the transfer learning approach achieved an accuracy of 90.2 (vs. 91.1 for fine tuning) with GoogLeNet, suggesting the feasibility of using it in assisting pathology-based binary classification problems. Our results also show that the superiority of the lower-level or the higher-level features over the other ones was determined by the architecture of deep CNNs.	['School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, 73019, USA.', 'Department of Pathology, University of Oklahoma Health Sciences Center, Oklahoma City, OK, 73104, USA.', 'School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, 73019, USA.', 'Department of Radiology, University of Oklahoma Health Sciences Center, Oklahoma City, OK, 73104, USA.', 'Department of Obstetrics and Gynecology, University of Oklahoma Health Sciences Center, Oklahoma City, OK, 73104, USA.', 'Department of Obstetrics and Gynecology, University of Oklahoma Health Sciences Center, Oklahoma City, OK, 73104, USA.', 'School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, 73019, USA.', 'School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, 73019, USA.', 'School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, 73019, USA. qiuyuchen@ou.edu.']	['10.1007/s10439-018-2095-6 [doi]', '10.1007/s10439-018-2095-6 [pii]']	['Du Y', 'Zhang R', 'Zargari A', 'Thai TC', 'Gunderson CC', 'Moxley KM', 'Liu H', 'Zheng B', 'Qiu Y']							['2018/07/28 06:00']	20190301	20180726	2018 Dec	2018/07/28 06:00		['Du, Yue', 'Zhang, Roy', 'Zargari, Abolfazl', 'Thai, Theresa C', 'Gunderson, Camille C', 'Moxley, Katherine M', 'Liu, Hong', 'Zheng, Bin', 'Qiu, Yuchen']		['R01 CA197150/CA/NCI NIH HHS/United States', 'HR15-016/Oklahoma Center for the Advancement of Science and Technology', 'R01CA197150/National Cancer Institute']	12		1573-9686 (Electronic) 0090-6964 (Linking)	0361512	Annals of biomedical engineering	['eng']	10.1007/s10439-018-2095-6 [doi]	20191201	['Breast Neoplasms/*pathology', 'Databases, Factual', '*Deep Learning', 'Female', 'Humans', '*Image Processing, Computer-Assisted', 'Ovarian Neoplasms/*pathology', 'Tissue Array Analysis']	2019/03/02 06:00	['NIHMS996226']	['CNNs', 'Deep learning', 'Epithelium and stroma', 'TSR', 'Transfer learning']	['NOTNLM']	NLM	1988-1999	['2018/03/08 00:00 [received]', '2018/07/13 00:00 [accepted]', '2018/07/28 06:00 [pubmed]', '2019/03/02 06:00 [medline]', '2018/07/28 06:00 [entrez]']	United States	PMC6286645		30051247	ppublish	['Journal Article']			IM		Ann Biomed Eng. 2018 Dec;46(12):1988-1999. doi: 10.1007/s10439-018-2095-6. Epub 2018 Jul 26.	MEDLINE	Ann Biomed Eng	Classification of Tumor Epithelium and Stroma by Exploiting Image Features Learned by Deep Convolutional Neural Networks.		46	Classification of Tumor Epithelium and Stroma by Exploiting Image Features Learned by Deep Convolutional Neural Networks.
We have devised and implemented a novel computational strategy for de novo design of molecules with desired properties termed ReLeaSE (Reinforcement Learning for Structural Evolution). On the basis of deep and reinforcement learning (RL) approaches, ReLeaSE integrates two deep neural networks-generative and predictive-that are trained separately but are used jointly to generate novel targeted chemical libraries. ReLeaSE uses simple representation of molecules by their simplified molecular-input line-entry system (SMILES) strings only. Generative models are trained with a stack-augmented memory network to produce chemically feasible SMILES strings, and predictive models are derived to forecast the desired properties of the de novo-generated compounds. In the first phase of the method, generative and predictive models are trained separately with a supervised learning algorithm. In the second phase, both models are trained jointly with the RL approach to bias the generation of new chemical structures toward those with the desired physical and/or biological properties. In the proof-of-concept study, we have used the ReLeaSE method to design chemical libraries with a bias toward structural complexity or toward compounds with maximal, minimal, or specific range of physical properties, such as melting point or hydrophobicity, or toward compounds with inhibitory activity against Janus protein kinase 2. The approach proposed herein can find a general use for generating targeted chemical libraries of novel compounds optimized for either a single desired property or multiple properties.	['Laboratory for Molecular Modeling, Division of Chemical Biology and Medicinal Chemistry, UNC Eshelman School of Pharmacy, University of North Carolina, Chapel Hill, NC 27599, USA.', 'Moscow Institute of Physics and Technology, Dolgoprudny, Moscow 141700, Russia.', 'Skolkovo Institute of Science and Technology, Moscow 143026, Russia.', 'Laboratory for Molecular Modeling, Division of Chemical Biology and Medicinal Chemistry, UNC Eshelman School of Pharmacy, University of North Carolina, Chapel Hill, NC 27599, USA.', 'Laboratory for Molecular Modeling, Division of Chemical Biology and Medicinal Chemistry, UNC Eshelman School of Pharmacy, University of North Carolina, Chapel Hill, NC 27599, USA.']	['10.1126/sciadv.aap7885 [doi]', 'aap7885 [pii]']	['Popova M', 'Isayev O', 'Tropsha A']	['ORCID: 0000-0001-7581-8497', 'ORCID: 0000-0003-3802-8896']						['2018/07/28 06:00']	20190906	20180725	2018 Jul	2018/07/28 06:00		['Popova, Mariya', 'Isayev, Olexandr', 'Tropsha, Alexander']		['T32 GM067553/GM/NIGMS NIH HHS/United States']	7		2375-2548 (Electronic) 2375-2548 (Linking)	101653440	Science advances	['eng']	10.1126/sciadv.aap7885 [doi]	20190906	['*Deep Learning', '*Drug Design', 'Janus Kinase 2/antagonists & inhibitors/metabolism', 'Models, Molecular', 'Neural Networks (Computer)', 'Quantitative Structure-Activity Relationship', 'Small Molecule Libraries/chemistry']	2019/09/07 06:00				NLM	eaap7885	['2017/08/26 00:00 [received]', '2018/06/13 00:00 [accepted]', '2018/07/28 06:00 [entrez]', '2018/07/28 06:00 [pubmed]', '2019/09/07 06:00 [medline]']	United States	PMC6059760		30050984	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Small Molecule Libraries)', 'EC 2.7.10.2 (Janus Kinase 2)']	IM		Sci Adv. 2018 Jul 25;4(7):eaap7885. doi: 10.1126/sciadv.aap7885. eCollection 2018 Jul.	MEDLINE	Sci Adv	Deep reinforcement learning for de novo drug design.		4	Deep reinforcement learning for de novo drug design.
For the past several decades, research in understanding the molecular basis of human muscle aging has progressed significantly. However, the development of accessible tissue-specific biomarkers of human muscle aging that may be measured to evaluate the effectiveness of therapeutic interventions is still a major challenge. Here we present a method for tracking age-related changes of human skeletal muscle. We analyzed publicly available gene expression profiles of young and old tissue from healthy donors. Differential gene expression and pathway analysis were performed to compare signatures of young and old muscle tissue and to preprocess the resulting data for a set of machine learning algorithms. Our study confirms the established mechanisms of human skeletal muscle aging, including dysregulation of cytosolic Ca(2+) homeostasis, PPAR signaling and neurotransmitter recycling along with IGFR and PI3K-Akt-mTOR signaling. Applying several supervised machine learning techniques, including neural networks, we built a panel of tissue-specific biomarkers of aging. Our predictive model achieved 0.91 Pearson correlation with respect to the actual age values of the muscle tissue samples, and a mean absolute error of 6.19 years on the test set. The performance of models was also evaluated on gene expression samples of the skeletal muscles from the Gene expression Genotype-Tissue Expression (GTEx) project. The best model achieved the accuracy of 0.80 with respect to the actual age bin prediction on the external validation set. Furthermore, we demonstrated that aging biomarkers can be used to identify new molecular targets for tissue-specific anti-aging therapies.	['Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States.', 'Department of Computer Science, University of Oxford, Oxford, United Kingdom.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States.', 'Computer Technologies Lab, Saint Petersburg State University of Information Technologies, Mechanics and Optics, Saint Petersburg, Russia.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States.', 'Biogerontology Research Foundation, London, United Kingdom.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States.', 'Biogerontology Research Foundation, London, United Kingdom.', 'Buck Institute for Research on Aging, Novato, CA, United States.']	['10.3389/fgene.2018.00242 [doi]']	['Mamoshina P', 'Volosnikova M', 'Ozerov IV', 'Putin E', 'Skibina E', 'Cortese F', 'Zhavoronkov A']							['2018/07/28 06:00']		20180712	2018	2018/07/28 06:00		['Mamoshina, Polina', 'Volosnikova, Marina', 'Ozerov, Ivan V', 'Putin, Evgeny', 'Skibina, Ekaterina', 'Cortese, Franco', 'Zhavoronkov, Alex']					1664-8021 (Print) 1664-8021 (Linking)	101560621	Frontiers in genetics	['eng']	10.3389/fgene.2018.00242 [doi]	20191120		2018/07/28 06:01		['aging', 'biomarkers of aging', 'deep learning', 'machine learning', 'pathway analysis', 'target identification']	['NOTNLM']	NLM	242	['2018/03/26 00:00 [received]', '2018/06/19 00:00 [accepted]', '2018/07/28 06:00 [entrez]', '2018/07/28 06:00 [pubmed]', '2018/07/28 06:01 [medline]']	Switzerland	PMC6052089		30050560	epublish	['Journal Article']					Front Genet. 2018 Jul 12;9:242. doi: 10.3389/fgene.2018.00242. eCollection 2018.	PubMed-not-MEDLINE	Front Genet	Machine Learning on Human Muscle Transcriptomic Data for Biomarker Discovery and Tissue-Specific Drug Target Identification.		9	Machine Learning on Human Muscle Transcriptomic Data for Biomarker Discovery and Tissue-Specific Drug Target Identification.
The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.	['Department of Chemistry and Chemical Biology, Harvard University, 12 Oxford Street, Cambridge, MA 02138, USA.', 'Department of Chemistry and Department of Computer Science, University of Toronto, Toronto, Ontario M5S 3H6, Canada. aspuru@utoronto.ca.', 'Vector Institute for Artificial Intelligence, Toronto, Ontario M5S 1M1, Canada.', 'Canadian Institute for Advanced Research (CIFAR) Senior Fellow, Toronto, Ontario M5S 1M1, Canada.']	['361/6400/360 [pii]', '10.1126/science.aat2663 [doi]']	['Sanchez-Lengeling B', 'Aspuru-Guzik A']	['ORCID: https://orcid.org/0000-0002-1116-1745', 'ORCID: https://orcid.org/0000-0002-8277-4434']	['Copyright (c) 2018 The Authors, some rights reserved; exclusive licensee American', 'Association for the Advancement of Science. No claim to original U.S. Government', 'Works.']					['2018/07/28 06:00']	20180926	20180726	2018 Jul 27	2018/07/28 06:00		['Sanchez-Lengeling, Benjamin', 'Aspuru-Guzik, Alan']			6400		1095-9203 (Electronic) 0036-8075 (Linking)	0404511	Science (New York, N.Y.)	['eng']	10.1126/science.aat2663 [doi]	20180926		2018/07/28 06:01				NLM	360-365	['2018/07/28 06:00 [entrez]', '2018/07/28 06:00 [pubmed]', '2018/07/28 06:01 [medline]']	United States			30049875	ppublish	['Journal Article', 'Review']					Science. 2018 Jul 27;361(6400):360-365. doi: 10.1126/science.aat2663. Epub 2018 Jul 26.	PubMed-not-MEDLINE	Science	Inverse molecular design using machine learning: Generative models for matter engineering.		361	Inverse molecular design using machine learning: Generative models for matter engineering.
Deep learning techniques, e.g., Convolutional Neural Networks (CNNs), have been explosively applied to the research in the fields of information retrieval and natural language processing. However, few research efforts have addressed semantic indexing with deep learning. The use of semantic indexing in the biomedical literature has been limited for several reasons. For instance, MEDLINE citations contain a large number of semantic labels from automatically annotated MeSH terms, and for a great deal of the literature, only the information of the title and the abstract is readily available. In this paper, we propose a Boltzmann Convolutional neural network framework (B-CNN) for biomedicine semantic indexing. In our hybrid learning framework, the CNN can adaptively deal with features of documents that have sequence relationships, and can capture context information accordingly; the Deep Boltzmann Machine (DBM) merges global (the entity in each document) and local information through its training with undirected connections. Additionally, we have designed a hierarchical coarse to fine style indexing structure for learning and classifying documents, and a novel feature extension approach with word sequence embedding and Wikipedia categorization. Comparative experiments were conducted for semantic indexing of biomedical abstract documents; these experiments verified the encouraged performance of our B-CNN model.	['Department of Computer Science and Technology, School of Mechanical Electronic and Information Engineering, China University of Mining and Technology, Beijing, 100083, China.', 'Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China.', 'Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China.', 'Key Laboratory of Computational Linguistics, Peking University, Ministry of Education, Beijing 100871, China.', 'Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China.']	['10.1371/journal.pone.0197933 [doi]', 'PONE-D-17-01778 [pii]']	['Yan Y', 'Yin XC', 'Yang C', 'Li S', 'Zhang BW']	['ORCID: 0000-0002-0187-7010']				['The authors have declared that no competing interests exist.']		['2018/07/27 06:00']	20181227	20180726	2018	2018/07/27 06:00		['Yan, Yan', 'Yin, Xu-Cheng', 'Yang, Chun', 'Li, Sujian', 'Zhang, Bo-Wen']			7		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0197933 [doi]	20181227	['*Abstracting and Indexing as Topic', 'Humans', 'Information Storage and Retrieval', 'MEDLINE', '*Machine Learning', '*Natural Language Processing', '*Neural Networks (Computer)', 'Periodicals as Topic', 'Semantics']	2018/12/28 06:00				NLM	e0197933	['2017/01/13 00:00 [received]', '2018/05/10 00:00 [accepted]', '2018/07/27 06:00 [entrez]', '2018/07/27 06:00 [pubmed]', '2018/12/28 06:00 [medline]']	United States	PMC6061982		30048461	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Jul 26;13(7):e0197933. doi: 10.1371/journal.pone.0197933. eCollection 2018.	MEDLINE	PLoS One	Biomedical literature classification with a CNNs-based hybrid learning network.		13	Biomedical literature classification with a CNNs-based hybrid learning network.
A novel computer-aided detection method based on deep learning framework was proposed to detect small intestinal ulcer and erosion in wireless capsule endoscopy (WCE) images. To the best of our knowledge, this is the first time that deep learning framework has been exploited on automated ulcer and erosion detection in WCE images. Compared with the traditional detection method, deep learning framework can produce image features directly from the data and increase recognition accuracy as well as efficiency, especially for big data. The developed method included image cropping and image compression. The AlexNet convolutional neural network was trained to the database with tens of thousands of WCE images to differentiate lesion and normal tissue. The results of ulcer and erosion detection reached a high accuracy of 95.16% and 95.34%, sensitivity of 96.80% and 93.67%, and specificity of 94.79% and 95.98%, correspondingly. The area under the receiver operating characteristic curve was over 0.98 in both of the networks. The promising results indicate that the proposed method has the potential to work in tandem with doctors to efficiently detect intestinal ulcer and erosion.	"[""College of Life Information Science and Instrument Engineering, Hangzhou Dianzi University, Hangzhou 310018, People's Republic of China.""]"	['10.1088/1361-6560/aad51c [doi]']	['Fan S', 'Xu L', 'Fan Y', 'Wei K', 'Li L']							['2018/07/24 06:00']	20190724	20180810	2018 Aug 10	2018/07/24 06:00		['Fan, Shanhui', 'Xu, Lanmeng', 'Fan, Yihong', 'Wei, Kaihua', 'Li, Lihua']			16		1361-6560 (Electronic) 0031-9155 (Linking)	0401220	Physics in medicine and biology	['eng']	10.1088/1361-6560/aad51c [doi]	20190724	['Capsule Endoscopy/*methods', 'Case-Control Studies', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Intestine, Small/diagnostic imaging/*pathology', '*Neural Networks (Computer)', 'ROC Curve', 'Ulcer/*diagnosis/diagnostic imaging']	2019/07/25 06:00				NLM	165001	['2018/07/24 06:00 [pubmed]', '2019/07/25 06:00 [medline]', '2018/07/24 06:00 [entrez]']	England			30033931	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					Phys Med Biol. 2018 Aug 10;63(16):165001. doi: 10.1088/1361-6560/aad51c.	MEDLINE	Phys Med Biol	Computer-aided detection of small intestinal ulcer and erosion in wireless capsule endoscopy images.		63	Computer-aided detection of small intestinal ulcer and erosion in wireless capsule endoscopy images.
Atrial Fibrillation (AF), either permanent or intermittent (paroxysnal AF), increases the risk of cardioembolic stroke. Accurate diagnosis of AF is obligatory for initiation of effective treatment to prevent stroke. Long term cardiac monitoring improves the likelihood of diagnosing paroxysmal AF. We used a deep learning system to detect AF beats in Heart Rate (HR) signals. The data was partitioned with a sliding window of 100 beats. The resulting signal blocks were directly fed into a deep Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM). The system was validated and tested with data from the MIT-BIH Atrial Fibrillation Database. It achieved 98.51% accuracy with 10-fold cross-validation (20 subjects) and 99.77% with blindfold validation (3 subjects). The proposed system structure is straight forward, because there is no need for information reduction through feature extraction. All the complexity resides in the deep learning system, which gets the entire information from a signal block. This setup leads to the robust performance for unknown data, as measured with the blind fold validation. The proposed Computer-Aided Diagnosis (CAD) system can be used for long-term monitoring of the human heart. To the best of our knowledge, the proposed system is the first to incorporate deep learning for AF beat detection.	['Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom. Electronic address: oliver.faust@gmail.com.', 'Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom.', 'Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom.', 'National Heart Centre Singapore, Singapore.', 'Fac. of Software and Information Science, Iwate Prefectural University, Iwate, Japan.', 'Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, SUSS, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylors University, 47500, Subang Jaya, Malaysia.']	['S0010-4825(18)30184-7 [pii]', '10.1016/j.compbiomed.2018.07.001 [doi]']	['Faust O', 'Shenfield A', 'Kareem M', 'San TR', 'Fujita H', 'Acharya UR']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/07/23 06:00']	20191028	20180717	2018 Nov 1	2018/07/23 06:00		['Faust, Oliver', 'Shenfield, Alex', 'Kareem, Murtadha', 'San, Tan Ru', 'Fujita, Hamido', 'Acharya, U Rajendra']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30184-7 [pii] 10.1016/j.compbiomed.2018.07.001 [doi]	20191028	['Algorithms', 'Atrial Fibrillation/*diagnosis', 'Data Collection', 'Databases, Factual', 'Deep Learning', 'Diagnosis, Computer-Assisted/*methods', '*Electrocardiography', '*Electronic Data Processing', 'Heart Rate', 'Humans', 'Monitoring, Physiologic', 'Neural Networks (Computer)', 'Reproducibility of Results', 'Risk', 'Sensitivity and Specificity', '*Signal Processing, Computer-Assisted', 'Software', 'Support Vector Machine']	2019/10/29 06:00		['*Atrial fibrillation', '*Deep learning', '*Heart rate', '*Recurrent neural network']	['NOTNLM']	NLM	327-335	['2018/05/16 00:00 [received]', '2018/07/04 00:00 [revised]', '2018/07/04 00:00 [accepted]', '2018/07/23 06:00 [pubmed]', '2019/10/29 06:00 [medline]', '2018/07/23 06:00 [entrez]']	United States			30031535	ppublish	['Journal Article']			IM		Comput Biol Med. 2018 Nov 1;102:327-335. doi: 10.1016/j.compbiomed.2018.07.001. Epub 2018 Jul 17.	MEDLINE	Comput Biol Med	Automated detection of atrial fibrillation using long short-term memory network with RR interval signals.		102	Automated detection of atrial fibrillation using long short-term memory network with RR interval signals.
BACKGROUND: Long short-term memory (LSTM) is one of the most attractive deep learning methods to learn time series or contexts of input data. Increasing studies, including biological sequence analyses in bioinformatics, utilize this architecture. Amino acid sequence profiles are widely used for bioinformatics studies, such as sequence similarity searches, multiple alignments, and evolutionary analyses. Currently, many biological sequences are becoming available, and the rapidly increasing amount of sequence data emphasizes the importance of scalable generators of amino acid sequence profiles. RESULTS: We employed the LSTM network and developed a novel profile generator to construct profiles without any assumptions, except for input sequence context. Our method could generate better profiles than existing de novo profile generators, including CSBuild and RPS-BLAST, on the basis of profile-sequence similarity search performance with linear calculation costs against input sequence size. In addition, we analyzed the effects of the memory power of LSTM and found that LSTM had high potential power to detect long-range interactions between amino acids, as in the case of beta-strand formation, which has been a difficult problem in protein bioinformatics using sequence information. CONCLUSION: We demonstrated the importance of sequence context and the feasibility of LSTM on biological sequence analyses. Our results demonstrated the effectiveness of memories in LSTM and showed that our de novo profile generator, SPBuild, achieved higher performance than that of existing methods for profile prediction of beta-strands, where long-range interactions of amino acids are important and are known to be difficult for the existing window-based prediction methods. Our findings will be useful for the development of other prediction methods related to biological sequences by machine learning methods.	['Graduate School of Information Sciences, Tohoku University, Sendai, Japan.', 'Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan.', 'Graduate School of Information Sciences, Tohoku University, Sendai, Japan. kengo@ecei.tohoku.ac.jp.', 'Tohoku Medical Megabank Organization, Tohoku University, Sendai, Japan. kengo@ecei.tohoku.ac.jp.', 'Institute of Development, Aging, and Cancer, Tohoku University, Sendai, Japan. kengo@ecei.tohoku.ac.jp.']	['10.1186/s12859-018-2284-1 [doi]', '10.1186/s12859-018-2284-1 [pii]']	['Yamada KD', 'Kinoshita K']							['2018/07/20 06:00']	20190422	20180718	2018 Jul 18	2018/07/20 06:00		['Yamada, Kazunori D', 'Kinoshita, Kengo']		['18K18143/Japan Society for the Promotion of Science/International']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2284-1 [doi]	20190422	['Amino Acid Sequence', 'Computational Biology/*methods', 'Databases as Topic', '*Deep Learning', '*Neural Networks (Computer)', 'Proteins/chemistry', 'ROC Curve', 'Sequence Homology, Amino Acid']	2019/04/23 06:00		['*Deep learning', '*Long short-term memory', '*Neural networks', '*Protein sequence profile', '*Sequence context', '*Similarity search']	['NOTNLM']	NLM	272	['2018/05/17 00:00 [received]', '2018/07/11 00:00 [accepted]', '2018/07/20 06:00 [entrez]', '2018/07/20 06:00 [pubmed]', '2019/04/23 06:00 [medline]']	England	PMC6052547		30021530	epublish	['Journal Article']		['0 (Proteins)']	IM		BMC Bioinformatics. 2018 Jul 18;19(1):272. doi: 10.1186/s12859-018-2284-1.	MEDLINE	BMC Bioinformatics	De novo profile generation based on sequence context specificity with the long short-term memory network.		19	De novo profile generation based on sequence context specificity with the long short-term memory network.
Mining relations between chemicals and proteins from the biomedical literature is an increasingly important task. The CHEMPROT track at BioCreative VI aims to promote the development and evaluation of systems that can automatically detect the chemical-protein relations in running text (PubMed abstracts). This work describes our CHEMPROT track entry, which is an ensemble of three systems, including a support vector machine, a convolutional neural network, and a recurrent neural network. Their output is combined using majority voting or stacking for final predictions. Our CHEMPROT system obtained 0.7266 in precision and 0.5735 in recall for an F-score of 0.6410 during the challenge, demonstrating the effectiveness of machine learning-based approaches for automatic relation extraction from biomedical literature and achieving the highest performance in the task during the 2017 challenge.Database URL: http://www.biocreative.org/tasks/biocreative-vi/track-5/.	['National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, USA.', 'National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, USA.', 'Department of Computer Science, University of Kentucky, Lexington, KY, USA.', 'Department of Computer Science, University of Kentucky, Lexington, KY, USA.', 'Division of Biomedical Informatics Department of Internal Medicine, University of Kentucky, Lexington, KY, USA.', 'National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, USA.']	['5055578 [pii]', '10.1093/database/bay073 [doi]']	['Peng Y', 'Rios A', 'Kavuluru R', 'Lu Z']							['2018/07/19 06:00']	20181102		2018 Jan 1	2018/07/19 06:00		['Peng, Yifan', 'Rios, Anthony', 'Kavuluru, Ramakanth', 'Lu, Zhiyong']		['R21 LM012274/LM/NLM NIH HHS/United States']			1758-0463 (Electronic) 1758-0463 (Linking)	101517697	Database : the journal of biological databases and curation	['eng']	10.1093/database/bay073 [doi]	20181114	['Data Curation', '*Databases, Chemical', 'Databases, Protein', '*Machine Learning', '*Models, Theoretical', 'Neural Networks (Computer)', 'Proteins/*chemistry', 'Reproducibility of Results', '*Support Vector Machine']	2018/11/06 06:00				NLM		['2018/02/05 00:00 [received]', '2018/06/15 00:00 [accepted]', '2018/07/19 06:00 [entrez]', '2018/07/19 06:00 [pubmed]', '2018/11/06 06:00 [medline]']	England	PMC6051439		30020437	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural', 'Research Support, N.I.H., Intramural']		['0 (Proteins)']	IM		Database (Oxford). 2018 Jan 1;2018. pii: 5055578. doi: 10.1093/database/bay073.	MEDLINE	Database (Oxford)	Extracting chemical-protein relations with ensembles of SVM and deep learning models.		2018	Extracting chemical-protein relations with ensembles of SVM and deep learning models.
Chemical-disease relation (CDR) extraction is significantly important to various areas of biomedical research and health care. Nowadays, many large-scale biomedical knowledge bases (KBs) containing triples about entity pairs and their relations have been built. KBs are important resources for biomedical relation extraction. However, previous research pays little attention to prior knowledge. In addition, the dependency tree contains important syntactic and semantic information, which helps to improve relation extraction. So how to effectively use it is also worth studying. In this paper, we propose a novel convolutional attention network (CAN) for CDR extraction. Firstly, we extract the shortest dependency path (SDP) between chemical and disease pairs in a sentence, which includes a sequence of words, dependency directions, and dependency relation tags. Then the convolution operations are performed on the SDP to produce deep semantic dependency features. After that, an attention mechanism is employed to learn the importance/weight of each semantic dependency vector related to knowledge representations learned from KBs. Finally, in order to combine dependency information and prior knowledge, the concatenation of weighted semantic dependency representations and knowledge representations is fed to the softmax layer for classification. Experiments on the BioCreative V CDR dataset show that our method achieves comparable performance with the state-of-the-art systems, and both dependency information and prior knowledge play important roles in CDR extraction task.	['School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, Liaoning, China. Electronic address: zhouhuiwei@dlut.edu.cn.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, Liaoning, China. Electronic address: ningshixian@mail.dlut.edu.cn.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, Liaoning, China. Electronic address: SDyyl_1949@mail.dlut.edu.cn.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, Liaoning, China. Electronic address: zhuangliu1992@mail.dlut.edu.cn.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, Liaoning, China. Electronic address: kunkun@mail.dlut.edu.cn.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian 116024, Liaoning, China. Electronic address: lyydut@sina.com.']	['S1532-0464(18)30133-3 [pii]', '10.1016/j.jbi.2018.07.007 [doi]']	['Zhou H', 'Ning S', 'Yang Y', 'Liu Z', 'Lang C', 'Lin Y']		['Copyright (c) 2018. Published by Elsevier Inc.']					['2018/07/19 06:00']	20191119	20180711	2018 Aug	2018/07/19 06:00		['Zhou, Huiwei', 'Ning, Shixian', 'Yang, Yunlong', 'Liu, Zhuang', 'Lang, Chengkun', 'Lin, Yingyu']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30133-3 [pii] 10.1016/j.jbi.2018.07.007 [doi]	20191119	['Algorithms', 'Biomedical Research', '*Chemically-Induced Disorders', 'Computational Biology', '*Databases, Factual', 'False Positive Reactions', 'Humans', '*Knowledge Bases', 'Language', 'Machine Learning', 'Models, Statistical', 'Natural Language Processing', 'Neural Networks (Computer)', 'Precision Medicine/methods', 'Research Design', '*Semantics']	2019/11/20 06:00		['*Attention mechanism', '*CDR extraction', '*Dependency information', '*Prior knowledge']	['NOTNLM']	NLM	171-178	['2018/01/29 00:00 [received]', '2018/07/09 00:00 [revised]', '2018/07/11 00:00 [accepted]', '2018/07/19 06:00 [pubmed]', '2019/11/20 06:00 [medline]', '2018/07/19 06:00 [entrez]']	United States			30017973	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Aug;84:171-178. doi: 10.1016/j.jbi.2018.07.007. Epub 2018 Jul 11.	MEDLINE	J Biomed Inform	Chemical-induced disease relation extraction with dependency information and prior knowledge.		84	Chemical-induced disease relation extraction with dependency information and prior knowledge.
Although machine learning has been successfully used to propose novel molecules that satisfy desired properties, it is still challenging to explore a large chemical space efficiently. In this paper, we present a conditional molecular design method that facilitates generating new molecules with desired properties. The proposed model, which simultaneously performs both property prediction and molecule generation, is built as a semisupervised variational autoencoder trained on a set of existing molecules with only a partial annotation. We generate new molecules with desired properties by sampling from the generative distribution estimated by the model. We demonstrate the effectiveness of the proposed model by evaluating it on drug-like molecules. The model improves the performance of property prediction by exploiting unlabeled molecules and efficiently generates novel molecules fulfilling various target conditions.	['Department of Systems Management Engineering , Sungkyunkwan University , 2066 Seobu-ro , Jangan-gu, Suwon 16419 , Republic of Korea.', 'Department of Computer Science & Center for Data Science , New York University , 60 5th Avenue , New York , New York 10011 , United States.', 'Facebook AI Research , 770 Broadway , New York , New York 10003 , United States.', 'CIFAR Azrieli Global Scholar , Canadian Institute for Advanced Research , 661 University Avenue , Toronto , ON M5G 1M1 , Canada.']	['10.1021/acs.jcim.8b00263 [doi]']	['Kang S', 'Cho K']	['ORCID: 0000-0002-0960-0294']						['2018/07/18 06:00']	20191202	20180727	2019 Jan 28	2018/07/18 06:00		['Kang, Seokho', 'Cho, Kyunghyun']			1		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.8b00263 [doi]	20191202	['Computer Simulation', '*Drug Design', '*Machine Learning', '*Models, Molecular']	2019/12/04 06:00				NLM	43-52	['2018/07/18 06:00 [pubmed]', '2019/12/04 06:00 [medline]', '2018/07/18 06:00 [entrez]']	United States			30016587	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Chem Inf Model. 2019 Jan 28;59(1):43-52. doi: 10.1021/acs.jcim.8b00263. Epub 2018 Jul 27.	MEDLINE	J Chem Inf Model	Conditional Molecular Design with Deep Generative Models.		59	Conditional Molecular Design with Deep Generative Models.
Key challenges for human genetics, precision medicine and evolutionary biology include deciphering the regulatory code of gene expression and understanding the transcriptional effects of genome variation. However, this is extremely difficult because of the enormous scale of the noncoding mutation space. We developed a deep learning-based framework, ExPecto, that can accurately predict, ab initio from a DNA sequence, the tissue-specific transcriptional effects of mutations, including those that are rare or that have not been observed. We prioritized causal variants within disease- or trait-associated loci from all publicly available genome-wide association studies and experimentally validated predictions for four immune-related diseases. By exploiting the scalability of ExPecto, we characterized the regulatory mutation space for human RNA polymerase II-transcribed genes by in silico saturation mutagenesis and profiled > 140 million promoter-proximal mutations. This enables probing of evolutionary constraints on gene expression and ab initio prediction of mutation disease effects, making ExPecto an end-to-end computational framework for the in silico prediction of expression and disease risk.	['Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, NJ, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Flatiron Institute, Simons Foundation, New York, NY, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA. ogt@cs.princeton.edu.', 'Flatiron Institute, Simons Foundation, New York, NY, USA. ogt@cs.princeton.edu.', 'Department of Computer Science, Princeton University, Princeton, NJ, USA. ogt@cs.princeton.edu.']	['10.1038/s41588-018-0160-6 [doi]', '10.1038/s41588-018-0160-6 [pii]']	['Zhou J', 'Theesfeld CL', 'Yao K', 'Chen KM', 'Wong AK', 'Troyanskaya OG']	['ORCID: http://orcid.org/0000-0002-8379-6600', 'ORCID: http://orcid.org/0000-0002-5676-5737']		['Nat Methods. 2018 Aug;15(8):571. PMID: 30065379']				['2018/07/18 06:00']	20190424	20180716	2018 Aug	2018/07/18 06:00		['Zhou, Jian', 'Theesfeld, Chandra L', 'Yao, Kevin', 'Chen, Kathleen M', 'Wong, Aaron K', 'Troyanskaya, Olga G']		['HHSN272201000054C/AI/NIAID NIH HHS/United States', 'U54 HL117798/HL/NHLBI NIH HHS/United States', 'R01 GM071966/GM/NIGMS NIH HHS/United States', 'U19 AI117873/AI/NIAID NIH HHS/United States', 'R01 HG005998/HG/NHGRI NIH HHS/United States']	8		1546-1718 (Electronic) 1061-4036 (Linking)	9216904	Nature genetics	['eng']	10.1038/s41588-018-0160-6 [doi]	20190601	['Algorithms', 'Computer Simulation', '*Deep Learning', 'Gene Expression', '*Genetic Predisposition to Disease', 'Genome-Wide Association Study/*methods', 'Humans', 'Models, Genetic', '*Mutation', 'Polymorphism, Single Nucleotide', 'Promoter Regions, Genetic', 'Quantitative Trait Loci/genetics']	2019/04/25 06:00	['NIHMS965313']			NLM	1171-1179	['2017/12/09 00:00 [received]', '2018/05/03 00:00 [accepted]', '2018/07/18 06:00 [pubmed]', '2019/04/25 06:00 [medline]', '2018/07/18 06:00 [entrez]']	United States	PMC6094955		30013180	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, P.H.S.""]"			IM		Nat Genet. 2018 Aug;50(8):1171-1179. doi: 10.1038/s41588-018-0160-6. Epub 2018 Jul 16.	MEDLINE	Nat Genet	Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk.		50	Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk.
Electromyogram (EMG) signal decoding is the essential part of myoelectric control. However, traditional machine learning methods lack the capability of learning and expressing the information contained in EMG signals, and the robustness of the myoelectric control system is not sufficient for real life applications. In this article, a novel model based on recurrent convolutional neural networks (RCNNs) is proposed for hand movement classification and tested on the noninvasive EMG dataset. The proposed model uses deep architecture, which has advantages of dealing with complex time-series data, such as EMG signals. Transfer learning is used in the training of multimodal model. The classification performance is compared with support vector machine (SVM) and convolutional neural networks (CNNs) on the same dataset. To improve the adaptability to the effect of arm movements, we fused the EMG signals and acceleration data that are the multimodal input of the model. The parameter transferring of deep neural networks is used to accelerate the training process and avoid over-fitting. The experimental results show that time domain input and 1-dimensional convolution have higher accuracy in the RCNN model. Compared with SVM and CNNs, the proposed model has higher classification accuracy. Sensor fusion can improve the model performance in the condition of arm movements. The RCNN model is a promising decoder of EMG and the sensor fusion can increase the accuracy and robustness of the myoelectric control system.	['School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China.', 'School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China.', 'School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China.', 'School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China.', 'School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China.']	['10.1111/aor.13153 [doi]']	['Wang W', 'Chen B', 'Xia P', 'Hu J', 'Peng Y']	['ORCID: http://orcid.org/0000-0002-1406-3315', 'ORCID: http://orcid.org/0000-0002-1118-2714']	['(c) 2018 International Center for Artificial Organs and Transplantation and Wiley', 'Periodicals, Inc.']					['2018/07/14 06:00']	20190129	20180713	2018 Sep	2018/07/14 06:00		['Wang, Weiming', 'Chen, Biao', 'Xia, Peng', 'Hu, Jie', 'Peng, Yinghong']		['2011CB707503/National Basic Research Program of China', '51675342/National Natural Science Foundation of China', '51675329/National Natural Science Foundation of China', '51605302/National Natural Science Foundation of China', '2016YFF0101602/National Key Scientific Instruments and Equipment Development', 'Program of China', '2016YFC0104104/National Key Scientific Instruments and Equipment Development', 'Program of China', '2013YQ03065105/National Key Scientific Instruments and Equipment Development', 'Program of China', 'Cross Fund for Medical and Engineering', 'YG2014MS12/Shanghai Jiao Tong University']	9		1525-1594 (Electronic) 0160-564X (Linking)	7802778	Artificial organs	['eng']	10.1111/aor.13153 [doi]	20190129	['Adult', 'Algorithms', '*Deep Learning', '*Electromyography', 'Female', 'Humans', 'Male', 'Muscle, Skeletal/*physiology', '*Neural Networks (Computer)', 'Support Vector Machine', 'Transfer (Psychology)']	2019/01/30 06:00		['Deep learning', 'Electromyogram', 'Recurrent convolutional neural networks', 'Sensor fusion', 'Transfer learning']	['NOTNLM']	NLM	E272-E282	['2018/01/15 00:00 [received]', '2018/02/21 00:00 [revised]', '2018/03/06 00:00 [accepted]', '2018/07/14 06:00 [pubmed]', '2019/01/30 06:00 [medline]', '2018/07/14 06:00 [entrez]']	United States			30003559	ppublish	['Journal Article']			IM		Artif Organs. 2018 Sep;42(9):E272-E282. doi: 10.1111/aor.13153. Epub 2018 Jul 13.	MEDLINE	Artif Organs	Sensor Fusion for Myoelectric Control Based on Deep Learning With Recurrent Convolutional Neural Networks.		42	Sensor Fusion for Myoelectric Control Based on Deep Learning With Recurrent Convolutional Neural Networks.
With the advent of biomedical imaging technology, the number of captured and stored biomedical images is rapidly increasing day by day in hospitals, imaging laboratories and biomedical institutions. Therefore, more robust biomedical image analysis technology is needed to meet the requirement of the diagnosis and classification of various kinds of diseases using biomedical images. However, the current biomedical image classification methods and general non-biomedical image classifiers cannot extract more compact biomedical image features or capture the tiny differences between similar images with different types of diseases from the same category. In this paper, we propose a novel fused convolutional neural network to develop a more accurate and highly efficient classifier for biomedical images, which combines shallow layer features and deep layer features from the proposed deep neural network architecture. In the analysis, it was observed that the shallow layers provided more detailed local features, which could distinguish different diseases in the same category, while the deep layers could convey more high-level semantic information used to classify the diseases among the various categories. A detailed comparison of our approach with traditional classification algorithms and popular deep classifiers across several public biomedical image datasets showed the superior performance of our proposed method for biomedical image classification. In addition, we also evaluated the performance of our method in modality classification of medical images using the ImageCLEFmed dataset. Graphical abstract The graphical abstract shows the fused, deep convolutional neural network architecture proposed for biomedical image classification. In the architecture, we can clearly see the feature-fusing process going from shallow layers and the deep layers.	['Department of Computational Intelligence, College of Computer Science and Technology, Jilin University, Qianjin Street 2699, Changchun, Jilin Province, China.', 'Department of Computing, Macquarie University, Sydney, NSW, 2109, Australia.', 'China Mobile (HangZhou) Information Technology Co., Ltd, Hangzhou, China.', 'Department of Computing, Macquarie University, Sydney, NSW, 2109, Australia.', 'Department of Computational Intelligence, College of Computer Science and Technology, Jilin University, Qianjin Street 2699, Changchun, Jilin Province, China. yuzz@jlu.edu.cn.']	['10.1007/s11517-018-1819-y [doi]', '10.1007/s11517-018-1819-y [pii]']	['Pang S', 'Du A', 'Orgun MA', 'Yu Z']	['ORCID: http://orcid.org/0000-0003-1758-632X']						['2018/07/14 06:00']	20190521	20180712	2019 Jan	2018/07/14 06:00		['Pang, Shuchao', 'Du, Anan', 'Orgun, Mehmet A', 'Yu, Zhezhou']		['20150204007GX/project of Science and Technology Development Plan of Jilin', 'Province, China', '20120061110045/Specialized Research Fund for the Doctoral Program of Higher', 'Education of China']	1		1741-0444 (Electronic) 0140-0118 (Linking)	7704869	Medical & biological engineering & computing	['eng']	10.1007/s11517-018-1819-y [doi]	20190521	['Algorithms', 'Deep Learning', 'Diagnostic Imaging/*classification', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Neural Networks (Computer)']	2019/05/22 06:00		['Biomedical image classification', 'Convolutional neural networks', 'Deep feature', 'Deep learning', 'Shallow feature']	['NOTNLM']	NLM	107-121	['2017/08/01 00:00 [received]', '2018/03/17 00:00 [accepted]', '2018/07/14 06:00 [pubmed]', '2019/05/22 06:00 [medline]', '2018/07/14 06:00 [entrez]']	United States			30003400	ppublish	['Journal Article']			IM		Med Biol Eng Comput. 2019 Jan;57(1):107-121. doi: 10.1007/s11517-018-1819-y. Epub 2018 Jul 12.	MEDLINE	Med Biol Eng Comput	A novel fused convolutional neural network for biomedical image classification.		57	A novel fused convolutional neural network for biomedical image classification.
Retinal fundus photographs have been used in the diagnosis of many ocular diseases such as glaucoma, pathological myopia, age-related macular degeneration, and diabetic retinopathy. With the development of computer science, computer aided diagnosis has been developed to process and analyze the retinal images automatically. One of the challenges in the analysis is that the quality of the retinal image is often degraded. For example, a cataract in human lens will attenuate the retinal image, just as a cloudy camera lens which reduces the quality of a photograph. It often obscures the details in the retinal images and posts challenges in retinal image processing and analyzing tasks. In this paper, we approximate the degradation of the retinal images as a combination of human-lens attenuation and scattering. A novel structure-preserving guided retinal image filtering (SGRIF) is then proposed to restore images based on the attenuation and scattering model. The proposed SGRIF consists of a step of global structure transferring and a step of global edge-preserving smoothing. Our results show that the proposed SGRIF method is able to improve the contrast of retinal images, measured by histogram flatness measure, histogram spread, and variability of local luminosity. In addition, we further explored the benefits of SGRIF for subsequent retinal image processing and analyzing tasks. In the two applications of deep learning-based optic cup segmentation and sparse learning-based cup-to-disk ratio (CDR) computation, our results show that we are able to achieve more accurate optic cup segmentation and CDR measurements from images processed by SGRIF.		['10.1109/TMI.2018.2838550 [doi]']	['Cheng J', 'Li Z', 'Gu Z', 'Fu H', 'Wong DWK', 'Liu J']							['2018/07/12 06:00']	20190819	20180521	2018 Nov	2018/07/12 06:00		['Cheng, Jun', 'Li, Zhengguo', 'Gu, Zaiwang', 'Fu, Huazhu', 'Wong, Damon Wing Kee', 'Liu, Jiang']			11		1558-254X (Electronic) 0278-0062 (Linking)	8310780	IEEE transactions on medical imaging	['eng']	10.1109/TMI.2018.2838550 [doi]	20190819	['Algorithms', '*Deep Learning', '*Diagnostic Techniques, Ophthalmological', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Optic Disk/*diagnostic imaging', 'Retina/diagnostic imaging', 'Retinal Diseases/diagnostic imaging']	2019/08/20 06:00				NLM	2536-2546	['2018/07/12 06:00 [pubmed]', '2019/08/20 06:00 [medline]', '2018/07/12 06:00 [entrez]']	United States			29994522	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					IEEE Trans Med Imaging. 2018 Nov;37(11):2536-2546. doi: 10.1109/TMI.2018.2838550. Epub 2018 May 21.	MEDLINE	IEEE Trans Med Imaging	Structure-Preserving Guided Retinal Image Filtering and Its Application for Optic Disk Analysis.		37	Structure-Preserving Guided Retinal Image Filtering and Its Application for Optic Disk Analysis.
Fungus is enormously notorious for food, human health, and archives. Fungus sign and symptoms in medical science are non-specific and asymmetrical for extremely large areas resulting into a challenging task of fungal detection. Various traditional and computer vision techniques were applied to meet the challenge of early fungus detection. On the other hand, features learned through the convolutional neural network (CNN) provided state-of-the-art results in many other applications of object detection and classification. However, the large amount of data is an essential prerequisite for its effective application. In pursuing this idea, we present a novel fungus dataset of its kind, with the goal of advancing the state of the art in fungus classification by placing the question of fungus detection. This is achieved by gathering various images of complex fungal spores by extracting samples from contaminated fruits, archives, and laboratory-incubated fungus colonies. These images primarily consisted of five different types of fungus spores and dirt. An optical sensor system was utilized to obtain these images, which were further annotated to mark fungal spores as a region of interest using specially designed graphical user interface. As a result, 40,800 labeled images were used to develop the fungus dataset to aid in precise fungus detection and classification. The other main objective of this research was to develop a CNN-based approach for the detection of fungus and distinguish different types of fungus. A CNN architecture was designed, and it showed the promising results with an accuracy of 94.8%. The obtained results proved the possibility of early detection of several types of fungus spores using CNN and could estimate all possible threats due to fungus.		['10.1109/TNB.2018.2839585 [doi]']	['Tahir MW', 'Zaidi NA', 'Rao AA', 'Blank R', 'Vellekoop MJ', 'Lang W']							['2018/07/12 06:00']	20190508	20180522	2018 Jul	2018/07/12 06:00		['Tahir, Muhammad Waseem', 'Zaidi, Nayyer Abbas', 'Rao, Adeel Akhtar', 'Blank, Roland', 'Vellekoop, Michael J', 'Lang, Walter']			3		1558-2639 (Electronic) 1536-1241 (Linking)	101152869	IEEE transactions on nanobioscience	['eng']	10.1109/TNB.2018.2839585 [doi]	20190508	['*Databases, Factual', 'Deep Learning', '*Fungi/classification/cytology', 'Image Processing, Computer-Assisted/*methods', 'Microscopy', '*Neural Networks (Computer)', '*Spores, Fungal/classification/cytology']	2019/05/09 06:00				NLM	281-290	['2018/07/12 06:00 [pubmed]', '2019/05/09 06:00 [medline]', '2018/07/12 06:00 [entrez]']	United States			29994314	ppublish	"['Dataset', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		IEEE Trans Nanobioscience. 2018 Jul;17(3):281-290. doi: 10.1109/TNB.2018.2839585. Epub 2018 May 22.	MEDLINE	IEEE Trans Nanobioscience	A Fungus Spores Dataset and a Convolutional Neural Network Based Approach for Fungus Detection.		17	A Fungus Spores Dataset and a Convolutional Neural Network Based Approach for Fungus Detection.
Self-interacting proteins (SIPs) play a significant role in the execution of most important molecular processes in cells, such as signal transduction, gene expression regulation, immune response and enzyme activation. Although the traditional experimental methods can be used to generate SIPs data, it is very expensive and time-consuming based only on biological technique. Therefore, it is important and urgent to develop an efficient computational method for SIPs detection. In this study, we present a novel SIPs identification method based on machine learning technology by combing the Zernike Moments (ZMs) descriptor on Position Specific Scoring Matrix (PSSM) with Probabilistic Classification Vector Machines (PCVM) and Stacked Sparse Auto-Encoder (SSAE). More specifically, an efficient feature extraction technique called ZMs is firstly utilized to generate feature vectors on Position Specific Scoring Matrix (PSSM); Then, Deep neural network is employed for reducing the feature dimensions and noise; Finally, the Probabilistic Classification Vector Machine is used to execute the classification. The prediction performance of the proposed method is evaluated on S.erevisiae and Human SIPs datasets via cross-validation. The experimental results indicate that the proposed method can achieve good accuracies of 92.55% and 97.47%, respectively. To further evaluate the advantage of our scheme for SIPs prediction, we also compared the PCVM classifier with the Support Vector Machine (SVM) and other existing techniques on the same data sets. Comparison results reveal that the proposed strategy is outperforms other methods and could be a used tool for identifying SIPs.	['University of Chinese Academy of Sciences, Beijing 100049, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi 830011, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi 830011, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi 830011, China.', 'Institute of Machine Learning and Systems Biology, School of Electronics and Information Engineering, Tongji University, Caoan Road 4800, Shanghai 201804, China.', 'College of Computer Science and Technology, and Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, Jilin 130012, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi 830011, China.']	['10.7150/ijbs.23817 [doi]', 'ijbsv14p0983 [pii]']	['Wang YB', 'You ZH', 'Li LP', 'Huang DS', 'Zhou FF', 'Yang S']					['Competing Interests: The authors have declared that no competing interest exists.']		['2018/07/11 06:00']	20190731	20180523	2018	2018/07/11 06:00		['Wang, Yan-Bin', 'You, Zhu-Hong', 'Li, Li-Ping', 'Huang, De-Shuang', 'Zhou, Feng-Feng', 'Yang, Shan']			8		1449-2288 (Electronic) 1449-2288 (Linking)	101235568	International journal of biological sciences	['eng']	10.7150/ijbs.23817 [doi]	20190731	['Algorithms', 'Computational Biology/*methods', 'Deep Learning', 'Protein Interaction Mapping', 'Proteins/*chemistry', 'Support Vector Machine']	2019/08/01 06:00		['*Deep learning', '*Probabilistic Classification Vector Machines', '*Zernike Moments']	['NOTNLM']	NLM	983-991	['2017/11/13 00:00 [received]', '2018/03/29 00:00 [accepted]', '2018/07/11 06:00 [entrez]', '2018/07/11 06:00 [pubmed]', '2019/08/01 06:00 [medline]']	Australia	PMC6036743		29989064	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"		['0 (Proteins)']			Int J Biol Sci. 2018 May 23;14(8):983-991. doi: 10.7150/ijbs.23817. eCollection 2018.	MEDLINE	Int J Biol Sci	Improving Prediction of Self-interacting Proteins Using Stacked Sparse Auto-Encoder with PSSM profiles.		14	Improving Prediction of Self-interacting Proteins Using Stacked Sparse Auto-Encoder with PSSM profiles.
BACKGROUND: Bilingual lexicon induction (BLI) is an important task in the biomedical domain as translation resources are usually available for general language usage, but are often lacking in domain-specific settings. In this article we consider BLI as a classification problem and train a neural network composed of a combination of recurrent long short-term memory and deep feed-forward networks in order to obtain word-level and character-level representations. RESULTS: The results show that the word-level and character-level representations each improve state-of-the-art results for BLI and biomedical translation mining. The best results are obtained by exploiting the synergy between these word-level and character-level representations in the classification model. We evaluate the models both quantitatively and qualitatively. CONCLUSIONS: Translation of domain-specific biomedical terminology benefits from the character-level representations compared to relying solely on word-level representations. It is beneficial to take a deep learning approach and learn character-level representations rather than relying on handcrafted representations that are typically used. Our combined model captures the semantics at the word level while also taking into account that specialized terminology often originates from a common root form (e.g., from Greek or Latin).	['LIIR, Department of Computer Science, Celestijnenlaan 200A, Leuven, Belgium. geert.heyman@cs.kuleuven.be.', 'Language Technology Lab, DTAL, University of Cambridge, 9 West Road, Cambridge, UK.', 'LIIR, Department of Computer Science, Celestijnenlaan 200A, Leuven, Belgium.']	['10.1186/s12859-018-2245-8 [doi]', '10.1186/s12859-018-2245-8 [pii]']	['Heyman G', 'Vulic I', 'Moens MF']	['ORCID: 0000-0001-6276-424X']						['2018/07/11 06:00']	20190212	20180709	2018 Jul 9	2018/07/11 06:00		['Heyman, Geert', 'Vulic, Ivan', 'Moens, Marie-Francine']			1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2245-8 [doi]	20190215	['Data Mining/*methods', '*Deep Learning', 'Humans', 'Knowledge Bases', 'Multilingualism', '*Natural Language Processing', '*Semantics']	2019/02/13 06:00		['*Bilingual lexicon induction', '*Biomedical text mining', '*Medical terminology', '*Representation learning']	['NOTNLM']	NLM	259	['2017/06/06 00:00 [received]', '2018/06/14 00:00 [accepted]', '2018/07/11 06:00 [entrez]', '2018/07/11 06:00 [pubmed]', '2019/02/13 06:00 [medline]']	England	PMC6038323		29986664	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Bioinformatics. 2018 Jul 9;19(1):259. doi: 10.1186/s12859-018-2245-8.	MEDLINE	BMC Bioinformatics	A deep learning approach to bilingual lexicon induction in the biomedical domain.		19	A deep learning approach to bilingual lexicon induction in the biomedical domain.
The efficient operation of wastewater treatment plants (WWTPs) is key to ensuring a sustainable and friendly green environment. Monitoring wastewater processes is helpful not only for evaluating the process operating conditions but also for inspecting product quality. This paper presents a flexible and efficient fault detection approach based on unsupervised deep learning to monitor the operating conditions of WWTPs. Specifically, this approach integrates a deep belief networks (DBN) model and a one-class support vector machine (OCSVM) to separate normal from abnormal features by simultaneously taking advantage of the feature-extraction capability of DBNs and the superior predicting capacity of OCSVM. Here, the DBN model, which is a powerful tool with greedy learning features, accounts for the nonlinear aspects of WWTPs, while OCSVM is used to reliably detect the faults. The developed DBN-OCSVM approach is tested through a practical application on data from a decentralized WWTP in Golden, CO, USA. The results from the DBN-OCSVM are compared with two other detectors: DBN-based K-nearest neighbor and K-means algorithms. The results show the capability of the developed strategy to monitor the WWTP, suggesting that it can raise an early alert to the abnormal conditions.	['King Abdullah University of Science and Technology (KAUST), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal 23955-6900, Saudi Arabia. Electronic address: fouzi.harrou@kaust.edu.sa.', 'Computer Science Department, University of Oran, 1 Ahmed Ben Bella, Algeria Street El senia el mnouer bp, 31000 Oran, Algeria. Electronic address: dairi.aek@gmail.com.', 'King Abdullah University of Science and Technology (KAUST), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal 23955-6900, Saudi Arabia.', 'Computer Science Department, University of Oran, 1 Ahmed Ben Bella, Algeria Street El senia el mnouer bp, 31000 Oran, Algeria.']	['S0301-4797(18)30739-4 [pii]', '10.1016/j.jenvman.2018.06.087 [doi]']	['Harrou F', 'Dairi A', 'Sun Y', 'Senouci M']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/07/10 06:00']	20181105	20180705	2018 Oct 1	2018/07/10 06:00		['Harrou, Fouzi', 'Dairi, Abdelkader', 'Sun, Ying', 'Senouci, Mohamed']					1095-8630 (Electronic) 0301-4797 (Linking)	0401664	Journal of environmental management	['eng']	S0301-4797(18)30739-4 [pii] 10.1016/j.jenvman.2018.06.087 [doi]	20181105	['*Algorithms', 'Models, Theoretical', '*Support Vector Machine', 'Waste Management', '*Waste Water']	2018/11/06 06:00		['Anomaly detection', 'DBNs', 'Learning', 'OCSVM', 'Statistical monitoring', 'Wastewater']	['NOTNLM']	NLM	807-814	['2017/12/09 00:00 [received]', '2018/04/01 00:00 [revised]', '2018/06/28 00:00 [accepted]', '2018/07/10 06:00 [pubmed]', '2018/11/06 06:00 [medline]', '2018/07/10 06:00 [entrez]']	England			29986328	ppublish	['Journal Article']		['0 (Waste Water)']	IM		J Environ Manage. 2018 Oct 1;223:807-814. doi: 10.1016/j.jenvman.2018.06.087. Epub 2018 Jul 5.	MEDLINE	J Environ Manage	Statistical monitoring of a wastewater treatment plant: A case study.		223	Statistical monitoring of a wastewater treatment plant: A case study.
The current deluge of newly identified RNA transcripts presents a singular opportunity for improved assessment of coding potential, a cornerstone of genome annotation, and for machine-driven discovery of biological knowledge. While traditional, feature-based methods for RNA classification are limited by current scientific knowledge, deep learning methods can independently discover complex biological rules in the data de novo. We trained a gated recurrent neural network (RNN) on human messenger RNA (mRNA) and long noncoding RNA (lncRNA) sequences. Our model, mRNA RNN (mRNN), surpasses state-of-the-art methods at predicting protein-coding potential despite being trained with less data and with no prior concept of what features define mRNAs. To understand what mRNN learned, we probed the network and uncovered several context-sensitive codons highly predictive of coding potential. Our results suggest that gated RNNs can learn complex and long-range patterns in full-length human transcripts, making them ideal for performing a wide range of difficult classification tasks and, most importantly, for harvesting new biological insights from the rising flood of sequencing data.	['School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, OR 97331, USA.', 'Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, OR 97331, USA.', 'Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, OR 97331, USA.', 'School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, OR 97331, USA.', 'School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, OR 97331, USA.', 'School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, OR 97331, USA.', 'Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, OR 97331, USA.']	['5050624 [pii]', '10.1093/nar/gky567 [doi]']	['Hill ST', 'Kuintzle R', 'Teegarden A', 'Merrill E 3rd', 'Danaee P', 'Hendrix DA']							['2018/07/10 06:00']	20190813		2018 Sep 19	2018/07/10 06:00		['Hill, Steven T', 'Kuintzle, Rachael', 'Teegarden, Amy', 'Merrill, Erich 3rd', 'Danaee, Padideh', 'Hendrix, David A']			16		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gky567 [doi]	20190813	['Base Sequence', 'Computational Biology/*methods', 'Humans', 'Machine Learning', '*Neural Networks (Computer)', 'Open Reading Frames/*genetics', 'Protein Biosynthesis', 'RNA, Long Noncoding/*genetics', 'RNA, Messenger/*genetics', 'Reproducibility of Results', 'Sequence Analysis, RNA/methods']	2019/08/14 06:00				NLM	8105-8113	['2018/04/11 00:00 [received]', '2018/06/15 00:00 [accepted]', '2018/07/10 06:00 [pubmed]', '2019/08/14 06:00 [medline]', '2018/07/10 06:00 [entrez]']	England	PMC6144860		29986088	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA, Long Noncoding)', '0 (RNA, Messenger)']			Nucleic Acids Res. 2018 Sep 19;46(16):8105-8113. doi: 10.1093/nar/gky567.	MEDLINE	Nucleic Acids Res	A deep recurrent neural network discovers complex biological rules to decipher RNA protein-coding potential.		46	A deep recurrent neural network discovers complex biological rules to decipher RNA protein-coding potential.
Motivation: In bioinformatics, machine learning-based methods that predict the compound-protein interactions (CPIs) play an important role in the virtual screening for drug discovery. Recently, end-to-end representation learning for discrete symbolic data (e.g. words in natural language processing) using deep neural networks has demonstrated excellent performance on various difficult problems. For the CPI problem, data are provided as discrete symbolic data, i.e. compounds are represented as graphs where the vertices are atoms, the edges are chemical bonds, and proteins are sequences in which the characters are amino acids. In this study, we investigate the use of end-to-end representation learning for compounds and proteins, integrate the representations, and develop a new CPI prediction approach by combining a graph neural network (GNN) for compounds and a convolutional neural network (CNN) for proteins. Results: Our experiments using three CPI datasets demonstrated that the proposed end-to-end approach achieves competitive or higher performance as compared to various existing CPI prediction methods. In addition, the proposed approach significantly outperformed existing methods on an unbalanced dataset. This suggests that data-driven representations of compounds and proteins obtained by end-to-end GNNs and CNNs are more robust than traditional chemical and biological features obtained from databases. Although analyzing deep learning models is difficult due to their black-box nature, we address this issue using a neural attention mechanism, which allows us to consider which subsequences in a protein are more important for a drug compound when predicting its interaction. The neural attention mechanism also provides effective visualization, which makes it easier to analyze a model even when modeling is performed using real-valued representations instead of discrete features. Availability and implementation: https://github.com/masashitsubaki. Supplementary information: Supplementary data are available at Bioinformatics online.	['National Institute of Advanced Industrial Science and Technology, Artificial Intelligence Research Center, Tokyo, Japan.', 'National Institute of Advanced Industrial Science and Technology, Artificial Intelligence Research Center, Tokyo, Japan.', 'AIST- Tokyo Tech Real World Big-Data Computation Open Innovation Laboratory, Tokyo, Japan.', 'National Institute of Advanced Industrial Science and Technology, Artificial Intelligence Research Center, Tokyo, Japan.', 'AIST- Tokyo Tech Real World Big-Data Computation Open Innovation Laboratory, Tokyo, Japan.']	['5050020 [pii]', '10.1093/bioinformatics/bty535 [doi]']	['Tsubaki M', 'Tomii K', 'Sese J']							['2018/07/09 06:00']	20191024		2019 Jan 15	2018/07/10 06:00		['Tsubaki, Masashi', 'Tomii, Kentaro', 'Sese, Jun']			2		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty535 [doi]	20191024	['*Deep Learning', 'Drug Discovery', '*Neural Networks (Computer)', '*Protein Interaction Mapping', 'Proteins/*chemistry']	2019/10/28 06:00				NLM	309-318	['2018/01/09 00:00 [received]', '2018/07/03 00:00 [accepted]', '2018/07/10 06:00 [pubmed]', '2019/10/28 06:00 [medline]', '2018/07/09 06:00 [entrez]']	England			29982330	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		Bioinformatics. 2019 Jan 15;35(2):309-318. doi: 10.1093/bioinformatics/bty535.	MEDLINE	Bioinformatics	Compound-protein interaction prediction with end-to-end learning of neural networks for graphs and sequences.		35	Compound-protein interaction prediction with end-to-end learning of neural networks for graphs and sequences.
PURPOSE OF REVIEW: Evidence that artificial intelligence (AI) is useful for predicting risk factors for hypertension and its management is emerging. However, we are far from harnessing the innovative AI tools to predict these risk factors for hypertension and applying them to personalized management. This review summarizes recent advances in the computer science and medical field, illustrating the innovative AI approach for potential prediction of early stages of hypertension. Additionally, we review ongoing research and future implications of AI in hypertension management and clinical trials, with an eye towards personalized medicine. RECENT FINDINGS: Although recent studies demonstrate that AI in hypertension research is feasible and possibly useful, AI-informed care has yet to transform blood pressure (BP) control. This is due, in part, to lack of data on AI's consistency, accuracy, and reliability in the BP sphere. However, many factors contribute to poorly controlled BP, including biological, environmental, and lifestyle issues. AI allows insight into extrapolating data analytics to inform prescribers and patients about specific factors that may impact their BP control. To date, AI has been mainly used to investigate risk factors for hypertension, but has not yet been utilized for hypertension management due to the limitations of study design and of physician's engagement in computer science literature. The future of AI with more robust architecture using multi-omics approaches and wearable technology will likely be an important tool allowing to incorporate biological, lifestyle, and environmental factors into decision-making of appropriate drug use for BP control.	['Department of Internal Medicine, Icahn School of Medicine at Mount Sinai, Tenth Avenue, Suite 3A-09, New York, NY, 10019, USA. Chayakrit.Krittanawong@Mountsinai.org.', 'Division of Nephrology, College of Physicians and Surgeons, Columbia University, New York, NY, USA.', 'Cardiovascular Institute, Icahn School of Medicine at Mount Sinai, New York, NY, USA.', 'Department of Cardiovascular Medicine, NYU Langone Health, School of Medicine, New York University, New York, NY, USA.', 'Mount Sinai Icahn School of Medicine, New York, NY, USA.', 'University of Bern, Bern, Switzerland.', 'Jagiellonian University Krakow, Krakow, Poland.', 'Department of Cardiovascular Medicine, Heart and Vascular Institute, Cleveland, OH, USA.', 'Department of Cellular and Molecular Medicine, Lerner Research Institute, Cleveland, OH, USA.', 'Center for Clinical Genomics, Cleveland Clinic, Cleveland, OH, USA.']	['10.1007/s11906-018-0875-x [doi]', '10.1007/s11906-018-0875-x [pii]']	['Krittanawong C', 'Bomback AS', 'Baber U', 'Bangalore S', 'Messerli FH', 'Wilson Tang WH']							['2018/07/08 06:00']	20190918	20180706	2018 Jul 6	2018/07/08 06:00		['Krittanawong, Chayakrit', 'Bomback, Andrew S', 'Baber, Usman', 'Bangalore, Sripal', 'Messerli, Franz H', 'Wilson Tang, W H']			9		1534-3111 (Electronic) 1522-6417 (Linking)	100888982	Current hypertension reports	['eng']	10.1007/s11906-018-0875-x [doi]	20190918	['*Artificial Intelligence', 'Biomedical Research', '*Disease Management', 'Humans', 'Hypertension/*therapy', 'Practice Guidelines as Topic', 'Precision Medicine']	2019/09/19 06:00		['*Artificial intelligence', '*Big data', '*Deep learning', '*Hypertension', '*Machine learning', '*Wearable technology']	['NOTNLM']	NLM	75	['2018/07/08 06:00 [entrez]', '2018/07/08 06:00 [pubmed]', '2019/09/19 06:00 [medline]']	United States			29980865	epublish	['Journal Article', 'Review']			IM		Curr Hypertens Rep. 2018 Jul 6;20(9):75. doi: 10.1007/s11906-018-0875-x.	MEDLINE	Curr Hypertens Rep	Future Direction for Using Artificial Intelligence to Predict and Manage Hypertension.		20	Future Direction for Using Artificial Intelligence to Predict and Manage Hypertension.
OBJECTIVES: Automated detection and quantification of plant diseases would enable more rapid gains in plant breeding and faster scouting of farmers' fields. However, it is difficult for a simple algorithm to distinguish between the target disease and other sources of dead plant tissue in a typical field, especially given the many variations in lighting and orientation. Training a machine learning algorithm to accurately detect a given disease from images taken in the field requires a massive amount of human-generated training data. DATA DESCRIPTION: This data set contains images of maize (Zea mays L.) leaves taken in three ways: by a hand-held camera, with a camera mounted on a boom, and with a camera mounted on a small unmanned aircraft system (sUAS, commonly known as a drone). Lesions of northern leaf blight (NLB), a common foliar disease of maize, were annotated in each image by one of two human experts. The three data sets together contain 18,222 images annotated with 105,705 NLB lesions, making this the largest publicly available image set annotated for a single plant disease.	['Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY, 14853, USA.', 'Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY, 14853, USA.', 'Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY, 14853, USA.', 'Department of Computer Science, Columbia University, New York, NY, 10027, USA.', 'Department of Computer Science, Columbia University, New York, NY, 10027, USA.', 'Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University, Ithaca, NY, 14853, USA.', 'Department of Mechanical Engineering and Institute of Data Science, Columbia University, New York, NY, 10027, USA.', 'Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY, 14853, USA. mag87@cornell.edu.']	['10.1186/s13104-018-3548-6 [doi]', '10.1186/s13104-018-3548-6 [pii]']	['Wiesner-Hanks T', 'Stewart EL', 'Kaczmar N', 'DeChant C', 'Wu H', 'Nelson RJ', 'Lipson H', 'Gore MA']							['2018/07/05 06:00']	20190103	20180703	2018 Jul 3	2018/07/05 06:00		['Wiesner-Hanks, Tyr', 'Stewart, Ethan L', 'Kaczmar, Nicholas', 'DeChant, Chad', 'Wu, Harvey', 'Nelson, Rebecca J', 'Lipson, Hod', 'Gore, Michael A']		['1527232/National Science Foundation']	1		1756-0500 (Electronic) 1756-0500 (Linking)	101462768	BMC research notes	['eng']	10.1186/s13104-018-3548-6 [doi]	20190103	['Algorithms', '*Data Curation', '*Deep Learning', 'Humans', '*Plant Breeding', 'Plant Diseases', '*Zea mays']	2019/01/04 06:00		['Convolutional neural network', 'Corn', 'Deep learning', 'Disease', 'Images', 'Machine learning', 'Maize', 'Phytopathology', 'Plant disease']	['NOTNLM']	NLM	440	['2018/04/19 00:00 [received]', '2018/06/27 00:00 [accepted]', '2018/07/05 06:00 [entrez]', '2018/07/05 06:00 [pubmed]', '2019/01/04 06:00 [medline]']	England	PMC6030791		29970178	epublish	['Journal Article']			IM		BMC Res Notes. 2018 Jul 3;11(1):440. doi: 10.1186/s13104-018-3548-6.	MEDLINE	BMC Res Notes	Image set for deep learning: field images of maize annotated with disease symptoms.		11	Image set for deep learning: field images of maize annotated with disease symptoms.
CellProfiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. Here, we describe CellProfiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3D) image stacks, increasingly common in biomedical research. CellProfiler's infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. New plugins enable running pretrained deep learning models on images. Designed by and for biologists, CellProfiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows.	['Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Skolkovo Institute of Science and Technology, Skolkovo, Moscow Region, Russia.', 'Moscow Institute of Physics and Technology, Dolgoprudny, Moscow Region, Russia.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Allen Institute for Cell Science, Seattle, Washington, United States of America.', 'Allen Institute for Cell Science, Seattle, Washington, United States of America.', 'Allen Institute for Cell Science, Seattle, Washington, United States of America.', 'Allen Institute for Cell Science, Seattle, Washington, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, Massachusetts, United States of America.']	['10.1371/journal.pbio.2005970 [doi]', 'pbio.2005970 [pii]']	['McQuin C', 'Goodman A', 'Chernyshev V', 'Kamentsky L', 'Cimini BA', 'Karhohs KW', 'Doan M', 'Ding L', 'Rafelski SM', 'Thirstrup D', 'Wiegraebe W', 'Singh S', 'Becker T', 'Caicedo JC', 'Carpenter AE']					['The authors have declared that no competing interests exist.']		['2018/07/04 06:00']	20190506	20180703	2018 Jul	2018/07/04 06:00		['McQuin, Claire', 'Goodman, Allen', 'Chernyshev, Vasiliy', 'Kamentsky, Lee', 'Cimini, Beth A', 'Karhohs, Kyle W', 'Doan, Minh', 'Ding, Liya', 'Rafelski, Susanne M', 'Thirstrup, Derek', 'Wiegraebe, Winfried', 'Singh, Shantanu', 'Becker, Tim', 'Caicedo, Juan C', 'Carpenter, Anne E']		['R35 GM122547/GM/NIGMS NIH HHS/United States']	7		1545-7885 (Electronic) 1544-9173 (Linking)	101183755	PLoS biology	['eng']	10.1371/journal.pbio.2005970 [doi]	20190506	['Animals', 'Cell Nucleus/metabolism', 'DNA/metabolism', 'Deep Learning', 'Humans', '*Image Processing, Computer-Assisted', 'Imaging, Three-Dimensional', 'Induced Pluripotent Stem Cells/cytology/metabolism', 'Mice', 'RNA, Messenger/genetics/metabolism', '*Software']	2019/05/07 06:00				NLM	e2005970	['2018/03/09 00:00 [received]', '2018/05/25 00:00 [accepted]', '2018/07/04 06:00 [entrez]', '2018/07/04 06:00 [pubmed]', '2019/05/07 06:00 [medline]']	United States	PMC6029841		29969450	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA, Messenger)', '9007-49-2 (DNA)']	IM		PLoS Biol. 2018 Jul 3;16(7):e2005970. doi: 10.1371/journal.pbio.2005970. eCollection 2018 Jul.	MEDLINE	PLoS Biol	CellProfiler 3.0: Next-generation image processing for biology.		16	CellProfiler 3.0: Next-generation image processing for biology.
We propose a deep learning model - Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients (PPES-Met) for estimating short-term life expectancy (>3 months) of the patients by analyzing free-text clinical notes in the electronic medical record, while maintaining the temporal visit sequence. In a single framework, we integrated semantic data mapping and neural embedding technique to produce a text processing method that extracts relevant information from heterogeneous types of clinical notes in an unsupervised manner, and we designed a recurrent neural network to model the temporal dependency of the patient visits. The model was trained on a large dataset (10,293 patients) and validated on a separated dataset (1818 patients). Our method achieved an area under the ROC curve (AUC) of 0.89. To provide explain-ability, we developed an interactive graphical tool that may improve physician understanding of the basis for the model's predictions. The high accuracy and explain-ability of the PPES-Met model may enable our model to be used as a decision support tool to personalize metastatic cancer treatment and provide valuable assistance to the physicians.	['Department of Biomedical Data Science, Stanford University, Stanford, CA, USA. imonb@stanford.edu.', 'Department of Radiation Oncology, Stanford University, Stanford, CA, USA.', 'Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.', 'Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.', 'Department of Radiation Oncology, Stanford University, Stanford, CA, USA.', 'Department of Radiation Oncology, Stanford University, Stanford, CA, USA.', 'Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.', 'Biomedical Data Science, Radiology, and Medicine (BMIR) Stanford University, Stanford, CA, USA.']	['10.1038/s41598-018-27946-5 [doi]', '10.1038/s41598-018-27946-5 [pii]']	['Banerjee I', 'Gensheimer MF', 'Wood DJ', 'Henry S', 'Aggarwal S', 'Chang DT', 'Rubin DL']	['ORCID: 0000-0002-4332-9696', 'ORCID: 0000-0003-1591-1897']						['2018/07/04 06:00']	20191126	20180703	2018 Jul 3	2018/07/04 06:00		['Banerjee, Imon', 'Gensheimer, Michael Francis', 'Wood, Douglas J', 'Henry, Solomon', 'Aggarwal, Sonya', 'Chang, Daniel T', 'Rubin, Daniel L']		['P30 CA124435/CA/NCI NIH HHS/United States', 'UL1 RR025744/RR/NCRR NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-27946-5 [doi]	20191126	['Aged', 'Area Under Curve', 'Computer Simulation', 'Data Mining/*methods', 'Deep Learning', 'Electronic Health Records', 'Female', 'Humans', 'Male', 'Middle Aged', '*Models, Statistical', 'Neoplasm Metastasis', 'Neoplasms/*mortality', 'Neural Networks (Computer)', 'Prognosis', 'ROC Curve', 'Survival Analysis']	2019/11/27 06:00				NLM	10037	['2017/12/01 00:00 [received]', '2018/06/12 00:00 [accepted]', '2018/07/04 06:00 [entrez]', '2018/07/04 06:00 [pubmed]', '2019/11/27 06:00 [medline]']	England	PMC6030075		29968730	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Jul 3;8(1):10037. doi: 10.1038/s41598-018-27946-5.	MEDLINE	Sci Rep	Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients (PPES-Met) Utilizing Free-Text Clinical Narratives.		8	Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients (PPES-Met) Utilizing Free-Text Clinical Narratives.
Neuroimaging science has seen a recent explosion in dataset size driving the need to develop database management with efficient processing pipelines. Multi-center neuroimaging databases consistently receive magnetic resonance imaging (MRI) data with unlabeled or incorrectly labeled contrast. There is a need to automatically identify the contrast of MRI scans to save database-managing facilities valuable resources spent by trained technicians required for visual inspection. We developed a deep learning (DL) algorithm with convolution neural network architecture to automatically infer the contrast of MRI scans based on the image intensity of multiple slices. For comparison, we developed a random forest (RF) algorithm to automatically infer the contrast of MRI scans based on acquisition parameters. The DL algorithm was able to automatically identify the MRI contrast of an unseen dataset with <0.2% error rate. The RF algorithm was able to identify the MRI contrast of the same dataset with 1.74% error rate. Our analysis showed that reduced dataset sizes caused the DL algorithm to lose generalizability. Finally, we developed a confidence measure, which made it possible to detect, with 100% specificity, all MRI volumes that were misclassified by the DL algorithm. This confidence measure can be used to alert the user on the need to inspect the small fraction of MRI volumes that are prone to misclassification. Our study introduces a practical solution for automatically identifying the MRI contrast. Furthermore, it demonstrates the powerful combination of convolution neural networks and DL for analyzing large MRI datasets.	['Montreal Neurological Institute, Departments of Neurology, Neurosurgery, Physiology, and Biomedical Engineering, McGill University, 3801 University, Room 786, Montreal, QC, H3A 2B4, Canada. ricardo.pizarro@mcgill.ca.', 'NeuroRx Research, Montreal, QC, Canada. ricardo.pizarro@mcgill.ca.', 'NeuroRx Research, Montreal, QC, Canada.', 'NeuroRx Research, Montreal, QC, Canada.', 'NeuroRx Research, Montreal, QC, Canada.', 'NeuroRx Research, Montreal, QC, Canada.', 'NeuroRx Research, Montreal, QC, Canada.', 'Montreal Neurological Institute, Departments of Neurology, Neurosurgery, Physiology, and Biomedical Engineering, McGill University, 3801 University, Room 786, Montreal, QC, H3A 2B4, Canada. amir.shmuel@mcgill.ca.']	['10.1007/s12021-018-9387-8 [doi]', '10.1007/s12021-018-9387-8 [pii]']	['Pizarro R', 'Assemlal HE', 'De Nigris D', 'Elliott C', 'Antel S', 'Arnold D', 'Shmuel A']	['ORCID: http://orcid.org/0000-0003-3889-1577']						['2018/06/30 06:00']	20190821		2019 Jan	2018/06/30 06:00		['Pizarro, Ricardo', 'Assemlal, Haz-Edine', 'De Nigris, Dante', 'Elliott, Colm', 'Antel, Samson', 'Arnold, Douglas', 'Shmuel, Amir']			1		1559-0089 (Electronic) 1539-2791 (Linking)	101142069	Neuroinformatics	['eng']	10.1007/s12021-018-9387-8 [doi]	20191109	['*Algorithms', 'Brain/*diagnostic imaging', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/methods', 'Neuroimaging/*methods']	2019/08/23 06:00		['*Automatic contrast identification', '*Convolutional neural network', '*Database management', '*Deep learning', '*Magnetic resonance imaging']	['NOTNLM']	NLM	115-130	['2018/06/30 06:00 [pubmed]', '2019/08/23 06:00 [medline]', '2018/06/30 06:00 [entrez]']	United States			29956131	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					Neuroinformatics. 2019 Jan;17(1):115-130. doi: 10.1007/s12021-018-9387-8.	MEDLINE	Neuroinformatics	Using Deep Learning Algorithms to Automatically Identify the Brain MRI Contrast: Implications for Managing Large Databases.		17	Using Deep Learning Algorithms to Automatically Identify the Brain MRI Contrast: Implications for Managing Large Databases.
The fields of medicine science and health informatics have made great progress recently and have led to in-depth analytics that is demanded by generation, collection and accumulation of massive data. Meanwhile, we are entering a new period where novel technologies are starting to analyze and explore knowledge from tremendous amount of data, bringing limitless potential for information growth. One fact that cannot be ignored is that the techniques of machine learning and deep learning applications play a more significant role in the success of bioinformatics exploration from biological data point of view, and a linkage is emphasized and established to bridge these two data analytics techniques and bioinformatics in both industry and academia. This survey concentrates on the review of recent researches using data mining and deep learning approaches for analyzing the specific domain knowledge of bioinformatics. The authors give a brief but pithy summarization of numerous data mining algorithms used for preprocessing, classification and clustering as well as various optimized neural network architectures in deep learning methods, and their advantages and disadvantages in the practical applications are also discussed and compared in terms of their industrial usage. It is believed that in this review paper, valuable insights are provided for those who are dedicated to start using data analytics methods in bioinformatics.	"['Department of Computer and Information Science, University of Macau, Taipa, Macau, China.', ""Department of Media integration technology center, Zhejiang Radio & TV Group, Hangzhou, People's Republic of China."", 'Department of Computer and Information Science, University of Macau, Taipa, Macau, China. ccfong@umac.mo.', 'First Affiliated Hospital of Guangzhou University of TCM, Guangzhou, 510405, Guangdong, China.', 'School of Medicine, University of Western Sydney, Sydney, NSW, Australia.', 'Department of Information Technology, Techno India College of Technology, Kolkata, West Bengal, 740000, India.']"	['10.1007/s10916-018-1003-9 [doi]', '10.1007/s10916-018-1003-9 [pii]']	['Lan K', 'Wang DT', 'Fong S', 'Liu LS', 'Wong KKL', 'Dey N']							['2018/06/30 06:00']	20181113	20180628	2018 Jun 28	2018/06/30 06:00		['Lan, Kun', 'Wang, Dan-Tong', 'Fong, Simon', 'Liu, Lian-Sheng', 'Wong, Kelvin K L', 'Dey, Nilanjan']		['FDCT/126/2014/A3/FDCT Macau SAR Government', 'MYRG2016-00069/Universidade de Macau']	8		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-018-1003-9 [doi]	20181114	['Algorithms', 'Bayes Theorem', '*Computational Biology', '*Data Mining', 'Machine Learning', 'Surveys and Questionnaires']	2018/11/14 06:00		['Bioinformatics', 'Biomedicine', 'Data mining', 'Deep learning', 'Machine learning']	['NOTNLM']	NLM	139	['2018/03/28 00:00 [received]', '2018/06/21 00:00 [accepted]', '2018/06/30 06:00 [entrez]', '2018/06/30 06:00 [pubmed]', '2018/11/14 06:00 [medline]']	United States			29956014	epublish	['Journal Article', 'Review']			IM		J Med Syst. 2018 Jun 28;42(8):139. doi: 10.1007/s10916-018-1003-9.	MEDLINE	J Med Syst	A Survey of Data Mining and Deep Learning in Bioinformatics.		42	A Survey of Data Mining and Deep Learning in Bioinformatics.
Wound segmentation plays an important supporting role in the wound observation and wound healing. Current methods of image segmentation include those based on traditional process of image and those based on deep neural networks. The traditional methods use the artificial image features to complete the task without large amounts of labeled data. Meanwhile, the methods based on deep neural networks can extract the image features effectively without the artificial design, but lots of training data are required. Combined with the advantages of them, this paper presents a composite model of wound segmentation. The model uses the skin with wound detection algorithm we designed in the paper to highlight image features. Then, the preprocessed images are segmented by deep neural networks. And semantic corrections are applied to the segmentation results at last. The model shows a good performance in our experiment.	['Science and Technology on Parallel and Distributed Laboratory, Changsha, China.', 'College of Computer, National University of Defense Technology, Changsha, China.', 'Science and Technology on Parallel and Distributed Laboratory, Changsha, China.', 'Science and Technology on Parallel and Distributed Laboratory, Changsha, China.', 'Science and Technology on Parallel and Distributed Laboratory, Changsha, China.']	['10.1155/2018/4149103 [doi]']	['Li F', 'Wang C', 'Liu X', 'Peng Y', 'Jin S']	['ORCID: 0000-0002-8064-3510', 'ORCID: 0000-0002-8223-5588']						['2018/06/30 06:00']	20181009	20180531	2018	2018/06/30 06:00	['Comput Intell Neurosci. 2018 Sep 12;2018:4967290. PMID: 30275821']	['Li, Fangzhao', 'Wang, Changjian', 'Liu, Xiaohui', 'Peng, Yuxing', 'Jin, Shiyao']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2018/4149103 [doi]	20181114	['Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Machine Learning', '*Neural Networks (Computer)', 'Skin/pathology', 'Wound Healing', 'Wounds and Injuries/*diagnosis/pathology']	2018/10/10 06:00				NLM	4149103	['2018/01/18 00:00 [received]', '2018/03/14 00:00 [revised]', '2018/04/29 00:00 [accepted]', '2018/06/30 06:00 [entrez]', '2018/06/30 06:00 [pubmed]', '2018/10/10 06:00 [medline]']	United States	PMC6000917		29955227	epublish	['Journal Article']			IM		Comput Intell Neurosci. 2018 May 31;2018:4149103. doi: 10.1155/2018/4149103. eCollection 2018.	MEDLINE	Comput Intell Neurosci	A Composite Model of Wound Segmentation Based on Traditional Methods and Deep Neural Networks.		2018	A Composite Model of Wound Segmentation Based on Traditional Methods and Deep Neural Networks.
Motivation: Super-resolution fluorescence microscopy with a resolution beyond the diffraction limit of light, has become an indispensable tool to directly visualize biological structures in living cells at a nanometer-scale resolution. Despite advances in high-density super-resolution fluorescent techniques, existing methods still have bottlenecks, including extremely long execution time, artificial thinning and thickening of structures, and lack of ability to capture latent structures. Results: Here, we propose a novel deep learning guided Bayesian inference (DLBI) approach, for the time-series analysis of high-density fluorescent images. Our method combines the strength of deep learning and statistical inference, where deep learning captures the underlying distribution of the fluorophores that are consistent with the observed time-series fluorescent images by exploring local features and correlation along time-axis, and statistical inference further refines the ultrastructure extracted by deep learning and endues physical meaning to the final image. In particular, our method contains three main components. The first one is a simulator that takes a high-resolution image as the input, and simulates time-series low-resolution fluorescent images based on experimentally calibrated parameters, which provides supervised training data to the deep learning model. The second one is a multi-scale deep learning module to capture both spatial information in each input low-resolution image as well as temporal information among the time-series images. And the third one is a Bayesian inference module that takes the image from the deep learning module as the initial localization of fluorophores and removes artifacts by statistical inference. Comprehensive experimental results on both real and simulated datasets demonstrate that our method provides more accurate and realistic local patch and large-field reconstruction than the state-of-the-art method, the 3B analysis, while our method is more than two orders of magnitude faster. Availability and implementation: The main program is available at https://github.com/lykaust15/DLBI. Supplementary information: Supplementary data are available at Bioinformatics online.	['King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia.', 'High Performance Computer Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China.', 'High Performance Computer Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China.', 'Key Laboratory of RNA Biology, Institute of Biophysics, Chinese Academy of Sciences, Beijing, China.', 'Key Laboratory of RNA Biology, Institute of Biophysics, Chinese Academy of Sciences, Beijing, China.', 'Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou, China.', 'Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou, China.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia.']	['5045796 [pii]', '10.1093/bioinformatics/bty241 [doi]']	['Li Y', 'Xu F', 'Zhang F', 'Xu P', 'Zhang M', 'Fan M', 'Li L', 'Gao X', 'Han R']							['2018/06/29 06:00']	20191016		2018 Jul 1	2018/06/29 06:00		['Li, Yu', 'Xu, Fan', 'Zhang, Fa', 'Xu, Pingyong', 'Zhang, Mingshu', 'Fan, Ming', 'Li, Lihua', 'Gao, Xin', 'Han, Renmin']			13		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty241 [doi]	20191016	['Bayes Theorem', 'Cells/ultrastructure', 'Computer Simulation', '*Deep Learning', '*Microscopy, Fluorescence', '*Software']	2019/10/17 06:00				NLM	i284-i294	['2018/06/29 06:00 [entrez]', '2018/06/29 06:00 [pubmed]', '2019/10/17 06:00 [medline]']	England	PMC6022599		29950012	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Bioinformatics. 2018 Jul 1;34(13):i284-i294. doi: 10.1093/bioinformatics/bty241.	MEDLINE	Bioinformatics	DLBI: deep learning guided Bayesian inference for structure reconstruction of super-resolution fluorescence microscopy.		34	DLBI: deep learning guided Bayesian inference for structure reconstruction of super-resolution fluorescence microscopy.
Motivation: A large number of newly sequenced proteins are generated by the next-generation sequencing technologies and the biochemical function assignment of the proteins is an important task. However, biological experiments are too expensive to characterize such a large number of protein sequences, thus protein function prediction is primarily done by computational modeling methods, such as profile Hidden Markov Model (pHMM) and k-mer based methods. Nevertheless, existing methods have some limitations; k-mer based methods are not accurate enough to assign protein functions and pHMM is not fast enough to handle large number of protein sequences from numerous genome projects. Therefore, a more accurate and faster protein function prediction method is needed. Results: In this paper, we introduce DeepFam, an alignment-free method that can extract functional information directly from sequences without the need of multiple sequence alignments. In extensive experiments using the Clusters of Orthologous Groups (COGs) and G protein-coupled receptor (GPCR) dataset, DeepFam achieved better performance in terms of accuracy and runtime for predicting functions of proteins compared to the state-of-the-art methods, both alignment-free and alignment-based methods. Additionally, we showed that DeepFam has a power of capturing conserved regions to model protein families. In fact, DeepFam was able to detect conserved regions documented in the Prosite database while predicting functions of proteins. Our deep learning method will be useful in characterizing functions of the ever increasing protein sequences. Availability and implementation: Codes are available at https://bhi-kimlab.github.io/DeepFam.	['Department of Computer Science and Engineering, Seoul National University, Seoul, Korea.', 'Department of Computer Science and Engineering, Seoul National University, Seoul, Korea.', 'Interdisciplinary Program in Bioinformatics, Seoul National University, Seoul, Korea.', 'Department of Computer Science and Engineering, Seoul National University, Seoul, Korea.', 'Interdisciplinary Program in Bioinformatics, Seoul National University, Seoul, Korea.', 'Bioinformatics Institute, Seoul National University, Seoul, Korea.']	['5045722 [pii]', '10.1093/bioinformatics/bty275 [doi]']	['Seo S', 'Oh M', 'Park Y', 'Kim S']							['2018/06/29 06:00']	20190827		2018 Jul 1	2018/06/29 06:00		['Seo, Seokjun', 'Oh, Minsik', 'Park, Youngjune', 'Kim, Sun']			13		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty275 [doi]	20190827	['*Deep Learning', 'Proteins/chemistry/*metabolism', 'Receptors, G-Protein-Coupled/chemistry/metabolism', 'Sequence Analysis, Protein/*methods', '*Software']	2019/08/28 06:00				NLM	i254-i262	['2018/06/29 06:00 [entrez]', '2018/06/29 06:00 [pubmed]', '2019/08/28 06:00 [medline]']	England	PMC6022622		29949966	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)', '0 (Receptors, G-Protein-Coupled)']	IM		Bioinformatics. 2018 Jul 1;34(13):i254-i262. doi: 10.1093/bioinformatics/bty275.	MEDLINE	Bioinformatics	DeepFam: deep learning based alignment-free method for protein family modeling and prediction.		34	DeepFam: deep learning based alignment-free method for protein family modeling and prediction.
Motivation: Alternative splice site selection is inherently competitive and the probability of a given splice site to be used also depends on the strength of neighboring sites. Here, we present a new model named the competitive splice site model (COSSMO), which explicitly accounts for these competitive effects and predicts the percent selected index (PSI) distribution over any number of putative splice sites. We model an alternative splicing event as the choice of a 3' acceptor site conditional on a fixed upstream 5' donor site or the choice of a 5' donor site conditional on a fixed 3' acceptor site. We build four different architectures that use convolutional layers, communication layers, long short-term memory and residual networks, respectively, to learn relevant motifs from sequence alone. We also construct a new dataset from genome annotations and RNA-Seq read data that we use to train our model. Results: COSSMO is able to predict the most frequently used splice site with an accuracy of 70% on unseen test data, and achieve an R2 of 0.6 in modeling the PSI distribution. We visualize the motifs that COSSMO learns from sequence and show that COSSMO recognizes the consensus splice site sequences and many known splicing factors with high specificity. Availability and implementation: Model predictions, our training dataset, and code are available from http://cossmo.genes.toronto.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['Deep Genomics Inc, Toronto, Canada.', 'Department of Computer Science, University of Toronto, Toronto, Canada.', 'Deep Genomics Inc, Toronto, Canada.', 'Deep Genomics Inc, Toronto, Canada.', 'Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada.', 'Deep Genomics Inc, Toronto, Canada.', 'Deep Genomics Inc, Toronto, Canada.', 'Department of Computer Science, University of Toronto, Toronto, Canada.', 'Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada.']	['5045709 [pii]', '10.1093/bioinformatics/bty244 [doi]']	['Bretschneider H', 'Gandhi S', 'Deshwar AG', 'Zuberi K', 'Frey BJ']							['2018/06/29 06:00']	20190827		2018 Jul 1	2018/06/29 06:00		['Bretschneider, Hannes', 'Gandhi, Shreshth', 'Deshwar, Amit G', 'Zuberi, Khalid', 'Frey, Brendan J']			13		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty244 [doi]	20190827	['*Alternative Splicing', 'Computational Biology/methods', '*Deep Learning', 'Humans', 'Models, Genetic', 'Probability', '*RNA Splice Sites', 'Sequence Analysis, RNA/*methods', 'Software']	2019/08/28 06:00				NLM	i429-i437	['2018/06/29 06:00 [entrez]', '2018/06/29 06:00 [pubmed]', '2019/08/28 06:00 [medline]']	England	PMC6022534		29949959	ppublish	['Journal Article']		['0 (RNA Splice Sites)']	IM		Bioinformatics. 2018 Jul 1;34(13):i429-i437. doi: 10.1093/bioinformatics/bty244.	MEDLINE	Bioinformatics	COSSMO: predicting competitive alternative splice site selection using deep learning.		34	COSSMO: predicting competitive alternative splice site selection using deep learning.
A major challenge for effective application of CRISPR systems is to accurately predict the single guide RNA (sgRNA) on-target knockout efficacy and off-target profile, which would facilitate the optimized design of sgRNAs with high sensitivity and specificity. Here we present DeepCRISPR, a comprehensive computational platform to unify sgRNA on-target and off-target site prediction into one framework with deep learning, surpassing available state-of-the-art in silico tools. In addition, DeepCRISPR fully automates the identification of sequence and epigenetic features that may affect sgRNA knockout efficacy in a data-driven manner. DeepCRISPR is available at http://www.deepcrispr.net/ .	"[""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', 'School of Life Science and Technology, ShanghaiTech University, Shanghai, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', 'R&D Information, Innovation Center China, AstraZeneca, 199 Liangjing Road, Shanghai, 201203, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', 'State Key Laboratory Cultivation Base and Key Laboratory of Vision Science, Ministry of Health and Zhejiang Provincial Key Laboratory of Ophthalmology and Optometry, School of Ophthalmology and Optometry, Eye Hospital, Wenzhou Medical University, Wenzhou, Zhejiang, 325027, China.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China.', 'Machine Learning & Systems Biology Lab, School of Electronics and Information Engineering, Tongji University, Shanghai, 201804, China. dshuang@tongji.edu.cn.', 'R&D Information, Innovation Center China, AstraZeneca, 199 Liangjing Road, Shanghai, 201203, China. Jenny.Wei@astrazeneca.com.', ""Department of Endocrinology & Metabolism, Shanghai Tenth People's Hospital, Tongji University, Shanghai, 20009, China. qiliu@tongji.edu.cn."", 'Bioinformatics Department, School of Life Sciences and Technology, Tongji University, Shanghai, 20009, China. qiliu@tongji.edu.cn.']"	['10.1186/s13059-018-1459-4 [doi]', '10.1186/s13059-018-1459-4 [pii]']	['Chuai G', 'Ma H', 'Yan J', 'Chen M', 'Hong N', 'Xue D', 'Zhou C', 'Zhu C', 'Chen K', 'Duan B', 'Gu F', 'Qu S', 'Huang D', 'Wei J', 'Liu Q']							['2018/06/28 06:00']	20181030	20180626	2018 Jun 26	2018/06/28 06:00		['Chuai, Guohui', 'Ma, Hanhui', 'Yan, Jifang', 'Chen, Ming', 'Hong, Nanfang', 'Xue, Dongyu', 'Zhou, Chi', 'Zhu, Chenyu', 'Chen, Ke', 'Duan, Bin', 'Gu, Feng', 'Qu, Sheng', 'Huang, Deshuang', 'Wei, Jia', 'Liu, Qi']			1		1474-760X (Electronic) 1474-7596 (Linking)	100960660	Genome biology	['eng']	10.1186/s13059-018-1459-4 [doi]	20181114	['CRISPR-Cas Systems/*genetics', 'Cell Line', 'Cell Line, Tumor', 'Clustered Regularly Interspaced Short Palindromic Repeats/*genetics', 'Computational Biology/methods', 'Computer Simulation', 'HCT116 Cells', 'HEK293 Cells', 'HL-60 Cells', 'HeLa Cells', 'Humans', 'Machine Learning', 'RNA Editing/genetics', 'RNA, Guide/*genetics']	2018/10/31 06:00		['*CRISPR system', '*Deep learning', '*Gene knockout', '*Off-targets', '*On-targets']	['NOTNLM']	NLM	80	['2018/01/17 00:00 [received]', '2018/05/28 00:00 [accepted]', '2018/06/28 06:00 [entrez]', '2018/06/28 06:00 [pubmed]', '2018/10/31 06:00 [medline]']	England	PMC6020378		29945655	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA, Guide)']	IM		Genome Biol. 2018 Jun 26;19(1):80. doi: 10.1186/s13059-018-1459-4.	MEDLINE	Genome Biol	DeepCRISPR: optimized CRISPR guide RNA design by deep learning.		19	DeepCRISPR: optimized CRISPR guide RNA design by deep learning.
BACKGROUND: A major barrier to the practice of evidence-based medicine is efficiently finding scientifically sound studies on a given clinical topic. OBJECTIVE: To investigate a deep learning approach to retrieve scientifically sound treatment studies from the biomedical literature. METHODS: We trained a Convolutional Neural Network using a noisy dataset of 403,216 PubMed citations with title and abstract as features. The deep learning model was compared with state-of-the-art search filters, such as PubMed's Clinical Query Broad treatment filter, McMaster's textword search strategy (no Medical Subject Heading, MeSH, terms), and Clinical Query Balanced treatment filter. A previously annotated dataset (Clinical Hedges) was used as the gold standard. RESULTS: The deep learning model obtained significantly lower recall than the Clinical Queries Broad treatment filter (96.9% vs 98.4%; P<.001); and equivalent recall to McMaster's textword search (96.9% vs 97.1%; P=.57) and Clinical Queries Balanced filter (96.9% vs 97.0%; P=.63). Deep learning obtained significantly higher precision than the Clinical Queries Broad filter (34.6% vs 22.4%; P<.001) and McMaster's textword search (34.6% vs 11.8%; P<.001), but was significantly lower than the Clinical Queries Balanced filter (34.6% vs 40.9%; P<.001). CONCLUSIONS: Deep learning performed well compared to state-of-the-art search filters, especially when citations were not indexed. Unlike previous machine learning approaches, the proposed deep learning model does not require feature engineering, or time-sensitive or proprietary features, such as MeSH terms and bibliometrics. Deep learning is a promising approach to identifying reports of scientifically rigorous clinical research. Further work is needed to optimize the deep learning model and to assess generalizability to other areas, such as diagnosis, etiology, and prognosis.	['University of Utah, Department of Biomedical Informatics, Salt Lake City, UT, United States.', 'Evid Science, Los Angeles, CA, United States.', 'InferLink Corporation, Los Angeles, CA, United States.', 'Department of Health Research Methods, Evidence, and Impact, McMaster University, Hamilton, ON, Canada.', 'Department of Medicine, Faculty of Health Sciences, McMaster University, Hamilton, ON, Canada.', 'Health Information Research Unit, McMaster University, Hamilton, ON, Canada.', 'Department of Health Research Methods, Evidence, and Impact, McMaster University, Hamilton, ON, Canada.', 'Department of Medicine, Faculty of Health Sciences, McMaster University, Hamilton, ON, Canada.']	['v20i6e10281 [pii]', '10.2196/10281 [doi]']	['Del Fiol G', 'Michelson M', 'Iorio A', 'Cotoi C', 'Haynes RB']	['ORCID: 0000-0001-9954-6799', 'ORCID: 0000-0003-3346-2132', 'ORCID: 0000-0002-3331-8766', 'ORCID: 0000-0001-7029-0582', 'ORCID: 0000-0002-1453-3196']	['(c)Guilherme Del Fiol, Matthew Michelson, Alfonso Iorio, Chris Cotoi, R Brian', 'Haynes. Originally published in the Journal of Medical Internet Research', '(http://www.jmir.org), 25.06.2018.']					['2018/06/27 06:00']	20190710	20180625	2018 Jun 25	2018/06/27 06:00		['Del Fiol, Guilherme', 'Michelson, Matthew', 'Iorio, Alfonso', 'Cotoi, Chris', 'Haynes, R Brian']		['R01 LM011416/LM/NLM NIH HHS/United States', 'U24 CA204800/CA/NCI NIH HHS/United States']	6		1438-8871 (Electronic) 1438-8871 (Linking)	100959882	Journal of medical Internet research	['eng']	10.2196/10281 [doi]	20190710	['Deep Learning/*standards', 'Humans', 'Information Storage and Retrieval/*methods', '*Neural Networks (Computer)', 'PubMed/*standards']	2019/07/11 06:00		['*deep learning', '*evidence-based medicine', '*information retrieval', '*literature databases', '*machine learning']	['NOTNLM']	NLM	e10281	['2018/03/05 00:00 [received]', '2018/05/12 00:00 [accepted]', '2018/04/26 00:00 [revised]', '2018/06/27 06:00 [entrez]', '2018/06/27 06:00 [pubmed]', '2019/07/11 06:00 [medline]']	Canada	PMC6037944		29941415	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		J Med Internet Res. 2018 Jun 25;20(6):e10281. doi: 10.2196/10281.	MEDLINE	J Med Internet Res	A Deep Learning Method to Automatically Identify Reports of Scientifically Rigorous Clinical Research from the Biomedical Literature: Comparative Analytic Study.		20	A Deep Learning Method to Automatically Identify Reports of Scientifically Rigorous Clinical Research from the Biomedical Literature: Comparative Analytic Study.
Environmental sustainability research is dependent on accurate land cover information. Even with the increased number of satellite systems and sensors acquiring data with improved spectral, spatial, radiometric and temporal characteristics and the new data distribution policy, most existing land cover datasets are derived from a pixel-based, single-date multi-spectral remotely sensed image with an unacceptable accuracy. One major bottleneck for accuracy improvement is how to develop an accurate and effective image classification protocol. By incorporating and utilizing multi-spectral, multi-temporal and spatial information in remote sensing images and considering the inherit spatial and sequential interdependence among neighboring pixels, we propose a new patch-based recurrent neural network (PB-RNN) system tailored for classifying multi-temporal remote sensing data. The system is designed by incorporating distinctive characteristics of multi-temporal remote sensing data. In particular, it uses multi-temporal-spectral-spatial samples and deals with pixels contaminated by clouds/shadow present in multi-temporal data series. Using a Florida Everglades ecosystem study site covering an area of 771 square kilometers, the proposed PB-RNN system has achieved a significant improvement in the classification accuracy over a pixel-based recurrent neural network (RNN) system, a pixel-based single-image neural network (NN) system, a pixel-based multi-image NN system, a patch-based single-image NN system, and a patch-based multi-image NN system. For example, the proposed system achieves 97.21% classification accuracy while the pixel-based single-image NN system achieves 64.74%. By utilizing methods like the proposed PB-RNN one, we believe that much more accurate land cover datasets can be produced over large areas.	['Department of Computer Science, Florida State University, Tallahassee, FL 32306-4530, USA. Electronic address: as13an@my.fsu.edu.', 'Department of Computer Science, Florida State University, Tallahassee, FL 32306-4530, USA. Electronic address: liux@cs.fsu.edu.', 'Department of Geography, Florida State University, Tallahassee, FL 32306-2190, USA. Electronic address: xyang@fsu.edu.']	['S0893-6080(18)30181-3 [pii]', '10.1016/j.neunet.2018.05.019 [doi]']	['Sharma A', 'Liu X', 'Yang X']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/06/23 06:00']	20181101	20180602	2018 Sep	2018/06/23 06:00		['Sharma, Atharva', 'Liu, Xiuwen', 'Yang, Xiaojun']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30181-3 [pii] 10.1016/j.neunet.2018.05.019 [doi]	20181101	['Machine Learning', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/methods/standards', 'Satellite Imagery/*methods/standards']	2018/11/02 06:00		['Deep learning', 'LSTMs', 'Land cover classification', 'Multi-temporal remote sensing imagery', 'Patch-based RNNs', 'Spatial context']	['NOTNLM']	NLM	346-355	['2017/11/04 00:00 [received]', '2018/03/23 00:00 [revised]', '2018/05/28 00:00 [accepted]', '2018/06/23 06:00 [pubmed]', '2018/11/02 06:00 [medline]', '2018/06/23 06:00 [entrez]']	United States			29933156	ppublish	['Letter']			IM		Neural Netw. 2018 Sep;105:346-355. doi: 10.1016/j.neunet.2018.05.019. Epub 2018 Jun 2.	MEDLINE	Neural Netw	Land cover classification from multi-temporal, multi-spectral remotely sensed imagery using patch-based recurrent neural networks.		105	Land cover classification from multi-temporal, multi-spectral remotely sensed imagery using patch-based recurrent neural networks.
Motivation: During the last decade, improvements in high-throughput sequencing have generated a wealth of genomic data. Functionally interpreting these sequences and finding the biological signals that are hallmarks of gene function and regulation is currently mostly done using automated genome annotation platforms, which mainly rely on integrated machine learning frameworks to identify different functional sites of interest, including splice sites. Splicing is an essential step in the gene regulation process, and the correct identification of splice sites is a major cornerstone in a genome annotation system. Results: In this paper, we present SpliceRover, a predictive deep learning approach that outperforms the state-of-the-art in splice site prediction. SpliceRover uses convolutional neural networks (CNNs), which have been shown to obtain cutting edge performance on a wide variety of prediction tasks. We adapted this approach to deal with genomic sequence inputs, and show it consistently outperforms already existing approaches, with relative improvements in prediction effectiveness of up to 80.9% when measured in terms of false discovery rate. However, a major criticism of CNNs concerns their 'black box' nature, as mechanisms to obtain insight into their reasoning processes are limited. To facilitate interpretability of the SpliceRover models, we introduce an approach to visualize the biologically relevant information learnt. We show that our visualization approach is able to recover features known to be important for splice site prediction (binding motifs around the splice site, presence of polypyrimidine tracts and branch points), as well as reveal new features (e.g. several types of exclusion patterns near splice sites). Availability and implementation: SpliceRover is available as a web service. The prediction tool and instructions can be found at http://bioit2.irc.ugent.be/splicerover/. Supplementary information: Supplementary data are available at Bioinformatics online.	['Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, South Korea.', 'IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, Belgium.', 'IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, Belgium.', 'Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, South Korea.', 'IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, Belgium.', 'Department of Biomedical Molecular Biology, Ghent University, Ghent, Belgium.', 'Data Mining and Modeling for Biomedicine, VIB Inflammation Research Center, Ghent, Belgium.', 'Data Mining and Modeling for Biomedicine, VIB Inflammation Research Center, Ghent, Belgium.', 'Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium.', 'Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, South Korea.', 'IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, Belgium.']	['5042169 [pii]', '10.1093/bioinformatics/bty497 [doi]']	['Zuallaert J', 'Godin F', 'Kim M', 'Soete A', 'Saeys Y', 'De Neve W']							['2018/06/23 06:00']	20191022		2018 Dec 15	2018/06/23 06:00		['Zuallaert, Jasper', 'Godin, Frederic', 'Kim, Mijung', 'Soete, Arne', 'Saeys, Yvan', 'De Neve, Wesley']			24		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty497 [doi]	20191022	['Computational Biology', 'Genomics', 'High-Throughput Nucleotide Sequencing', '*Machine Learning', '*Neural Networks (Computer)', '*RNA Splicing', 'Software']	2019/10/23 06:00				NLM	4180-4188	['2017/10/23 00:00 [received]', '2018/06/19 00:00 [accepted]', '2018/06/23 06:00 [pubmed]', '2019/10/23 06:00 [medline]', '2018/06/23 06:00 [entrez]']	England			29931149	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Bioinformatics. 2018 Dec 15;34(24):4180-4188. doi: 10.1093/bioinformatics/bty497.	MEDLINE	Bioinformatics	SpliceRover: interpretable convolutional neural networks for improved splice site prediction.		34	SpliceRover: interpretable convolutional neural networks for improved splice site prediction.
BACKGROUND & AIMS: The benefit of colonoscopy for colorectal cancer prevention depends on the adenoma detection rate (ADR). The ADR should reflect the adenoma prevalence rate, which is estimated to be higher than 50% in the screening-age population. However, the ADR by colonoscopists varies from 7% to 53%. It is estimated that every 1% increase in ADR lowers the risk of interval colorectal cancers by 3%-6%. New strategies are needed to increase the ADR during colonoscopy. We tested the ability of computer-assisted image analysis using convolutional neural networks (CNNs; a deep learning model for image analysis) to improve polyp detection, a surrogate of ADR. METHODS: We designed and trained deep CNNs to detect polyps using a diverse and representative set of 8,641 hand-labeled images from screening colonoscopies collected from more than 2000 patients. We tested the models on 20 colonoscopy videos with a total duration of 5 hours. Expert colonoscopists were asked to identify all polyps in 9 de-identified colonoscopy videos, which were selected from archived video studies, with or without benefit of the CNN overlay. Their findings were compared with those of the CNN using CNN-assisted expert review as the reference. RESULTS: When tested on manually labeled images, the CNN identified polyps with an area under the receiver operating characteristic curve of 0.991 and an accuracy of 96.4%. In the analysis of colonoscopy videos in which 28 polyps were removed, 4 expert reviewers identified 8 additional polyps without CNN assistance that had not been removed and identified an additional 17 polyps with CNN assistance (45 in total). All polyps removed and identified by expert review were detected by the CNN. The CNN had a false-positive rate of 7%. CONCLUSION: In a set of 8,641 colonoscopy images containing 4,088 unique polyps, the CNN identified polyps with a cross-validation accuracy of 96.4% and an area under the receiver operating characteristic curve of 0.991. The CNN system detected and localized polyps well within real-time constraints using an ordinary desktop machine with a contemporary graphics processing unit. This system could increase the ADR and decrease interval colorectal cancers but requires validation in large multicenter trials.	['Department of Computer Science, University of California, Irvine, California; Institute for Genomics and Bioinformatics, University of California, Irvine, California.', 'Department of Medicine, University of California, Irvine, California.', 'Department of Medicine, University of California, Irvine, California; H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, California.', 'Department of Medicine, University of California, Irvine, California.', 'Department of Medicine, University of California, Irvine, California; H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, California.', 'Department of Medicine, University of California, Irvine, California; H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, California.', 'Department of Computer Science, University of California, Irvine, California; Institute for Genomics and Bioinformatics, University of California, Irvine, California; Center for Machine Learning and Intelligent Systems, University of California, Irvine, California. Electronic address: pfbaldi@uci.edu.']	['S0016-5085(18)34659-6 [pii]', '10.1053/j.gastro.2018.06.037 [doi]']	['Urban G', 'Tripathi P', 'Alkayali T', 'Mittal M', 'Jalali F', 'Karnes W', 'Baldi P']		['Copyright (c) 2018 AGA Institute. Published by Elsevier Inc. All rights reserved.']	['Transl Gastroenterol Hepatol. 2018 Dec 24;3:106. PMID: 30701213']				['2018/06/22 06:00']	20181023	20180618	2018 Oct	2018/06/22 06:00		['Urban, Gregor', 'Tripathi, Priyam', 'Alkayali, Talal', 'Mittal, Mohit', 'Jalali, Farid', 'Karnes, William', 'Baldi, Pierre']		['R01 GM123558/GM/NIGMS NIH HHS/United States']	4		1528-0012 (Electronic) 0016-5085 (Linking)	0374630	Gastroenterology	['eng']	S0016-5085(18)34659-6 [pii] 10.1053/j.gastro.2018.06.037 [doi]	20191001	['Adenomatous Polyps/*pathology', 'Area Under Curve', 'Colonic Polyps/*pathology', 'Colonoscopy/*methods', 'Colorectal Neoplasms/*pathology', 'Diagnosis, Computer-Assisted/*methods', 'Early Detection of Cancer/*methods', 'Feasibility Studies', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', '*Neural Networks (Computer)', 'Observer Variation', 'Predictive Value of Tests', 'Prognosis', 'ROC Curve', 'Reproducibility of Results', 'Video Recording']	2018/10/24 06:00	['NIHMS976040']	['*Adenoma Detection Rate Improving Technology', '*Colorectal Cancer Prevention', '*Convolutional Neural Networks', '*Machine Learning']	['NOTNLM']	NLM	1069-1078.e8	['2017/09/28 00:00 [received]', '2018/04/30 00:00 [revised]', '2018/06/11 00:00 [accepted]', '2018/06/22 06:00 [pubmed]', '2018/10/24 06:00 [medline]', '2018/06/22 06:00 [entrez]']	United States	PMC6174102		29928897	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S."", 'Video-Audio Media']"			AIM IM		Gastroenterology. 2018 Oct;155(4):1069-1078.e8. doi: 10.1053/j.gastro.2018.06.037. Epub 2018 Jun 18.	MEDLINE	Gastroenterology	Deep Learning Localizes and Identifies Polyps in Real Time With 96% Accuracy in Screening Colonoscopy.		155	Deep Learning Localizes and Identifies Polyps in Real Time With 96% Accuracy in Screening Colonoscopy.
BACKGROUND: Coronary computed tomographic angiography (CTA) is a reliable modality to detect coronary artery disease. However, CTA generally overestimates stenosis severity compared with invasive angiography, and angiographic stenosis does not necessarily imply hemodynamic relevance when fractional flow reserve (FFR) is used as reference. CTA-based FFR (CT-FFR), using computational fluid dynamics (CFD), improves the correlation with invasive FFR results but is computationally demanding. More recently, a new machine-learning (ML) CT-FFR algorithm has been developed based on a deep learning model, which can be performed on a regular workstation. In this large multicenter cohort, the diagnostic performance ML-based CT-FFR was compared with CTA and CFD-based CT-FFR for detection of functionally obstructive coronary artery disease. METHODS AND RESULTS: At 5 centers in Europe, Asia, and the United States, 351 patients, including 525 vessels with invasive FFR comparison, were included. ML-based and CFD-based CT-FFR were performed on the CTA data, and diagnostic performance was evaluated using invasive FFR as reference. Correlation between ML-based and CFD-based CT-FFR was excellent (R=0.997). ML-based (area under curve, 0.84) and CFD-based CT-FFR (0.84) outperformed visual CTA (0.69; P<0.0001). On a per-vessel basis, diagnostic accuracy improved from 58% (95% confidence interval, 54%-63%) by CTA to 78% (75%-82%) by ML-based CT-FFR. The per-patient accuracy improved from 71% (66%-76%) by CTA to 85% (81%-89%) by adding ML-based CT-FFR as 62 of 85 (73%) false-positive CTA results could be correctly reclassified by adding ML-based CT-FFR. CONCLUSIONS: On-site CT-FFR based on ML improves the performance of CTA by correctly reclassifying hemodynamically nonsignificant stenosis and performs equally well as CFD-based CT-FFR.	['Department of Cardiology (A.C., M.L.L., J.D., K.N.) a.coenen@erasmusmc.nl.', 'Department of Radiology (A.C., A.K., M.L.L., K.N.).', 'Erasmus University Medical Center, Rotterdam, the Netherlands. Department of Cardiology, Heart Institute (Y.-H.K.).', 'Asan Medical Center, University of Ulsan College of Medicine, Seoul, Korea. Coronary Disease and Structural Heart Diseases Department, Institute of Cardiology, Warsaw, Poland (M.K., C.K.).', 'Division of Cardiovascular Imaging, Medical University of South Carolina, Charleston (C.T., U.J.S.).', 'Department of Radiology and Department of Medical and Health Sciences, Center for Medical Image Science and Visualization, Linkoping University, Sweden (J.D.G., A.P.).', 'Department of Radiology (A.C., A.K., M.L.L., K.N.).', 'Department of Radiology, Ehime University Graduate School of Medicine, Japan (A.K.).', 'Department of Cardiology (A.C., M.L.L., J.D., K.N.).', 'Department of Radiology (A.C., A.K., M.L.L., K.N.).', 'Department of Cardiology (A.C., M.L.L., J.D., K.N.).', 'Corporate Technology, Siemens SRL, Brasov, Romania (L.I.).', 'Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ (S.R., P.S.).', 'Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ (S.R., P.S.).', 'Computed Tomography-Research & Development, Siemens Healthcare GmbH, Forchheim, Germany (C.S.).', 'Department of Radiology and Department of Medical and Health Sciences, Center for Medical Image Science and Visualization, Linkoping University, Sweden (J.D.G., A.P.).', 'Division of Cardiovascular Imaging, Medical University of South Carolina, Charleston (C.T., U.J.S.).', 'Asan Medical Center, University of Ulsan College of Medicine, Seoul, Korea. Coronary Disease and Structural Heart Diseases Department, Institute of Cardiology, Warsaw, Poland (M.K., C.K.).', 'Department of Radiology (D.H.Y.).', 'Department of Cardiology (A.C., M.L.L., J.D., K.N.).', 'Department of Radiology (A.C., A.K., M.L.L., K.N.).', 'Stanford University School of Medicine, Cardiovascular Institute, Stanford, CA, USA (K.N.).']	['CIRCIMAGING.117.007217 [pii]', '10.1161/CIRCIMAGING.117.007217 [doi]']	['Coenen A', 'Kim YH', 'Kruk M', 'Tesche C', 'De Geer J', 'Kurata A', 'Lubbers ML', 'Daemen J', 'Itu L', 'Rapaka S', 'Sharma P', 'Schwemmer C', 'Persson A', 'Schoepf UJ', 'Kepka C', 'Hyun Yang D', 'Nieman K']		['(c) 2018 American Heart Association, Inc.']	['Circ Cardiovasc Imaging. 2018 Jun;11(6):e007943. PMID: 29914868', 'Circ Cardiovasc Imaging. 2018 Jun;11(6):e007950. PMID: 29914869']				['2018/06/20 06:00']	20190812		2018 Jun	2018/06/20 06:00		['Coenen, Adriaan', 'Kim, Young-Hak', 'Kruk, Mariusz', 'Tesche, Christian', 'De Geer, Jakob', 'Kurata, Akira', 'Lubbers, Marisa L', 'Daemen, Joost', 'Itu, Lucian', 'Rapaka, Saikiran', 'Sharma, Puneet', 'Schwemmer, Chris', 'Persson, Anders', 'Schoepf, U Joseph', 'Kepka, Cezary', 'Hyun Yang, Dong', 'Nieman, Koen']			6		1942-0080 (Electronic) 1941-9651 (Linking)	101479935	Circulation. Cardiovascular imaging	['eng']	10.1161/CIRCIMAGING.117.007217 [doi]	20190812	['Aged', 'Asia', 'Computed Tomography Angiography/*methods', 'Coronary Angiography/*methods', 'Coronary Artery Disease/*diagnostic imaging/physiopathology', 'Coronary Stenosis/*diagnostic imaging/physiopathology', 'Coronary Vessels/*diagnostic imaging/physiopathology', '*Deep Learning', 'Europe', 'Female', '*Fractional Flow Reserve, Myocardial', 'Humans', 'Male', 'Middle Aged', 'Predictive Value of Tests', 'Prospective Studies', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Reproducibility of Results', 'Retrospective Studies', 'Severity of Illness Index', 'United States']	2019/08/14 06:00		['*area under curve', '*computed tomography angiography', '*coronary artery disease', '*hemodynamics', '*machine learning']	['NOTNLM']	NLM	e007217	['2017/10/12 00:00 [received]', '2018/04/25 00:00 [accepted]', '2018/06/20 06:00 [entrez]', '2018/06/20 06:00 [pubmed]', '2019/08/14 06:00 [medline]']	United States			29914866	ppublish	"['Comparative Study', 'Journal Article', 'Multicenter Study', ""Research Support, Non-U.S. Gov't""]"					Circ Cardiovasc Imaging. 2018 Jun;11(6):e007217. doi: 10.1161/CIRCIMAGING.117.007217.	MEDLINE	Circ Cardiovasc Imaging	Diagnostic Accuracy of a Machine-Learning Approach to Coronary Computed Tomographic Angiography-Based Fractional Flow Reserve: Result From the MACHINE Consortium.		11	Diagnostic Accuracy of a Machine-Learning Approach to Coronary Computed Tomographic Angiography-Based Fractional Flow Reserve: Result From the MACHINE Consortium.
Recently, recurrent neural networks (RNNs) have been applied in predicting disease onset risks with Electronic Health Record (EHR) data. While these models demonstrated promising results on relatively small data sets, the generalizability and transferability of those models and its applicability to different patient populations across hospitals have not been evaluated. In this study, we evaluated an RNN model, RETAIN, over Cerner Health Facts(R) EMR data, for heart failure onset risk prediction. Our data set included over 150,000 heart failure patients and over 1,000,000 controls from nearly 400 hospitals. Convincingly, RETAIN achieved an AUC of 82% in comparison to an AUC of 79% for logistic regression, demonstrating the power of more expressive deep learning models for EHR predictive modeling. The prediction performance fluctuated across different patient groups and varied from hospital to hospital. Also, we trained RETAIN models on individual hospitals and found that the model can be applied to other hospitals with only about 3.6% of reduction of AUC. Our results demonstrated the capability of RNN for predictive modeling with large and heterogeneous EHR data, and pave the road for future improvements.	['School of Biomedical Informatics, University of Texas Health Science Center at Houston (UTHealth), Houston, TX, United States.', 'Department of Health Outcomes & Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States.', 'Department of Biostatistics and Data Science, School of Public Health, University of Texas Health Science Center at Houston (UTHealth), Houston, TX, United States.', 'BGI-Shenzhen, Shenzhen, 518083, China.', 'School of Biomedical Informatics, University of Texas Health Science Center at Houston (UTHealth), Houston, TX, United States.', 'Department of Healthcare Policy and Research, Weill Cornell Medicine, Cornell University, New York, NY, United States.', 'Department of Biostatistics and Data Science, School of Public Health, University of Texas Health Science Center at Houston (UTHealth), Houston, TX, United States.', 'School of Biomedical Informatics, University of Texas Health Science Center at Houston (UTHealth), Houston, TX, United States.', 'School of Biomedical Informatics, University of Texas Health Science Center at Houston (UTHealth), Houston, TX, United States. Electronic address: Degui.Zhi@uth.tmc.edu.']	['S1532-0464(18)30117-5 [pii]', '10.1016/j.jbi.2018.06.011 [doi]']	['Rasmy L', 'Wu Y', 'Wang N', 'Geng X', 'Zheng WJ', 'Wang F', 'Wu H', 'Xu H', 'Zhi D']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/06/18 06:00']	20191119	20180615	2018 Aug	2018/06/18 06:00		['Rasmy, Laila', 'Wu, Yonghui', 'Wang, Ningtao', 'Geng, Xin', 'Zheng, W Jim', 'Wang, Fei', 'Wu, Hulin', 'Xu, Hua', 'Zhi, Degui']		['R01 HG008115/HG/NHGRI NIH HHS/United States']			1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30117-5 [pii] 10.1016/j.jbi.2018.06.011 [doi]	20191119	['Aged', 'Aged, 80 and over', 'Algorithms', 'Area Under Curve', 'Case-Control Studies', 'Computer Simulation', 'Databases, Factual', '*Deep Learning', '*Electronic Health Records', 'Female', 'Heart Failure/*diagnosis', 'Humans', 'Logistic Models', 'Male', 'Medical Informatics/methods', 'Middle Aged', '*Neural Networks (Computer)', 'Reproducibility of Results']	2019/11/20 06:00	['NIHMS979002']	['*Deep learning', '*EHR', '*Predictive modeling', '*RNN']	['NOTNLM']	NLM	11-16	['2017/12/30 00:00 [received]', '2018/05/17 00:00 [revised]', '2018/06/14 00:00 [accepted]', '2018/06/18 06:00 [pubmed]', '2019/11/20 06:00 [medline]', '2018/06/18 06:00 [entrez]']	United States	PMC6076336		29908902	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Aug;84:11-16. doi: 10.1016/j.jbi.2018.06.011. Epub 2018 Jun 15.	MEDLINE	J Biomed Inform	A study of generalizability of recurrent neural network-based predictive models for heart failure onset risk using a large and heterogeneous EHR data set.		84	A study of generalizability of recurrent neural network-based predictive models for heart failure onset risk using a large and heterogeneous EHR data set.
Deep learning has been increasingly used to solve a number of problems with state-of-the-art performance in a wide variety of fields. In biology, deep learning can be applied to reduce feature extraction time and achieve high levels of performance. In our present work, we apply deep learning via two-dimensional convolutional neural networks and position-specific scoring matrices to classify Rab protein molecules, which are main regulators in membrane trafficking for transferring proteins and other macromolecules throughout the cell. The functional loss of specific Rab molecular functions has been implicated in a variety of human diseases, e.g., choroideremia, intellectual disabilities, cancer. Therefore, creating a precise model for classifying Rabs is crucial in helping biologists understand the molecular functions of Rabs and design drug targets according to such specific human disease information. We constructed a robust deep neural network for classifying Rabs that achieved an accuracy of 99%, 99.5%, 96.3%, and 97.6% for each of four specific molecular functions. Our approach demonstrates superior performance to traditional artificial neural networks. Therefore, from our proposed study, we provide both an effective tool for classifying Rab proteins and a basis for further research that can improve the performance of biological modeling using deep neural networks.	['Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, 32003, Taiwan. Electronic address: khanhlee87@gmail.com.', 'Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, 32003, Taiwan. Electronic address: hoquangthaiholy@gmail.com.', 'Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, 32003, Taiwan. Electronic address: yien@saturn.yzu.edu.tw.']	['S0003-2697(18)30418-4 [pii]', '10.1016/j.ab.2018.06.011 [doi]']	['Le NQ', 'Ho QT', 'Ou YY']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/06/17 06:00']	20190723	20180613	2018 Aug 15	2018/06/17 06:00		['Le, Nguyen-Quoc-Khanh', 'Ho, Quang-Thai', 'Ou, Yu-Yen']					1096-0309 (Electronic) 0003-2697 (Linking)	0370535	Analytical biochemistry	['eng']	S0003-2697(18)30418-4 [pii] 10.1016/j.ab.2018.06.011 [doi]	20190723	['Cell Membrane/*metabolism', 'Choroideremia/*metabolism', 'Humans', 'Intellectual Disability/*metabolism', '*Machine Learning', '*Models, Biological', 'Neoplasm Proteins/*metabolism', 'Neoplasms/*metabolism', '*Neural Networks (Computer)', 'Protein Transport', 'rab GTP-Binding Proteins/*metabolism']	2019/07/25 06:00		['*Classification', '*Deep learning', '*DeepRab', '*Membrane trafficking', '*Neural networks', '*Rab protein']	['NOTNLM']	NLM	33-41	['2018/04/16 00:00 [received]', '2018/06/07 00:00 [revised]', '2018/06/12 00:00 [accepted]', '2018/06/17 06:00 [pubmed]', '2019/07/25 06:00 [medline]', '2018/06/17 06:00 [entrez]']	United States			29908156	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Neoplasm Proteins)', 'EC 3.6.5.2 (rab GTP-Binding Proteins)']			Anal Biochem. 2018 Aug 15;555:33-41. doi: 10.1016/j.ab.2018.06.011. Epub 2018 Jun 13.	MEDLINE	Anal Biochem	Classifying the molecular functions of Rab GTPases in membrane trafficking using deep convolutional neural networks.		555	Classifying the molecular functions of Rab GTPases in membrane trafficking using deep convolutional neural networks.
Arrhythmia is a cardiac conduction disorder characterized by irregular heartbeats. Abnormalities in the conduction system can manifest in the electrocardiographic (ECG) signal. However, it can be challenging and time-consuming to visually assess the ECG signals due to the very low amplitudes. Implementing an automated system in the clinical setting can potentially help expedite diagnosis of arrhythmia, and improve the accuracies. In this paper, we propose an automated system using a combination of convolutional neural network (CNN) and long short-term memory (LSTM) for diagnosis of normal sinus rhythm, left bundle branch block (LBBB), right bundle branch block (RBBB), atrial premature beats (APB) and premature ventricular contraction (PVC) on ECG signals. The novelty of this work is that we used ECG segments of variable length from the MIT-BIT arrhythmia physio bank database. The proposed system demonstrated high classification performance in the handling of variable-length data, achieving an accuracy of 98.10%, sensitivity of 97.50% and specificity of 98.70% using ten-fold cross validation strategy. Our proposed model can aid clinicians to detect common arrhythmias accurately on routine screening ECG.	['Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore.', 'National Heart Centre Singapore, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore University of Social Sciences, Singapore; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia. Electronic address: aru@np.edu.sg.']	['S0010-4825(18)30144-6 [pii]', '10.1016/j.compbiomed.2018.06.002 [doi]']	['Oh SL', 'Ng EYK', 'Tan RS', 'Acharya UR']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/06/16 06:00']	20191028	20180605	2018 Nov 1	2018/06/16 06:00		['Oh, Shu Lih', 'Ng, Eddie Y K', 'Tan, Ru San', 'Acharya, U Rajendra']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30144-6 [pii] 10.1016/j.compbiomed.2018.06.002 [doi]	20191028	['Algorithms', 'Arrhythmias, Cardiac/*diagnostic imaging', 'Bundle-Branch Block/diagnostic imaging', 'Deep Learning', 'Diagnosis, Computer-Assisted/*methods', '*Electrocardiography', '*Heart Rate', 'Humans', 'Neural Networks (Computer)', 'Pattern Recognition, Automated', 'Reproducibility of Results', '*Signal Processing, Computer-Assisted', 'Ventricular Premature Complexes/diagnostic imaging']	2019/10/29 06:00		['*Ambulatory electrocardiogram', '*Arrhythmia', '*Automation', '*Computer aided detection', '*Convolutional neural network', '*Deep learning', '*Diagnosis', '*Long short-term memory']	['NOTNLM']	NLM	278-287	['2018/04/26 00:00 [received]', '2018/06/01 00:00 [revised]', '2018/06/02 00:00 [accepted]', '2018/06/16 06:00 [pubmed]', '2019/10/29 06:00 [medline]', '2018/06/16 06:00 [entrez]']	United States			29903630	ppublish	['Journal Article']			IM		Comput Biol Med. 2018 Nov 1;102:278-287. doi: 10.1016/j.compbiomed.2018.06.002. Epub 2018 Jun 5.	MEDLINE	Comput Biol Med	Automated diagnosis of arrhythmia using combination of CNN and LSTM techniques with variable length heart beats.		102	Automated diagnosis of arrhythmia using combination of CNN and LSTM techniques with variable length heart beats.
BACKGROUND AND OBJECTIVE: Leukocyte classification and cytometry have wide applications in medical domain, previous researches usually exploit machine learning techniques to classify leukocytes automatically. However, constrained by the past development of machine learning techniques, for example, extracting distinctive features from raw microscopic images are difficult, the widely used SVM classifier only has relative few parameters to tune, these methods cannot efficiently handle fine-grained classification cases when the white blood cells have up to 40 categories. METHODS: Based on deep learning theory, a systematic study is conducted on finer leukocyte classification in this paper. A deep residual neural network based leukocyte classifier is constructed at first, which can imitate the domain expert's cell recognition process, and extract salient features robustly and automatically. Then the deep neural network classifier's topology is adjusted according to the prior knowledge of white blood cell test. After that the microscopic image dataset with almost one hundred thousand labeled leukocytes belonging to 40 categories is built, and combined training strategies are adopted to make the designed classifier has good generalization ability. RESULTS: The proposed deep residual neural network based classifier was tested on microscopic image dataset with 40 leukocyte categories. It achieves top-1 accuracy of 77.80%, top-5 accuracy of 98.75% during the training procedure. The average accuracy on the test set is nearly 76.84%. CONCLUSIONS: This paper presents a fine-grained leukocyte classification method for microscopic images, based on deep residual learning theory and medical domain knowledge. Experimental results validate the feasibility and effectiveness of our approach. Extended experiments support that the fine-grained leukocyte classifier could be used in real medical applications, assist doctors in diagnosing diseases, reduce human power significantly.	['School of Computer Science and Technology, Hangzhou Dianzi University, China. Electronic address: qinfeiwei@hdu.edu.cn.', 'School of Computer Science and Technology, Hangzhou Dianzi University, China.', 'School of Computer Science and Technology, Hangzhou Dianzi University, China.', 'School of Media and Design, Hangzhou Dianzi University, China.', 'Department of Orthopaedic Surgery, Sir Run Run Shaw Hospital, China.', 'School of Computer Science and Technology, Hangzhou Dianzi University, China.']	['S0169-2607(18)30056-7 [pii]', '10.1016/j.cmpb.2018.05.024 [doi]']	['Qin F', 'Gao N', 'Peng Y', 'Wu Z', 'Shen S', 'Grudtsin A']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/06/16 06:00']	20181015	20180522	2018 Aug	2018/06/16 06:00		['Qin, Feiwei', 'Gao, Nannan', 'Peng, Yong', 'Wu, Zizhao', 'Shen, Shuying', 'Grudtsin, Artur']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30056-7 [pii] 10.1016/j.cmpb.2018.05.024 [doi]	20181015	['Humans', 'Leukocytes/*cytology', '*Machine Learning', '*Microscopy', 'Models, Statistical', '*Neural Networks (Computer)', 'Pattern Recognition, Automated', '*Support Vector Machine']	2018/10/16 06:00		['Deep learning', 'Image analysis', 'Leukocyte', 'Residual learning']	['NOTNLM']	NLM	243-252	['2018/01/11 00:00 [received]', '2018/04/11 00:00 [revised]', '2018/05/16 00:00 [accepted]', '2018/06/16 06:00 [entrez]', '2018/06/16 06:00 [pubmed]', '2018/10/16 06:00 [medline]']	Ireland			29903491	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Aug;162:243-252. doi: 10.1016/j.cmpb.2018.05.024. Epub 2018 May 22.	MEDLINE	Comput Methods Programs Biomed	Fine-grained leukocyte classification with deep residual learning for microscopic images.		162	Fine-grained leukocyte classification with deep residual learning for microscopic images.
BACKGROUND: Deep Neural Networks (DNN), in particular, Convolutional Neural Networks (CNN), has recently achieved state-of-art results for the task of Drug-Drug Interaction (DDI) extraction. Most CNN architectures incorporate a pooling layer to reduce the dimensionality of the convolution layer output, preserving relevant features and removing irrelevant details. All the previous CNN based systems for DDI extraction used max-pooling layers. RESULTS: In this paper, we evaluate the performance of various pooling methods (in particular max-pooling, average-pooling and attentive pooling), as well as their combination, for the task of DDI extraction. Our experiments show that max-pooling exhibits a higher performance in F1-score (64.56%) than attentive pooling (59.92%) and than average-pooling (58.35%). CONCLUSIONS: Max-pooling outperforms the others alternatives because is the only one which is invariant to the special pad tokens that are appending to the shorter sentences known as padding. Actually, the combination of max-pooling and attentive pooling does not improve the performance as compared with the single max-pooling technique.	['Computer Science Department, Carlos III University of Madrid, 28911, Leganes, Spain. vspaniag@inf.uc3m.es.', 'Computer Science Department, Carlos III University of Madrid, 28911, Leganes, Spain.']	['10.1186/s12859-018-2195-1 [doi]', '10.1186/s12859-018-2195-1 [pii]']	['Suarez-Paniagua V', 'Segura-Bedmar I']							['2018/06/14 06:00']	20190517	20180613	2018 Jun 13	2018/06/14 06:00		['Suarez-Paniagua, Victor', 'Segura-Bedmar, Isabel']			Suppl 8		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2195-1 [doi]	20190517	['*Algorithms', 'Databases as Topic', 'Deep Learning', '*Drug Interactions', 'Humans', '*Information Storage and Retrieval', 'Neural Networks (Computer)']	2019/05/18 06:00		['*Attention model', '*Convolutional neural network', '*Deep learning', '*Drug-drug interaction extraction', '*Pooling']	['NOTNLM']	NLM	209	['2018/06/14 06:00 [entrez]', '2018/06/14 06:00 [pubmed]', '2019/05/18 06:00 [medline]']	England	PMC5998766		29897318	epublish	['Journal Article']			IM		BMC Bioinformatics. 2018 Jun 13;19(Suppl 8):209. doi: 10.1186/s12859-018-2195-1.	MEDLINE	BMC Bioinformatics	Evaluation of pooling operations in convolutional architectures for drug-drug interaction extraction.		19	Evaluation of pooling operations in convolutional architectures for drug-drug interaction extraction.
Deep neural networks have demonstrated promising potential for the field of medical image reconstruction, successfully generating high quality images for CT, PET and MRI. In this work, an MRI reconstruction algorithm, which is referred to as quantitative susceptibility mapping (QSM), has been developed using a deep neural network in order to perform dipole deconvolution, which restores magnetic susceptibility source from an MRI field map. Previous approaches of QSM require multiple orientation data (e.g. Calculation of Susceptibility through Multiple Orientation Sampling or COSMOS) or regularization terms (e.g. Truncated K-space Division or TKD; Morphology Enabled Dipole Inversion or MEDI) to solve an ill-conditioned dipole deconvolution problem. Unfortunately, they either entail challenges in data acquisition (i.e. long scan time and multiple head orientations) or suffer from image artifacts. To overcome these shortcomings, a deep neural network, which is referred to as QSMnet, is constructed to generate a high quality susceptibility source map from single orientation data. The network has a modified U-net structure and is trained using COSMOS QSM maps, which are considered as gold standard. Five head orientation datasets from five subjects were employed for patch-wise network training after doubling the training data using a model-based data augmentation. Seven additional datasets of five head orientation images (i.e. total 35 images) were used for validation (one dataset) and test (six datasets). The QSMnet maps of the test dataset were compared with the maps from TKD and MEDI for their image quality and consistency with respect to multiple head orientations. Quantitative and qualitative image quality comparisons demonstrate that the QSMnet results have superior image quality to those of TKD or MEDI results and have comparable image quality to those of COSMOS. Additionally, QSMnet maps reveal substantially better consistency across the multiple head orientation data than those from TKD or MEDI. As a preliminary application, the network was further tested for three patients, one with microbleed, another with multiple sclerosis lesions, and the third with hemorrhage. The QSMnet maps showed similar lesion contrasts with those from MEDI, demonstrating potential for future applications.	['Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea.', 'Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Radiology, Stanford University, Stanford, CA, USA.', 'National Nanotechnology Center, Pathum Thani, Thailand.', 'Department of Radiology, Harvard Medical School, Boston, MA, USA.', 'Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea.', 'Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea.', 'Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea.', 'Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea.', 'Department of Radiology, Harvard Medical School, Boston, MA, USA.', 'Department of Radiology, Stanford University, Stanford, CA, USA.', 'Department of Radiology, Gil Medical Center, Gachon University College of Medicine, Incheon, South Korea.', 'Department of Electrical Engineering, Stanford University, Stanford, CA, USA.', 'Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea. Electronic address: jonghoyi@snu.ac.kr.']	['S1053-8119(18)30537-8 [pii]', '10.1016/j.neuroimage.2018.06.030 [doi]']	['Yoon J', 'Gong E', 'Chatnuntawech I', 'Bilgic B', 'Lee J', 'Jung W', 'Ko J', 'Jung H', 'Setsompop K', 'Zaharchuk G', 'Kim EY', 'Pauly J', 'Lee J']		['Copyright (c) 2018. Published by Elsevier Inc.']					['2018/06/13 06:00']	20190213	20180615	2018 Oct 1	2018/06/13 06:00		['Yoon, Jaeyeon', 'Gong, Enhao', 'Chatnuntawech, Itthi', 'Bilgic, Berkin', 'Lee, Jingu', 'Jung, Woojin', 'Ko, Jingyu', 'Jung, Hosan', 'Setsompop, Kawin', 'Zaharchuk, Greg', 'Kim, Eung Yeop', 'Pauly, John', 'Lee, Jongho']					1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(18)30537-8 [pii] 10.1016/j.neuroimage.2018.06.030 [doi]	20190215	['Adult', 'Aged', '*Algorithms', 'Brain/anatomy & histology', 'Brain Mapping/*methods', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'Middle Aged', '*Neural Networks (Computer)']	2019/02/14 06:00		['*Dipole', '*MRI', '*Machine learning', '*Magnetic susceptibility', '*QSM', '*Reconstruction']	['NOTNLM']	NLM	199-206	['2018/03/20 00:00 [received]', '2018/06/05 00:00 [revised]', '2018/06/08 00:00 [accepted]', '2018/06/13 06:00 [pubmed]', '2019/02/14 06:00 [medline]', '2018/06/13 06:00 [entrez]']	United States			29894829	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroimage. 2018 Oct 1;179:199-206. doi: 10.1016/j.neuroimage.2018.06.030. Epub 2018 Jun 15.	MEDLINE	Neuroimage	Quantitative susceptibility mapping using deep neural network: QSMnet.		179	Quantitative susceptibility mapping using deep neural network: QSMnet.
Machine learning methods for protein function prediction are urgently needed, especially now that a substantial fraction of known sequences remains unannotated despite the extensive use of functional assignments based on sequence similarity. One major bottleneck supervised learning faces in protein function prediction is the structured, multi-label nature of the problem, because biological roles are represented by lists of terms from hierarchically organised controlled vocabularies such as the Gene Ontology. In this work, we build on recent developments in the area of deep learning and investigate the usefulness of multi-task deep neural networks (MTDNN), which consist of upstream shared layers upon which are stacked in parallel as many independent modules (additional hidden layers with their own output units) as the number of output GO terms (the tasks). MTDNN learns individual tasks partially using shared representations and partially from task-specific characteristics. When no close homologues with experimentally validated functions can be identified, MTDNN gives more accurate predictions than baseline methods based on annotation frequencies in public databases or homology transfers. More importantly, the results show that MTDNN binary classification accuracy is higher than alternative machine learning-based methods that do not exploit commonalities and differences among prediction tasks. Interestingly, compared with a single-task predictor, the performance improvement is not linearly correlated with the number of tasks in MTDNN, but medium size models provide more improvement in our case. One of advantages of MTDNN is that given a set of features, there is no requirement for MTDNN to have a bootstrap feature selection procedure as what traditional machine learning algorithms do. Overall, the results indicate that the proposed MTDNN algorithm improves the performance of protein function prediction. On the other hand, there is still large room for deep learning techniques to further enhance prediction ability.	['The Francis Crick Institute, London, United Kingdom.', 'Computer Science Department, University College London, London, United Kingdom.', 'The Francis Crick Institute, London, United Kingdom.', 'Computer Science Department, University College London, London, United Kingdom.', 'The Francis Crick Institute, London, United Kingdom.', 'Computer Science Department, University College London, London, United Kingdom.', 'The Francis Crick Institute, London, United Kingdom.', 'Computer Science Department, University College London, London, United Kingdom.']	['10.1371/journal.pone.0198216 [doi]', 'PONE-D-18-03436 [pii]']	['Fa R', 'Cozzetto D', 'Wan C', 'Jones DT']	['ORCID: 0000-0003-4588-7971', 'ORCID: 0000-0001-8626-3765']				['We have no competing financial, professional or personal interests that might', 'have influenced the performance or presentation of the work described in this', 'manuscript. The fact that one of our founders, Elsevier, is a commercial company', 'does not alter our adherence to PLOS ONE policies on sharing data and materials.']		['2018/06/12 06:00']	20181211	20180611	2018	2018/06/12 06:00		['Fa, Rui', 'Cozzetto, Domenico', 'Wan, Cen', 'Jones, David T']		['BB/L020505/1/Biotechnology and Biological Sciences Research Council/United', 'Kingdom', 'BB/L002817/1/Biotechnology and Biological Sciences Research Council/United', 'Kingdom']	6		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0198216 [doi]	20181211	['*Databases, Protein', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', '*Proteins/chemistry/genetics/metabolism']	2018/12/12 06:00				NLM	e0198216	['2018/02/01 00:00 [received]', '2018/05/15 00:00 [accepted]', '2018/06/12 06:00 [entrez]', '2018/06/12 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	United States	PMC5995439		29889900	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		PLoS One. 2018 Jun 11;13(6):e0198216. doi: 10.1371/journal.pone.0198216. eCollection 2018.	MEDLINE	PLoS One	Predicting human protein function with multi-task deep neural networks.		13	Predicting human protein function with multi-task deep neural networks.
Machine learning, a collection of data-analytical techniques aimed at building predictive models from multi-dimensional datasets, is becoming integral to modern biological research. By enabling one to generate models that learn from large datasets and make predictions on likely outcomes, machine learning can be used to study complex cellular systems such as biological networks. Here, we provide a primer on machine learning for life scientists, including an introduction to deep learning. We discuss opportunities and challenges at the intersection of machine learning and network biology, which could impact disease biology, drug discovery, microbiome research, and synthetic biology.	['Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA 02115, USA.', 'Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA 02115, USA; Department of Brain & Cognitive Sciences and Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA 02139, USA.', 'Computational Bioscience Program, Department of Pharmacology, University of Colorado Anschutz Medical Campus, Aurora, CO 80045, USA.', 'Computational Bioscience Program, Department of Pharmacology, University of Colorado Anschutz Medical Campus, Aurora, CO 80045, USA. Electronic address: james.costello@ucdenver.edu.', 'Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA 02115, USA; Department of Biological Engineering and Institute for Medical Engineering & Science, Massachusetts Institute of Technology, Cambridge, MA 02139, USA; Broad Institute of MIT and Harvard, Cambridge, MA 02142, USA. Electronic address: jimjc@mit.edu.']	['S0092-8674(18)30592-0 [pii]', '10.1016/j.cell.2018.05.015 [doi]']	['Camacho DM', 'Collins KM', 'Powers RK', 'Costello JC', 'Collins JJ']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/06/12 06:00']	20190313	20180607	2018 Jun 14	2018/06/12 06:00		['Camacho, Diogo M', 'Collins, Katherine M', 'Powers, Rani K', 'Costello, James C', 'Collins, James J']			7		1097-4172 (Electronic) 0092-8674 (Linking)	0413066	Cell	['eng']	S0092-8674(18)30592-0 [pii] 10.1016/j.cell.2018.05.015 [doi]	20190313	['Algorithms', 'Computational Biology/*methods', 'Databases, Factual', 'Drug Discovery', 'Drug-Related Side Effects and Adverse Reactions', 'Humans', '*Machine Learning', 'Microbiota', 'Neural Networks (Computer)']	2019/03/14 06:00		['*Machine leaning', '*deep learning', '*network biology', '*neural networks', '*synthetic biology', '*systems biology']	['NOTNLM']	NLM	1581-1592	['2017/10/10 00:00 [received]', '2018/03/10 00:00 [revised]', '2018/05/07 00:00 [accepted]', '2018/06/12 06:00 [pubmed]', '2019/03/14 06:00 [medline]', '2018/06/12 06:00 [entrez]']	United States			29887378	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Cell. 2018 Jun 14;173(7):1581-1592. doi: 10.1016/j.cell.2018.05.015. Epub 2018 Jun 7.	MEDLINE	Cell	Next-Generation Machine Learning for Biological Networks.		173	Next-Generation Machine Learning for Biological Networks.
As of April 2018, UniProtKB has collected more than 115 million protein sequences. Less than 0.15% of these proteins, however, have been associated with experimental GO annotations. As such, the use of automatic protein function prediction (AFP) to reduce this huge gap becomes increasingly important. The previous studies conclude that sequence homology based methods are highly effective in AFP. In addition, mining motif, domain, and functional information from protein sequences has been found very helpful for AFP. Other than sequences, alternative information sources such as text, however, may be useful for AFP as well. Instead of using BOW (bag of words) representation in traditional text-based AFP, we propose a new method called DeepText2GO that relies on deep semantic text representation, together with different kinds of available protein information such as sequence homology, families, domains, and motifs, to improve large-scale AFP. Furthermore, DeepText2GO integrates text-based methods with sequence-based ones by means of a consensus approach. Extensive experiments on the benchmark dataset extracted from UniProt/SwissProt have demonstrated that DeepText2GO significantly outperformed both text-based and sequence-based methods, validating its superiority.	['School of Computer Science and Shanghai Key Lab of Intelligent Information Processing, Fudan University, China; Center for Computational System Biology, ISTBI, Fudan University, Shanghai 200433, China.', 'School of Computing and Mathematics, Charles Sturt University, Albury, NSW 2640, Australia.', 'School of Computer Science and Shanghai Key Lab of Intelligent Information Processing, Fudan University, China; Center for Computational System Biology, ISTBI, Fudan University, Shanghai 200433, China. Electronic address: zhusf@fudan.edu.cn.']	['S1046-2023(18)30002-1 [pii]', '10.1016/j.ymeth.2018.05.026 [doi]']	['You R', 'Huang X', 'Zhu S']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/06/09 06:00']	20190520	20180606	2018 Aug 1	2018/06/09 06:00		['You, Ronghui', 'Huang, Xiaodi', 'Zhu, Shanfeng']					1095-9130 (Electronic) 1046-2023 (Linking)	9426302	Methods (San Diego, Calif.)	['eng']	S1046-2023(18)30002-1 [pii] 10.1016/j.ymeth.2018.05.026 [doi]	20190520	['Animals', 'Computational Biology/methods', 'Data Mining/*methods', 'Eukaryota/metabolism', '*Gene Ontology', 'Humans', 'Machine Learning', 'Proteins/*metabolism/physiology', 'Semantics', 'Sequence Analysis, Protein/*methods']	2019/05/21 06:00		['*Large-scale protein function prediction', '*Text classification']	['NOTNLM']	NLM	82-90	['2018/02/13 00:00 [received]', '2018/04/30 00:00 [revised]', '2018/05/31 00:00 [accepted]', '2018/06/09 06:00 [pubmed]', '2019/05/21 06:00 [medline]', '2018/06/09 06:00 [entrez]']	United States			29883746	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		Methods. 2018 Aug 1;145:82-90. doi: 10.1016/j.ymeth.2018.05.026. Epub 2018 Jun 6.	MEDLINE	Methods	DeepText2GO: Improving large-scale protein function prediction with deep semantic text representation.		145	DeepText2GO: Improving large-scale protein function prediction with deep semantic text representation.
"Having accurate, detailed, and up-to-date information about the location and behavior of animals in the wild would improve our ability to study and conserve ecosystems. We investigate the ability to automatically, accurately, and inexpensively collect such data, which could help catalyze the transformation of many fields of ecology, wildlife biology, zoology, conservation biology, and animal behavior into ""big data"" sciences. Motion-sensor ""camera traps"" enable collecting wildlife pictures inexpensively, unobtrusively, and frequently. However, extracting information from these pictures remains an expensive, time-consuming, manual task. We demonstrate that such information can be automatically extracted by deep learning, a cutting-edge type of artificial intelligence. We train deep convolutional neural networks to identify, count, and describe the behaviors of 48 species in the 3.2 million-image Snapshot Serengeti dataset. Our deep neural networks automatically identify animals with >93.8% accuracy, and we expect that number to improve rapidly in years to come. More importantly, if our system classifies only images it is confident about, our system can automate animal identification for 99.3% of the data while still performing at the same 96.6% accuracy as that of crowdsourced teams of human volunteers, saving >8.4 y (i.e., >17,000 h at 40 h/wk) of human labeling effort on this 3.2 million-image dataset. Those efficiency gains highlight the importance of using deep neural networks to automate data extraction from camera-trap images, reducing a roadblock for this widely used technology. Our results suggest that deep learning could enable the inexpensive, unobtrusive, high-volume, and even real-time collection of a wealth of information about vast numbers of animals in the wild."	['Department of Computer Science, University of Wyoming, Laramie, WY 82071.', 'Department of Computer Science and Software Engineering, Auburn University, Auburn, AL 36849.', 'Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA 02138.', 'Department of Physics, University of Oxford, Oxford OX1 3RH, United Kingdom.', 'Department of Ecology, Evolution, and Behavior, University of Minnesota, St. Paul, MN 55108.', 'Department of Ecology, Evolution, and Behavior, University of Minnesota, St. Paul, MN 55108.', 'Department of Computer Science, University of Wyoming, Laramie, WY 82071; jeffclune@uwyo.edu.', 'Uber AI Labs, San Francisco, CA 94103.']	['1719367115 [pii]', '10.1073/pnas.1719367115 [doi]']	['Norouzzadeh MS', 'Nguyen A', 'Kosmala M', 'Swanson A', 'Palmer MS', 'Packer C', 'Clune J']		['Copyright (c) 2018 the Author(s). Published by PNAS.']			['The authors declare no conflict of interest.']		['2018/06/07 06:00']	20180827	20180605	2018 Jun 19	2018/06/07 06:00		['Norouzzadeh, Mohammad Sadegh', 'Nguyen, Anh', 'Kosmala, Margaret', 'Swanson, Alexandra', 'Palmer, Meredith S', 'Packer, Craig', 'Clune, Jeff']			25		1091-6490 (Electronic) 0027-8424 (Linking)	7505876	Proceedings of the National Academy of Sciences of the United States of America	['eng']	10.1073/pnas.1719367115 [doi]	20181114	['Algorithms', 'Animals', 'Animals, Wild/*physiology', 'Artificial Intelligence', 'Behavior, Animal/*physiology', 'Ecology/methods', 'Ecosystem', 'Humans', 'Machine Learning', 'Neural Networks (Computer)']	2018/08/28 06:00		['*artificial intelligence', '*camera-trap images', '*deep learning', '*deep neural networks', '*wildlife ecology']	['NOTNLM']	NLM	E5716-E5725	['2018/06/07 06:00 [pubmed]', '2018/08/28 06:00 [medline]', '2018/06/07 06:00 [entrez]']	United States	PMC6016780		29871948	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Proc Natl Acad Sci U S A. 2018 Jun 19;115(25):E5716-E5725. doi: 10.1073/pnas.1719367115. Epub 2018 Jun 5.	MEDLINE	Proc Natl Acad Sci U S A	Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning.		115	Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning.
Motivation: The explosive increase of biomedical literature has made information extraction an increasingly important tool for biomedical research. A fundamental task is the recognition of biomedical named entities in text (BNER) such as genes/proteins, diseases and species. Recently, a domain-independent method based on deep learning and statistical word embeddings, called long short-term memory network-conditional random field (LSTM-CRF), has been shown to outperform state-of-the-art entity-specific BNER tools. However, this method is dependent on gold-standard corpora (GSCs) consisting of hand-labeled entities, which tend to be small but highly reliable. An alternative to GSCs are silver-standard corpora (SSCs), which are generated by harmonizing the annotations made by several automatic annotation systems. SSCs typically contain more noise than GSCs but have the advantage of containing many more training examples. Ideally, these corpora could be combined to achieve the benefits of both, which is an opportunity for transfer learning. In this work, we analyze to what extent transfer learning improves upon state-of-the-art results for BNER. Results: We demonstrate that transferring a deep neural network (DNN) trained on a large, noisy SSC to a smaller, but more reliable GSC significantly improves upon state-of-the-art results for BNER. Compared to a state-of-the-art baseline evaluated on 23 GSCs covering four different entity classes, transfer learning results in an average reduction in error of approximately 11%. We found transfer learning to be especially beneficial for target datasets with a small number of labels (approximately 6000 or less). Availability and implementation: Source code for the LSTM-CRF is available at https://github.com/Franck-Dernoncourt/NeuroNER/ and links to the corpora are available at https://github.com/BaderLab/Transfer-Learning-BNER-Bioinformatics-2018/. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of Toronto, Toronto, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, Canada.', 'Department of Computer Science, University of Toronto, Toronto, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.']	['5026661 [pii]', '10.1093/bioinformatics/bty449 [doi]']	['Giorgi JM', 'Bader GD']							['2018/06/06 06:00']	20191022		2018 Dec 1	2018/06/06 06:00		['Giorgi, John M', 'Bader, Gary D']		['U41 HG006623/HG/NHGRI NIH HHS/United States']	23		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty449 [doi]	20191022	['Computational Biology', '*Deep Learning', '*Information Storage and Retrieval', '*Neural Networks (Computer)', '*Software']	2019/10/23 06:00				NLM	4087-4094	['2018/02/12 00:00 [received]', '2018/05/29 00:00 [accepted]', '2018/06/06 06:00 [pubmed]', '2019/10/23 06:00 [medline]', '2018/06/06 06:00 [entrez]']	England	PMC6247938		29868832	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Bioinformatics. 2018 Dec 1;34(23):4087-4094. doi: 10.1093/bioinformatics/bty449.	MEDLINE	Bioinformatics	Transfer learning for biomedical named entity recognition with neural networks.		34	Transfer learning for biomedical named entity recognition with neural networks.
OBJECTIVES: The aims of this study were, first, to evaluate a deep learning-based, automatic glioblastoma (GB) tumor segmentation algorithm on clinical routine data from multiple centers and compare the results to a ground truth, manual expert segmentation, and second, to evaluate the quality of the segmentation results across heterogeneous acquisition protocols of routinely acquired clinical magnetic resonance imaging (MRI) examinations from multiple centers. MATERIALS AND METHODS: The data consisted of preoperative MRI scans (T1, T2, FLAIR, and contrast-enhanced [CE] T1) of 64 patients with an initial diagnosis of primary GB, which were acquired in 15 institutions with varying protocols. All images underwent preprocessing (coregistration, skull stripping, resampling to isotropic resolution, normalization) and were fed into an independently trained deep learning model based on DeepMedic, a multilayer, multiscale convolutional neural network for detection and segmentation of tumor compartments. Automatic segmentation results for the whole tumor, necrosis, and CE tumor were compared with manual segmentations. RESULTS: Whole tumor and CE tumor compartments were correctly detected in 100% of the cases; necrosis was correctly detected in 91% of the cases. A high segmentation accuracy comparable to interrater variability was achieved for the whole tumor (mean dice similarity coefficient [DSC], 0.86 +/- 0.09) and CE tumor (DSC, 0.78 +/- 0.15). The DSC for tumor necrosis was 0.62 +/- 0.30. We have observed robust segmentation quality over heterogeneous image acquisition protocols, for example, there were no correlations between resolution and segmentation accuracy of the single tumor compartments. Furthermore, no relevant correlation was found between quality of automatic segmentation and volume of interest properties (surface-to-volume ratio and volume). CONCLUSIONS: The proposed approach for automatic segmentation of GB proved to be robust on routine clinical data and showed on all tumor compartments a high automatic detection rate and a high accuracy, comparable to interrater variability. Further work on improvements of the segmentation accuracy for the necrosis compartments should be guided by the evaluation of the clinical relevance.Therefore, we propose this approach as a suitable building block for automatic tumor segmentation to support radiologists or neurosurgeons in the preoperative reading of GB MRI images and characterization of primary GB.	['Clinical Applications Research, Philips Research, Aachen.', 'Department of Neurosurgery, University Hospital Cologne, Cologne, Germany.', 'Clinical Applications Research, Philips Research, Aachen.', 'Clinical Applications Research, Philips Research, Aachen.', 'Data Science, Philips Healthcare, Bangalore, India.']	['10.1097/RLI.0000000000000484 [doi]']	['Perkuhn M', 'Stavrinou P', 'Thiele F', 'Shakirin G', 'Mohan M', 'Garmpis D', 'Kabbasch C', 'Borggrefe J']							['2018/06/05 06:00']	20190612		2018 Nov	2018/06/05 06:00		['Perkuhn, Michael', 'Stavrinou, Pantelis', 'Thiele, Frank', 'Shakirin, Georgy', 'Mohan, Manoj', 'Garmpis, Dionysios', 'Kabbasch, Christoph', 'Borggrefe, Jan']			11		1536-0210 (Electronic) 0020-9996 (Linking)	0045377	Investigative radiology	['eng']	10.1097/RLI.0000000000000484 [doi]	20190613	['Adult', 'Aged', 'Aged, 80 and over', 'Algorithms', 'Brain/diagnostic imaging', 'Brain Neoplasms/*diagnostic imaging', '*Deep Learning', 'Female', 'Glioblastoma/*diagnostic imaging', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', 'Retrospective Studies']	2019/06/14 06:00				NLM	647-654	['2018/06/05 06:00 [pubmed]', '2019/06/14 06:00 [medline]', '2018/06/05 06:00 [entrez]']	United States			29863600	ppublish	['Journal Article']			IM		Invest Radiol. 2018 Nov;53(11):647-654. doi: 10.1097/RLI.0000000000000484.	MEDLINE	Invest Radiol	Clinical Evaluation of a Multiparametric Deep Learning Model for Glioblastoma Segmentation Using Heterogeneous Magnetic Resonance Imaging Data From Clinical Routine.		53	Clinical Evaluation of a Multiparametric Deep Learning Model for Glioblastoma Segmentation Using Heterogeneous Magnetic Resonance Imaging Data From Clinical Routine.
Clinical Named Entity Recognition (NER) is a critical natural language processing (NLP) task to extract important concepts (named entities) from clinical narratives. Researchers have extensively investigated machine learning models for clinical NER. Recently, there have been increasing efforts to apply deep learning models to improve the performance of current clinical NER systems. This study examined two popular deep learning architectures, the Convolutional Neural Network (CNN) and the Recurrent Neural Network (RNN), to extract concepts from clinical texts. We compared the two deep neural network architectures with three baseline Conditional Random Fields (CRFs) models and two state-of-the-art clinical NER systems using the i2b2 2010 clinical concept extraction corpus. The evaluation results showed that the RNN model trained with the word embeddings achieved a new state-of-the- art performance (a strict F1 score of 85.94%) for the defined clinical NER task, outperforming the best-reported system that used both manually defined and unsupervised learning features. This study demonstrates the advantage of using deep neural network architectures for clinical concept extraction, including distributed feature representation, automatic feature learning, and long-term dependencies capture. This is one of the first studies to compare the two widely used deep learning models and demonstrate the superior performance of the RNN model for clinical NER.	['School of Biomedical Informatics, the University of Texas Health Science Center at Houston, Houston, TX, USA.', 'School of Biomedical Informatics, the University of Texas Health Science Center at Houston, Houston, TX, USA.', 'School of Biomedical Informatics, the University of Texas Health Science Center at Houston, Houston, TX, USA.', 'School of Biomedical Informatics, the University of Texas Health Science Center at Houston, Houston, TX, USA.', 'School of Biomedical Informatics, the University of Texas Health Science Center at Houston, Houston, TX, USA.']		['Wu Y', 'Jiang M', 'Xu J', 'Zhi D', 'Xu H']							['2018/06/02 06:00']	20190226	20180416	2017	2018/06/02 06:00		['Wu, Yonghui', 'Jiang, Min', 'Xu, Jun', 'Zhi, Degui', 'Xu, Hua']		['R01 GM102282/GM/NIGMS NIH HHS/United States', 'R01 GM103859/GM/NIGMS NIH HHS/United States', 'R01 LM010681/LM/NLM NIH HHS/United States', 'U24 CA194215/CA/NCI NIH HHS/United States']			1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20190226	['Datasets as Topic', '*Deep Learning', 'Medical Records', '*Natural Language Processing', '*Neural Networks (Computer)']	2019/02/27 06:00				NLM	1812-1819	['2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2019/02/27 06:00 [medline]']	United States	PMC5977567		29854252	epublish	['Comparative Study', 'Journal Article', 'Research Support, N.I.H., Extramural']			IM		AMIA Annu Symp Proc. 2018 Apr 16;2017:1812-1819. eCollection 2017.	MEDLINE	AMIA Annu Symp Proc	Clinical Named Entity Recognition Using Deep Learning Models.		2017	Clinical Named Entity Recognition Using Deep Learning Models.
Monitoring the future health status of patients from the historical Electronic Health Record (EHR) is a core research topic in predictive healthcare. The most important challenges are to model the temporality of sequential EHR data and to interpret the prediction results. In order to reduce the future risk of diseases, we propose a multi-task framework that can monitor the multiple status ofdiagnoses. Patients' historical records are directly fed into a Recurrent Neural Network (RNN) which memorizes all the past visit information, and then a task-specific layer is trained to predict multiple diagnoses. Moreover, three attention mechanisms for RNNs are introduced to measure the relationships between past visits and current status. Experimental results show that the proposed attention-based RNNs can significantly improve the prediction accuracy compared to widely used approaches. With the attention mechanisms, the proposed framework is able to identify the visit information which is important to the final prediction.	['Department of Computer Science and Engineering, University at Buffalo, NY, USA.', 'Department of Computer Science and Engineering, University at Buffalo, NY, USA.', 'Department of Surgical and Medical Sciences, Magna Graecia University, Catanzaro, Italy.', 'Department of Computer Science and Engineering, University at Buffalo, NY, USA.', 'Department of Computer Science and Engineering, University at Buffalo, NY, USA.', 'Department of Surgical and Medical Sciences, Magna Graecia University, Catanzaro, Italy.', 'Metabolic Diseases Unit, Department of Clinical and Experimental Medicine, Mater Domini Hospital, Magna Graecia University, Catanzaro, Italy.']		['Suo Q', 'Ma F', 'Canino G', 'Gao J', 'Zhang A', 'Veltri P', 'Agostino G']							['2018/06/02 06:00']	20190412	20180416	2017	2018/06/02 06:00		['Suo, Qiuling', 'Ma, Fenglong', 'Canino, Giovanni', 'Gao, Jing', 'Zhang, Aidong', 'Veltri, Pierangelo', 'Agostino, Gnasso']					1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20190412	['Deep Learning', '*Disease Progression', '*Electronic Health Records', 'Humans', '*Neural Networks (Computer)', 'Patient Care Management/*methods']	2019/04/13 06:00				NLM	1665-1674	['2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2019/04/13 06:00 [medline]']	United States	PMC5977646		29854237	epublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		AMIA Annu Symp Proc. 2018 Apr 16;2017:1665-1674. eCollection 2017.	MEDLINE	AMIA Annu Symp Proc	A Multi-Task Framework for Monitoring Health Conditions via Attention-based Recurrent Neural Networks.		2017	A Multi-Task Framework for Monitoring Health Conditions via Attention-based Recurrent Neural Networks.
Data augmentation is an essential part of training discriminative Convolutional Neural Networks (CNNs). A variety of augmentation strategies, including horizontal flips, random crops, and principal component analysis (PCA), have been proposed and shown to capture important characteristics of natural images. However, while data augmentation has been commonly used for deep learning in medical imaging, little work has been done to determine which augmentation strategies best capture medical image statistics, leading to more discriminative models. This work compares augmentation strategies and shows that the extent to which an augmented training set retains properties of the original medical images determines model performance. Specifically, augmentation strategies such as flips and gaussian filters lead to validation accuracies of 84% and 88%, respectively. On the other hand, a less effective strategy such as adding noise leads to a significantly worse validation accuracy of 66%. Finally, we show that the augmentation affects mass generation.	['Stanford University, Department of Computer Science, Stanford, CA.', 'Stanford University, Department of Radiology, Stanford, CA.', 'Stanford University, Department of Radiology, Stanford, CA.', 'Stanford University, Department of Radiology, Stanford, CA.']		['Hussain Z', 'Gimenez F', 'Yi D', 'Rubin D']							['2018/06/02 06:00']	20190328	20180416	2017	2018/06/02 06:00		['Hussain, Zeshan', 'Gimenez, Francisco', 'Yi, Darvin', 'Rubin, Daniel']					1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20190328	['Data Visualization', 'Datasets as Topic', '*Deep Learning', 'Diagnostic Imaging', 'Humans', 'Image Enhancement/*methods', 'Mammography/*classification', '*Neural Networks (Computer)', 'Radiology Information Systems']	2019/03/29 06:00				NLM	979-984	['2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2019/03/29 06:00 [medline]']	United States	PMC5977656		29854165	epublish	['Comparative Study', 'Journal Article']			IM		AMIA Annu Symp Proc. 2018 Apr 16;2017:979-984. eCollection 2017.	MEDLINE	AMIA Annu Symp Proc	Differential Data Augmentation Techniques for Medical Imaging Classification Tasks.		2017	Differential Data Augmentation Techniques for Medical Imaging Classification Tasks.
Opioid analgesics, as commonly prescribed medications used for relieving pain in patients, are especially prevalent in US these years. However, an increasing amount of opioid misuse and abuse have caused lots of consequences. Researchers and clinicians have attempted to discover the factors leading to opioid long-term use, dependence, and abuse, but only limited incidents are understood from previous works. Motivated by recent successes of deep learning and the abundant amount of electronic health records, we apply state-of-the-art deep and recurrent neural network models on a dataset of more than one hundred thousand opioid users. Our models are shown to achieve robust and superior results on classifying opioid users, and are able to extract key factors for different opioid user groups. This work is also a good demonstration on adopting novel deep learning methods for real-world health care problems.	['Department of Computer Science, University of Southern California, Los Angeles, CA.', 'Department of Computer Science, University of Southern California, Los Angeles, CA.', 'Department of Health Sciences Research, Mayo Clinic, Rochester, MN.', 'Department of Computer Science, University of Southern California, Los Angeles, CA.']		['Che Z', 'St Sauver J', 'Liu H', 'Liu Y']							['2018/06/02 06:00']	20190311	20180416	2017	2018/06/02 06:00		['Che, Zhengping', 'St Sauver, Jennifer', 'Liu, Hongfang', 'Liu, Yan']		['R01 AG034676/AG/NIA NIH HHS/United States', 'U01 TR002062/TR/NCATS NIH HHS/United States']			1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20190311	"['Adolescent', 'Adult', 'Aged', 'Analgesics, Opioid/*therapeutic use', 'Datasets as Topic', '*Deep Learning', 'Drug Prescriptions/statistics & numerical data', '*Electronic Health Records', 'Female', 'Humans', 'Male', 'Middle Aged', 'Neural Networks (Computer)', 'Opioid-Related Disorders/*classification', ""Practice Patterns, Physicians'/statistics & numerical data"", 'Young Adult']"	2019/03/12 06:00				NLM	525-534	['2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2019/03/12 06:00 [medline]']	United States	PMC5977635		29854117	epublish	['Journal Article']		['0 (Analgesics, Opioid)']	IM		AMIA Annu Symp Proc. 2018 Apr 16;2017:525-534. eCollection 2017.	MEDLINE	AMIA Annu Symp Proc	Deep Learning Solutions for Classifying Patients on Opioid Use.		2017	Deep Learning Solutions for Classifying Patients on Opioid Use.
	['International Center for Health Information Technology, Taipei Medical University, Taipei, Taiwan.', 'Graduate Institute of Biomedical Informatics, College of Medicine Science and Technology, Taipei Medical University, Taipei, Taiwan.', 'International Center for Health Information Technology, Taipei Medical University, Taipei, Taiwan; Graduate Institute of Biomedical Informatics, College of Medicine Science and Technology, Taipei Medical University, Taipei, Taiwan; Chair, Dept. of Dermatology, Wan Fang Hospital, Taipei, Taiwan. Electronic address: jack@tmu.edu.tw.']	['S0169-2607(18)30686-2 [pii]', '10.1016/j.cmpb.2018.05.014 [doi]']	['Yang HC', 'Islam MM', 'Jack Li YC']							['2018/06/02 06:00']	20181023		2018 Jul	2018/06/02 06:00		['Yang, Hsuan-Chia', 'Islam, Md Mohaimenul', 'Jack Li, Yu-Chuan']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30686-2 [pii] 10.1016/j.cmpb.2018.05.014 [doi]	20181023	['Algorithms', '*Delivery of Health Care', 'Diagnosis, Computer-Assisted', 'Humans', '*Machine Learning', 'Neural Networks (Computer)']	2018/10/24 06:00				NLM	A1	['2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2018/10/24 06:00 [medline]']	Ireland			29852972	ppublish	['Editorial', 'Introductory Journal Article']			IM		Comput Methods Programs Biomed. 2018 Jul;161:A1. doi: 10.1016/j.cmpb.2018.05.014.	MEDLINE	Comput Methods Programs Biomed	Potentiality of deep learning application in healthcare.		161	Potentiality of deep learning application in healthcare.
In recent years, advanced neurocomputing and machine learning techniques have been used for Electroencephalogram (EEG)-based diagnosis of various neurological disorders. In this paper, a novel computer model is presented for EEG-based screening of depression using a deep neural network machine learning approach, known as Convolutional Neural Network (CNN). The proposed technique does not require a semi-manually-selected set of features to be fed into a classifier for classification. It learns automatically and adaptively from the input EEG signals to differentiate EEGs obtained from depressive and normal subjects. The model was tested using EEGs obtained from 15 normal and 15 depressed patients. The algorithm attained accuracies of 93.5% and 96.0% using EEG signals from the left and right hemisphere, respectively. It was discovered in this research that the EEG signals from the right hemisphere are more distinctive in depression than those from the left hemisphere. This discovery is consistent with recent research and revelation that the depression is associated with a hyperactive right hemisphere. An exciting extension of this research would be diagnosis of different stages and severity of depression and development of a Depression Severity Index (DSI).	['Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore 599489, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore University of Social Sciences, Singapore; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia. Electronic address: aru@np.edu.sg.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore 599489, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore 599489, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore 599489, Singapore.', 'Departments of Neuroscience, Neurology, Biomedical Informatics, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, United States.', 'Department of Electrical Engineering, National Institute of Technology Calicut, India.']	['S0169-2607(18)30149-4 [pii]', '10.1016/j.cmpb.2018.04.012 [doi]']	['Acharya UR', 'Oh SL', 'Hagiwara Y', 'Tan JH', 'Adeli H', 'Subha DP']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/06/02 06:00']	20181022	20180418	2018 Jul	2018/06/02 06:00		['Acharya, U Rajendra', 'Oh, Shu Lih', 'Hagiwara, Yuki', 'Tan, Jen Hong', 'Adeli, Hojjat', 'Subha, D P']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30149-4 [pii] 10.1016/j.cmpb.2018.04.012 [doi]	20181202	['Algorithms', 'Computer Simulation', 'Depression/*diagnostic imaging', 'Diagnosis, Computer-Assisted/*methods', '*Electroencephalography', '*Electronic Data Processing', 'Humans', 'Machine Learning', '*Neural Networks (Computer)', 'Reproducibility of Results', '*Signal Processing, Computer-Assisted']	2018/10/23 06:00		['Convolutional neural network', 'Deep learning', 'Depression', 'EEG', 'Electroencephalogram']	['NOTNLM']	NLM	103-113	['2018/01/30 00:00 [received]', '2018/03/27 00:00 [revised]', '2018/04/17 00:00 [accepted]', '2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2018/10/23 06:00 [medline]']	Ireland			29852953	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Jul;161:103-113. doi: 10.1016/j.cmpb.2018.04.012. Epub 2018 Apr 18.	MEDLINE	Comput Methods Programs Biomed	Automated EEG-based screening of depression using deep convolutional neural network.		161	Automated EEG-based screening of depression using deep convolutional neural network.
BACKGROUND AND OBJECTIVE: We have cast the net into the ocean of knowledge to retrieve the latest scientific research on deep learning methods for physiological signals. We found 53 research papers on this topic, published from 01.01.2008 to 31.12.2017. METHODS: An initial bibliometric analysis shows that the reviewed papers focused on Electromyogram(EMG), Electroencephalogram(EEG), Electrocardiogram(ECG), and Electrooculogram(EOG). These four categories were used to structure the subsequent content review. RESULTS: During the content review, we understood that deep learning performs better for big and varied datasets than classic analysis and machine classification methods. Deep learning algorithms try to develop the model by using all the available input. CONCLUSIONS: This review paper depicts the application of various deep learning algorithms used till recently, but in future it will be used for more healthcare areas to improve the quality of diagnosis.	['Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom. Electronic address: o.faust@shu.ac.uk.', 'Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, SIM University, Singapore; Department of Biomedical Imaging, Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia.']	['S0169-2607(18)30122-6 [pii]', '10.1016/j.cmpb.2018.04.005 [doi]']	['Faust O', 'Hagiwara Y', 'Hong TJ', 'Lih OS', 'Acharya UR']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/06/02 06:00']	20181022	20180411	2018 Jul	2018/06/02 06:00		['Faust, Oliver', 'Hagiwara, Yuki', 'Hong, Tan Jen', 'Lih, Oh Shu', 'Acharya, U Rajendra']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(18)30122-6 [pii] 10.1016/j.cmpb.2018.04.005 [doi]	20181022	['Algorithms', 'Diagnosis, Computer-Assisted/*methods', 'Electrocardiography', 'Electroencephalography', 'Electromyography', 'Electrooculography', 'Humans', 'Linear Models', '*Machine Learning', 'Medical Informatics/*methods', 'Neurons', 'Quality of Health Care', 'Signal Processing, Computer-Assisted']	2018/10/23 06:00		['Deep learning', 'Electrocardiogram', 'Electroencephalogram', 'Electromyogram', 'Electrooculogram', 'Physiological signals']	['NOTNLM']	NLM	1-13	['2018/01/24 00:00 [received]', '2018/03/23 00:00 [revised]', '2018/04/02 00:00 [accepted]', '2018/06/02 06:00 [entrez]', '2018/06/02 06:00 [pubmed]', '2018/10/23 06:00 [medline]']	Ireland			29852952	ppublish	['Journal Article', 'Review']			IM		Comput Methods Programs Biomed. 2018 Jul;161:1-13. doi: 10.1016/j.cmpb.2018.04.005. Epub 2018 Apr 11.	MEDLINE	Comput Methods Programs Biomed	Deep learning for healthcare applications based on physiological signals: A review.		161	Deep learning for healthcare applications based on physiological signals: A review.
To help clinicians to efficiently diagnose the severity of a person's depression, the affective computing community and the artificial intelligence field have shown a growing interest in designing automated systems. The speech features have useful information for the diagnosis of depression. However, manually designing and domain knowledge are still important for the selection of the feature, which makes the process labor consuming and subjective. In recent years, deep-learned features based on neural networks have shown superior performance to hand-crafted features in various areas. In this paper, to overcome the difficulties mentioned above, we propose a combination of hand-crafted and deep-learned features which can effectively measure the severity of depression from speech. In the proposed method, Deep Convolutional Neural Networks (DCNN) are firstly built to learn deep-learned features from spectrograms and raw speech waveforms. Then we manually extract the state-of-the-art texture descriptors named median robust extended local binary patterns (MRELBP) from spectrograms. To capture the complementary information within the hand-crafted features and deep-learned features, we propose joint fine-tuning layers to combine the raw and spectrogram DCNN to boost the depression recognition performance. Moreover, to address the problems with small samples, a data augmentation method was proposed. Experiments conducted on AVEC2013 and AVEC2014 depression databases show that our approach is robust and effective for the diagnosis of depression when compared to state-of-the-art audio-based methods.	"[""NPU-VUB joint AVSP Research Lab, School of Computer Science, Northwestern Polytechnical University (NPU), Xi'an, China. Electronic address: langhe@mail.nwpu.edu.cn."", 'Moscow Institute of Arts, Weinan Normal University, Weinan, China.']"	['S1532-0464(18)30090-X [pii]', '10.1016/j.jbi.2018.05.007 [doi]']	['He L', 'Cao C']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/06/01 06:00']	20191030	20180529	2018 Jul	2018/06/01 06:00		['He, Lang', 'Cao, Cui']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30090-X [pii] 10.1016/j.jbi.2018.05.007 [doi]	20191030	['*Deep Learning', 'Depression/*diagnosis', '*Diagnosis, Computer-Assisted', 'Humans', '*Neural Networks (Computer)', '*Speech']	2019/10/31 06:00		['*Automatic diagnosis', '*Depression', '*Median Robust extended Local Binary Patterns(MRELBP)', '*Speech processing']	['NOTNLM']	NLM	103-111	['2017/11/06 00:00 [received]', '2018/04/25 00:00 [revised]', '2018/05/12 00:00 [accepted]', '2018/06/01 06:00 [pubmed]', '2019/10/31 06:00 [medline]', '2018/06/01 06:00 [entrez]']	United States			29852317	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Jul;83:103-111. doi: 10.1016/j.jbi.2018.05.007. Epub 2018 May 29.	MEDLINE	J Biomed Inform	Automated depression analysis using convolutional neural networks from speech.		83	Automated depression analysis using convolutional neural networks from speech.
Achieving the upper limits of face identification accuracy in forensic applications can minimize errors that have profound social and personal consequences. Although forensic examiners identify faces in these applications, systematic tests of their accuracy are rare. How can we achieve the most accurate face identification: using people and/or machines working alone or in collaboration? In a comprehensive comparison of face identification by humans and computers, we found that forensic facial examiners, facial reviewers, and superrecognizers were more accurate than fingerprint examiners and students on a challenging face identification test. Individual performance on the test varied widely. On the same test, four deep convolutional neural networks (DCNNs), developed between 2015 and 2017, identified faces within the range of human accuracy. Accuracy of the algorithms increased steadily over time, with the most recent DCNN scoring above the median of the forensic facial examiners. Using crowd-sourcing methods, we fused the judgments of multiple forensic facial examiners by averaging their rating-based identity judgments. Accuracy was substantially better for fused judgments than for individuals working alone. Fusion also served to stabilize performance, boosting the scores of lower-performing individuals and decreasing variability. Single forensic facial examiners fused with the best algorithm were more accurate than the combination of two examiners. Therefore, collaboration among humans and between humans and machines offers tangible benefits to face identification accuracy in important applications. These results offer an evidence-based roadmap for achieving the most accurate face identification possible.	['Information Access Division, National Institute of Standards and Technology, Gaithersburg, MD 20899; jonathon@nist.gov.', 'Information Access Division, National Institute of Standards and Technology, Gaithersburg, MD 20899.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.', 'Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20854.', 'Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20854.', 'University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20854.', 'University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20854.', 'Department of Electrical and Computer Engineering, University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20854.', 'School of Psychology, The University of New South Wales, Sydney, NSW 2052, Australia.', 'School of Behavioral and Brain Sciences, The University of Texas at Dallas, Richardson, TX 75080.']	['1721355115 [pii]', '10.1073/pnas.1721355115 [doi]']	"['Phillips PJ', 'Yates AN', 'Hu Y', 'Hahn CA', 'Noyes E', 'Jackson K', 'Cavazos JG', 'Jeckeln G', 'Ranjan R', 'Sankaranarayanan S', 'Chen JC', 'Castillo CD', 'Chellappa R', 'White D', ""O'Toole AJ""]"	['ORCID: 0000-0001-6284-5197']	['Copyright (c) 2018 the Author(s). Published by PNAS.']	['Nat Hum Behav. 2018 Jul;2(7):444. PMID: 31097803']		['Conflict of interest statement: The University of Maryland is filing a US patent', 'application that will cover portions of algorithms A2017a and A2017b. R.R.,', 'C.D.C., and R.C. are coinventors on this patent.']		['2018/05/31 06:00']	20180905	20180529	2018 Jun 12	2018/05/31 06:00		"['Phillips, P Jonathon', 'Yates, Amy N', 'Hu, Ying', 'Hahn, Carina A', 'Noyes, Eilidh', 'Jackson, Kelsey', 'Cavazos, Jacqueline G', 'Jeckeln, Geraldine', 'Ranjan, Rajeev', 'Sankaranarayanan, Swami', 'Chen, Jun-Cheng', 'Castillo, Carlos D', 'Chellappa, Rama', 'White, David', ""O'Toole, Alice J""]"			24		1091-6490 (Electronic) 0027-8424 (Linking)	7505876	Proceedings of the National Academy of Sciences of the United States of America	['eng']	10.1073/pnas.1721355115 [doi]	20181114	['*Algorithms', 'Biometric Identification/*methods', 'Face/*anatomy & histology', 'Forensic Sciences/*methods', 'Humans', 'Machine Learning', 'Reproducibility of Results']	2018/09/06 06:00		['*face identification', '*face recognition algorithm', '*forensic science', '*machine learning technology', '*wisdom-of-crowds']	['NOTNLM']	NLM	6171-6176	['2018/05/31 06:00 [pubmed]', '2018/09/06 06:00 [medline]', '2018/05/31 06:00 [entrez]']	United States	PMC6004481		29844174	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Proc Natl Acad Sci U S A. 2018 Jun 12;115(24):6171-6176. doi: 10.1073/pnas.1721355115. Epub 2018 May 29.	MEDLINE	Proc Natl Acad Sci U S A	Face recognition accuracy of forensic examiners, superrecognizers, and face recognition algorithms.		115	Face recognition accuracy of forensic examiners, superrecognizers, and face recognition algorithms.
The electroencephalogram (EEG) is the most prominent means to study epilepsy and capture changes in electrical brain activity that could declare an imminent seizure. In this work, Long Short-Term Memory (LSTM) networks are introduced in epileptic seizure prediction using EEG signals, expanding the use of deep learning algorithms with convolutional neural networks (CNN). A pre-analysis is initially performed to find the optimal architecture of the LSTM network by testing several modules and layers of memory units. Based on these results, a two-layer LSTM network is selected to evaluate seizure prediction performance using four different lengths of preictal windows, ranging from 15min to 2h. The LSTM model exploits a wide range of features extracted prior to classification, including time and frequency domain features, between EEG channels cross-correlation and graph theoretic features. The evaluation is performed using long-term EEG recordings from the open CHB-MIT Scalp EEG database, suggest that the proposed methodology is able to predict all 185 seizures, providing high rates of seizure prediction sensitivity and low false prediction rates (FPR) of 0.11-0.02 false alarms per hour, depending on the duration of the preictal window. The proposed LSTM-based methodology delivers a significant increase in seizure prediction performance compared to both traditional machine learning techniques and convolutional neural networks that have been previously evaluated in the literature.	['Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, GR15773, Athens, Greece; Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, GR45110, Ioannina, Greece.', 'Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, GR45110, Ioannina, Greece.', 'Digital Image and Signal Processing Laboratory, School of Electrical and Computer Engineering Technical University of Crete, Chania, Greece.', 'Dept. of Neurology, Medical School, University of Ioannina, GR45110, Ioannina, Greece.', 'Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, GR15773, Athens, Greece.', 'Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, GR45110, Ioannina, Greece; Dept. of Biomedical Research, Institute of Molecular Biology and Biotechnology, FORTH, GR45110, Ioannina, Greece. Electronic address: fotiadis@cc.uoi.gr.']	['S0010-4825(18)30132-X [pii]', '10.1016/j.compbiomed.2018.05.019 [doi]']	['Tsiouris KappaMu', 'Pezoulas VC', 'Zervakis M', 'Konitsiotis S', 'Koutsouris DD', 'Fotiadis DI']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/05/29 06:00']	20190710	20180517	2018 Aug 1	2018/05/29 06:00		['Tsiouris, Kappaostas Mu', 'Pezoulas, Vasileios C', 'Zervakis, Michalis', 'Konitsiotis, Spiros', 'Koutsouris, Dimitrios D', 'Fotiadis, Dimitrios I']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30132-X [pii] 10.1016/j.compbiomed.2018.05.019 [doi]	20190710	['Adolescent', 'Adult', '*Algorithms', 'Child', 'Child, Preschool', '*Deep Learning', '*Electroencephalography', 'Female', 'Humans', 'Male', 'Predictive Value of Tests', 'Seizures/*physiopathology']	2019/07/11 06:00		['*Deep learning', '*EEG', '*Epilepsy', '*LSTM model', '*Seizure prediction']	['NOTNLM']	NLM	24-37	['2018/03/07 00:00 [received]', '2018/05/07 00:00 [revised]', '2018/05/16 00:00 [accepted]', '2018/05/29 06:00 [pubmed]', '2019/07/11 06:00 [medline]', '2018/05/29 06:00 [entrez]']	United States			29807250	ppublish	['Journal Article']			IM		Comput Biol Med. 2018 Aug 1;99:24-37. doi: 10.1016/j.compbiomed.2018.05.019. Epub 2018 May 17.	MEDLINE	Comput Biol Med	A Long Short-Term Memory deep learning network for the prediction of epileptic seizures using EEG signals.		99	A Long Short-Term Memory deep learning network for the prediction of epileptic seizures using EEG signals.
The objective of this work is to develop a computer-aided diagnostic system for early diagnosis of prostate cancer. The presented system integrates both clinical biomarkers (prostate-specific antigen) and extracted features from diffusion-weighted magnetic resonance imaging collected at multiple b values. The presented system performs 3 major processing steps. First, prostate delineation using a hybrid approach that combines a level-set model with nonnegative matrix factorization. Second, estimation and normalization of diffusion parameters, which are the apparent diffusion coefficients of the delineated prostate volumes at different b values followed by refinement of those apparent diffusion coefficients using a generalized Gaussian Markov random field model. Then, construction of the cumulative distribution functions of the processed apparent diffusion coefficients at multiple b values. In parallel, a K-nearest neighbor classifier is employed to transform the prostate-specific antigen results into diagnostic probabilities. Finally, those prostate-specific antigen-based probabilities are integrated with the initial diagnostic probabilities obtained using stacked nonnegativity constraint sparse autoencoders that employ apparent diffusion coefficient-cumulative distribution functions for better diagnostic accuracy. Experiments conducted on 18 diffusion-weighted magnetic resonance imaging data sets achieved 94.4% diagnosis accuracy (sensitivity = 88.9% and specificity = 100%), which indicate the promising results of the presented computer-aided diagnostic system.	['1 Faculty of Computers and Information, Mansoura University, Mansoura, Egypt.', '2 Department of Bioengineering, University of Louisville, Louisville, KY, USA.', '3 Electrical and Computer Engineering Department, Abu Dhabi University, Abu Dhabi, United Arab Emirates.', '1 Faculty of Computers and Information, Mansoura University, Mansoura, Egypt.', '2 Department of Bioengineering, University of Louisville, Louisville, KY, USA.', '1 Faculty of Computers and Information, Mansoura University, Mansoura, Egypt.', '2 Department of Bioengineering, University of Louisville, Louisville, KY, USA.', '4 Radiology Department, Mansoura University, Mansoura, Egypt.', '5 Department of Computer Engineering and Computer Science, University of Louisville, Louisville, KY, USA.', '3 Electrical and Computer Engineering Department, Abu Dhabi University, Abu Dhabi, United Arab Emirates.', '2 Department of Bioengineering, University of Louisville, Louisville, KY, USA.']	['10.1177/1533034618775530 [doi]']	['Reda I', 'Khalil A', 'Elmogy M', 'Abou El-Fetouh A', 'Shalaby A', 'Abou El-Ghar M', 'Elmaghraby A', 'Ghazal M', 'El-Baz A']							['2018/05/29 06:00']	20190401		2018 Jan 1	2018/05/29 06:00		['Reda, Islam', 'Khalil, Ashraf', 'Elmogy, Mohammed', 'Abou El-Fetouh, Ahmed', 'Shalaby, Ahmed', 'Abou El-Ghar, Mohamed', 'Elmaghraby, Adel', 'Ghazal, Mohammed', 'El-Baz, Ayman']					1533-0338 (Electronic) 1533-0338 (Linking)	101140941	Technology in cancer research & treatment	['eng']	10.1177/1533034618775530 [doi]	20190401	['Algorithms', '*Deep Learning', 'Diffusion Magnetic Resonance Imaging', '*Early Detection of Cancer/methods', 'Humans', 'Image Interpretation, Computer-Assisted', 'Male', 'Prostatic Neoplasms/*diagnosis', 'ROC Curve', 'Reproducibility of Results', 'Sensitivity and Specificity']	2019/04/02 06:00		['*ADC', '*CAD', '*PSA', '*SNCSAE', '*prostate cancer']	['NOTNLM']	NLM	1533034618775530	['2018/05/29 06:00 [entrez]', '2018/05/29 06:00 [pubmed]', '2019/04/02 06:00 [medline]']	United States	PMC5972199		29804518	ppublish	['Journal Article']			IM		Technol Cancer Res Treat. 2018 Jan 1;17:1533034618775530. doi: 10.1177/1533034618775530.	MEDLINE	Technol Cancer Res Treat	Deep Learning Role in Early Diagnosis of Prostate Cancer.		17	Deep Learning Role in Early Diagnosis of Prostate Cancer.
Importance: Retinopathy of prematurity (ROP) is a leading cause of childhood blindness worldwide. The decision to treat is primarily based on the presence of plus disease, defined as dilation and tortuosity of retinal vessels. However, clinical diagnosis of plus disease is highly subjective and variable. Objective: To implement and validate an algorithm based on deep learning to automatically diagnose plus disease from retinal photographs. Design, Setting, and Participants: A deep convolutional neural network was trained using a data set of 5511 retinal photographs. Each image was previously assigned a reference standard diagnosis (RSD) based on consensus of image grading by 3 experts and clinical diagnosis by 1 expert (ie, normal, pre-plus disease, or plus disease). The algorithm was evaluated by 5-fold cross-validation and tested on an independent set of 100 images. Images were collected from 8 academic institutions participating in the Imaging and Informatics in ROP (i-ROP) cohort study. The deep learning algorithm was tested against 8 ROP experts, each of whom had more than 10 years of clinical experience and more than 5 peer-reviewed publications about ROP. Data were collected from July 2011 to December 2016. Data were analyzed from December 2016 to September 2017. Exposures: A deep learning algorithm trained on retinal photographs. Main Outcomes and Measures: Receiver operating characteristic analysis was performed to evaluate performance of the algorithm against the RSD. Quadratic-weighted kappa coefficients were calculated for ternary classification (ie, normal, pre-plus disease, and plus disease) to measure agreement with the RSD and 8 independent experts. Results: Of the 5511 included retinal photographs, 4535 (82.3%) were graded as normal, 805 (14.6%) as pre-plus disease, and 172 (3.1%) as plus disease, based on the RSD. Mean (SD) area under the receiver operating characteristic curve statistics were 0.94 (0.01) for the diagnosis of normal (vs pre-plus disease or plus disease) and 0.98 (0.01) for the diagnosis of plus disease (vs normal or pre-plus disease). For diagnosis of plus disease in an independent test set of 100 retinal images, the algorithm achieved a sensitivity of 93% with 94% specificity. For detection of pre-plus disease or worse, the sensitivity and specificity were 100% and 94%, respectively. On the same test set, the algorithm achieved a quadratic-weighted kappa coefficient of 0.92 compared with the RSD, outperforming 6 of 8 ROP experts. Conclusions and Relevance: This fully automated algorithm diagnosed plus disease in ROP with comparable or better accuracy than human experts. This has potential applications in disease detection, monitoring, and prognosis in infants at risk of ROP.	"['Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown.', 'Department of Ophthalmology, Casey Eye Institute, Oregon Health and Science University, Portland.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown.', 'Department of Ophthalmology, Casey Eye Institute, Oregon Health and Science University, Portland.', 'Department of Ophthalmology and Visual Sciences, Illinois Eye and Ear Infirmary, University of Illinois at Chicago.', 'Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts.', 'Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts.', 'Department of Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown.', ""Massachusetts General Hospital and Brigham and Women's Hospital Center for Clinical Data Science, Boston."", 'Department of Ophthalmology, Casey Eye Institute, Oregon Health and Science University, Portland.', 'Department of Medical Informatics and Clinical Epidemiology, Oregon Health and Science University, Portland.']"	['2680579 [pii]', '10.1001/jamaophthalmol.2018.1934 [doi]']	['Brown JM', 'Campbell JP', 'Beers A', 'Chang K', 'Ostmo S', 'Chan RVP', 'Dy J', 'Erdogmus D', 'Ioannidis S', 'Kalpathy-Cramer J', 'Chiang MF']				['Imaging and Informatics in Retinopathy of Prematurity (i-ROP) Research Consortium']			['2018/05/26 06:00']	20190927		2018 Jul 1	2018/05/26 06:00		['Brown, James M', 'Campbell, J Peter', 'Beers, Andrew', 'Chang, Ken', 'Ostmo, Susan', 'Chan, R V Paul', 'Dy, Jennifer', 'Erdogmus, Deniz', 'Ioannidis, Stratis', 'Kalpathy-Cramer, Jayashree', 'Chiang, Michael F']		['T32 EB001680/EB/NIBIB NIH HHS/United States', 'R01 EY019474/EY/NEI NIH HHS/United States', 'P41 EB015896/EB/NIBIB NIH HHS/United States', 'T90 DA022759/DA/NIDA NIH HHS/United States', 'R90 DA023427/DA/NIDA NIH HHS/United States']	7		2168-6173 (Electronic) 2168-6165 (Linking)	101589539	JAMA ophthalmology	['eng']	10.1001/jamaophthalmol.2018.1934 [doi]	20190927	['Algorithms', 'Deep Learning', 'Female', 'Gestational Age', 'Humans', '*Image Interpretation, Computer-Assisted', 'Infant', 'Infant, Newborn', 'Infant, Premature', 'Male', '*Neural Networks (Computer)', '*Photography', 'ROC Curve', 'Reproducibility of Results', 'Retinal Vessels/*diagnostic imaging/pathology', 'Retinopathy of Prematurity/*diagnosis', 'Sensitivity and Specificity']	2019/09/29 06:00				NLM	803-810	['2018/05/26 06:00 [pubmed]', '2019/09/29 06:00 [medline]', '2018/05/26 06:00 [entrez]']	United States	PMC6136045		29801159	ppublish	"['Comparative Study', 'Journal Article', 'Multicenter Study', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S."", 'Validation Studies']"			AIM IM		JAMA Ophthalmol. 2018 Jul 1;136(7):803-810. doi: 10.1001/jamaophthalmol.2018.1934.	MEDLINE	JAMA Ophthalmol	Automated Diagnosis of Plus Disease in Retinopathy of Prematurity Using Deep Convolutional Neural Networks.		136	Automated Diagnosis of Plus Disease in Retinopathy of Prematurity Using Deep Convolutional Neural Networks.
Residue solvent accessibility is closely related to the spatial arrangement and packing of residues. Predicting the solvent accessibility of a protein is an important step to understand its structure and function. In this work, we present a deep learning method to predict residue solvent accessibility, which is based on a stacked deep bidirectional recurrent neural network applied to sequence profiles. To capture more long-range sequence information, a merging operator was proposed when bidirectional information from hidden nodes was merged for outputs. Three types of merging operators were used in our improved model, with a long short-term memory network performing as a hidden computing node. The trained database was constructed from 7361 proteins extracted from the PISCES server using a cut-off of 25% sequence identity. Sequence-derived features including position-specific scoring matrix, physical properties, physicochemical characteristics, conservation score and protein coding were used to represent a residue. Using this method, predictive values of continuous relative solvent-accessible area were obtained, and then, these values were transformed into binary states with predefined thresholds. Our experimental results showed that our deep learning method improved prediction quality relative to current methods, with mean absolute error and Pearson's correlation coefficient values of 8.8% and 74.8%, respectively, on the CB502 dataset and 8.2% and 78%, respectively, on the Manesh215 dataset.	['School of Computer Science and Technology, Soochow University, Suzhou 215006, China. 20154027005@stu.suda.edu.cn.', 'School of Computer and Information, Anqing Normal University, Anqing 246011, China. 20154027005@stu.suda.edu.cn.', 'School of Computer Science and Technology, Soochow University, Suzhou 215006, China. linqinglee@gmail.com.', 'School of Computer Science and Technology, Soochow University, Suzhou 215006, China. qiang@suda.edu.cn.']	['biom8020033 [pii]', '10.3390/biom8020033 [doi]']	['Zhang B', 'Li L', 'Lu Q']	['ORCID: 0000-0001-6173-1681']						['2018/05/26 06:00']	20190529	20180525	2018 May 25	2018/05/26 06:00		['Zhang, Buzhong', 'Li, Linqing', 'Lu, Qiang']			2		2218-273X (Electronic) 2218-273X (Linking)	101596414	Biomolecules	['eng']	E33 [pii] 10.3390/biom8020033 [doi]	20190529	['Animals', '*Deep Learning', 'Humans', '*Hydrophobic and Hydrophilic Interactions', 'Protein Conformation', 'Sequence Analysis, Protein/*methods', 'Solubility']	2019/05/30 06:00		['*bidirectional recurrent network', '*merging operator', '*sequence profile', '*solvent-accessibility prediction']	['NOTNLM']	NLM		['2018/04/21 00:00 [received]', '2018/05/18 00:00 [revised]', '2018/05/22 00:00 [accepted]', '2018/05/26 06:00 [entrez]', '2018/05/26 06:00 [pubmed]', '2019/05/30 06:00 [medline]']	Switzerland	PMC6023031		29799510	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Biomolecules. 2018 May 25;8(2). pii: biom8020033. doi: 10.3390/biom8020033.	MEDLINE	Biomolecules	Protein Solvent-Accessibility Prediction by a Stacked Deep Bidirectional Recurrent Neural Network.		8	Protein Solvent-Accessibility Prediction by a Stacked Deep Bidirectional Recurrent Neural Network.
OBJECTIVE: In this paper, we aim to investigate the effect of computer-aided triage system, which is implemented for the health checkup of lung lesions involving tens of thousands of chest X-rays (CXRs) that are required for diagnosis. Therefore, high accuracy of diagnosis by an automated system can reduce the radiologist's workload on scrutinizing the medical images. METHOD: We present a deep learning model in order to efficiently detect abnormal levels or identify normal levels during mass chest screening so as to obtain the probability confidence of the CXRs. Moreover, a convolutional sparse denoising autoencoder is designed to compute the reconstruction error. We employ four publicly available radiology datasets pertaining to CXRs, analyze their reports, and utilize their images for mining the correct disease level of the CXRs that are to be submitted to a computer aided triaging system. Based on our approach, we vote for the final decision from multi-classifiers to determine which three levels of the images (i.e. normal, abnormal, and uncertain cases) that the CXRs fall into. RESULTS: We only deal with the grade diagnosis for physical examination and propose multiple new metric indices. Combining predictors for classification by using the area under a receiver operating characteristic curve, we observe that the final decision is related to the threshold from reconstruction error and the probability value. Our method achieves promising results in terms of precision of 98.7 and 94.3% based on the normal and abnormal cases, respectively. CONCLUSION: The results achieved by the proposed framework show superiority in classifying the disease level with high accuracy. This can potentially save the radiologists time and effort, so as to allow them to focus on higher-level risk CXRs.	['Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China.', 'University of Chinese Academy of Sciences, 52 Sanlihe Road, Beijing, 100864, China.', 'Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, 518060, China.', 'Department of Computer Science, Misr Higher Institute for Commerce and Computers, Mansoura, 35516, Egypt.', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China.', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China.', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China. qm.hu@siat.ac.cn.', 'Key Laboratory of Human-Machine Intelligence Synergy Systems, 1068 Xueyuan Boulevard, Shenzhen, 518055, China. qm.hu@siat.ac.cn.']	['10.1186/s12938-018-0496-2 [doi]', '10.1186/s12938-018-0496-2 [pii]']	['Wang C', 'Elazab A', 'Jia F', 'Wu J', 'Hu Q']							['2018/05/25 06:00']	20181004	20180523	2018 May 23	2018/05/25 06:00		['Wang, Changmiao', 'Elazab, Ahmed', 'Jia, Fucang', 'Wu, Jianhuang', 'Hu, Qingmao']		['U1713215/Joint Key project of NSFC-Shenzhen Robot Foundation Research Center', 'JCYJ20160331191401141/Shenzhen Key Basic Research Grant', '61671440/National Natural Science Foundation of China']	1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-018-0496-2 [doi]	20181114	['Automation', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Lung/diagnostic imaging', '*Machine Learning', 'ROC Curve', '*Radiography, Thoracic', '*Signal-To-Noise Ratio', 'Triage/*methods']	2018/10/05 06:00		['Autoencoder', 'Chest screening', 'Computer aided diagnosis', 'Deep learning', 'Receiver operating characteristic']	['NOTNLM']	NLM	63	['2018/04/04 00:00 [received]', '2018/05/09 00:00 [accepted]', '2018/05/25 06:00 [entrez]', '2018/05/25 06:00 [pubmed]', '2018/10/05 06:00 [medline]']	England	PMC5966927		29792208	epublish	['Journal Article']			IM		Biomed Eng Online. 2018 May 23;17(1):63. doi: 10.1186/s12938-018-0496-2.	MEDLINE	Biomed Eng Online	Automated chest screening based on a hybrid model of transfer learning and convolutional sparse denoising autoencoder.		17	Automated chest screening based on a hybrid model of transfer learning and convolutional sparse denoising autoencoder.
ComplexContact (http://raptorx2.uchicago.edu/ComplexContact/) is a web server for sequence-based interfacial residue-residue contact prediction of a putative protein complex. Interfacial residue-residue contacts are critical for understanding how proteins form complex and interact at residue level. When receiving a pair of protein sequences, ComplexContact first searches for their sequence homologs and builds two paired multiple sequence alignments (MSA), then it applies co-evolution analysis and a CASP-winning deep learning (DL) method to predict interfacial contacts from paired MSAs and visualizes the prediction as an image. The DL method was originally developed for intra-protein contact prediction and performed the best in CASP12. Our large-scale experimental test further shows that ComplexContact greatly outperforms pure co-evolution methods for inter-protein contact prediction, regardless of the species.	['School of Computer Science and Technology, Hangzhou Dianzi University, China.', 'King Abdullah University of Science and Technology (KAUST), Saudi Arabia.', 'Toyota Technological Institute at Chicago, USA.', 'Toyota Technological Institute at Chicago, USA.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, China.', 'School of Computer Science and Technology, Hangzhou Dianzi University, China.', 'School of Computer Science and Technology, Hangzhou Dianzi University, China.', 'School of Computer Science and Technology, Hangzhou Dianzi University, China.', 'Toyota Technological Institute at Chicago, USA.']	['5001161 [pii]', '10.1093/nar/gky420 [doi]']	['Zeng H', 'Wang S', 'Zhou T', 'Zhao F', 'Li X', 'Wu Q', 'Xu J']							['2018/05/24 06:00']	20190806		2018 Jul 2	2018/05/24 06:00		['Zeng, Hong', 'Wang, Sheng', 'Zhou, Tianming', 'Zhao, Feifeng', 'Li, Xiufeng', 'Wu, Qing', 'Xu, Jinbo']		['R01 GM089753/GM/NIGMS NIH HHS/United States']	W1		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gky420 [doi]	20190806	['Amino Acid Sequence', 'Computational Biology/*methods', 'Databases, Factual', 'Deep Learning/*statistics & numerical data', 'Escherichia coli/chemistry/genetics', 'Humans', 'Internet', 'Protein Interaction Domains and Motifs', 'Protein Structure, Secondary', 'Proteins/*chemistry', 'Sequence Alignment', 'Sequence Homology, Amino Acid', '*Software', '*Structural Homology, Protein']	2019/08/07 06:00				NLM	W432-W437	['2018/02/13 00:00 [received]', '2018/05/20 00:00 [accepted]', '2018/05/24 06:00 [pubmed]', '2019/08/07 06:00 [medline]', '2018/05/24 06:00 [entrez]']	England	PMC6030867		29790960	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Proteins)']			Nucleic Acids Res. 2018 Jul 2;46(W1):W432-W437. doi: 10.1093/nar/gky420.	MEDLINE	Nucleic Acids Res	ComplexContact: a web server for inter-protein contact prediction using deep learning.		46	ComplexContact: a web server for inter-protein contact prediction using deep learning.
This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phase-encoding direction to capture high-resolution image information, while permitting the image-folding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, a small number of low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of the Fourier transforms of the subsampled and fully sampled k-space data. Our experiments show the remarkable performance of the proposed method; only 29[Formula: see text] of the k-space data can generate images of high quality as effectively as standard MRI reconstruction with the fully sampled data.	['Department of Computational Science and Engineering, Yonsei University, Seoul, Republic of Korea.']	['10.1088/1361-6560/aac71a [doi]']	['Hyun CM', 'Kim HP', 'Lee SM', 'Lee S', 'Seo JK']							['2018/05/23 06:00']	20190523	20180625	2018 Jun 25	2018/05/23 06:00		['Hyun, Chang Min', 'Kim, Hwa Pyung', 'Lee, Sung Min', 'Lee, Sungchul', 'Seo, Jin Keun']			13		1361-6560 (Electronic) 0031-9155 (Linking)	0401220	Physics in medicine and biology	['eng']	10.1088/1361-6560/aac71a [doi]	20190523	['Algorithms', '*Deep Learning', 'Fourier Analysis', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Magnetic Resonance Imaging', 'Uncertainty']	2019/05/24 06:00				NLM	135007	['2018/05/23 06:00 [pubmed]', '2019/05/24 06:00 [medline]', '2018/05/23 06:00 [entrez]']	England			29787383	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Phys Med Biol. 2018 Jun 25;63(13):135007. doi: 10.1088/1361-6560/aac71a.	MEDLINE	Phys Med Biol	Deep learning for undersampled MRI reconstruction.		63	Deep learning for undersampled MRI reconstruction.
Early detection of high fall risk is an essential component of fall prevention in older adults. Wearable sensors can provide valuable insight into daily-life activities; biomechanical features extracted from such inertial data have been shown to be of added value for the assessment of fall risk. Body-worn sensors such as accelerometers can provide valuable insight into fall risk. Currently, biomechanical features derived from accelerometer data are used for the assessment of fall risk. Here, we studied whether deep learning methods from machine learning are suited to automatically derive features from raw accelerometer data that assess fall risk. We used an existing dataset of 296 older adults. We compared the performance of three deep learning model architectures (convolutional neural network (CNN), long short-term memory (LSTM) and a combination of these two (ConvLSTM)) to each other and to a baseline model with biomechanical features on the same dataset. The results show that the deep learning models in a single-task learning mode are strong in recognition of identity of the subject, but that these models only slightly outperform the baseline method on fall risk assessment. When using multi-task learning, with gender and age as auxiliary tasks, deep learning models perform better. We also found that preprocessing of the data resulted in the best performance (AUC = 0.75). We conclude that deep learning models, and in particular multi-task learning, effectively assess fall risk on the basis of wearable sensor data.	['Department of Computer Science, Amsterdam University of Applied Sciences, 1091 GM Amsterdam, The Netherlands. a.nait.aicha@hva.nl.', 'Human Media Interaction, University of Twente, 7522 NH Enschede, The Netherlands. englebienne@gmail.com.', 'Neuroscience Research Australia, University of New South Wales, Sydney 2031, Australia. k.vanschooten@neura.edu.au.', 'Department of Human Movement Sciences, Vrije Universiteit Amsterdam, 1081 HV Amsterdam, The Netherlands. m.pijnappels@vu.nl.', 'Department of Computer Science, Amsterdam University of Applied Sciences, 1091 GM Amsterdam, The Netherlands. b.j.a.krose@hva.nl.', 'Informatics Institute, University of Amsterdam, 1098 XH Amsterdam, The Netherlands. b.j.a.krose@hva.nl.']	['s18051654 [pii]', '10.3390/s18051654 [doi]']	['Nait Aicha A', 'Englebienne G', 'van Schooten KS', 'Pijnappels M', 'Krose B']	['ORCID: 0000-0001-8966-9736', 'ORCID: 0000-0003-0902-8440', 'ORCID: 0000-0003-1237-0618']						['2018/05/23 06:00']	20180926	20180522	2018 May 22	2018/05/23 06:00		['Nait Aicha, Ahmed', 'Englebienne, Gwenn', 'van Schooten, Kimberley S', 'Pijnappels, Mirjam', 'Krose, Ben']			5		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1654 [pii] 10.3390/s18051654 [doi]	20181114	['Accelerometry/*methods', 'Accidental Falls/*prevention & control', '*Activities of Daily Living', 'Aged', 'Aged, 80 and over', 'Female', 'Humans', 'Machine Learning', 'Male', 'Monitoring, Ambulatory/*methods', 'Neural Networks (Computer)']	2018/09/27 06:00		['accelerometry', 'accidental falls', 'convolutional neural network', 'long short-term memory', 'machine learning', 'neural networks', 'older adults']	['NOTNLM']	NLM		['2018/03/31 00:00 [received]', '2018/05/13 00:00 [revised]', '2018/05/18 00:00 [accepted]', '2018/05/23 06:00 [entrez]', '2018/05/23 06:00 [pubmed]', '2018/09/27 06:00 [medline]']	Switzerland	PMC5981199		29786659	epublish	['Journal Article', 'Review']			IM		Sensors (Basel). 2018 May 22;18(5). pii: s18051654. doi: 10.3390/s18051654.	MEDLINE	Sensors (Basel)	Deep Learning to Predict Falls in Older Adults Based on Daily-Life Trunk Accelerometry.		18	Deep Learning to Predict Falls in Older Adults Based on Daily-Life Trunk Accelerometry.
BACKGROUND: There is growing interest in utilizing artificial intelligence, and particularly deep learning, for computer vision in histopathology. While accumulating studies highlight expert-level performance of convolutional neural networks (CNNs) on focused classification tasks, most studies rely on probability distribution scores with empirically defined cutoff values based on post-hoc analysis. More generalizable tools that allow humans to visualize histology-based deep learning inferences and decision making are scarce. RESULTS: Here, we leverage t-distributed Stochastic Neighbor Embedding (t-SNE) to reduce dimensionality and depict how CNNs organize histomorphologic information. Unique to our workflow, we develop a quantitative and transparent approach to visualizing classification decisions prior to softmax compression. By discretizing the relationships between classes on the t-SNE plot, we show we can super-impose randomly sampled regions of test images and use their distribution to render statistically-driven classifications. Therefore, in addition to providing intuitive outputs for human review, this visual approach can carry out automated and objective multi-class classifications similar to more traditional and less-transparent categorical probability distribution scores. Importantly, this novel classification approach is driven by a priori statistically defined cutoffs. It therefore serves as a generalizable classification and anomaly detection tool less reliant on post-hoc tuning. CONCLUSION: Routine incorporation of this convenient approach for quantitative visualization and error reduction in histopathology aims to accelerate early adoption of CNNs into generalized real-world applications where unanticipated and previously untrained classes are often encountered.	['Department of Computer Science, University of Toronto, 40 St. George Street, Toronto, ON, M5S 2E4, Canada.', 'Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, M5S 1A8, Canada.', 'Department of Computer Science, University of Toronto, 40 St. George Street, Toronto, ON, M5S 2E4, Canada.', 'The Edward S. Rogers Sr. Department of Electrical & Computer Engineering, University of Toronto, Toronto, ON, Canada.', 'Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, M5S 1A8, Canada.', 'Laboratory Medicine Program, Department of Pathology, University Health Network, 200 Elizabeth Street, Toronto, ON, M5G 2C4, Canada.', 'Laboratory Medicine Program, Department of Pathology, University Health Network, 200 Elizabeth Street, Toronto, ON, M5G 2C4, Canada.', 'Princess Margaret Cancer Centre, MacFeeters Hamilton Centre for Neuro-Oncology Research, 101 College Street, Toronto, ON, M5G 1L7, Canada.', 'Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, M5S 1A8, Canada. p.diamandis@mail.utoronto.ca.', 'Laboratory Medicine Program, Department of Pathology, University Health Network, 200 Elizabeth Street, Toronto, ON, M5G 2C4, Canada. p.diamandis@mail.utoronto.ca.', 'Princess Margaret Cancer Centre, MacFeeters Hamilton Centre for Neuro-Oncology Research, 101 College Street, Toronto, ON, M5G 1L7, Canada. p.diamandis@mail.utoronto.ca.']	['10.1186/s12859-018-2184-4 [doi]', '10.1186/s12859-018-2184-4 [pii]']	['Faust K', 'Xie Q', 'Han D', 'Goyle K', 'Volynskaya Z', 'Djuric U', 'Diamandis P']	['ORCID: 0000-0001-5291-9068']						['2018/05/18 06:00']	20190617	20180516	2018 May 16	2018/05/18 06:00		['Faust, Kevin', 'Xie, Quin', 'Han, Dominick', 'Goyle, Kartikay', 'Volynskaya, Zoya', 'Djuric, Ugljesa', 'Diamandis, Phedias']			1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2184-4 [doi]	20190617	['Artificial Intelligence/*standards', 'Deep Learning/*classification', 'Humans', 'Machine Learning/*standards', '*Neural Networks (Computer)']	2019/06/18 06:00		['*Artificial intelligence', '*Cancer', '*Convolutional neural networks', '*Deep learning', '*Diagnostics', '*Digital pathology', '*Glioblastoma', '*Machine learning', '*Neuropathology', '*t-SNE']	['NOTNLM']	NLM	173	['2017/12/19 00:00 [received]', '2018/05/02 00:00 [accepted]', '2018/05/18 06:00 [entrez]', '2018/05/18 06:00 [pubmed]', '2019/06/18 06:00 [medline]']	England	PMC5956828		29769044	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Bioinformatics. 2018 May 16;19(1):173. doi: 10.1186/s12859-018-2184-4.	MEDLINE	BMC Bioinformatics	Visualizing histopathologic deep learning classification and anomaly detection using nonlinear feature space dimensionality reduction.		19	Visualizing histopathologic deep learning classification and anomaly detection using nonlinear feature space dimensionality reduction.
BACKGROUND: Precise identification of three-dimensional genome organization, especially enhancer-promoter interactions (EPIs), is important to deciphering gene regulation, cell differentiation and disease mechanisms. Currently, it is a challenging task to distinguish true interactions from other nearby non-interacting ones since the power of traditional experimental methods is limited due to low resolution or low throughput. RESULTS: We propose a novel computational framework EP2vec to assay three-dimensional genomic interactions. We first extract sequence embedding features, defined as fixed-length vector representations learned from variable-length sequences using an unsupervised deep learning method in natural language processing. Then, we train a classifier to predict EPIs using the learned representations in supervised way. Experimental results demonstrate that EP2vec obtains F1 scores ranging from 0.841~ 0.933 on different datasets, which outperforms existing methods. We prove the robustness of sequence embedding features by carrying out sensitivity analysis. Besides, we identify motifs that represent cell line-specific information through analysis of the learned sequence embedding features by adopting attention mechanism. Last, we show that even superior performance with F1 scores 0.889~ 0.940 can be achieved by combining sequence embedding features and experimental features. CONCLUSIONS: EP2vec sheds light on feature extraction for DNA sequences of arbitrary lengths and provides a powerful approach for EPIs identification.	['MOE Key Laboratory of Bioinformatics; Bioinformatics Division and Center for Synthetic & Systems Biology, Beijing, 100084, China.', 'Department of Automation, Tsinghua University, Beijing, 100084, China.', 'MOE Key Laboratory of Bioinformatics; Bioinformatics Division and Center for Synthetic & Systems Biology, Beijing, 100084, China.', 'Department of Computer Science, Tsinghua University, Beijing, 100084, China.', 'MOE Key Laboratory of Bioinformatics; Bioinformatics Division and Center for Synthetic & Systems Biology, Beijing, 100084, China. ruijiang@tsinghua.edu.cn.', 'Department of Automation, Tsinghua University, Beijing, 100084, China. ruijiang@tsinghua.edu.cn.']	['10.1186/s12864-018-4459-6 [doi]', '10.1186/s12864-018-4459-6 [pii]']	['Zeng W', 'Wu M', 'Jiang R']							['2018/05/17 06:00']	20181217	20180509	2018 May 9	2018/05/17 06:00		['Zeng, Wanwen', 'Wu, Mengmeng', 'Jiang, Rui']			Suppl 2		1471-2164 (Electronic) 1471-2164 (Linking)	100965258	BMC genomics	['eng']	10.1186/s12864-018-4459-6 [doi]	20181217	['Cell Line, Tumor', 'Computational Biology/*methods', 'Databases, Genetic', 'HeLa Cells', 'Human Umbilical Vein Endothelial Cells', 'Humans', 'K562 Cells', 'Natural Language Processing', '*Promoter Regions, Genetic', '*Regulatory Sequences, Nucleic Acid', 'Sequence Analysis, DNA', 'Unsupervised Machine Learning']	2018/12/18 06:00		['Enhancer-promoter interactions', 'Natural language processing', 'Three-dimensinal interactions', 'Unsupervised learning']	['NOTNLM']	NLM	84	['2018/05/17 06:00 [entrez]', '2018/05/17 06:00 [pubmed]', '2018/12/18 06:00 [medline]']	England	PMC5954283		29764360	epublish	['Journal Article']			IM		BMC Genomics. 2018 May 9;19(Suppl 2):84. doi: 10.1186/s12864-018-4459-6.	MEDLINE	BMC Genomics	Prediction of enhancer-promoter interactions via natural language processing.		19	Prediction of enhancer-promoter interactions via natural language processing.
In silico modeling is a crucial milestone in modern drug design and development. Although computer-aided approaches in this field are well-studied, the application of deep learning methods in this research area is at the beginning. In this work, we present an original deep neural network (DNN) architecture named RANC (Reinforced Adversarial Neural Computer) for the de novo design of novel small-molecule organic structures based on the generative adversarial network (GAN) paradigm and reinforcement learning (RL). As a generator RANC uses a differentiable neural computer (DNC), a category of neural networks, with increased generation capabilities due to the addition of an explicit memory bank, which can mitigate common problems found in adversarial settings. The comparative results have shown that RANC trained on the SMILES string representation of the molecules outperforms its first DNN-based counterpart ORGANIC by several metrics relevant to drug discovery: the number of unique structures, passing medicinal chemistry filters (MCFs), Muegge criteria, and high QED scores. RANC is able to generate structures that match the distributions of the key chemical features/descriptors (e.g., MW, logP, TPSA) and lengths of the SMILES strings in the training data set. Therefore, RANC can be reasonably regarded as a promising starting point to develop novel molecules with activity against different biological targets or pathways. In addition, this approach allows scientists to save time and covers a broad chemical space populated with novel and diverse compounds.	['Pharma.AI Department , Insilico Medicine, Inc , Baltimore , Maryland 21218 , United States.', 'Computer Technologies Lab , ITMO University , St. Petersburg 197101 , Russia.', 'Computer Technologies Lab , ITMO University , St. Petersburg 197101 , Russia.', 'Pharma.AI Department , Insilico Medicine, Inc , Baltimore , Maryland 21218 , United States.', 'Moscow Institute of Physics and Technology (State University) , 9 Institutskiy lane , Dolgoprudny City, Moscow Region , 141700 , Russian Federation.', 'Institute of Biochemistry and Genetics Russian Academy of Science (IBG RAS) , Ufa Scientific Centre, Oktyabrya Prospekt 71 , 450054 , Ufa , Russian Federation.', 'Pharma.AI Department , Insilico Medicine, Inc , Baltimore , Maryland 21218 , United States.', 'Moscow Institute of Physics and Technology (State University) , 9 Institutskiy lane , Dolgoprudny City, Moscow Region , 141700 , Russian Federation.', 'Chemistry and Chemical Biology Department , Harvard University , 12 Oxford Street , Cambridge , Massachusetts 02143 , United States.', 'Chemistry and Chemical Biology Department , Harvard University , 12 Oxford Street , Cambridge , Massachusetts 02143 , United States.', 'Biologically-Inspired Solar Energy Program , Canadian Institute for Advanced Research (CIFAR) , Toronto , Ontario M5S 1M1 , Canada.', 'Pharma.AI Department , Insilico Medicine, Inc , Baltimore , Maryland 21218 , United States.', 'The Buck Institute for Research on Aging , 8001 Redwood Boulevard , Novato , California 94945 , United States.']	['10.1021/acs.jcim.7b00690 [doi]']	['Putin E', 'Asadulaev A', 'Ivanenkov Y', 'Aladinskiy V', 'Sanchez-Lengeling B', 'Aspuru-Guzik A', 'Zhavoronkov A']	['ORCID: 0000-0002-3012-9708', 'ORCID: 0000-0002-8277-4434', 'ORCID: 0000-0001-7067-8966']						['2018/05/16 06:00']	20190624	20180612	2018 Jun 25	2018/05/16 06:00		['Putin, Evgeny', 'Asadulaev, Arip', 'Ivanenkov, Yan', 'Aladinskiy, Vladimir', 'Sanchez-Lengeling, Benjamin', 'Aspuru-Guzik, Alan', 'Zhavoronkov, Alex']			6		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.7b00690 [doi]	20190624	['Algorithms', '*Computer-Aided Design/instrumentation', '*Deep Learning', '*Drug Design', '*Drug Discovery/instrumentation/methods', 'Equipment Design', 'Machine Learning', 'Neural Networks (Computer)']	2019/06/25 06:00				NLM	1194-1204	['2018/05/16 06:00 [pubmed]', '2019/06/25 06:00 [medline]', '2018/05/16 06:00 [entrez]']	United States			29762023	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Chem Inf Model. 2018 Jun 25;58(6):1194-1204. doi: 10.1021/acs.jcim.7b00690. Epub 2018 Jun 12.	MEDLINE	J Chem Inf Model	Reinforced Adversarial Neural Computer for de Novo Molecular Design.		58	Reinforced Adversarial Neural Computer for de Novo Molecular Design.
OBJECTIVES: To investigate whether liver fibrosis can be staged by deep learning techniques based on CT images. METHODS: This clinical retrospective study, approved by our institutional review board, included 496 CT examinations of 286 patients who underwent dynamic contrast-enhanced CT for evaluations of the liver and for whom histopathological information regarding liver fibrosis stage was available. The 396 portal phase images with age and sex data of patients (F0/F1/F2/F3/F4 = 113/36/56/66/125) were used for training a deep convolutional neural network (DCNN); the data for the other 100 (F0/F1/F2/F3/F4 = 29/9/14/16/32) were utilised for testing the trained network, with the histopathological fibrosis stage used as reference. To improve robustness, additional images for training data were generated by rotating or parallel shifting the images, or adding Gaussian noise. Supervised training was used to minimise the difference between the liver fibrosis stage and the fibrosis score obtained from deep learning based on CT images (FDLCT score) output by the model. Testing data were input into the trained DCNNs to evaluate their performance. RESULTS: The FDLCT scores showed a significant correlation with liver fibrosis stage (Spearman's correlation coefficient = 0.48, p < 0.001). The areas under the receiver operating characteristic curves (with 95% confidence intervals) for diagnosing significant fibrosis (>/= F2), advanced fibrosis (>/= F3) and cirrhosis (F4) by using FDLCT scores were 0.74 (0.64-0.85), 0.76 (0.66-0.85) and 0.73 (0.62-0.84), respectively. CONCLUSIONS: Liver fibrosis can be staged by using a deep learning model based on CT images, with moderate performance. KEY POINTS: * Liver fibrosis can be staged by a deep learning model based on magnified CT images including the liver surface, with moderate performance. * Scores from a trained deep learning model showed moderate correlation with histopathological liver fibrosis staging. * Further improvement are necessary before utilisation in clinical settings.	['Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan.', 'Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan.', 'Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan.', 'Department of Radiology, Graduate School of Medicine, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan.', 'Department of Radiology, Graduate School of Medical Sciences, International University of Health and Welfare, 537-3 Iguchi, Nasushiobara, Tochigi, 329-2763, Japan. kiryu-tky@umin.ac.jp.']	['10.1007/s00330-018-5499-7 [doi]', '10.1007/s00330-018-5499-7 [pii]']	['Yasaka K', 'Akai H', 'Kunimatsu A', 'Abe O', 'Kiryu S']	['ORCID: http://orcid.org/0000-0003-1440-9483']						['2018/05/16 06:00']	20190508	20180514	2018 Nov	2018/05/16 06:00		['Yasaka, Koichiro', 'Akai, Hiroyuki', 'Kunimatsu, Akira', 'Abe, Osamu', 'Kiryu, Shigeru']			11		1432-1084 (Electronic) 0938-7994 (Linking)	9114774	European radiology	['eng']	10.1007/s00330-018-5499-7 [doi]	20190508	['Aged', '*Deep Learning', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Liver Cirrhosis/*diagnosis', 'Male', 'Middle Aged', 'Pilot Projects', 'ROC Curve', 'Retrospective Studies', 'Tomography, X-Ray Computed/*methods']	2019/05/09 06:00		['Artificial intelligence', 'Liver cirrhosis', 'Multidetector computed tomography', 'ROC curve']	['NOTNLM']	NLM	4578-4585	['2018/01/30 00:00 [received]', '2018/04/18 00:00 [accepted]', '2018/04/10 00:00 [revised]', '2018/05/16 06:00 [pubmed]', '2019/05/09 06:00 [medline]', '2018/05/16 06:00 [entrez]']	Germany			29761358	ppublish	['Journal Article']			IM		Eur Radiol. 2018 Nov;28(11):4578-4585. doi: 10.1007/s00330-018-5499-7. Epub 2018 May 14.	MEDLINE	Eur Radiol	Deep learning for staging liver fibrosis on CT: a pilot study.		28	Deep learning for staging liver fibrosis on CT: a pilot study.
Object: Pathologic prediction of prostate cancer can be made by predicting the patient's prostate metastasis prior to surgery based on biopsy information. Because biopsy variables associated with pathology have uncertainty regarding individual patient differences, a method for classification according to these variables is needed. Method: We propose a deep belief network and Dempster-Shafer- (DBN-DS-) based multiclassifier for the pathologic prediction of prostate cancer. The DBN-DS learns prostate-specific antigen (PSA), Gleason score, and clinical T stage variable information using three DBNs. Uncertainty regarding the predicted output was removed from the DBN and combined with information from DS to make a correct decision. Result: The new method was validated on pathology data from 6342 patients with prostate cancer. The pathology stages consisted of organ-confined disease (OCD; 3892 patients) and non-organ-confined disease (NOCD; 2453 patients). The results showed that the accuracy of the proposed DBN-DS was 81.27%, which is higher than the 64.14% of the Partin table. Conclusion: The proposed DBN-DS is more effective than other methods in predicting pathology stage. The performance is high because of the linear combination using the results of pathology-related features. The proposed method may be effective in decision support for prostate cancer treatment.	"['Department of Computer Science and Information Engineering, Inha University, InhaRo 100, Nam-gu, Incheon, Republic of Korea.', 'Department of Medical Informatics, College of Medicine, The Catholic University of Seoul, 222 Banpo-daero, Seocho-gu, Seoul 06591, Republic of Korea.', 'Department of Computer Science and Information Engineering, Inha University, InhaRo 100, Nam-gu, Incheon, Republic of Korea.', 'Department of Urology, University of Ulsan College of Medicine, Seoul, Republic of Korea.', 'Department of Urology, University of Ulsan College of Medicine, Seoul, Republic of Korea.', 'Department of Urology, Sungkyunkwan University School of Medicine, Seoul, Republic of Korea.', 'Department of Urology, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Urology, Seoul National University Bundang Hospital, Seongnam, Republic of Korea.', 'Department of Urology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Department of Urology, Yonsei University College of Medicine, Seoul, Republic of Korea.', ""Department of Urology, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea."", ""Department of Urology, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea."", 'Department of Medical Informatics, College of Medicine, The Catholic University of Seoul, 222 Banpo-daero, Seocho-gu, Seoul 06591, Republic of Korea.']"	['10.1155/2018/4651582 [doi]']	['Kim JK', 'Choi MJ', 'Lee JS', 'Hong JH', 'Kim CS', 'Seo SI', 'Jeong CW', 'Byun SS', 'Koo KC', 'Chung BH', 'Park YH', 'Lee JY', 'Choi IY']	['ORCID: 0000-0001-9982-5413', 'ORCID: 0000-0002-7464-3207', 'ORCID: 0000-0002-2860-9411']						['2018/05/15 06:00']	20191125	20180319	2018	2018/05/15 06:00		['Kim, Jae Kwon', 'Choi, Mun Joo', 'Lee, Jong Sik', 'Hong, Jun Hyuk', 'Kim, Choung-Soo', 'Seo, Seong Il', 'Jeong, Chang Wook', 'Byun, Seok-Soo', 'Koo, Kyo Chul', 'Chung, Byung Ha', 'Park, Yong Hyun', 'Lee, Ji Youl', 'Choi, In Young']					2040-2295 (Print) 2040-2295 (Linking)	101528166	Journal of healthcare engineering	['eng']	10.1155/2018/4651582 [doi]	20191125	['Biopsy', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Humans', 'Male', 'Neoplasm Grading', 'Neoplasm Staging/*methods', 'Prostate/*pathology', 'Prostate-Specific Antigen/blood', '*Prostatic Neoplasms/diagnosis/pathology']	2019/11/26 06:00				NLM	4651582	['2017/08/25 00:00 [received]', '2018/01/09 00:00 [accepted]', '2018/05/15 06:00 [entrez]', '2018/05/15 06:00 [pubmed]', '2019/11/26 06:00 [medline]']	England	PMC5884161		29755715	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['EC 3.4.21.77 (Prostate-Specific Antigen)']	IM		J Healthc Eng. 2018 Mar 19;2018:4651582. doi: 10.1155/2018/4651582. eCollection 2018.	MEDLINE	J Healthc Eng	A Deep Belief Network and Dempster-Shafer-Based Multiclassifier for the Pathology Stage of Prostate Cancer.		2018	A Deep Belief Network and Dempster-Shafer-Based Multiclassifier for the Pathology Stage of Prostate Cancer.
INTRODUCTION: Technological solutions for quantifying Parkinson's disease (PD) symptoms may provide an objective means to track response to treatment, including side effects such as levodopa-induced dyskinesia. Vision-based systems are advantageous as they do not require physical contact with the body and have minimal instrumentation compared to wearables. We have developed a vision-based system to quantify a change in dyskinesia as reported by patients using 2D videos of clinical assessments during acute levodopa infusions. METHODS: Nine participants with PD completed a total of 16 levodopa infusions, where they were asked to report important changes in dyskinesia (i.e. onset and remission). Participants were simultaneously rated using the UDysRS Part III (from video recordings analyzed post-hoc). Body joint positions and movements were tracked using a state-of-the-art deep learning pose estimation algorithm applied to the videos. 416 features (e.g. kinematics, frequency distribution) were extracted to characterize movements. The sensitivity and specificity of each feature to patient-reported changes in dyskinesia severity was computed and compared with physician-rated results. RESULTS: Features achieved similar or superior performance to the UDysRS for detecting the onset and remission of dyskinesia. The best AUC for detecting onset of dyskinesia was 0.822 and for remission of dyskinesia was 0.958, compared to 0.826 and 0.802 for the UDysRS. CONCLUSIONS: Video-based features may provide an objective means of quantifying the severity of levodopa-induced dyskinesia, and have responsiveness as good or better than the clinically-rated UDysRS. The results demonstrate encouraging evidence for future integration of video-based technology into clinical research and eventually clinical practice.	"['Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, Ontario, M5G 2A2, Canada; Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Room 407, Toronto, Ontario, M5S 3G9, Canada. Electronic address: michaelhg.li@alum.utoronto.ca.', ""Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, Ontario, M5T 2S8, Canada; The Ottawa Hospital Research Institute, 1053 Carling Ave, Ottawa, Ontario, K1Y 4E9, Canada; Division of Neurology, Department of Medicine, 1053 Carling Ave, Ottawa, Ontario, K1Y 4E9, Canada; Division of Neurology, University of Toronto, Suite RFE 3-805, 200 Elizabeth St, Toronto, Ontario, M5G 2C4, Canada. Electronic address: tmestre@toh.ca."", ""Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, Ontario, M5T 2S8, Canada; Division of Neurology, University of Toronto, Suite RFE 3-805, 200 Elizabeth St, Toronto, Ontario, M5G 2C4, Canada. Electronic address: susan.fox@uhnresearch.ca."", ""Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, Ontario, M5G 2A2, Canada; Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Room 407, Toronto, Ontario, M5S 3G9, Canada; Department of Computer Science, University of Toronto, 10 King's College Road, Room 3302, Toronto, Ontario, M5S 3G4, Canada. Electronic address: babak.taati@uhn.ca.""]"	['S1353-8020(18)30222-0 [pii]', '10.1016/j.parkreldis.2018.04.036 [doi]']	['Li MH', 'Mestre TA', 'Fox SH', 'Taati B']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/05/12 06:00']	20190913	20180505	2018 Aug	2018/05/12 06:00		['Li, Michael H', 'Mestre, Tiago A', 'Fox, Susan H', 'Taati, Babak']					1873-5126 (Electronic) 1353-8020 (Linking)	9513583	Parkinsonism & related disorders	['eng']	S1353-8020(18)30222-0 [pii] 10.1016/j.parkreldis.2018.04.036 [doi]	20190913	['Aged', 'Antiparkinson Agents/*adverse effects', 'Biomechanical Phenomena', '*Deep Learning', 'Dyskinesia, Drug-Induced/*diagnosis/etiology', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods/standards', 'Levodopa/*adverse effects', 'Male', 'Middle Aged', 'Parkinson Disease/*drug therapy', '*Patient Reported Outcome Measures', 'Sensitivity and Specificity', 'Severity of Illness Index', 'Video Recording']	2019/09/14 06:00		"['*Clinimetric testing', '*Computer vision', '*Levodopa-induced dyskinesia', '*Objective assessment', ""*Parkinson's disease""]"	['NOTNLM']	NLM	42-45	['2017/12/31 00:00 [received]', '2018/04/11 00:00 [revised]', '2018/04/28 00:00 [accepted]', '2018/05/12 06:00 [pubmed]', '2019/09/14 06:00 [medline]', '2018/05/12 06:00 [entrez]']	England			29748112	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Antiparkinson Agents)', '46627O600J (Levodopa)']	IM		Parkinsonism Relat Disord. 2018 Aug;53:42-45. doi: 10.1016/j.parkreldis.2018.04.036. Epub 2018 May 5.	MEDLINE	Parkinsonism Relat Disord	Automated assessment of levodopa-induced dyskinesia: Evaluating the responsiveness of video-based features.		53	Automated assessment of levodopa-induced dyskinesia: Evaluating the responsiveness of video-based features.
BACKGROUND: Protein secondary structure is the three dimensional form of local segments of proteins and its prediction is an important problem in protein tertiary structure prediction. Developing computational approaches for protein secondary structure prediction is becoming increasingly urgent. RESULTS: We present a novel deep learning based model, referred to as CNNH_PSS, by using multi-scale CNN with highway. In CNNH_PSS, any two neighbor convolutional layers have a highway to deliver information from current layer to the output of the next one to keep local contexts. As lower layers extract local context while higher layers extract long-range interdependencies, the highways between neighbor layers allow CNNH_PSS to have ability to extract both local contexts and long-range interdependencies. We evaluate CNNH_PSS on two commonly used datasets: CB6133 and CB513. CNNH_PSS outperforms the multi-scale CNN without highway by at least 0.010 Q8 accuracy and also performs better than CNF, DeepCNF and SSpro8, which cannot extract long-range interdependencies, by at least 0.020 Q8 accuracy, demonstrating that both local contexts and long-range interdependencies are indeed useful for prediction. Furthermore, CNNH_PSS also performs better than GSM and DCRNN which need extra complex model to extract long-range interdependencies. It demonstrates that CNNH_PSS not only cost less computer resource, but also achieves better predicting performance. CONCLUSION: CNNH_PSS have ability to extracts both local contexts and long-range interdependencies by combing multi-scale CNN and highway network. The evaluations on common datasets and comparisons with state-of-the-art methods indicate that CNNH_PSS is an useful and efficient tool for protein secondary structure prediction.	['School Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, HIT Campus Shenzhen University Town, Xili, Shenzhen, Guangdong, 518055, China.', 'Department of Computing, the Hong Kong Polytechnic University, Hung Hom, Hong Kong.', 'School Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, HIT Campus Shenzhen University Town, Xili, Shenzhen, Guangdong, 518055, China.', 'School Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, HIT Campus Shenzhen University Town, Xili, Shenzhen, Guangdong, 518055, China.', 'School Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, HIT Campus Shenzhen University Town, Xili, Shenzhen, Guangdong, 518055, China. xuruifeng@hit.edu.cn.', 'Department of Computing, the Hong Kong Polytechnic University, Hung Hom, Hong Kong.']	['10.1186/s12859-018-2067-8 [doi]', '10.1186/s12859-018-2067-8 [pii]']	['Zhou J', 'Wang H', 'Zhao Z', 'Xu R', 'Lu Q']							['2018/05/11 06:00']	20190517	20180508	2018 May 8	2018/05/11 06:00		['Zhou, Jiyun', 'Wang, Hongpeng', 'Zhao, Zhishan', 'Xu, Ruifeng', 'Lu, Qin']			Suppl 4		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2067-8 [doi]	20190517	['Databases, Protein', 'Deep Learning', '*Neural Networks (Computer)', 'Protein Structure, Secondary', 'Proteins/*chemistry']	2019/05/18 06:00		['*Convolutional neural network', '*Highway', '*Local context', '*Long-range interdependency', '*Protein secondary structure']	['NOTNLM']	NLM	60	['2018/05/11 06:00 [entrez]', '2018/05/11 06:00 [pubmed]', '2019/05/18 06:00 [medline]']	England	PMC5998876		29745837	epublish	['Journal Article']		['0 (Proteins)']	IM		BMC Bioinformatics. 2018 May 8;19(Suppl 4):60. doi: 10.1186/s12859-018-2067-8.	MEDLINE	BMC Bioinformatics	CNNH_PSS: protein 8-class secondary structure prediction by convolutional neural network with highway.		19	CNNH_PSS: protein 8-class secondary structure prediction by convolutional neural network with highway.
"BACKGROUND: Conducting surveys in low- and middle-income countries is often challenging because many areas lack a complete sampling frame, have outdated census information, or have limited data available for designing and selecting a representative sample. Geosampling is a probability-based, gridded population sampling method that addresses some of these issues by using geographic information system (GIS) tools to create logistically manageable area units for sampling. GIS grid cells are overlaid to partition a country's existing administrative boundaries into area units that vary in size from 50 m x 50 m to 150 m x 150 m. To avoid sending interviewers to unoccupied areas, researchers manually classify grid cells as ""residential"" or ""nonresidential"" through visual inspection of aerial images. ""Nonresidential"" units are then excluded from sampling and data collection. This process of manually classifying sampling units has drawbacks since it is labor intensive, prone to human error, and creates the need for simplifying assumptions during calculation of design-based sampling weights. In this paper, we discuss the development of a deep learning classification model to predict whether aerial images are residential or nonresidential, thus reducing manual labor and eliminating the need for simplifying assumptions. RESULTS: On our test sets, the model performs comparable to a human-level baseline in both Nigeria (94.5% accuracy) and Guatemala (96.4% accuracy), and outperforms baseline machine learning models trained on crowdsourced or remote-sensed geospatial features. Additionally, our findings suggest that this approach can work well in new areas with relatively modest amounts of training data. CONCLUSIONS: Gridded population sampling methods like geosampling are becoming increasingly popular in countries with outdated or inaccurate census data because of their timeliness, flexibility, and cost. Using deep learning models directly on satellite images, we provide a novel method for sample frame construction that identifies residential gridded aerial units. In cases where manual classification of satellite images is used to (1) correct for errors in gridded population data sets or (2) classify grids where population estimates are unavailable, this methodology can help reduce annotation burden with comparable quality to human analysts."	['Center for Data Science, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA. rchew@rti.org.', 'Division for Statistical and Data Sciences, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA.', 'Center for Data Science, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA.', 'Division for Statistical and Data Sciences, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA.', 'Geospatial Science and Technology Program, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA.', 'Geospatial Science and Technology Program, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA.', 'Geospatial Science and Technology Program, RTI International, 3040 East Cornwallis Road, Research Triangle Park, NC, USA.']	['10.1186/s12942-018-0132-1 [doi]', '10.1186/s12942-018-0132-1 [pii]']	['Chew RF', 'Amer S', 'Jones K', 'Unangst J', 'Cajka J', 'Allpress J', 'Bruhn M']							['2018/05/11 06:00']	20190109	20180509	2018 May 9	2018/05/11 06:00		['Chew, Robert F', 'Amer, Safaa', 'Jones, Kasey', 'Unangst, Jennifer', 'Cajka, James', 'Allpress, Justine', 'Bruhn, Mark']			1		1476-072X (Electronic) 1476-072X (Linking)	101152198	International journal of health geographics	['eng']	10.1186/s12942-018-0132-1 [doi]	20190109	['Data Collection/classification/methods', 'Demography/*classification/methods', 'Developing Countries/*classification', 'Guatemala/epidemiology', 'Humans', '*Neural Networks (Computer)', 'Nigeria/epidemiology', 'Residence Characteristics/*classification', 'Satellite Imagery/*classification/methods']	2019/01/10 06:00		['*Clustering', '*Complex sample design', '*Deep learning', '*GIS', '*Machine learning', '*Probability based', '*Remote sensing', '*Scene classification']	['NOTNLM']	NLM	12	['2018/01/26 00:00 [received]', '2018/05/03 00:00 [accepted]', '2018/05/11 06:00 [entrez]', '2018/05/11 06:00 [pubmed]', '2019/01/10 06:00 [medline]']	England	PMC5944062		29743081	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Int J Health Geogr. 2018 May 9;17(1):12. doi: 10.1186/s12942-018-0132-1.	MEDLINE	Int J Health Geogr	Residential scene classification for gridded population sampling in developing countries using deep convolutional neural networks on satellite imagery.		17	Residential scene classification for gridded population sampling in developing countries using deep convolutional neural networks on satellite imagery.
With the introduction of various advanced deep learning algorithms, initiatives for image classification systems have transitioned over from traditional machine learning algorithms (e.g., SVM) to Convolutional Neural Networks (CNNs) using deep learning software tools. A prerequisite in applying CNN to real world applications is a system that collects meaningful and useful data. For such purposes, Wireless Image Sensor Networks (WISNs), that are capable of monitoring natural environment phenomena using tiny and low-power cameras on resource-limited embedded devices, can be considered as an effective means of data collection. However, with limited battery resources, sending high-resolution raw images to the backend server is a burdensome task that has direct impact on network lifetime. To address this problem, we propose an energy-efficient pre- and post- processing mechanism using image resizing and color quantization that can significantly reduce the amount of data transferred while maintaining the classification accuracy in the CNN at the backend server. We show that, if well designed, an image in its highly compressed form can be well-classified with a CNN model trained in advance using adequately compressed data. Our evaluation using a real image dataset shows that an embedded device can reduce the amount of transmitted data by approximately 71% while maintaining a classification accuracy of approximately 98%. Under the same conditions, this process naturally reduces energy consumption by approximately 71% compared to a WISN that sends the original uncompressed images.	['Department of Computer Engineering, Ajou University, Suwon, Republic of Korea.', 'Department of Computer Engineering, Ajou University, Suwon, Republic of Korea.', 'Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea.', 'School of Computer Science & Engineering, Chung-Ang University, Seoul, Republic of Korea.', 'Department of Computer Engineering, Ajou University, Suwon, Republic of Korea.']	['10.1371/journal.pone.0196251 [doi]', 'PONE-D-17-42065 [pii]']	['Ahn J', 'Park J', 'Park D', 'Paek J', 'Ko J']	['ORCID: 0000-0003-0799-4039']						['2018/05/09 06:00']	20180731	20180508	2018	2018/05/09 06:00		['Ahn, Jungmo', 'Park, JaeYeon', 'Park, Donghwan', 'Paek, Jeongyeup', 'Ko, JeongGil']			5		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0196251 [doi]	20181114	['Algorithms', 'Animals', '*Biosensing Techniques', 'Birds/*growth & development', 'Data Collection/*instrumentation', 'Environmental Monitoring/*methods', 'Humans', 'Machine Learning', '*Nesting Behavior', '*Neural Networks (Computer)', 'Software', '*Wireless Technology']	2018/08/01 06:00				NLM	e0196251	['2017/11/29 00:00 [received]', '2018/04/09 00:00 [accepted]', '2018/05/09 06:00 [entrez]', '2018/05/09 06:00 [pubmed]', '2018/08/01 06:00 [medline]']	United States	PMC5940226		29738564	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM	['figshare/5853651.v2']	PLoS One. 2018 May 8;13(5):e0196251. doi: 10.1371/journal.pone.0196251. eCollection 2018.	MEDLINE	PLoS One	Convolutional neural network-based classification system design with compressed wireless sensor network images.		13	Convolutional neural network-based classification system design with compressed wireless sensor network images.
In recent years, the use of advanced magnetic resonance (MR) imaging methods such as functional magnetic resonance imaging (fMRI) and structural magnetic resonance imaging (sMRI) has recorded a great increase in neuropsychiatric disorders. Deep learning is a branch of machine learning that is increasingly being used for applications of medical image analysis such as computer-aided diagnosis. In a bid to classify and represent learning tasks, this study utilized one of the most powerful deep learning algorithms (deep belief network (DBN)) for the combination of data from Autism Brain Imaging Data Exchange I and II (ABIDE I and ABIDE II) datasets. The DBN was employed so as to focus on the combination of resting-state fMRI (rs-fMRI), gray matter (GM), and white matter (WM) data. This was done based on the brain regions that were defined using the automated anatomical labeling (AAL), in order to classify autism spectrum disorders (ASDs) from typical controls (TCs). Since the diagnosis of ASD is much more effective at an early age, only 185 individuals (116 ASD and 69 TC) ranging in age from 5 to 10 years were included in this analysis. In contrast, the proposed method is used to exploit the latent or abstract high-level features inside rs-fMRI and sMRI data while the old methods consider only the simple low-level features extracted from neuroimages. Moreover, combining multiple data types and increasing the depth of DBN can improve classification accuracy. In this study, the best combination comprised rs-fMRI, GM, and WM for DBN of depth 3 with 65.56% accuracy (sensitivity = 84%, specificity = 32.96%, F1 score = 74.76%) obtained via 10-fold cross-validation. This result outperforms previously presented methods on ABIDE I dataset.	['Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran. maryam_akhavan_aghdam@yahoo.com.', 'Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran.', 'Department of Electrical and Computer Engineering, Kharazmi University, Tehran, Iran.']	['10.1007/s10278-018-0093-8 [doi]', '10.1007/s10278-018-0093-8 [pii]']	['Akhavan Aghdam M', 'Sharifi A', 'Pedram MM']	['ORCID: 0000-0002-2441-9477']						['2018/05/09 06:00']	20191106		2018 Dec	2018/05/08 06:00		['Akhavan Aghdam, Maryam', 'Sharifi, Arash', 'Pedram, Mir Mohsen']			6		1618-727X (Electronic) 0897-1889 (Linking)	9100529	Journal of digital imaging	['eng']	10.1007/s10278-018-0093-8 [doi]	20191106	['Autism Spectrum Disorder/*diagnosis/physiopathology', 'Brain/*diagnostic imaging/*physiopathology', 'Brain Mapping/*methods', 'Child', 'Child, Preschool', 'Diagnosis, Differential', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Machine Learning', 'Magnetic Resonance Imaging/*methods', 'Male', 'Sensitivity and Specificity']	2019/11/07 06:00		['*Autism spectrum disorder', '*Deep belief network', '*Gray matter', '*White matter', '*rs-fMRI', '*sMRI']	['NOTNLM']	NLM	895-903	['2018/05/08 06:00 [pubmed]', '2019/11/07 06:00 [medline]', '2018/05/09 06:00 [entrez]']	United States	PMC6261184		29736781	ppublish	['Journal Article']			IM		J Digit Imaging. 2018 Dec;31(6):895-903. doi: 10.1007/s10278-018-0093-8.	MEDLINE	J Digit Imaging	Combination of rs-fMRI and sMRI Data to Discriminate Autism Spectrum Disorders in Young Children Using Deep Belief Network.		31	Combination of rs-fMRI and sMRI Data to Discriminate Autism Spectrum Disorders in Young Children Using Deep Belief Network.
Random backpropagation (RBP) is a variant of the backpropagation algorithm for training neural networks, where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. It is remarkable both because of its effectiveness, in spite of using random matrices to communicate error information, and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. To better understand random backpropagation, we first connect it to the notions of local learning and learning channels. Through this connection, we derive several alternatives to RBP, including skipped RBP (SRPB), adaptive RBP (ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their computational complexity. We then study their behavior through simulations using the MNIST and CIFAR-10 bechnmark datasets. These simulations show that most of these variants work robustly, almost as well as backpropagation, and that multiplication by the derivatives of the activation functions is important. As a follow-up, we study also the low-end of the number of bits required to communicate error information over the learning channel. We then provide partial intuitive explanations for some of the remarkable properties of RBP and its variations. Finally, we prove several mathematical results, including the convergence to fixed points of linear chains of arbitrary length, the convergence to fixed points of linear autoencoders with decorrelated data, the long-term existence of solutions for linear systems with a single hidden layer and convergence in special cases, and the convergence to fixed points of non-linear chains, when the derivative of the activation functions is included.	['Department of Computer Science, University of California, Irvine.', 'Department of Computer Science, University of California, Irvine.', 'Department of Mathematics, University of California, Irvine.']	['10.1016/j.artint.2018.03.003 [doi]']	['Baldi P', 'Sadowski P', 'Lu Z']							['2018/05/08 06:00']		20180403	2018 Jul	2018/05/08 06:00		['Baldi, Pierre', 'Sadowski, Peter', 'Lu, Zhiqin']		['R01 GM123558/GM/NIGMS NIH HHS/United States', 'R25 LM011170/LM/NLM NIH HHS/United States']			0004-3702 (Print) 0004-3702 (Linking)	0262613	Artificial intelligence	['eng']	10.1016/j.artint.2018.03.003 [doi]	20191120		2018/05/08 06:01	['NIHMS961685']			NLM	1-35	['2018/05/08 06:00 [entrez]', '2018/05/08 06:00 [pubmed]', '2018/05/08 06:01 [medline]']	Netherlands	PMC5931406		29731511	ppublish	['Journal Article']					Artif Intell. 2018 Jul;260:1-35. doi: 10.1016/j.artint.2018.03.003. Epub 2018 Apr 3.	PubMed-not-MEDLINE	Artif Intell	Learning in the Machine: Random Backpropagation and the Deep Learning Channel.		260	Learning in the Machine: Random Backpropagation and the Deep Learning Channel.
"Genome scale modeling (GSM) predicts the performance of microbial workhorses and helps identify beneficial gene targets. GSM integrated with intracellular flux dynamics, omics, and thermodynamics have shown remarkable progress in both elucidating complex cellular phenomena and computational strain design (CSD). Nonetheless, these models still show high uncertainty due to a poor understanding of innate pathway regulations, metabolic burdens, and other factors (such as stress tolerance and metabolite channeling). Besides, the engineered hosts may have genetic mutations or non-genetic variations in bioreactor conditions and thus CSD rarely foresees fermentation rate and titer. Metabolic models play important role in design-build-test-learn cycles for strain improvement, and machine learning (ML) may provide a viable complementary approach for driving strain design and deciphering cellular processes. In order to develop quality ML models, knowledge engineering leverages and standardizes the wealth of information in literature (e.g., genomic/phenomic data, synthetic biology strategies, and bioprocess variables). Data driven frameworks can offer new constraints for mechanistic models to describe cellular regulations, to design pathways, to search gene targets, and to estimate fermentation titer/rate/yield under specified growth conditions (e.g., mixing, nutrients, and O2). This review highlights the scope of information collections, database constructions, and machine learning techniques (such as deep learning and transfer learning), which may facilitate ""Learn and Design"" for strain development."	['Department of Energy, Environmental and Chemical Engineering, Washington University in Saint Louis, Saint Louis, MO 63130, USA.', 'Department of Computer Science, Iowa State University, Ames, IA 50011, USA.', 'Department of Energy, Environmental and Chemical Engineering, Washington University in Saint Louis, Saint Louis, MO 63130, USA.', 'DOE, Joint BioEnergy Institute, Emeryville, CA 94608, USA; DOE, Agile BioFoundry, Emeryville, CA 94608, USA; Biological Systems and Engineering Division, Lawrence Berkeley National Lab, Berkeley, California 94720, USA.', 'Department of Energy, Environmental and Chemical Engineering, Washington University in Saint Louis, Saint Louis, MO 63130, USA. Electronic address: yinjie.tang@wustl.edu.']	['S0734-9750(18)30080-6 [pii]', '10.1016/j.biotechadv.2018.04.008 [doi]']	['Oyetunde T', 'Bao FS', 'Chen JW', 'Martin HG', 'Tang YJ']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/05/06 06:00']	20190225	20180503	2018 Jul - Aug	2018/05/08 06:00		['Oyetunde, Tolutola', 'Bao, Forrest Sheng', 'Chen, Jiung-Wen', 'Martin, Hector Garcia', 'Tang, Yinjie J']			4		1873-1899 (Electronic) 0734-9750 (Linking)	8403708	Biotechnology advances	['eng']	S0734-9750(18)30080-6 [pii] 10.1016/j.biotechadv.2018.04.008 [doi]	20190225	['*Bioreactors', '*Machine Learning', '*Metabolic Engineering', '*Models, Biological', '*Synthetic Biology']	2019/02/26 06:00		['*Deep learning', '*Design-build-test-learn', '*Genome scale modeling', '*Metabolic burdens']	['NOTNLM']	NLM	1308-1315	['2017/10/03 00:00 [received]', '2018/02/27 00:00 [revised]', '2018/04/26 00:00 [accepted]', '2018/05/08 06:00 [pubmed]', '2019/02/26 06:00 [medline]', '2018/05/06 06:00 [entrez]']	England			29729378	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S."", 'Review']"			IM		Biotechnol Adv. 2018 Jul - Aug;36(4):1308-1315. doi: 10.1016/j.biotechadv.2018.04.008. Epub 2018 May 3.	MEDLINE	Biotechnol Adv	Leveraging knowledge engineering and machine learning for microbial bio-manufacturing.		36	Leveraging knowledge engineering and machine learning for microbial bio-manufacturing.
PURPOSE: The routine MRI scan protocol consists of multiple pulse sequences that acquire images of varying contrast. Since high frequency contents such as edges are not significantly affected by image contrast, down-sampled images in one contrast may be improved by high resolution (HR) images acquired in another contrast, reducing the total scan time. In this study, we propose a new deep learning framework that uses HR MR images in one contrast to generate HR MR images from highly down-sampled MR images in another contrast. MATERIALS AND METHODS: The proposed convolutional neural network (CNN) framework consists of two CNNs: (a) a reconstruction CNN for generating HR images from the down-sampled images using HR images acquired with a different MRI sequence and (b) a discriminator CNN for improving the perceptual quality of the generated HR images. The proposed method was evaluated using a public brain tumor database and in vivo datasets. The performance of the proposed method was assessed in tumor and no-tumor cases separately, with perceptual image quality being judged by a radiologist. To overcome the challenge of training the network with a small number of available in vivo datasets, the network was pretrained using the public database and then fine-tuned using the small number of in vivo datasets. The performance of the proposed method was also compared to that of several compressed sensing (CS) algorithms. RESULTS: Incorporating HR images of another contrast improved the quantitative assessments of the generated HR image in reference to ground truth. Also, incorporating a discriminator CNN yielded perceptually higher image quality. These results were verified in regions of normal tissue as well as tumors for various MRI sequences from pseudo k-space data generated from the public database. The combination of pretraining with the public database and fine-tuning with the small number of real k-space datasets enhanced the performance of CNNs in in vivo application compared to training CNNs from scratch. The proposed method outperformed the compressed sensing methods. CONCLUSIONS: The proposed method can be a good strategy for accelerating routine MRI scanning.	['Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea.', 'Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea.', 'Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea.', 'Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea.', 'Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea.']	['10.1002/mp.12945 [doi]']	['Kim KH', 'Do WJ', 'Park SH']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/05/06 06:00']	20181023	20180518	2018 Jul	2018/05/08 06:00		['Kim, Ki Hwan', 'Do, Won-Joon', 'Park, Sung-Hong']			7		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.12945 [doi]	20181023	['Image Enhancement/*methods', '*Machine Learning', '*Magnetic Resonance Imaging', 'Neural Networks (Computer)']	2018/10/24 06:00		['convolutional neural network', 'generative adversarial network', 'magnetic resonance imaging']	['NOTNLM']	NLM	3120-3131	['2017/12/06 00:00 [received]', '2018/04/16 00:00 [revised]', '2018/04/22 00:00 [accepted]', '2018/05/08 06:00 [pubmed]', '2018/10/24 06:00 [medline]', '2018/05/06 06:00 [entrez]']	United States			29729006	ppublish	['Journal Article']			IM		Med Phys. 2018 Jul;45(7):3120-3131. doi: 10.1002/mp.12945. Epub 2018 May 18.	MEDLINE	Med Phys	Improving resolution of MR images with an adversarial network incorporating images with different contrast.		45	Improving resolution of MR images with an adversarial network incorporating images with different contrast.
There is recent popularity in applying machine learning to medical imaging, notably deep learning, which has achieved state-of-the-art performance in image analysis and processing. The rapid adoption of deep learning may be attributed to the availability of machine learning frameworks and libraries to simplify their use. In this tutorial, we provide a high-level overview of how to build a deep neural network for medical image classification, and provide code that can help those new to the field begin their informatics projects.	['Department of Radiology, Sidney Kimmel Jefferson Medical College, Thomas Jefferson University Hospital, Philadelphia, PA, 19107, USA. paras.lakhani@jefferson.edu.', 'Sidney Kimmel Jefferson Medical College, Philadelphia, PA, USA.', 'Sidney Kimmel Jefferson Medical College, Philadelphia, PA, USA.', 'Department of Radiology, Johns Hopkins University School of Medicine, Baltimore, MD, USA.', 'Division of Health Science Informatics, Johns Hopkins University School of Public Health, Baltimore, MD, USA.', 'Department of Radiology, Weill Cornell Medical College, New York, NY, USA.']	['10.1007/s10278-018-0079-6 [doi]', '10.1007/s10278-018-0079-6 [pii]']	['Lakhani P', 'Gray DL', 'Pett CR', 'Nagy P', 'Shih G']	['ORCID: http://orcid.org/0000-0003-3373-9226']						['2018/05/05 06:00']	20190807		2018 Jun	2018/05/05 06:00		['Lakhani, Paras', 'Gray, Daniel L', 'Pett, Carl R', 'Nagy, Paul', 'Shih, George']			3		1618-727X (Electronic) 0897-1889 (Linking)	9100529	Journal of digital imaging	['eng']	10.1007/s10278-018-0079-6 [doi]	20191112	['*Deep Learning', 'Diagnostic Imaging/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Radiology/*education']	2019/08/08 06:00		['*Artificial neural networks', '*Deep learning', '*Machine learning', '*Medical imaging']	['NOTNLM']	NLM	283-289	['2018/05/05 06:00 [pubmed]', '2019/08/08 06:00 [medline]', '2018/05/05 06:00 [entrez]']	United States	PMC5959832		29725961	ppublish	['Journal Article', 'Review']					J Digit Imaging. 2018 Jun;31(3):283-289. doi: 10.1007/s10278-018-0079-6.	MEDLINE	J Digit Imaging	Hello World Deep Learning in Medical Imaging.		31	Hello World Deep Learning in Medical Imaging.
Lung sounds convey relevant information related to pulmonary disorders, and to evaluate patients with pulmonary conditions, the physician or the doctor uses the traditional auscultation technique. However, this technique suffers from limitations. For example, if the physician is not well trained, this may lead to a wrong diagnosis. Moreover, lung sounds are non-stationary, complicating the tasks of analysis, recognition, and distinction. This is why developing automatic recognition systems can help to deal with these limitations. In this paper, we compare three machine learning approaches for lung sounds classification. The first two approaches are based on the extraction of a set of handcrafted features trained by three different classifiers (support vector machines, k-nearest neighbor, and Gaussian mixture models) while the third approach is based on the design of convolutional neural networks (CNN). In the first approach, we extracted the 12 MFCC coefficients from the audio files then calculated six MFCCs statistics. We also experimented normalization using zero mean and unity variance to enhance accuracy. In the second approach, the local binary pattern (LBP) features are extracted from the visual representation of the audio files (spectrograms). The features are normalized using whitening. The dataset used in this work consists of seven classes (normal, coarse crackle, fine crackle, monophonic wheeze, polyphonic wheeze, squawk, and stridor). We have also experimentally tested dataset augmentation techniques on the spectrograms to enhance the ultimate accuracy of the CNN. The results show that CNN outperformed the handcrafted feature based classifiers.	['School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China. Electronic address: dalal.bardou@njust.edu.cn.', 'School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China. Electronic address: zhangkun@njust.edu.cn.', 'Lareb Technologies, India.']	['S0933-3657(17)30205-1 [pii]', '10.1016/j.artmed.2018.04.008 [doi]']	['Bardou D', 'Zhang K', 'Ahmad SM']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/05/05 06:00']	20190723	20180501	2018 Jun	2018/05/05 06:00		['Bardou, Dalal', 'Zhang, Kun', 'Ahmad, Sayed Mohammad']					1873-2860 (Electronic) 0933-3657 (Linking)	8915031	Artificial intelligence in medicine	['eng']	S0933-3657(17)30205-1 [pii] 10.1016/j.artmed.2018.04.008 [doi]	20190723	['*Acoustics', 'Adolescent', 'Adult', 'Aged', 'Auscultation/*classification', 'Child', '*Deep Learning', 'Female', 'Humans', 'Infant, Newborn', 'Lung/*physiopathology', 'Lung Diseases/classification/*diagnosis/physiopathology', 'Male', 'Middle Aged', 'Pattern Recognition, Automated', 'Predictive Value of Tests', 'Prognosis', 'Reproducibility of Results', 'Respiratory Sounds/*classification', '*Signal Processing, Computer-Assisted', 'Sound Spectrography', '*Support Vector Machine']	2019/07/25 06:00		['*Convolutional neural network', '*Deep learning', '*Handcrafted features extraction', '*Lung sounds classification', '*Models ensembling', '*Support vector machines']	['NOTNLM']	NLM	58-69	['2017/05/05 00:00 [received]', '2018/04/18 00:00 [revised]', '2018/04/23 00:00 [accepted]', '2018/05/05 06:00 [pubmed]', '2019/07/25 06:00 [medline]', '2018/05/05 06:00 [entrez]']	Netherlands			29724435	ppublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"					Artif Intell Med. 2018 Jun;88:58-69. doi: 10.1016/j.artmed.2018.04.008. Epub 2018 May 1.	MEDLINE	Artif Intell Med	Lung sounds classification using convolutional neural networks.		88	Lung sounds classification using convolutional neural networks.
"BACKGROUND: Current Chinese medicine has an urgent demand for convenient medical services. When facing a large number of patients, understanding patients' questions automatically and precisely is useful. Different from the high professional medical text, patients' questions contain only a small amount of descriptions regarding the symptoms, and the questions are slightly professional and colloquial. OBJECT: The aim of this paper is to implement a department classification system for patient questions. Patients' questions will be classified into 11 departments, such as surgery and others. METHODS: This paper presents a morpheme growth model that enhances the memories of key elements in questions, and later extracts the ""label-indicators"" and germinates the expansion vectors around them. Finally, the model inputs the expansion vectors into a neural network to assign department labels for patients' questions. RESULTS: All compared methods are validated by experiments on three datasets that are composed of real patient questions. The proposed method has some ability to improve the performance of the classification. CONCLUSIONS: The proposed method is effective for the departments classification of patients questions and serves as a useful system for the automatic understanding of patient questions."	['School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China. Electronic address: superhy199148@hotmail.com.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China. Electronic address: crghwen@scut.edu.cn.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China. Electronic address: mullma@outlook.com.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China. Electronic address: danyangedu@163.com.', 'Guangdong General Hospital, Guangzhou 510000, China. Electronic address: gzwchj@126.com.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China. Electronic address: 29777562@qq.com.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China. Electronic address: huaneryang@gmail.com.']	['S1532-0464(18)30075-3 [pii]', '10.1016/j.jbi.2018.04.011 [doi]']	['Hu Y', 'Wen G', 'Ma J', 'Li D', 'Wang C', 'Li H', 'Huan E']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/04/30 06:00']	20190723	20180427	2018 Jun	2018/05/01 06:00		['Hu, Yang', 'Wen, Guihua', 'Ma, Jiajiong', 'Li, Danyang', 'Wang, Changjun', 'Li, Huihui', 'Huan, Eryang']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30075-3 [pii] 10.1016/j.jbi.2018.04.011 [doi]	20190723	['China', '*Communication', 'Databases, Factual', 'Deep Learning', 'Delivery of Health Care', 'Humans', 'Medical Informatics/*methods', 'Natural Language Processing', '*Neural Networks (Computer)', 'Patient Participation', '*Physician-Patient Relations', 'Reproducibility of Results', 'Workflow']	2019/07/25 06:00		['*Department classification', '*Medical services', '*Morpheme growth', '*Neural network', '*Patient question']	['NOTNLM']	NLM	154-168	['2017/03/31 00:00 [received]', '2018/02/05 00:00 [revised]', '2018/04/24 00:00 [accepted]', '2018/05/01 06:00 [pubmed]', '2019/07/25 06:00 [medline]', '2018/04/30 06:00 [entrez]']	United States			29705197	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					J Biomed Inform. 2018 Jun;82:154-168. doi: 10.1016/j.jbi.2018.04.011. Epub 2018 Apr 27.	MEDLINE	J Biomed Inform	Label-indicator morpheme growth on LSTM for Chinese healthcare question department classification.		82	Label-indicator morpheme growth on LSTM for Chinese healthcare question department classification.
PURPOSE: Surgical data science is a new research field that aims to observe all aspects of the patient treatment process in order to provide the right assistance at the right time. Due to the breakthrough successes of deep learning-based solutions for automatic image annotation, the availability of reference annotations for algorithm training is becoming a major bottleneck in the field. The purpose of this paper was to investigate the concept of self-supervised learning to address this issue. METHODS: Our approach is guided by the hypothesis that unlabeled video data can be used to learn a representation of the target domain that boosts the performance of state-of-the-art machine learning algorithms when used for pre-training. Core of the method is an auxiliary task based on raw endoscopic video data of the target domain that is used to initialize the convolutional neural network (CNN) for the target task. In this paper, we propose the re-colorization of medical images with a conditional generative adversarial network (cGAN)-based architecture as auxiliary task. A variant of the method involves a second pre-training step based on labeled data for the target task from a related domain. We validate both variants using medical instrument segmentation as target task. RESULTS: The proposed approach can be used to radically reduce the manual annotation effort involved in training CNNs. Compared to the baseline approach of generating annotated data from scratch, our method decreases exploratively the number of labeled images by up to 75% without sacrificing performance. Our method also outperforms alternative methods for CNN pre-training, such as pre-training on publicly available non-medical (COCO) or medical data (MICCAI EndoVis2017 challenge) using the target task (in this instance: segmentation). CONCLUSION: As it makes efficient use of available (non-)public and (un-)labeled data, the approach has the potential to become a valuable tool for CNN (pre-)training.	['Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany. t.ross@dkfz-heidelberg.de.', 'Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.', 'Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.', 'Division of Biostatistics, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.', 'Translational Surgical Oncology, National Center for Tumor Diseases (NCT), Fetscherstrasse 74, 01307, Dresden, Germany.', 'understand.ai, Hirschstr. 71, 76133, Karlsruhe, Germany.', 'understand.ai, Hirschstr. 71, 76133, Karlsruhe, Germany.', 'Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, 69210, Heidelberg, Germany.', 'Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, 69210, Heidelberg, Germany.', 'Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, 69210, Heidelberg, Germany.', 'Translational Surgical Oncology, National Center for Tumor Diseases (NCT), Fetscherstrasse 74, 01307, Dresden, Germany.', 'Division of Biostatistics, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.', 'Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.', 'Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, 69210, Heidelberg, Germany.']	['10.1007/s11548-018-1772-0 [doi]', '10.1007/s11548-018-1772-0 [pii]']	['Ross T', 'Zimmerer D', 'Vemuri A', 'Isensee F', 'Wiesenfarth M', 'Bodenstedt S', 'Both F', 'Kessler P', 'Wagner M', 'Muller B', 'Kenngott H', 'Speidel S', 'Kopp-Schneider A', 'Maier-Hein K', 'Maier-Hein L']	['ORCID: http://orcid.org/0000-0002-7094-4926']						['2018/04/29 06:00']	20181011	20180427	2018 Jun	2018/04/29 06:00		['Ross, Tobias', 'Zimmerer, David', 'Vemuri, Anant', 'Isensee, Fabian', 'Wiesenfarth, Manuel', 'Bodenstedt, Sebastian', 'Both, Fabian', 'Kessler, Philip', 'Wagner, Martin', 'Muller, Beat', 'Kenngott, Hannes', 'Speidel, Stefanie', 'Kopp-Schneider, Annette', 'Maier-Hein, Klaus', 'Maier-Hein, Lena']			6		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-018-1772-0 [doi]	20181114	['*Algorithms', 'Endoscopy/*education', 'Humans', '*Neural Networks (Computer)', '*Supervised Machine Learning', '*Video Recording']	2018/10/12 06:00		['Computer vision', 'Endoscopic image processing', 'Endoscopic instrument segmentation', 'Self-supervised learning', 'Transfer learning']	['NOTNLM']	NLM	925-933	['2018/01/29 00:00 [received]', '2018/04/16 00:00 [accepted]', '2018/04/29 06:00 [pubmed]', '2018/10/12 06:00 [medline]', '2018/04/29 06:00 [entrez]']	Germany			29704196	ppublish	['Journal Article']			IM		Int J Comput Assist Radiol Surg. 2018 Jun;13(6):925-933. doi: 10.1007/s11548-018-1772-0. Epub 2018 Apr 27.	MEDLINE	Int J Comput Assist Radiol Surg	Exploiting the potential of unlabeled endoscopic video data with self-supervised learning.		13	Exploiting the potential of unlabeled endoscopic video data with self-supervised learning.
Unlike daily routine images, ultrasound images are usually monochrome and low-resolution. In ultrasound images, the cancer regions are usually blurred, vague margin and irregular in shape. Moreover, the features of cancer region are very similar to normal or benign tissues. Therefore, training ultrasound images with original Convolutional Neural Network (CNN) directly is not satisfactory. In our study, inspired by state-of-the-art object detection network Faster R-CNN, we develop a detector which is more suitable for thyroid papillary carcinoma detection in ultrasound images. In order to improve the accuracy of the detection, we add a spatial constrained layer to CNN so that the detector can extract the features of surrounding region in which the cancer regions are residing. In addition, by concatenating the shallow and deep layers of the CNN, the detector can detect blurrier or smaller cancer regions. The experiments demonstrate that the potential of this new methodology can reduce the workload for pathologists and increase the objectivity of diagnoses. We find that 93:5% of papillary thyroid carcinoma regions could be detected automatically while 81:5% of benign and normal tissue could be excluded without the use of any additional immunohistochemical markers or human intervention.	['School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, 510006, China.', 'College of Information Science and Technology/College of Cyber Security, Jinan University, Guangzhou, 510632, China. cryptjweng@gmail.com.', 'TopGene Tech Co., Ltd, Guangzhou, 510627, China.', 'College of Mathematics and Informatics, South China Agricultural University, Guangzhou, 510642, China.', 'College of Mathematics and Informatics, South China Agricultural University, Guangzhou, 510642, China.', 'School of Automation, Guangdong University of Technology, Guangzhou, 510006, China.', 'Sun Yat-sen University Cancer Center, Guangzhou, 510080, China.', 'College of Information Science and Technology/College of Cyber Security, Jinan University, Guangzhou, 510632, China.']	['10.1038/s41598-018-25005-7 [doi]', '10.1038/s41598-018-25005-7 [pii]']	['Li H', 'Weng J', 'Shi Y', 'Gu W', 'Mao Y', 'Wang Y', 'Liu W', 'Zhang J']	['ORCID: 0000-0001-6454-0565']						['2018/04/28 06:00']	20191016	20180426	2018 Apr 26	2018/04/28 06:00		['Li, Hailiang', 'Weng, Jian', 'Shi, Yujian', 'Gu, Wanrong', 'Mao, Yijun', 'Wang, Yonghua', 'Liu, Weiwei', 'Zhang, Jiajie']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-25005-7 [doi]	20191016	['Adolescent', 'Adult', 'Aged', 'Aged, 80 and over', 'Algorithms', 'Child', '*Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted', 'Male', 'Middle Aged', 'ROC Curve', 'Sensitivity and Specificity', 'Software', 'Thyroid Cancer, Papillary/*diagnostic imaging/pathology', '*Ultrasonography/methods/standards', 'Young Adult']	2019/10/17 06:00				NLM	6600	['2017/10/19 00:00 [received]', '2018/04/11 00:00 [accepted]', '2018/04/28 06:00 [entrez]', '2018/04/28 06:00 [pubmed]', '2019/10/17 06:00 [medline]']	England	PMC5920067		29700427	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Apr 26;8(1):6600. doi: 10.1038/s41598-018-25005-7.	MEDLINE	Sci Rep	An improved deep learning approach for detection of thyroid papillary cancer in ultrasound images.		8	An improved deep learning approach for detection of thyroid papillary cancer in ultrasound images.
Anonymized electronic medical records are an increasingly popular source of research data. However, these datasets often lack race and ethnicity information. This creates problems for researchers modeling human disease, as race and ethnicity are powerful confounders for many health exposures and treatment outcomes; race and ethnicity are closely linked to population-specific genetic variation. We showed that deep neural networks generate more accurate estimates for missing racial and ethnic information than competing methods (e.g., logistic regression, random forest, support vector machines, and gradient-boosted decision trees). RIDDLE yielded significantly better classification performance across all metrics that were considered: accuracy, cross-entropy loss (error), precision, recall, and area under the curve for receiver operating characteristic plots (all p < 10-9). We made specific efforts to interpret the trained neural network models to identify, quantify, and visualize medical features which are predictive of race and ethnicity. We used these characterizations of informative features to perform a systematic comparison of differential disease patterns by race and ethnicity. The fact that clinical histories are informative for imputing race and ethnicity could reflect (1) a skewed distribution of blue- and white-collar professions across racial and ethnic groups, (2) uneven accessibility and subjective importance of prophylactic health, (3) possible variation in lifestyle, such as dietary habits, and (4) differences in background genetic variation which predispose to diseases.	['Department of Computer Science, Princeton University, Princeton, New Jersey, United States of America.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia.', 'Institute for Genomics and Systems Biology, Computation Institute, Departments of Medicine and Human Genetics, University of Chicago, Chicago, Illinois, United States of America.']	['10.1371/journal.pcbi.1006106 [doi]', 'PCOMPBIOL-D-17-00984 [pii]']	['Kim JS', 'Gao X', 'Rzhetsky A']	['ORCID: 0000-0002-8966-529X', 'ORCID: 0000-0002-7108-3574', 'ORCID: 0000-0001-6959-7405']						['2018/04/27 06:00']	20180618	20180426	2018 Apr	2018/04/27 06:00		['Kim, Ji-Sung', 'Gao, Xin', 'Rzhetsky, Andrey']		['R01HL122712 /NH/NIH HHS/United States', 'P50 MH094267 /NH/NIH HHS/United States']	4		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1006106 [doi]	20181114	['Computational Biology', '*Continental Population Groups/genetics/statistics & numerical data', 'Electronic Health Records/*statistics & numerical data', 'Epidemiologic Factors', '*Ethnic Groups/genetics/statistics & numerical data', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genetics, Population/statistics & numerical data', 'Humans', 'Neural Networks (Computer)', 'Supervised Machine Learning']	2018/06/19 06:00				NLM	e1006106	['2017/06/19 00:00 [received]', '2018/03/20 00:00 [accepted]', '2018/05/08 00:00 [revised]', '2018/04/27 06:00 [pubmed]', '2018/06/19 06:00 [medline]', '2018/04/27 06:00 [entrez]']	United States	PMC5940243		29698408	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS Comput Biol. 2018 Apr 26;14(4):e1006106. doi: 10.1371/journal.pcbi.1006106. eCollection 2018 Apr.	MEDLINE	PLoS Comput Biol	RIDDLE: Race and ethnicity Imputation from Disease history with Deep LEarning.		14	RIDDLE: Race and ethnicity Imputation from Disease history with Deep LEarning.
This Perspective provides examples of current and future applications of deep learning in pharmacogenomics, including: identification of novel regulatory variants located in noncoding domains of the genome and their function as applied to pharmacoepigenomics; patient stratification from medical records; and the mechanistic prediction of drug response, targets and their interactions. Deep learning encapsulates a family of machine learning algorithms that has transformed many important subfields of artificial intelligence over the last decade, and has demonstrated breakthrough performance improvements on a wide range of tasks in biomedicine. We anticipate that in the future, deep learning will be widely used to predict personalized drug response and optimize medication selection and dosing, using knowledge extracted from large and complex molecular, epidemiological, clinical and demographic datasets.	['Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Statistics Online Computational Resource (SOCR), University of Michigan School of Nursing, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Statistics Online Computational Resource (SOCR), University of Michigan School of Nursing, Ann Arbor, MI 48109, USA.', 'Michigan Institute for Data Science (MIDAS), University of Michigan, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Department of Emergency Medicine, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Department of Computational Medicine & Bioinformatics, University of Michigan Medical School, Ann Arbor, MI 48109, USA.', 'Michigan Institute for Data Science (MIDAS), University of Michigan, Ann Arbor, MI 48109, USA.', 'Department of Internal Medicine, University of Michigan Health System, Ann Arbor, MI 48109, USA.', 'Department of Psychiatry, University of Michigan Medical School, Ann Arbor, MI 48109, USA.']	['10.2217/pgs-2018-0008 [doi]']	['Kalinin AA', 'Higgins GA', 'Reamaroon N', 'Soroushmehr S', 'Allyn-Feuer A', 'Dinov ID', 'Najarian K', 'Athey BD']							['2018/04/27 06:00']	20190211	20180426	2018 May	2018/04/27 06:00		['Kalinin, Alexandr A', 'Higgins, Gerald A', 'Reamaroon, Narathip', 'Soroushmehr, Sayedmohammadreza', 'Allyn-Feuer, Ari', 'Dinov, Ivo D', 'Najarian, Kayvan', 'Athey, Brian D']		['P30 AG053760/AG/NIA NIH HHS/United States', 'U54 EB020406/EB/NIBIB NIH HHS/United States', 'P20 NR015331/NR/NINR NIH HHS/United States', 'T32 GM070449/GM/NIGMS NIH HHS/United States', 'P30 DK089503/DK/NIDDK NIH HHS/United States', 'P50 NS091856/NS/NINDS NIH HHS/United States']	7		1744-8042 (Electronic) 1462-2416 (Linking)	100897350	Pharmacogenomics	['eng']	10.2217/pgs-2018-0008 [doi]	20190502	['Algorithms', 'Databases as Topic', '*Deep Learning/trends', 'Humans', '*Models, Educational', 'Neural Networks (Computer)', 'Pharmacogenetics/*education/*trends']	2019/02/12 06:00		['*adverse events', '*artificial intelligence', '*deep learning', '*drug discovery', '*drug-drug interaction', '*drug-gene interaction', '*noncoding regulatory variation', '*patient stratification', '*pharmacogenomics']	['NOTNLM']	NLM	629-650	['2018/04/27 06:00 [pubmed]', '2019/02/12 06:00 [medline]', '2018/04/27 06:00 [entrez]']	England	PMC6022084		29697304	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S."", 'Review']"			IM		Pharmacogenomics. 2018 May;19(7):629-650. doi: 10.2217/pgs-2018-0008. Epub 2018 Apr 26.	MEDLINE	Pharmacogenomics	Deep learning in pharmacogenomics: from gene regulation to patient stratification.		19	Deep learning in pharmacogenomics: from gene regulation to patient stratification.
Human activity recognition is a challenging problem for context-aware systems and applications. It is gaining interest due to the ubiquity of different sensor sources, wearable smart objects, ambient sensors, etc. This task is usually approached as a supervised machine learning problem, where a label is to be predicted given some input data, such as the signals retrieved from different sensors. For tackling the human activity recognition problem in sensor network environments, in this paper we propose the use of deep learning (convolutional neural networks) to perform activity recognition using the publicly available OPPORTUNITY dataset. Instead of manually choosing a suitable topology, we will let an evolutionary algorithm design the optimal topology in order to maximize the classification F1 score. After that, we will also explore the performance of committees of the models resulting from the evolutionary process. Results analysis indicates that the proposed model was able to perform activity recognition within a heterogeneous sensor network environment, achieving very high accuracies when tested with new sensor data. Based on all conducted experiments, the proposed neuroevolutionary system has proved to be able to systematically find a classification model which is capable of outperforming previous results reported in the state-of-the-art, showing that this approach is useful and improves upon previously manually-designed architectures.	['Computer Science Department, Universidad Carlos III de Madrid, 28911 Leganes, Spain. abaldomi@inf.uc3m.es.', 'Computer Science Department, Universidad Carlos III de Madrid, 28911 Leganes, Spain. yago.saez@uc3m.es.', 'Computer Science Department, Universidad Carlos III de Madrid, 28911 Leganes, Spain. isasi@ia.uc3m.es.']	['s18041288 [pii]', '10.3390/s18041288 [doi]']	['Baldominos A', 'Saez Y', 'Isasi P']	['ORCID: 0000-0002-8906-7572', 'ORCID: 0000-0002-0998-2907', 'ORCID: 0000-0002-5121-4821']				['The authors declare no conflict of interest.']		['2018/04/26 06:00']	20180605	20180423	2018 Apr 23	2018/04/25 06:00		['Baldominos, Alejandro', 'Saez, Yago', 'Isasi, Pedro']			4		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E1288 [pii] 10.3390/s18041288 [doi]	20181202	['Algorithms', '*Biological Evolution', 'Human Activities', 'Humans', 'Machine Learning', 'Neural Networks (Computer)']	2018/06/06 06:00		['convolutional neural networks', 'deep learning', 'human activity recognition', 'neuroevolution']	['NOTNLM']	NLM		['2018/03/19 00:00 [received]', '2018/04/17 00:00 [revised]', '2018/04/19 00:00 [accepted]', '2018/04/26 06:00 [entrez]', '2018/04/25 06:00 [pubmed]', '2018/06/06 06:00 [medline]']	Switzerland	PMC5948523		29690587	epublish	['Journal Article']			IM		Sensors (Basel). 2018 Apr 23;18(4). pii: s18041288. doi: 10.3390/s18041288.	MEDLINE	Sensors (Basel)	Evolutionary Design of Convolutional Neural Networks for Human Activity Recognition in Sensor-Rich Environments.		18	Evolutionary Design of Convolutional Neural Networks for Human Activity Recognition in Sensor-Rich Environments.
PURPOSE: An end-to-end deep convolutional neural network (CNN) based on deep residual network (ResNet) was proposed to efficiently reconstruct reliable T2 mapping from single-shot overlapping-echo detachment (OLED) planar imaging. METHODS: The training dataset was obtained from simulations that were carried out on SPROM (Simulation with PRoduct Operator Matrix) software developed by our group. The relationship between the original OLED image containing two echo signals and the corresponding T2 mapping was learned by ResNet training. After the ResNet was trained, it was applied to reconstruct the T2 mapping from simulation and in vivo human brain data. RESULTS: Although the ResNet was trained entirely on simulated data, the trained network was generalized well to real human brain data. The results from simulation and in vivo human brain experiments show that the proposed method significantly outperforms the echo-detachment-based method. Reliable T2 mapping with higher accuracy is achieved within 30 ms after the network has been trained, while the echo-detachment-based OLED reconstruction method took approximately 2 min. CONCLUSION: The proposed method will facilitate real-time dynamic and quantitative MR imaging via OLED sequence, and deep convolutional neural network has the potential to reconstruct maps from complex MRI sequences efficiently.	['Department of Electronic Science, Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, Xiamen University, Xiamen, China.', 'Department of Communication Engineering, Xiamen University, Xiamen, China.', 'Department of Communication Engineering, Xiamen University, Xiamen, China.', 'Department of Communication Engineering, Xiamen University, Xiamen, China.', 'Department of Electronic Science, Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, Xiamen University, Xiamen, China.', 'Paul C. Lauterbur Research Center for Biomedical Imaging, Shenzhen Institutes of Advanced Technology, CAS, Shenzhen, China.', 'Department of Communication Engineering, Xiamen University, Xiamen, China.', 'Department of Electronic Science, Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, Xiamen University, Xiamen, China.', 'Department of Communication Engineering, Xiamen University, Xiamen, China.', 'Department of Imaging Sciences, University of Rochester, Rochester, New York.', 'The Center for Brain Imaging Science and Technology and Collaborative Innovation Center for Diagnosis and Treatment of Infectious Diseases, Zhejiang University, Hangzhou, China.']	['10.1002/mrm.27205 [doi]']	['Cai C', 'Wang C', 'Zeng Y', 'Cai S', 'Liang D', 'Wu Y', 'Chen Z', 'Ding X', 'Zhong J']		['(c) 2018 International Society for Magnetic Resonance in Medicine.']					['2018/04/25 06:00']	20190917	20180424	2018 Nov	2018/04/25 06:00		['Cai, Congbo', 'Wang, Chao', 'Zeng, Yiqing', 'Cai, Shuhui', 'Liang, Dong', 'Wu, Yawen', 'Chen, Zhong', 'Ding, Xinghao', 'Zhong, Jianhui']			5		1522-2594 (Electronic) 0740-3194 (Linking)	8505245	Magnetic resonance in medicine	['eng']	10.1002/mrm.27205 [doi]	20190917	['Adult', 'Algorithms', 'Brain/diagnostic imaging', 'Computer Simulation', '*Deep Learning', 'Echo-Planar Imaging/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Phantoms, Imaging']	2019/09/19 06:00		['*T2 mapping', '*convolutional neural network', '*deep learning', '*image reconstruction', '*residual network']	['NOTNLM']	NLM	2202-2214	['2018/01/13 00:00 [received]', '2018/02/28 00:00 [revised]', '2018/03/11 00:00 [accepted]', '2018/04/25 06:00 [pubmed]', '2019/09/19 06:00 [medline]', '2018/04/25 06:00 [entrez]']	United States			29687915	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Magn Reson Med. 2018 Nov;80(5):2202-2214. doi: 10.1002/mrm.27205. Epub 2018 Apr 24.	MEDLINE	Magn Reson Med	Single-shot T2 mapping using overlapping-echo detachment planar imaging and a deep convolutional neural network.		80	Single-shot T2 mapping using overlapping-echo detachment planar imaging and a deep convolutional neural network.
Recent improvements in biomedical image analysis using deep learning based neural networks could be exploited to enhance the performance of Computer Aided Diagnosis (CAD) systems. Considering the importance of breast cancer worldwide and the promising results reported by deep learning based methods in breast imaging, an overview of the recent state-of-the-art deep learning based CAD systems developed for mammography and breast histopathology images is presented. In this study, the relationship between mammography and histopathology phenotypes is described, which takes biological aspects into account. We propose a computer based breast cancer modelling approach: the Mammography-Histology-Phenotype-Linking-Model, which develops a mapping of features/phenotypes between mammographic abnormalities and their histopathological representation. Challenges are discussed along with the potential contribution of such a system to clinical decision making and treatment management.	['Department of Computer Science, Aberystwyth University, United Kingdom. Electronic address: azh2@aber.ac.uk.', 'Department of Radiology, Norfolk and Norwich University Hospital, United Kingdom. Electronic address: erika.denton@nnuh.nhs.uk.', 'School of Computing, Ulster University, Coleraine, Northern Ireland, United Kingdom. Electronic address: y.rampun@ulster.ac.uk.', 'Department of Histopathology/Cytopathology, Norfolk and Norwich University Hospital, United Kingdom. Electronic address: kate.honnor@nnuh.nhs.uk.', 'Department of Computer Science, Aberystwyth University, United Kingdom. Electronic address: rrz@aber.ac.uk.']	['S1361-8415(18)30090-2 [pii]', '10.1016/j.media.2018.03.006 [doi]']	['Hamidinekoo A', 'Denton E', 'Rampun A', 'Honnor K', 'Zwiggelaar R']		['Crown Copyright (c) 2018. Published by Elsevier B.V. All rights reserved.']					['2018/04/22 06:00']	20190531	20180326	2018 Jul	2018/04/22 06:00		['Hamidinekoo, Azam', 'Denton, Erika', 'Rampun, Andrik', 'Honnor, Kate', 'Zwiggelaar, Reyer']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(18)30090-2 [pii] 10.1016/j.media.2018.03.006 [doi]	20190531	['Algorithms', 'Breast Neoplasms/*diagnostic imaging/*pathology', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Female', 'Forecasting', 'Humans', '*Mammography', 'Neural Networks (Computer)', 'Phenotype', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Sensitivity and Specificity']	2019/06/01 06:00		['*Breast histopathology', '*Computer Aided Diagnosis', '*Deep learning', '*Mammography']	['NOTNLM']	NLM	45-67	['2017/07/26 00:00 [received]', '2018/01/03 00:00 [revised]', '2018/03/14 00:00 [accepted]', '2018/04/22 06:00 [pubmed]', '2019/06/01 06:00 [medline]', '2018/04/22 06:00 [entrez]']	Netherlands			29679847	ppublish	['Journal Article', 'Review']			IM		Med Image Anal. 2018 Jul;47:45-67. doi: 10.1016/j.media.2018.03.006. Epub 2018 Mar 26.	MEDLINE	Med Image Anal	Deep learning in mammography and breast histology, an overview and future trends.		47	Deep learning in mammography and breast histology, an overview and future trends.
Timely determination of antimicrobial susceptibility for a bacterial infection enables precision prescription, shortens treatment time, and helps minimize the spread of antibiotic resistant infections. Current antimicrobial susceptibility testing (AST) methods often take several days and thus impede these clinical and health benefits. Here, we present an AST method by imaging freely moving bacterial cells in urine in real time and analyzing the videos with a deep learning algorithm. The deep learning algorithm determines if an antibiotic inhibits a bacterial cell by learning multiple phenotypic features of the cell without the need for defining and quantifying each feature. We apply the method to urinary tract infection, a common infection that affects millions of people, to determine the minimum inhibitory concentration of pathogens from human urine specimens spiked with lab strain E. coli (ATCC 43888) and an E. coli strain isolated from a clinical urine sample for different antibiotics within 30 min and validate the results with the gold standard broth macrodilution method. The deep learning video microscopy-based AST holds great potential to contribute to the solution of increasing drug-resistant infections.	['Institute for Personalized Medicine, School of Biomedical Engineering , Shanghai Jiao Tong University , Shanghai 200030 , China.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'State Key Laboratory of Analytical Chemistry for Life Science, School of Chemistry and Chemical Engineering , Nanjing University , Nanjing 210093 , China.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'State Key Laboratory of Analytical Chemistry for Life Science, School of Chemistry and Chemical Engineering , Nanjing University , Nanjing 210093 , China.', 'Department of Laboratory Medicine and Pathology, Mayo Clinic , Phoenix , Arizona 85054 , United States.', 'Biodesign Center for Immunotherapy, Vaccines, and Virotherapy , Arizona State University , Tempe , Arizona 85287 , United States.', 'School of Life Sciences , Arizona State University , Tempe , Arizona 85287 , United States.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'State Key Laboratory of Analytical Chemistry for Life Science, School of Chemistry and Chemical Engineering , Nanjing University , Nanjing 210093 , China.', 'Biodesign Center for Biosensors and Bioelectronics , Arizona State University , Tempe , Arizona 85287 , United States.', 'State Key Laboratory of Analytical Chemistry for Life Science, School of Chemistry and Chemical Engineering , Nanjing University , Nanjing 210093 , China.', 'School of Electrical, Computer and Energy Engineering , Arizona State University , Tempe , Arizona 85287 , United States.']	['10.1021/acs.analchem.8b01128 [doi]']	['Yu H', 'Jing W', 'Iriya R', 'Yang Y', 'Syal K', 'Mo M', 'Grys TE', 'Haydel SE', 'Wang S', 'Tao N']	['ORCID: 0000-0002-6927-4451', 'ORCID: 0000-0002-4223-2024', 'ORCID: 0000-0002-2680-0503']						['2018/04/21 06:00']	20190417	20180503	2018 May 15	2018/04/21 06:00	['Anal Chem. 2018 Jun 19;90(12):7784. PMID: 29847094']	['Yu, Hui', 'Jing, Wenwen', 'Iriya, Rafael', 'Yang, Yunze', 'Syal, Karan', 'Mo, Manni', 'Grys, Thomas E', 'Haydel, Shelley E', 'Wang, Shaopeng', 'Tao, Nongjian']			10		1520-6882 (Electronic) 0003-2700 (Linking)	0370536	Analytical chemistry	['eng']	10.1021/acs.analchem.8b01128 [doi]	20190417	['Anti-Bacterial Agents/*pharmacology', '*Deep Learning', 'Humans', 'Microbial Sensitivity Tests', 'Microscopy, Video', 'Phenotype', 'Urinary Tract Infections/microbiology', 'Urine/microbiology']	2019/04/18 06:00				NLM	6314-6322	['2018/04/21 06:00 [pubmed]', '2019/04/18 06:00 [medline]', '2018/04/21 06:00 [entrez]']	United States			29677440	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Anti-Bacterial Agents)']	IM		Anal Chem. 2018 May 15;90(10):6314-6322. doi: 10.1021/acs.analchem.8b01128. Epub 2018 May 3.	MEDLINE	Anal Chem	Phenotypic Antimicrobial Susceptibility Testing with Deep Learning Video Microscopy.		90	Phenotypic Antimicrobial Susceptibility Testing with Deep Learning Video Microscopy.
Motivation: Antibodies play essential roles in the immune system of vertebrates and are powerful tools in research and diagnostics. While hypervariable regions of antibodies, which are responsible for binding, can be readily identified from their amino acid sequence, it remains challenging to accurately pinpoint which amino acids will be in contact with the antigen (the paratope). Results: In this work, we present a sequence-based probabilistic machine learning algorithm for paratope prediction, named Parapred. Parapred uses a deep-learning architecture to leverage features from both local residue neighbourhoods and across the entire sequence. The method significantly improves on the current state-of-the-art methodology, and only requires a stretch of amino acid sequence corresponding to a hypervariable region as an input, without any information about the antigen. We further show that our predictions can be used to improve both speed and accuracy of a rigid docking algorithm. Availability and implementation: The Parapred method is freely available as a webserver at http://www-mvsoftware.ch.cam.ac.uk/and for download at https://github.com/eliberis/parapred. Supplementary information: Supplementary information is available at Bioinformatics online.	['Department of Computer Science and Technology, University of Cambridge, UK.', 'Department of Computer Science and Technology, University of Cambridge, UK.', 'Department of Chemistry, University of Cambridge, UK.', 'Department of Chemistry, University of Cambridge, UK.', 'Department of Computer Science and Technology, University of Cambridge, UK.']	['4972995 [pii]', '10.1093/bioinformatics/bty305 [doi]']	['Liberis E', 'Velickovic P', 'Sormanni P', 'Vendruscolo M', 'Lio P']							['2018/04/20 06:00']	20190930		2018 Sep 1	2018/04/20 06:00		['Liberis, Edgar', 'Velickovic, Petar', 'Sormanni, Pietro', 'Vendruscolo, Michele', 'Lio, Pietro']			17		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty305 [doi]	20190930	['Algorithms', 'Amino Acid Sequence', 'Antibodies/*chemistry/immunology', 'Binding Sites, Antibody', 'Deep Learning', 'Machine Learning', 'Models, Molecular', 'Neural Networks (Computer)']	2019/10/01 06:00				NLM	2944-2950	['2017/10/18 00:00 [received]', '2018/04/13 00:00 [accepted]', '2018/04/20 06:00 [pubmed]', '2019/10/01 06:00 [medline]', '2018/04/20 06:00 [entrez]']	England			29672675	ppublish	['Journal Article']		['0 (Antibodies)']	IM		Bioinformatics. 2018 Sep 1;34(17):2944-2950. doi: 10.1093/bioinformatics/bty305.	MEDLINE	Bioinformatics	Parapred: antibody paratope prediction using convolutional and recurrent neural networks.		34	Parapred: antibody paratope prediction using convolutional and recurrent neural networks.
	['a Department of Chemistry and Applied Biosciences , Swiss Federal Institute of Technology (ETH) , Zurich , Switzerland.', 'a Department of Chemistry and Applied Biosciences , Swiss Federal Institute of Technology (ETH) , Zurich , Switzerland.', 'b Laboratory for Molecular Biosciences, Life Science Informatics Research Unit , Kyoto University Graduate School of Medicine , Kyoto , Japan.', 'a Department of Chemistry and Applied Biosciences , Swiss Federal Institute of Technology (ETH) , Zurich , Switzerland.']	['10.1080/17460441.2018.1465407 [doi]']	['Gawehn E', 'Hiss JA', 'Brown JB', 'Schneider G']	['ORCID: 0000-0001-6706-1084']						['2018/04/19 06:00']	20190219	20180418	2018 Jul	2018/04/19 06:00		['Gawehn, Erik', 'Hiss, Jan A', 'Brown, J B', 'Schneider, Gisbert']			7		1746-045X (Electronic) 1746-0441 (Linking)	101295755	Expert opinion on drug discovery	['eng']	10.1080/17460441.2018.1465407 [doi]	20190320	['*Computer Graphics', '*Deep Learning', 'Drug Discovery/*methods', 'Humans', 'Neural Networks (Computer)']	2019/03/21 06:00		['*Artificial neural network', '*chemoinformatics', '*drug design', '*graphics processing unit', '*virtual screening']	['NOTNLM']	NLM	579-582	['2018/04/19 06:00 [pubmed]', '2019/03/21 06:00 [medline]', '2018/04/19 06:00 [entrez]']	England			29668343	ppublish	"['Editorial', ""Research Support, Non-U.S. Gov't""]"			IM		Expert Opin Drug Discov. 2018 Jul;13(7):579-582. doi: 10.1080/17460441.2018.1465407. Epub 2018 Apr 18.	MEDLINE	Expert Opin Drug Discov	Advancing drug discovery via GPU-based deep learning.		13	Advancing drug discovery via GPU-based deep learning.
Open-domain conversation is one of the most challenging artificial intelligence problems, which involves language understanding, reasoning, and the utilization of common sense knowledge. The goal of this paper is to further improve the response generation, using personalization criteria. We propose a novel method called PRGDDA (Personalized Response Generation by Dual-learning based Domain Adaptation) which is a personalized response generation model based on theories of domain adaptation and dual learning. During the training procedure, PRGDDA first learns the human responding style from large general data (without user-specific information), and then fine-tunes the model on a small size of personalized data to generate personalized conversations with a dual learning mechanism. We conduct experiments to verify the effectiveness of the proposed model on two real-world datasets in both English and Chinese. Experimental results show that our model can generate better personalized responses for different users.	['Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China. Electronic address: min.yang@siat.ac.cn.', 'School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China. Electronic address: tu.wenting@mail.shufe.edu.cn.', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China. Electronic address: qiang@siat.ac.cn.', 'School of Computing Science, Zhejiang University, Hangzhou, China. Electronic address: zhouzhao@zju.edu.cn.', 'College of Computer Science and Software, Shenzhen University, Shenzhen, China. Electronic address: xchen@szu.edu.cn.', 'School of Computer Science, South China Normal University, Guangzhou, China. Electronic address: jzhu@m.scnu.edu.cn.']	['S0893-6080(18)30094-7 [pii]', '10.1016/j.neunet.2018.03.009 [doi]']	['Yang M', 'Tu W', 'Qu Q', 'Zhao Z', 'Chen X', 'Zhu J']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/04/18 06:00']	20180827	20180405	2018 Jul	2018/04/18 06:00		['Yang, Min', 'Tu, Wenting', 'Qu, Qiang', 'Zhao, Zhou', 'Chen, Xiaojun', 'Zhu, Jia']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30094-7 [pii] 10.1016/j.neunet.2018.03.009 [doi]	20181202	['*Artificial Intelligence/trends', 'Databases, Factual/statistics & numerical data/trends', 'Humans', 'Language', 'Learning', '*Machine Learning', '*Multilingualism']	2018/08/28 06:00		['Deep reinforcement learning', 'Domain adaptation', 'Dual learning', 'Personalized response generation']	['NOTNLM']	NLM	72-82	['2017/09/04 00:00 [received]', '2018/01/27 00:00 [revised]', '2018/03/14 00:00 [accepted]', '2018/04/18 06:00 [pubmed]', '2018/08/28 06:00 [medline]', '2018/04/18 06:00 [entrez]']	United States			29665538	ppublish	['Journal Article']			IM		Neural Netw. 2018 Jul;103:72-82. doi: 10.1016/j.neunet.2018.03.009. Epub 2018 Apr 5.	MEDLINE	Neural Netw	Personalized response generation by Dual-learning based domain adaptation.		103	Personalized response generation by Dual-learning based domain adaptation.
Digital breast tomosynthesis (DBT) was developed in the field of breast cancer screening as a new tomographic technique to minimize the limitations of conventional digital mammography breast screening methods. A computer-aided detection (CAD) framework for mass detection in DBT has been developed and is described in this paper. The proposed framework operates on a set of two-dimensional (2D) slices. With plane-to-plane analysis on corresponding 2D slices from each DBT, it automatically learns complex patterns of 2D slices through a deep convolutional neural network (DCNN). It then applies multiple instance learning (MIL) with a randomized trees approach to classify DBT images based on extracted information from 2D slices. This CAD framework was developed and evaluated using 5040 2D image slices derived from 87 DBT volumes. The empirical results demonstrate that this proposed CAD framework achieves much better performance than CAD systems that use hand-crafted features and deep cardinality-restricted Bolzmann machines to detect masses in DBTs.	['Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, Quebec H3G 1M8, Canada. Electronic address: mi_yous@encs.concordia.ca.', 'Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, Quebec H3G 1M8, Canada.', 'Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, Quebec H3G 1M8, Canada.']	['S0010-4825(18)30079-9 [pii]', '10.1016/j.compbiomed.2018.04.004 [doi]']	['Yousefi M', 'Krzyzak A', 'Suen CY']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/04/18 06:00']	20190513	20180412	2018 May 1	2018/04/18 06:00		['Yousefi, Mina', 'Krzyzak, Adam', 'Suen, Ching Y']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(18)30079-9 [pii] 10.1016/j.compbiomed.2018.04.004 [doi]	20190513	['Algorithms', 'Breast/diagnostic imaging', 'Breast Neoplasms/*diagnostic imaging', '*Deep Learning', 'Female', 'Humans', 'Mammography/*methods', 'Radiographic Image Interpretation, Computer-Assisted/*methods']	2019/05/14 06:00		['*Computer-aided detection', '*Deep convolutional neural networks', '*Deep learning', '*Digital breast tomosynthesis', '*Masses', '*Multiple instance learning']	['NOTNLM']	NLM	283-293	['2018/02/15 00:00 [received]', '2018/04/05 00:00 [revised]', '2018/04/06 00:00 [accepted]', '2018/04/18 06:00 [pubmed]', '2019/05/14 06:00 [medline]', '2018/04/18 06:00 [entrez]']	United States			29665537	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Biol Med. 2018 May 1;96:283-293. doi: 10.1016/j.compbiomed.2018.04.004. Epub 2018 Apr 12.	MEDLINE	Comput Biol Med	Mass detection in digital breast tomosynthesis data using convolutional neural networks and multiple instance learning.		96	Mass detection in digital breast tomosynthesis data using convolutional neural networks and multiple instance learning.
BACKGROUND: Deep learning is the most promising methodology for automatic computer-aided diagnosis of prostate cancer (PCa) with multiparametric MRI (mp-MRI). PURPOSE: To develop an automatic approach based on deep convolutional neural network (DCNN) to classify PCa and noncancerous tissues (NC) with mp-MRI. STUDY TYPE: Retrospective. SUBJECTS: In all, 195 patients with localized PCa were collected from a PROSTATEx database. In total, 159/17/19 patients with 444/48/55 observations (215/23/23 PCas and 229/25/32 NCs) were randomly selected for training/validation/testing, respectively. SEQUENCE: T2 -weighted, diffusion-weighted, and apparent diffusion coefficient images. ASSESSMENT: A radiologist manually labeled the regions of interest of PCas and NCs and estimated the Prostate Imaging Reporting and Data System (PI-RADS) scores for each region. Inspired by VGG-Net, we designed a patch-based DCNN model to distinguish between PCa and NCs based on a combination of mp-MRI data. Additionally, an enhanced prediction method was used to improve the prediction accuracy. The performance of DCNN prediction was tested using a receiver operating characteristic (ROC) curve, and the area under the ROC curve (AUC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were calculated. Moreover, the predicted result was compared with the PI-RADS score to evaluate its clinical value using decision curve analysis. STATISTICAL TEST: Two-sided Wilcoxon signed-rank test with statistical significance set at 0.05. RESULTS: The DCNN produced excellent diagnostic performance in distinguishing between PCa and NC for testing datasets with an AUC of 0.944 (95% confidence interval: 0.876-0.994), sensitivity of 87.0%, specificity of 90.6%, PPV of 87.0%, and NPV of 90.6%. The decision curve analysis revealed that the joint model of PI-RADS and DCNN provided additional net benefits compared with the DCNN model and the PI-RADS scheme. DATA CONCLUSION: The proposed DCNN-based model with enhanced prediction yielded high performance in statistical analysis, suggesting that DCNN could be used in computer-aided diagnosis (CAD) for PCa classification. LEVEL OF EVIDENCE: 3 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2018;48:1570-1577.	['Shanghai Key Laboratory of Magnetic Resonance, East China Normal University, Shanghai, China.', 'Department of Radiology, First Affiliated Hospital with Nanjing Medical University, Nanjing, China.', 'MR Scientific Marketing, Siemens Healthcare, Shanghai, China.', 'Research Department, hImagingTek Ltd., Shanghai, China.', 'Shanghai University of Medicine & Health Sciences, Shanghai, China.', 'Shanghai Key Laboratory of Magnetic Resonance, East China Normal University, Shanghai, China.', 'Shanghai Key Laboratory of Magnetic Resonance, East China Normal University, Shanghai, China.']	['10.1002/jmri.26047 [doi]']	['Song Y', 'Zhang YD', 'Yan X', 'Liu H', 'Zhou M', 'Hu B', 'Yang G']	['ORCID: 0000-0001-7426-4496']	['(c) 2018 International Society for Magnetic Resonance in Medicine.']					['2018/04/17 06:00']	20191028	20180416	2018 Dec	2018/04/17 06:00		['Song, Yang', 'Zhang, Yu-Dong', 'Yan, Xu', 'Liu, Hui', 'Zhou, Minxiong', 'Hu, Bingwen', 'Yang, Guang']		['61731009/Key Project of the National Natural Science Foundation of', 'China/International', '2015M580453/China Postdoctoral Fund/International', 'BE2017756/Key Social Development Program for the Ministry of Science and', 'Technology of Jiangsu Province/International']	6		1522-2586 (Electronic) 1053-1807 (Linking)	9105850	Journal of magnetic resonance imaging : JMRI	['eng']	10.1002/jmri.26047 [doi]	20191028	['Area Under Curve', 'Databases, Factual', 'Deep Learning', 'Diagnosis, Computer-Assisted/*methods', '*Diffusion Magnetic Resonance Imaging', 'Humans', 'Male', '*Neural Networks (Computer)', 'Pattern Recognition, Automated', 'Predictive Value of Tests', 'Prostatic Neoplasms/*diagnostic imaging', 'ROC Curve', 'Reproducibility of Results', 'Retrospective Studies', 'Sensitivity and Specificity', 'Software']	2019/10/29 06:00		['*deep convolutional neural network', '*enhanced prediction', '*mp-MRI', '*multiparametric magnetic resonance imaging', '*prostate cancer']	['NOTNLM']	NLM	1570-1577	['2018/01/09 00:00 [received]', '2018/03/23 00:00 [accepted]', '2018/04/17 06:00 [pubmed]', '2019/10/29 06:00 [medline]', '2018/04/17 06:00 [entrez]']	United States			29659067	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Magn Reson Imaging. 2018 Dec;48(6):1570-1577. doi: 10.1002/jmri.26047. Epub 2018 Apr 16.	MEDLINE	J Magn Reson Imaging	Computer-aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI.		48	Computer-aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI.
BACKGROUND: Automatic identification of term variants or acceptable alternative free-text terms for gene and protein names from the millions of biomedical publications is a challenging task. Ontologies, such as the Cardiovascular Disease Ontology (CVDO), capture domain knowledge in a computational form and can provide context for gene/protein names as written in the literature. This study investigates: 1) if word embeddings from Deep Learning algorithms can provide a list of term variants for a given gene/protein of interest; and 2) if biological knowledge from the CVDO can improve such a list without modifying the word embeddings created. METHODS: We have manually annotated 105 gene/protein names from 25 PubMed titles/abstracts and mapped them to 79 unique UniProtKB entries corresponding to gene and protein classes from the CVDO. Using more than 14 M PubMed articles (titles and available abstracts), word embeddings were generated with CBOW and Skip-gram. We setup two experiments for a synonym detection task, each with four raters, and 3672 pairs of terms (target term and candidate term) from the word embeddings created. For Experiment I, the target terms for 64 UniProtKB entries were those that appear in the titles/abstracts; Experiment II involves 63 UniProtKB entries and the target terms are a combination of terms from PubMed titles/abstracts with terms (i.e. increased context) from the CVDO protein class expressions and labels. RESULTS: In Experiment I, Skip-gram finds term variants (full and/or partial) for 89% of the 64 UniProtKB entries, while CBOW finds term variants for 67%. In Experiment II (with the aid of the CVDO), Skip-gram finds term variants for 95% of the 63 UniProtKB entries, while CBOW finds term variants for 78%. Combining the results of both experiments, Skip-gram finds term variants for 97% of the 79 UniProtKB entries, while CBOW finds term variants for 81%. CONCLUSIONS: This study shows performance improvements for both CBOW and Skip-gram on a gene/protein synonym detection task by adding knowledge formalised in the CVDO and without modifying the word embeddings created. Hence, the CVDO supplies context that is effective in inducing term variability for both CBOW and Skip-gram while reducing ambiguity. Skip-gram outperforms CBOW and finds more pertinent term variants for gene/protein names annotated from the scientific literature.	['School of Computer Science, University of Manchester, Manchester, UK.', 'School of Computer Science, University of Manchester, Manchester, UK.', 'School of Computer Science, University of Manchester, Manchester, UK.', 'Salford Languages, University of Salford, Salford, UK.', 'Departamento de Linguistica Aplicada a la Ciencia y a la Tecnologia, Universidad Politecnica de Madrid, Madrid, Spain.', 'Midcheshire Hospital Foundation Trust NHS, Crewe, England, UK.', 'School of Computer Science, University of Manchester, Manchester, UK.', 'Manchester Institute of Biotechnology, University of Manchester, Manchester, UK.', 'Institut National de la Sante et de la Recherche Medicale (INSERM) U1048, Toulouse, France.', 'Universite Toulouse III Paul Sabatier, route de Narbonne, Toulouse, France.', 'School of Computer Science, University of Manchester, Manchester, UK.', 'Manchester Institute of Biotechnology, University of Manchester, Manchester, UK.', 'School of Computer Science, University of Manchester, Manchester, UK. Robert.Stevens@manchester.ac.uk.']	['10.1186/s13326-018-0181-1 [doi]', '10.1186/s13326-018-0181-1 [pii]']	['Arguello Casteleiro M', 'Demetriou G', 'Read W', 'Fernandez Prieto MJ', 'Maroto N', 'Maseda Fernandez D', 'Nenadic G', 'Klein J', 'Keane J', 'Stevens R']							['2018/04/14 06:00']	20190731	20180412	2018 Apr 12	2018/04/14 06:00		['Arguello Casteleiro, Mercedes', 'Demetriou, George', 'Read, Warren', 'Fernandez Prieto, Maria Jesus', 'Maroto, Nava', 'Maseda Fernandez, Diego', 'Nenadic, Goran', 'Klein, Julie', 'Keane, John', 'Stevens, Robert']		['MC_PC_13042/Medical Research Council/United Kingdom', 'MR/K006665/1/Medical Research Council/United Kingdom']	1		2041-1480 (Electronic)	101531992	Journal of biomedical semantics	['eng']	10.1186/s13326-018-0181-1 [doi]	20190731	['*Biological Ontologies', '*Cardiovascular Diseases/genetics/metabolism', '*Deep Learning', 'Humans', 'Molecular Sequence Annotation', 'PubMed', 'ROC Curve']	2019/08/01 06:00		['*CBOW', '*Cardiovascular disease ontology', '*Deep learning', '*Ontology', '*PubMed', '*Semantic deep learning', '*Skip-gram']	['NOTNLM']	NLM	13	['2017/09/27 00:00 [received]', '2018/03/06 00:00 [accepted]', '2018/04/14 06:00 [entrez]', '2018/04/14 06:00 [pubmed]', '2019/08/01 06:00 [medline]']	England	PMC5896136		29650041	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					J Biomed Semantics. 2018 Apr 12;9(1):13. doi: 10.1186/s13326-018-0181-1.	MEDLINE	J Biomed Semantics	Deep learning meets ontologies: experiments to anchor the cardiovascular disease ontology in the biomedical literature.		9	Deep learning meets ontologies: experiments to anchor the cardiovascular disease ontology in the biomedical literature.
Explicit structural inference is one key point to improve the accuracy of scene parsing. Meanwhile, adversarial training method is able to reinforce spatial contiguity in output segmentations. To take both advantages of the structural learning and adversarial training simultaneously, we propose a novel deep learning network architecture called Structural Inference Embedded Adversarial Networks (SIEANs) for pixel-wise scene labeling. The generator of our SIEANs, a novel designed scene parsing network, makes full use of convolutional neural networks and long short-term memory networks to learn the global contextual information of objects in four different directions from RGB-(D) images, which is able to describe the (three-dimensional) spatial distributions of objects in a more comprehensive and accurate way. To further improve the performance, we explore the adversarial training method to optimize the generator along with a discriminator, which can not only detect and correct higher-order inconsistencies between the predicted segmentations and corresponding ground truths, but also exploit full advantages of the generator by fine-tuning its parameters so as to obtain higher consistencies. The experimental results demonstrate that our proposed SIEANs is able to achieve a better performance on PASCAL VOC 2012, SIFT FLOW, PASCAL Person-Part, Cityscapes, Stanford Background, NYUDv2, and SUN-RGBD datasets compared to the most of state-of-the-art methods.	"['College of Computer Science and Technology, Harbin Engineering University, Harbin, HeiLongJiang, China.', 'College of Computer Science and Technology, Harbin Engineering University, Harbin, HeiLongJiang, China.', ""School of Aeronautics, Northwestern Polytechnical University, Xi'an, ShaanXi, China."", ""Shaanxi Key Laboratory of Integrated and Intelligent Navigation, Xi'an, ShaanXi, China."", ""School of Aeronautics, Northwestern Polytechnical University, Xi'an, ShaanXi, China."", 'College of Computer Science and Technology, Harbin Engineering University, Harbin, HeiLongJiang, China.']"	['10.1371/journal.pone.0195114 [doi]', 'PONE-D-17-30219 [pii]']	['Wang Z', 'Wu Y', 'Bu S', 'Han P', 'Zhang G']	['ORCID: 0000-0003-1218-054X', 'ORCID: 0000-0001-8384-9234']						['2018/04/13 06:00']	20180723	20180412	2018	2018/04/13 06:00		['Wang, ZeYu', 'Wu, YanXia', 'Bu, ShuHui', 'Han, PengCheng', 'Zhang, GuoYin']			4		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0195114 [doi]	20181114	['Algorithms', 'Image Processing, Computer-Assisted/*methods', 'Imaging, Three-Dimensional', 'Machine Learning', 'Models, Statistical', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', 'Software', 'User-Computer Interface']	2018/07/24 06:00				NLM	e0195114	['2017/08/15 00:00 [received]', '2018/03/17 00:00 [accepted]', '2018/04/13 06:00 [entrez]', '2018/04/13 06:00 [pubmed]', '2018/07/24 06:00 [medline]']	United States	PMC5896926		29649294	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2018 Apr 12;13(4):e0195114. doi: 10.1371/journal.pone.0195114. eCollection 2018.	MEDLINE	PLoS One	Structural inference embedded adversarial networks for scene parsing.		13	Structural inference embedded adversarial networks for scene parsing.
Sequencing by translocating DNA fragments through an array of nanopores is a rapidly maturing technology that offers faster and cheaper sequencing than other approaches. However, accurately deciphering the DNA sequence from the noisy and complex electrical signal is challenging. Here, we report Chiron, the first deep learning model to achieve end-to-end basecalling and directly translate the raw signal to DNA sequence without the error-prone segmentation step. Trained with only a small set of 4,000 reads, we show that our model provides state-of-the-art basecalling accuracy, even on previously unseen species. Chiron achieves basecalling speeds of more than 2,000 bases per second using desktop computer graphics processing units.	['Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia.', 'Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia.', 'Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia.', 'Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia.', 'Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, 23955, Saudi Arabia.', 'Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia.']	['4966989 [pii]', '10.1093/gigascience/giy037 [doi]']	['Teng H', 'Cao MD', 'Hall MB', 'Duarte T', 'Wang S', 'Coin LJM']							['2018/04/13 06:00']	20181116		2018 May 1	2018/04/13 06:00	['Gigascience. 2019 May 1;8(5):. PMID: 31077312']	['Teng, Haotian', 'Cao, Minh Duc', 'Hall, Michael B', 'Duarte, Tania', 'Wang, Sheng', 'Coin, Lachlan J M']			5		2047-217X (Electronic) 2047-217X (Linking)	101596872	GigaScience	['eng']	10.1093/gigascience/giy037 [doi]	20190514	['Base Pairing', 'Base Sequence', 'Escherichia coli/genetics', '*Machine Learning', 'Mycobacterium tuberculosis/genetics', '*Nanopores', 'Neural Networks (Computer)', 'Nucleotides/*genetics', 'Probability', 'Reproducibility of Results', 'Sequence Analysis, DNA/*methods', '*Signal Processing, Computer-Assisted', '*Software']	2018/11/18 06:00				NLM		['2017/11/09 00:00 [received]', '2018/04/13 06:00 [pubmed]', '2018/11/18 06:00 [medline]', '2018/04/13 06:00 [entrez]']	United States	PMC5946831		29648610	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Nucleotides)']	IM		Gigascience. 2018 May 1;7(5). pii: 4966989. doi: 10.1093/gigascience/giy037.	MEDLINE	Gigascience	Chiron: translating nanopore raw signal directly into nucleotide sequence using deep learning.		7	Chiron: translating nanopore raw signal directly into nucleotide sequence using deep learning.
Alzheimer's Disease (AD) is a progressive neurodegenerative disease where biomarkers for disease based on pathophysiology may be able to provide objective measures for disease diagnosis and staging. Neuroimaging scans acquired from MRI and metabolism images obtained by FDG-PET provide in-vivo measurements of structure and function (glucose metabolism) in a living brain. It is hypothesized that combining multiple different image modalities providing complementary information could help improve early diagnosis of AD. In this paper, we propose a novel deep-learning-based framework to discriminate individuals with AD utilizing a multimodal and multiscale deep neural network. Our method delivers 82.4% accuracy in identifying the individuals with mild cognitive impairment (MCI) who will convert to AD at 3 years prior to conversion (86.4% combined accuracy for conversion within 1-3 years), a 94.23% sensitivity in classifying individuals with clinical diagnosis of probable AD, and a 86.3% specificity in classifying non-demented controls improving upon results in published literature.	['School of Engineering Science, Simon Fraser University, Burnaby, V5A 1S6, Canada.', 'School of Engineering Science, Simon Fraser University, Burnaby, V5A 1S6, Canada.', 'School of Engineering Science, Simon Fraser University, Burnaby, V5A 1S6, Canada.', 'School of Engineering Science, Simon Fraser University, Burnaby, V5A 1S6, Canada.', 'School of Engineering Science, Simon Fraser University, Burnaby, V5A 1S6, Canada. mfbeg@sfu.ca.']	['10.1038/s41598-018-22871-z [doi]', '10.1038/s41598-018-22871-z [pii]']	['Lu D', 'Popuri K', 'Ding GW', 'Balachandar R', 'Beg MF']	['ORCID: 0000-0001-6706-8630']			"[""Alzheimer's Disease Neuroimaging Initiative""]"			['2018/04/11 06:00']	20191004	20180409	2018 Apr 9	2018/04/11 06:00		['Lu, Donghuan', 'Popuri, Karteek', 'Ding, Gavin Weiguang', 'Balachandar, Rakesh', 'Beg, Mirza Faisal']	"['Weiner, Michael', 'Aisen, Paul', 'Petersen, Ronald', 'Jack, Cliford', 'Jagust, William', 'Trojanowki, John', 'Toga, Arthur', 'Beckett, Laurel', 'Green, Robert', 'Saykin, Andrew', 'Morris, John', 'Shaw, Leslie', 'Kaye, Jefrey', 'Quinn, Joseph', 'Silbert, Lisa', 'Lind, Betty', 'Carter, Raina', 'Dolen, Sara', 'Schneider, Lon', 'Pawluczyk, Sonia', 'Beccera, Mauricio', 'Teodoro, Liberty', 'Spann, Bryan', 'Brewer, James', 'Vanderswag, Helen', 'Fleisher, Adam', 'Heidebrink, Judith', 'Lord, Joanne', 'Mason, Sara', 'Albers, Colleen', 'Knopman, David', 'Johnson, Kris', 'Doody, Rachelle', 'Villanueva-Meyer, Javier', 'Chowdhury, Munir', 'Rountree, Susan', 'Dang, Mimi', 'Stern, Yaakov', 'Honig, Lawrence', 'Bell, Karen', 'Ances, Beau', 'Carroll, Maria', 'Creech, Mary', 'Franklin, Erin', 'Mintun, Mark', 'Schneider, Stacy', 'Oliver, Angela', 'Marson, Daniel', 'Grifth, Randall', 'Clark, David', 'Geldmacher, David', 'Brockington, John', 'Roberson, Erik', 'Love, Marissa Natelson', 'Grossman, Hillel', 'Mitsis, Efe', 'Shah, Raj', 'deToledo-Morrell, Leyla', 'Duara, Ranjan', 'Varon, Daniel', 'Greig, Maria', 'Roberts, Peggy', 'Albert, Marilyn', 'Onyike, Chiadi', ""D'Agostino, Daniel"", 'Kielb, Stephanie', 'Galvin, James', 'Cerbone, Brittany', 'Michel, Christina', 'Pogorelec, Dana', 'Rusinek, Henry', 'de Leon, Mony', 'Glodzik, Lidia', 'Santi, Susan De', 'Doraiswamy, P', 'Petrella, Jefrey', 'Borges-Neto, Salvador', 'Wong, Terence', 'Coleman, Edward', 'Smith, Charles', 'Jicha, Greg', 'Hardy, Peter', 'Sinha, Partha', 'Oates, Elizabeth', 'Conrad, Gary', 'Porsteinsson, Anton', 'Goldstein, Bonnie', 'Martin, Kim', 'Makino, Kelly', 'Ismail, M', 'Brand, Connie', 'Mulnard, Ruth', 'Thai, Gaby', 'Mc-Adams-Ortiz, Catherine', 'Womack, Kyle', 'Mathews, Dana', 'Quiceno, Mary', 'Levey, Allan', 'Lah, James', 'Cellar, Janet', 'Burns, Jefrey', 'Swerdlow, Russell', 'Brooks, William', 'Apostolova, Liana', 'Tingus, Kathleen', 'Woo, Ellen', 'Silverman, Daniel', 'Lu, Po', 'Bartzokis, George', 'Graf-Radford, Neill', 'Parftt, Francine', 'Kendall, Tracy', 'Johnson, Heather', 'Farlow, Martin', 'Hake, Ann Marie', 'Matthews, Brandy', 'Brosch, Jared', 'Herring, Scott', 'Hunt, Cynthia', 'Dyck, Christopher', 'Carson, Richard', 'MacAvoy, Martha', 'Varma, Pradeep', 'Chertkow, Howard', 'Bergman, Howard', 'Hosein, Chris', 'Black, Sandra', 'Stefanovic, Bojana', 'Caldwell, Curtis', 'Hsiung, Ging-Yuek Robin', 'Feldman, Howard', 'Mudge, Benita', 'Assaly, Michele', 'Finger, Elizabeth', 'Pasternack, Stephen', 'Rachisky, Irina', 'Trost, Dick', 'Kertesz, Andrew', 'Bernick, Charles', 'Munic, Donna', 'Mesulam, Marek-Marsel', 'Lipowski, Kristine', 'Weintraub, Sandra', 'Bonakdarpour, Borna', 'Kerwin, Diana', 'Wu, Chuang-Kuo', 'Johnson, Nancy', 'Sadowsky, Carl', 'Villena, Teresa', 'Turner, Raymond Scott', 'Johnson, Kathleen', 'Reynolds, Brigid', 'Sperling, Reisa', 'Johnson, Keith', 'Marshall, Gad', 'Yesavage, Jerome', 'Taylor, Joy', 'Lane, Barton', 'Rosen, Allyson', 'Tinklenberg, Jared', 'Sabbagh, Marwan', 'Belden, Christine', 'Jacobson, Sandra', 'Sirrel, Sherye', 'Kowall, Neil', 'Killiany, Ronald', 'Budson, Andrew', 'Norbash, Alexander', 'Johnson, Patricia Lynn', 'Obisesan, Thomas', 'Wolday, Saba', 'Allard, Joanne', 'Lerner, Alan', 'Ogrocki, Paula', 'Tatsuoka, Curtis', 'Fatica, Parianne', 'Fletcher, Evan', 'Maillard, Pauline', 'Olichney, John', 'DeCarli, Charles', 'Carmichael, Owen', 'Kittur, Smita', 'Borrie, Michael', 'Lee, T-Y', 'Bartha, Rob', 'Johnson, Sterling', 'Asthana, Sanjay', 'Carlsson, Cynthia', 'Potkin, Steven', 'Preda, Adrian', 'Nguyen, Dana', 'Tariot, Pierre', 'Burke, Anna', 'Trncic, Nadira', 'Reeder, Stephanie', 'Bates, Vernice', 'Capote, Horacio', 'Rainka, Michelle', 'Scharre, Douglas', 'Kataki, Maria', 'Adeli, Anahita', 'Zimmerman, Earl', 'Celmins, Dzintra', 'Brown, Alice', 'Pearlson, Godfrey', 'Blank, Karen', 'Anderson, Karen', 'Flashman, Laura', 'Seltzer, Marc', 'Hynes, Mary', 'Santulli, Robert', 'Sink, Kaycee', 'Gordineer, Leslie', 'Williamson, Jef', 'Garg, Pradeep', 'Watkins, Franklin', 'Ott, Brian', 'Querfurth, Henry', 'Tremont, Geofrey', 'Salloway, Stephen', 'Malloy, Paul', 'Correia, Stephen', 'Rosen, Howard', 'Miller, Bruce', 'Perry, David', 'Mintzer, Jacobo', 'Spicer, Kenneth', 'Bachman, David', 'Pomara, Nunzio', 'Hernando, Raymundo', 'Sarrael, Antero', 'Relkin, Norman', 'Chaing, Gloria', 'Lin, Michael', 'Ravdin, Lisa', 'Smith, Amanda', 'Raj, Balebail Ashok', 'Fargher, Kristin']"	['P41 EB015922/EB/NIBIB NIH HHS/United States', 'CIHR/Canada', 'U01 AG024904/AG/NIA NIH HHS/United States']	1	"['Weiner M', 'Aisen P', 'Petersen R', 'Jack C', 'Jagust W', 'Trojanowki J', 'Toga A', 'Beckett L', 'Green R', 'Saykin A', 'Morris J', 'Shaw L', 'Kaye J', 'Quinn J', 'Silbert L', 'Lind B', 'Carter R', 'Dolen S', 'Schneider L', 'Pawluczyk S', 'Beccera M', 'Teodoro L', 'Spann B', 'Brewer J', 'Vanderswag H', 'Fleisher A', 'Heidebrink J', 'Lord J', 'Mason S', 'Albers C', 'Knopman D', 'Johnson K', 'Doody R', 'Villanueva-Meyer J', 'Chowdhury M', 'Rountree S', 'Dang M', 'Stern Y', 'Honig L', 'Bell K', 'Ances B', 'Carroll M', 'Creech M', 'Franklin E', 'Mintun M', 'Schneider S', 'Oliver A', 'Marson D', 'Grifth R', 'Clark D', 'Geldmacher D', 'Brockington J', 'Roberson E', 'Love MN', 'Grossman H', 'Mitsis E', 'Shah R', 'deToledo-Morrell L', 'Duara R', 'Varon D', 'Greig M', 'Roberts P', 'Albert M', 'Onyike C', ""D'Agostino D"", 'Kielb S', 'Galvin J', 'Cerbone B', 'Michel C', 'Pogorelec D', 'Rusinek H', 'de Leon M', 'Glodzik L', 'Santi S', 'Doraiswamy P', 'Petrella J', 'Borges-Neto S', 'Wong T', 'Coleman E', 'Smith C', 'Jicha G', 'Hardy P', 'Sinha P', 'Oates E', 'Conrad G', 'Porsteinsson A', 'Goldstein B', 'Martin K', 'Makino K', 'Ismail M', 'Brand C', 'Mulnard R', 'Thai G', 'Mc-Adams-Ortiz C', 'Womack K', 'Mathews D', 'Quiceno M', 'Levey A', 'Lah J', 'Cellar J', 'Burns J', 'Swerdlow R', 'Brooks W', 'Apostolova L', 'Tingus K', 'Woo E', 'Silverman D', 'Lu P', 'Bartzokis G', 'Graf-Radford N', 'Parftt F', 'Kendall T', 'Johnson H', 'Farlow M', 'Hake AM', 'Matthews B', 'Brosch J', 'Herring S', 'Hunt C', 'Dyck C', 'Carson R', 'MacAvoy M', 'Varma P', 'Chertkow H', 'Bergman H', 'Hosein C', 'Black S', 'Stefanovic B', 'Caldwell C', 'Hsiung GR', 'Feldman H', 'Mudge B', 'Assaly M', 'Finger E', 'Pasternack S', 'Rachisky I', 'Trost D', 'Kertesz A', 'Bernick C', 'Munic D', 'Mesulam MM', 'Lipowski K', 'Weintraub S', 'Bonakdarpour B', 'Kerwin D', 'Wu CK', 'Johnson N', 'Sadowsky C', 'Villena T', 'Turner RS', 'Johnson K', 'Reynolds B', 'Sperling R', 'Johnson K', 'Marshall G', 'Yesavage J', 'Taylor J', 'Lane B', 'Rosen A', 'Tinklenberg J', 'Sabbagh M', 'Belden C', 'Jacobson S', 'Sirrel S', 'Kowall N', 'Killiany R', 'Budson A', 'Norbash A', 'Johnson PL', 'Obisesan T', 'Wolday S', 'Allard J', 'Lerner A', 'Ogrocki P', 'Tatsuoka C', 'Fatica P', 'Fletcher E', 'Maillard P', 'Olichney J', 'DeCarli C', 'Carmichael O', 'Kittur S', 'Borrie M', 'Lee TY', 'Bartha R', 'Johnson S', 'Asthana S', 'Carlsson C', 'Potkin S', 'Preda A', 'Nguyen D', 'Tariot P', 'Burke A', 'Trncic N', 'Reeder S', 'Bates V', 'Capote H', 'Rainka M', 'Scharre D', 'Kataki M', 'Adeli A', 'Zimmerman E', 'Celmins D', 'Brown A', 'Pearlson G', 'Blank K', 'Anderson K', 'Flashman L', 'Seltzer M', 'Hynes M', 'Santulli R', 'Sink K', 'Gordineer L', 'Williamson J', 'Garg P', 'Watkins F', 'Ott B', 'Querfurth H', 'Tremont G', 'Salloway S', 'Malloy P', 'Correia S', 'Rosen H', 'Miller B', 'Perry D', 'Mintzer J', 'Spicer K', 'Bachman D', 'Pomara N', 'Hernando R', 'Sarrael A', 'Relkin N', 'Chaing G', 'Lin M', 'Ravdin L', 'Smith A', 'Raj BA', 'Fargher K']"	2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-22871-z [doi]	20191007	['Aged', 'Aged, 80 and over', 'Alzheimer Disease/*diagnostic imaging/metabolism', 'Brain/*diagnostic imaging/metabolism', 'Case-Control Studies', 'Cognitive Dysfunction/*diagnostic imaging/metabolism', 'Deep Learning', 'Early Diagnosis', 'Fluorodeoxyglucose F18/*metabolism', 'Humans', 'Magnetic Resonance Imaging/methods', 'Middle Aged', 'Multimodal Imaging/*methods', 'Neural Networks (Computer)', 'Positron-Emission Tomography/methods', 'Radiopharmaceuticals/*metabolism', 'Sensitivity and Specificity']	2019/10/08 06:00				NLM	5697	['2017/10/10 00:00 [received]', '2018/03/02 00:00 [accepted]', '2018/04/11 06:00 [entrez]', '2018/04/11 06:00 [pubmed]', '2019/10/08 06:00 [medline]']	England	PMC5890270		29632364	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Radiopharmaceuticals)', '0Z5B2CJX4D (Fluorodeoxyglucose F18)']	IM		Sci Rep. 2018 Apr 9;8(1):5697. doi: 10.1038/s41598-018-22871-z.	MEDLINE	Sci Rep	Multimodal and Multiscale Deep Neural Networks for the Early Diagnosis of Alzheimer's Disease using structural MR and FDG-PET images.		8	Multimodal and Multiscale Deep Neural Networks for the Early Diagnosis of Alzheimer's Disease using structural MR and FDG-PET images.
For a natural social human-robot interaction, it is essential for a robot to learn the human-like social skills. However, learning such skills is notoriously hard due to the limited availability of direct instructions from people to teach a robot. In this paper, we propose an intrinsically motivated reinforcement learning framework in which an agent gets the intrinsic motivation-based rewards through the action-conditional predictive model. By using the proposed method, the robot learned the social skills from the human-robot interaction experiences gathered in the real uncontrolled environments. The results indicate that the robot not only acquired human-like social skills but also took more human-like decisions, on a test dataset, than a robot which received direct rewards for the task achievement.	['Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan. Electronic address: qureshi.ahmed@irl.sys.es.osaka-u.ac.jp.', 'Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan.', 'Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan.', 'Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan.']	['S0893-6080(18)30107-2 [pii]', '10.1016/j.neunet.2018.03.014 [doi]']	['Qureshi AH', 'Nakamura Y', 'Yoshikawa Y', 'Ishiguro H']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/04/11 06:00']	20181211	20180326	2018 Nov	2018/04/11 06:00		['Qureshi, Ahmed Hussain', 'Nakamura, Yutaka', 'Yoshikawa, Yuichiro', 'Ishiguro, Hiroshi']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30107-2 [pii] 10.1016/j.neunet.2018.03.014 [doi]	20181211	['*Deep Learning', 'Humans', '*Neural Networks (Computer)', 'Robotics/*methods', '*Social Skills', '*User-Computer Interface']	2018/12/12 06:00		['Deep reinforcement learning', 'Human-robot interaction', 'Intrinsic motivation', 'Real-world robotics', 'Social robots']	['NOTNLM']	NLM	23-33	['2017/06/22 00:00 [received]', '2018/03/14 00:00 [revised]', '2018/03/17 00:00 [accepted]', '2018/04/11 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2018/04/11 06:00 [entrez]']	United States			29631753	ppublish	['Journal Article']			IM		Neural Netw. 2018 Nov;107:23-33. doi: 10.1016/j.neunet.2018.03.014. Epub 2018 Mar 26.	MEDLINE	Neural Netw	Intrinsically motivated reinforcement learning for human-robot interaction in the real-world.		107	Intrinsically motivated reinforcement learning for human-robot interaction in the real-world.
Data is often plagued by noise which encumbers machine learning of clinically useful biomarkers and electroencephalogram (EEG) data is no exemption. Intracranial EEG (iEEG) data enhances the training of deep learning models of the human brain, yet is often prohibitive due to the invasive recording process. A more convenient alternative is to record brain activity using scalp electrodes. However, the inherent noise associated with scalp EEG data often impedes the learning process of neural models, achieving substandard performance. Here, an ensemble deep learning architecture for nonlinearly mapping scalp to iEEG data is proposed. The proposed architecture exploits the information from a limited number of joint scalp-intracranial recording to establish a novel methodology for detecting the epileptic discharges from the sEEG of a general population of subjects. Statistical tests and qualitative analysis have revealed that the generated pseudo-intracranial data are highly correlated with the true intracranial data. This facilitated the detection of IEDs from the scalp recordings where such waveforms are not often visible. As a real-world clinical application, these pseudo-iEEGs are then used by a convolutional neural network for the automated classification of intracranial epileptic discharges (IEDs) and non-IED of trials in the context of epilepsy analysis. Although the aim of this work was to circumvent the unavailability of iEEG and the limitations of sEEG, we have achieved a classification accuracy of 68% an increase of 6% over the previously proposed linear regression mapping.	"['* Department of Computer Science, University of Surrey, Guildford, Surrey, GU2 7XH, United Kingdom.', 'dagger School of Engineering, University of Edinburgh, EH9 3FB, United Kingdom.', 'double dagger Kingston Hospital NHS FT, London, SE5 9RS, UK.', ""4 King's College London, WC2R 2LS, UK."", ""4 King's College London, WC2R 2LS, UK."", ""section sign King's College Hospital, London, UK."", ""4 King's College London, WC2R 2LS, UK."", 'paragraph sign Hamad Medical Corporation, Doha, Qatar.', '* Department of Computer Science, University of Surrey, Guildford, Surrey, GU2 7XH, United Kingdom.', '* Department of Computer Science, University of Surrey, Guildford, Surrey, GU2 7XH, United Kingdom.']"	['10.1142/S0129065718500090 [doi]']	['Antoniades A', 'Spyrou L', 'Martin-Lopez D', 'Valentin A', 'Alarcon G', 'Sanei S', 'Took CC']							['2018/04/11 06:00']	20181113	20180319	2018 Oct	2018/04/11 06:00		['Antoniades, Andreas', 'Spyrou, Loukianos', 'Martin-Lopez, David', 'Valentin, Antonio', 'Alarcon, Gonzalo', 'Sanei, Saeid', 'Took, Clive Cheong']			8		1793-6462 (Electronic) 0129-0657 (Linking)	9100527	International journal of neural systems	['eng']	10.1142/S0129065718500090 [doi]	20181113	['Brain/*physiology/physiopathology', 'Brain Mapping/*methods', 'Electroencephalography/*methods', 'Epilepsy/physiopathology', 'Female', 'Humans', 'Linear Models', 'Male', 'Models, Neurological', 'Neural Networks (Computer)', 'Neurophysiological Monitoring/methods', 'Pattern Recognition, Automated/methods', 'ROC Curve', 'Scalp/*physiology/physiopathology']	2018/11/14 06:00		['Interictal epileptic discharge', 'asymmetric deep learning', 'scalp to intracranial EEG mapping']	['NOTNLM']	NLM	1850009	['2018/04/11 06:00 [pubmed]', '2018/11/14 06:00 [medline]', '2018/04/11 06:00 [entrez]']	Singapore			29631503	ppublish	['Journal Article']			IM		Int J Neural Syst. 2018 Oct;28(8):1850009. doi: 10.1142/S0129065718500090. Epub 2018 Mar 19.	MEDLINE	Int J Neural Syst	Deep Neural Architectures for Mapping Scalp to Intracranial EEG.		28	Deep Neural Architectures for Mapping Scalp to Intracranial EEG.
Human detection in videos plays an important role in various real life applications. Most of traditional approaches depend on utilizing handcrafted features which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for human detection task. Pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with soft-max and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high performance Graphical Processing Unit (GPU).	['Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia.', 'Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia.', 'Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia.']	['10.1155/2018/1639561 [doi]']	['AlDahoul N', 'Md Sabri AQ', 'Mansoor AM']	['ORCID: 0000-0001-5522-0033', 'ORCID: 0000-0002-4758-5400']						['2018/04/07 06:00']	20180911	20180212	2018	2018/04/07 06:00		['AlDahoul, Nouar', 'Md Sabri, Aznul Qalid', 'Mansoor, Ali Mohammed']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2018/1639561 [doi]	20181114	['Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', 'Motion', 'Motor Activity', 'Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', 'Time Factors', '*Video Recording']	2018/09/12 06:00				NLM	1639561	['2017/07/18 00:00 [received]', '2017/11/18 00:00 [revised]', '2018/01/08 00:00 [accepted]', '2018/04/07 06:00 [entrez]', '2018/04/07 06:00 [pubmed]', '2018/09/12 06:00 [medline]']	United States	PMC5829342		29623089	epublish	['Journal Article']			IM		Comput Intell Neurosci. 2018 Feb 12;2018:1639561. doi: 10.1155/2018/1639561. eCollection 2018.	MEDLINE	Comput Intell Neurosci	Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models.		2018	Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models.
The purposes of this study are to evaluate the feasibility of protocol determination with a convolutional neural networks (CNN) classifier based on short-text classification and to evaluate the agreements by comparing protocols determined by CNN with those determined by musculoskeletal radiologists. Following institutional review board approval, the database of a hospital information system (HIS) was queried for lists of MRI examinations, referring department, patient age, and patient gender. These were exported to a local workstation for analyses: 5258 and 1018 consecutive musculoskeletal MRI examinations were used for the training and test datasets, respectively. The subjects for pre-processing were routine or tumor protocols and the contents were word combinations of the referring department, region, contrast media (or not), gender, and age. The CNN Embedded vector classifier was used with Word2Vec Google news vectors. The test set was tested with each classification model and results were output as routine or tumor protocols. The CNN determinations were evaluated using the receiver operating characteristic (ROC) curves. The accuracies were evaluated by a radiologist-confirmed protocol as the reference protocols. The optimal cut-off values for protocol determination between routine protocols and tumor protocols was 0.5067 with a sensitivity of 92.10%, a specificity of 95.76%, and an area under curve (AUC) of 0.977. The overall accuracy was 94.2% for the ConvNet model. All MRI protocols were correct in the pelvic bone, upper arm, wrist, and lower leg MRIs. Deep-learning-based convolutional neural networks were clinically utilized to determine musculoskeletal MRI protocols. CNN-based text learning and applications could be extended to other radiologic tasks besides image interpretations, improving the work performance of the radiologist.	['Department of Radiology, Research Institute of Radiological Science, YUHS-KRIBB Medical Convergence Research Institute and Center for Clinical Imaging Data Science, Yonsei University College of Medicine, 50-1 Yonsei-ro, Seodaemun-gu, Seoul, 03722, South Korea. sando@yuhs.ac.']	['10.1007/s10278-018-0066-y [doi]', '10.1007/s10278-018-0066-y [pii]']	['Lee YH']							['2018/04/06 06:00']	20191108		2018 Oct	2018/04/06 06:00		['Lee, Young Han']			5		1618-727X (Electronic) 0897-1889 (Linking)	9100529	Journal of digital imaging	['eng']	10.1007/s10278-018-0066-y [doi]	20191108	['Algorithms', 'Databases, Factual', '*Deep Learning', 'Efficiency, Organizational/*statistics & numerical data', 'Feasibility Studies', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', 'Musculoskeletal Diseases/*diagnostic imaging', 'Musculoskeletal System/diagnostic imaging', '*Neural Networks (Computer)', 'Sensitivity and Specificity', 'Workflow']	2019/11/09 06:00		['*Artificial neural networks', '*Image protocols', '*Machine learning', '*Magnetic resonance imaging protocol']	['NOTNLM']	NLM	604-610	['2018/04/06 06:00 [pubmed]', '2019/11/09 06:00 [medline]', '2018/04/06 06:00 [entrez]']	United States	PMC6148815		29619578	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Digit Imaging. 2018 Oct;31(5):604-610. doi: 10.1007/s10278-018-0066-y.	MEDLINE	J Digit Imaging	Efficiency Improvement in a Busy Radiology Practice: Determination of Musculoskeletal Magnetic Resonance Imaging Protocol Using Deep-Learning Convolutional Neural Networks.		31	Efficiency Improvement in a Busy Radiology Practice: Determination of Musculoskeletal Magnetic Resonance Imaging Protocol Using Deep-Learning Convolutional Neural Networks.
Deep learning describes a class of machine learning algorithms that are capable of combining raw inputs into layers of intermediate features. These algorithms have recently shown impressive results across a variety of domains. Biology and medicine are data-rich disciplines, but the data are complex and often ill-understood. Hence, deep learning techniques may be particularly well suited to solve problems of these fields. We examine applications of deep learning to a variety of biomedical problems-patient classification, fundamental biological processes and treatment of patients-and discuss whether deep learning will be able to transform these tasks or if the biomedical sphere poses unique challenges. Following from an extensive literature review, we find that deep learning has yet to revolutionize biomedicine or definitively resolve any of the most pressing challenges in the field, but promising advances have been made on the prior state of the art. Even though improvements over previous baselines have been modest in general, the recent progress indicates that deep learning methods will provide valuable means for speeding up or aiding human investigation. Though progress has been made linking a specific neural network's prediction to input features, understanding how users should interpret these models to make testable hypotheses about the system under study remains an open challenge. Furthermore, the limited amount of labelled data for training presents problems in some domains, as do legal and privacy constraints on work with sensitive health records. Nonetheless, we foresee deep learning enabling changes at both bench and bedside with the potential to transform several areas of biology and medicine.	['Molecular Biosciences and Bioengineering Graduate Program, University of Hawaii at Manoa, Honolulu, HI, USA.', 'Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.', 'Genomics and Computational Biology Graduate Group, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.', 'Department of Computational Medicine and Bioinformatics, University of Michigan Medical School, Ann Arbor, MI, USA.', 'Harvard Medical School, Boston, MA, USA.', 'Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.', 'Computational Biology and Stats, Target Sciences, GlaxoSmithKline, Stevenage, UK.', 'Data Science Institute, Imperial College London, London, UK.', 'Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.', 'Princess Margaret Cancer Centre, Toronto, Ontario, Canada.', 'Department of Medical Biophysics, University of Toronto, Toronto, Ontario, Canada.', 'Department of Computer Science, University of Toronto, Toronto, Ontario, Canada.', 'Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, USA.', 'Ecological and Evolutionary Signal-processing and Informatics Laboratory, Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA.', 'Computational Biology Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Biophysics Program, Stanford University, Stanford, CA, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA, USA.', 'Ecological and Evolutionary Signal-processing and Informatics Laboratory, Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA.', 'Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA, USA.', 'Department of Computer Science, Stanford University, Stanford, CA, USA.', 'Toyota Technological Institute at Chicago, Chicago, IL, USA.', 'Department of Computer Science, Trinity University, San Antonio, TX, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, USA.', 'Integrative Bioinformatics, National Institute of Environmental Health Sciences, National Institutes of Health, Research Triangle Park, NC, USA.', 'Howard Hughes Medical Institute, Janelia Research Campus, Ashburn, VA, USA.', 'Department of Computer Science, Stanford University, Stanford, CA, USA.', 'National Center for Biotechnology Information and National Library of Medicine, National Institutes of Health, Bethesda, MD, USA.', 'Department of Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, USA.', 'ClosedLoop.ai, Austin, TX, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA, USA.', 'Department of Computer Science, Stanford University, Stanford, CA, USA.', 'Department of Genetics, Stanford University, Stanford, CA, USA.', 'National Center for Biotechnology Information and National Library of Medicine, National Institutes of Health, Bethesda, MD, USA.', 'Division of Biomedical Informatics and Personalized Medicine, University of Colorado School of Medicine, Aurora, CO, USA.', 'Institute of Organic Chemistry, Westfalische Wilhelms-Universitat Munster, Munster, Germany.', 'Innovation Center for Biomedical Informatics, Georgetown University Medical Center, Washington, DC, USA.', 'Department of Pathology and Immunology, Washington University in Saint Louis, St Louis, MO, USA.', 'Department of Medicine, Brown University, Providence, RI, USA.', 'Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, WI, USA gitter@biostat.wisc.edu.', 'Morgridge Institute for Research, Madison, WI, USA.', 'Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA greenescientist@gmail.com.']	['rsif.2017.0387 [pii]', '10.1098/rsif.2017.0387 [doi]']	['Ching T', 'Himmelstein DS', 'Beaulieu-Jones BK', 'Kalinin AA', 'Do BT', 'Way GP', 'Ferrero E', 'Agapow PM', 'Zietz M', 'Hoffman MM', 'Xie W', 'Rosen GL', 'Lengerich BJ', 'Israeli J', 'Lanchantin J', 'Woloszynek S', 'Carpenter AE', 'Shrikumar A', 'Xu J', 'Cofer EM', 'Lavender CA', 'Turaga SC', 'Alexandari AM', 'Lu Z', 'Harris DJ', 'DeCaprio D', 'Qi Y', 'Kundaje A', 'Peng Y', 'Wiley LK', 'Segler MHS', 'Boca SM', 'Swamidass SJ', 'Huang A', 'Gitter A', 'Greene CS']	['ORCID: 0000-0002-5577-3516', 'ORCID: 0000-0002-3012-7446', 'ORCID: 0000-0002-6700-1468', 'ORCID: 0000-0003-4563-3226', 'ORCID: 0000-0003-4992-2623', 'ORCID: 0000-0002-0503-9348', 'ORCID: 0000-0002-8362-100X', 'ORCID: 0000-0003-1126-1479', 'ORCID: 0000-0003-0539-630X', 'ORCID: 0000-0002-4517-1562', 'ORCID: 0000-0002-1871-6846', 'ORCID: 0000-0003-1763-5750', 'ORCID: 0000-0001-8690-9554', 'ORCID: 0000-0003-1633-5780', 'ORCID: 0000-0003-0811-0944', 'ORCID: 0000-0003-0568-298X', 'ORCID: 0000-0003-1555-8261', 'ORCID: 0000-0002-6443-4671', 'ORCID: 0000-0001-7111-4839', 'ORCID: 0000-0003-3877-0433', 'ORCID: 0000-0002-7762-1089', 'ORCID: 0000-0003-3247-6487', 'ORCID: 0000-0001-8655-8109', 'ORCID: 0000-0001-9998-916X', 'ORCID: 0000-0003-3332-9307', 'ORCID: 0000-0001-8931-9461', 'ORCID: 0000-0002-5796-7453', 'ORCID: 0000-0003-3084-2287', 'ORCID: 0000-0001-9309-8331', 'ORCID: 0000-0001-6681-9754', 'ORCID: 0000-0001-8008-0546', 'ORCID: 0000-0002-1400-3398', 'ORCID: 0000-0003-2191-0778', 'ORCID: 0000-0003-1349-4030', 'ORCID: 0000-0002-5324-9833', 'ORCID: 0000-0001-8713-9213']	['(c) 2018 The Authors.']					['2018/04/06 06:00']	20190925		2018 Apr	2018/04/06 06:00		['Ching, Travers', 'Himmelstein, Daniel S', 'Beaulieu-Jones, Brett K', 'Kalinin, Alexandr A', 'Do, Brian T', 'Way, Gregory P', 'Ferrero, Enrico', 'Agapow, Paul-Michael', 'Zietz, Michael', 'Hoffman, Michael M', 'Xie, Wei', 'Rosen, Gail L', 'Lengerich, Benjamin J', 'Israeli, Johnny', 'Lanchantin, Jack', 'Woloszynek, Stephen', 'Carpenter, Anne E', 'Shrikumar, Avanti', 'Xu, Jinbo', 'Cofer, Evan M', 'Lavender, Christopher A', 'Turaga, Srinivas C', 'Alexandari, Amr M', 'Lu, Zhiyong', 'Harris, David J', 'DeCaprio, Dave', 'Qi, Yanjun', 'Kundaje, Anshul', 'Peng, Yifan', 'Wiley, Laura K', 'Segler, Marwin H S', 'Boca, Simina M', 'Swamidass, S Joshua', 'Huang, Austin', 'Gitter, Anthony', 'Greene, Casey S']		['UL1 TR001409/TR/NCATS NIH HHS/United States', 'T32 GM007753/GM/NIGMS NIH HHS/United States', 'P30 ES013508/ES/NIEHS NIH HHS/United States', 'DP2 GM123485/GM/NIGMS NIH HHS/United States', 'R35 GM122547/GM/NIGMS NIH HHS/United States', 'T32 HG000046/HG/NHGRI NIH HHS/United States', 'R01 GM089753/GM/NIGMS NIH HHS/United States']	141		1742-5662 (Electronic) 1742-5662 (Linking)	101217269	Journal of the Royal Society, Interface	['eng']	20170387 [pii] 10.1098/rsif.2017.0387 [doi]	20190925	['Algorithms', 'Biomedical Research/methods/*trends', 'Biomedical Technology/*trends', 'Decision Making', 'Deep Learning/*trends', 'Delivery of Health Care/methods/trends', 'Disease/genetics', 'Drug Design', 'Electronic Health Records/trends', 'Humans', 'Terminology as Topic']	2019/09/26 06:00		['*deep learning', '*genomics', '*machine learning', '*precision medicine']	['NOTNLM']	NLM		['2017/05/26 00:00 [received]', '2018/03/07 00:00 [accepted]', '2018/04/06 06:00 [entrez]', '2018/04/06 06:00 [pubmed]', '2019/09/26 06:00 [medline]']	England	PMC5938574		29618526	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S."", 'Review']"			IM		J R Soc Interface. 2018 Apr;15(141). pii: rsif.2017.0387. doi: 10.1098/rsif.2017.0387.	MEDLINE	J R Soc Interface	Opportunities and obstacles for deep learning in biology and medicine.		15	Opportunities and obstacles for deep learning in biology and medicine.
Objective: Deep learning has become a promising approach for automated support for clinical diagnosis. When medical data samples are limited, collaboration among multiple institutions is necessary to achieve high algorithm performance. However, sharing patient data often has limitations due to technical, legal, or ethical concerns. In this study, we propose methods of distributing deep learning models as an attractive alternative to sharing patient data. Methods: We simulate the distribution of deep learning models across 4 institutions using various training heuristics and compare the results with a deep learning model trained on centrally hosted patient data. The training heuristics investigated include ensembling single institution models, single weight transfer, and cyclical weight transfer. We evaluated these approaches for image classification in 3 independent image collections (retinal fundus photos, mammography, and ImageNet). Results: We find that cyclical weight transfer resulted in a performance that was comparable to that of centrally hosted patient data. We also found that there is an improvement in the performance of cyclical weight transfer heuristic with a high frequency of weight transfer. Conclusions: We show that distributing deep learning models is an effective alternative to sharing patient data. This finding has implications for any collaborative deep learning study.	['Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown, MA, 02129, USA.', 'Department of Radiology and Biomedical Data Science, Stanford University, Palo Alto, CA, 94305, USA.', 'Department of Radiology and Biomedical Data Science, Stanford University, Palo Alto, CA, 94305, USA.', 'Department of Radiology and Biomedical Data Science, Stanford University, Palo Alto, CA, 94305, USA.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown, MA, 02129, USA.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown, MA, 02129, USA.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown, MA, 02129, USA.', 'Department of Radiology and Biomedical Data Science, Stanford University, Palo Alto, CA, 94305, USA.', 'Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Charlestown, MA, 02129, USA.', 'MGH and BWH Center for Clinical Data Science, Massachusetts General Hospital, Boston, MA, 02114, USA.']	['4956468 [pii]', '10.1093/jamia/ocy017 [doi]']	['Chang K', 'Balachandar N', 'Lam C', 'Yi D', 'Brown J', 'Beers A', 'Rosen B', 'Rubin DL', 'Kalpathy-Cramer J']							['2018/04/05 06:00']	20191127		2018 Aug 1	2018/04/05 06:00		['Chang, Ken', 'Balachandar, Niranjan', 'Lam, Carson', 'Yi, Darvin', 'Brown, James', 'Beers, Andrew', 'Rosen, Bruce', 'Rubin, Daniel L', 'Kalpathy-Cramer, Jayashree']		['T32 EB001680/EB/NIBIB NIH HHS/United States', 'T90 DA022759/DA/NIDA NIH HHS/United States', 'R90 DA023427/DA/NIDA NIH HHS/United States', 'U01 CA154601/CA/NCI NIH HHS/United States', 'U24 CA180927/CA/NCI NIH HHS/United States', 'U24 CA180918/CA/NCI NIH HHS/United States', 'U01 CA190214/CA/NCI NIH HHS/United States', 'U01 CA187947/CA/NCI NIH HHS/United States']	8		1527-974X (Electronic) 1067-5027 (Linking)	9430800	Journal of the American Medical Informatics Association : JAMIA	['eng']	10.1093/jamia/ocy017 [doi]	20191127	['Computer Communication Networks', '*Deep Learning', '*Diagnostic Imaging', 'Humans', 'Medical Record Linkage', 'Neural Networks (Computer)']	2019/11/28 06:00				NLM	945-954	['2017/10/06 00:00 [received]', '2018/02/15 00:00 [accepted]', '2018/04/05 06:00 [pubmed]', '2019/11/28 06:00 [medline]', '2018/04/05 06:00 [entrez]']	England	PMC6077811		29617797	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		J Am Med Inform Assoc. 2018 Aug 1;25(8):945-954. doi: 10.1093/jamia/ocy017.	MEDLINE	J Am Med Inform Assoc	Distributed deep learning networks among institutions for medical imaging.		25	Distributed deep learning networks among institutions for medical imaging.
Beyond sample curation and basic pathologic characterization, the digitized H&E-stained images of TCGA samples remain underutilized. To highlight this resource, we present mappings of tumor-infiltrating lymphocytes (TILs) based on H&E images from 13 TCGA tumor types. These TIL maps are derived through computational staining using a convolutional neural network trained to classify patches of images. Affinity propagation revealed local spatial structure in TIL patterns and correlation with overall survival. TIL map structural patterns were grouped using standard histopathological parameters. These patterns are enriched in particular T cell subpopulations derived from molecular measures. TIL densities and spatial structure were differentially enriched among tumor types, immune subtypes, and tumor molecular subtypes, implying that spatial infiltrate state could reflect particular tumor cell aberration states. Obtaining spatial lymphocytic patterns linked to the rich genomic characterization of TCGA samples demonstrates one use for the TCGA image archives with insights into the tumor-immune microenvironment.	['Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, NY 11794, USA. Electronic address: joel.saltz@stonybrookmedicine.edu.', 'Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, NY 11794, USA; Department of Pathology, Stony Brook Medicine, Stony Brook, NY 11794, USA.', 'Department of Computer Science, Stony Brook University, Stony Brook, NY 11794, USA.', 'Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, NY 11794, USA.', 'Department of Bioinformatics and Computational Biology, University of Texas MD Anderson Cancer Center, Houston, TX 77030, USA.', 'Department of Computer Science, Stony Brook University, Stony Brook, NY 11794, USA.', 'Department of Computer Science, Stony Brook University, Stony Brook, NY 11794, USA.', 'Department of Pathology, Stony Brook Medicine, Stony Brook, NY 11794, USA.', 'Department of Pathology, Stony Brook Medicine, Stony Brook, NY 11794, USA.', 'Department of Pathology, Stony Brook Medicine, Stony Brook, NY 11794, USA.', 'Department of Pathology and Laboratory Medicine, Perelman School at the University of Pennsylvania, Philadelphia, PA 19104, USA.', 'Institute for Systems Biology, Seattle, WA 98109, USA.', 'Department of Bioinformatics and Computational Biology, University of Texas MD Anderson Cancer Center, Houston, TX 77030, USA; Department of Radiation Oncology, University of Texas MD Anderson Cancer Center, Houston, TX 77030, USA.', 'Departments of Pathology, Genomic Medicine, and Translational Molecular Pathology, The University of Texas MD Anderson Cancer Center, Houston, TX 77030, USA.', 'Department of Biomedical Informatics, Emory University, Atlanta, GA 30322, USA.', 'Institute for Systems Biology, Seattle, WA 98109, USA. Electronic address: vesteinn.thorsson@systemsbiology.org.']	['S2211-1247(18)30447-9 [pii]', '10.1016/j.celrep.2018.03.086 [doi]']	['Saltz J', 'Gupta R', 'Hou L', 'Kurc T', 'Singh P', 'Nguyen V', 'Samaras D', 'Shroyer KR', 'Zhao T', 'Batiste R', 'Van Arnam J', 'Shmulevich I', 'Rao AUK', 'Lazar AJ', 'Sharma A', 'Thorsson V']		['Copyright (c) 2018 The Authors. Published by Elsevier Inc. All rights reserved.']		['Cancer Genome Atlas Research Network']			['2018/04/05 06:00']	20190903		2018 Apr 3	2018/04/05 06:00		['Saltz, Joel', 'Gupta, Rajarsi', 'Hou, Le', 'Kurc, Tahsin', 'Singh, Pankaj', 'Nguyen, Vu', 'Samaras, Dimitris', 'Shroyer, Kenneth R', 'Zhao, Tianhao', 'Batiste, Rebecca', 'Van Arnam, John', 'Shmulevich, Ilya', 'Rao, Arvind U K', 'Lazar, Alexander J', 'Sharma, Ashish', 'Thorsson, Vesteinn']	"['Caesar-Johnson, Samantha J', 'Demchok, John A', 'Felau, Ina', 'Kasapi, Melpomeni', 'Ferguson, Martin L', 'Hutter, Carolyn M', 'Sofia, Heidi J', 'Tarnuzzer, Roy', 'Wang, Zhining', 'Yang, Liming', 'Zenklusen, Jean C', 'Zhang, Jiashan Julia', 'Chudamani, Sudha', 'Liu, Jia', 'Lolla, Laxmi', 'Naresh, Rashi', 'Pihl, Todd', 'Sun, Qiang', 'Wan, Yunhu', 'Wu, Ye', 'Cho, Juok', 'DeFreitas, Timothy', 'Frazer, Scott', 'Gehlenborg, Nils', 'Getz, Gad', 'Heiman, David I', 'Kim, Jaegil', 'Lawrence, Michael S', 'Lin, Pei', 'Meier, Sam', 'Noble, Michael S', 'Saksena, Gordon', 'Voet, Doug', 'Zhang, Hailei', 'Bernard, Brady', 'Chambwe, Nyasha', 'Dhankani, Varsha', 'Knijnenburg, Theo', 'Kramer, Roger', 'Leinonen, Kalle', 'Liu, Yuexin', 'Miller, Michael', 'Reynolds, Sheila', 'Shmulevich, Ilya', 'Thorsson, Vesteinn', 'Zhang, Wei', 'Akbani, Rehan', 'Broom, Bradley M', 'Hegde, Apurva M', 'Ju, Zhenlin', 'Kanchi, Rupa S', 'Korkut, Anil', 'Li, Jun', 'Liang, Han', 'Ling, Shiyun', 'Liu, Wenbin', 'Lu, Yiling', 'Mills, Gordon B', 'Ng, Kwok-Shing', 'Rao, Arvind', 'Ryan, Michael', 'Wang, Jing', 'Weinstein, John N', 'Zhang, Jiexin', 'Abeshouse, Adam', 'Armenia, Joshua', 'Chakravarty, Debyani', 'Chatila, Walid K', 'de Bruijn, Ino', 'Gao, Jianjiong', 'Gross, Benjamin E', 'Heins, Zachary J', 'Kundra, Ritika', 'La, Konnor', 'Ladanyi, Marc', 'Luna, Augustin', 'Nissan, Moriah G', 'Ochoa, Angelica', 'Phillips, Sarah M', 'Reznik, Ed', 'Sanchez-Vega, Francisco', 'Sander, Chris', 'Schultz, Nikolaus', 'Sheridan, Robert', 'Sumer, S Onur', 'Sun, Yichao', 'Taylor, Barry S', 'Wang, Jioajiao', 'Zhang, Hongxin', 'Anur, Pavana', 'Peto, Myron', 'Spellman, Paul', 'Benz, Christopher', 'Stuart, Joshua M', 'Wong, Christopher K', 'Yau, Christina', 'Hayes, D Neil', 'Parker, Joel S', 'Wilkerson, Matthew D', 'Ally, Adrian', 'Balasundaram, Miruna', 'Bowlby, Reanne', 'Brooks, Denise', 'Carlsen, Rebecca', 'Chuah, Eric', 'Dhalla, Noreen', 'Holt, Robert', 'Jones, Steven J M', 'Kasaian, Katayoon', 'Lee, Darlene', 'Ma, Yussanne', 'Marra, Marco A', 'Mayo, Michael', 'Moore, Richard A', 'Mungall, Andrew J', 'Mungall, Karen', 'Robertson, A Gordon', 'Sadeghi, Sara', 'Schein, Jacqueline E', 'Sipahimalani, Payal', 'Tam, Angela', 'Thiessen, Nina', 'Tse, Kane', 'Wong, Tina', 'Berger, Ashton C', 'Beroukhim, Rameen', 'Cherniack, Andrew D', 'Cibulskis, Carrie', 'Gabriel, Stacey B', 'Gao, Galen F', 'Ha, Gavin', 'Meyerson, Matthew', 'Schumacher, Steven E', 'Shih, Juliann', 'Kucherlapati, Melanie H', 'Kucherlapati, Raju S', 'Baylin, Stephen', 'Cope, Leslie', 'Danilova, Ludmila', 'Bootwalla, Moiz S', 'Lai, Phillip H', 'Maglinte, Dennis T', 'Van Den Berg, David J', 'Weisenberger, Daniel J', 'Auman, J Todd', 'Balu, Saianand', 'Bodenheimer, Tom', 'Fan, Cheng', 'Hoadley, Katherine A', 'Hoyle, Alan P', 'Jefferys, Stuart R', 'Jones, Corbin D', 'Meng, Shaowu', 'Mieczkowski, Piotr A', 'Mose, Lisle E', 'Perou, Amy H', 'Perou, Charles M', 'Roach, Jeffrey', 'Shi, Yan', 'Simons, Janae V', 'Skelly, Tara', 'Soloway, Matthew G', 'Tan, Donghui', 'Veluvolu, Umadevi', 'Fan, Huihui', 'Hinoue, Toshinori', 'Laird, Peter W', 'Shen, Hui', 'Zhou, Wanding', 'Bellair, Michelle', 'Chang, Kyle', 'Covington, Kyle', 'Creighton, Chad J', 'Dinh, Huyen', 'Doddapaneni, HarshaVardhan', 'Donehower, Lawrence A', 'Drummond, Jennifer', 'Gibbs, Richard A', 'Glenn, Robert', 'Hale, Walker', 'Han, Yi', 'Hu, Jianhong', 'Korchina, Viktoriya', 'Lee, Sandra', 'Lewis, Lora', 'Li, Wei', 'Liu, Xiuping', 'Morgan, Margaret', 'Morton, Donna', 'Muzny, Donna', 'Santibanez, Jireh', 'Sheth, Margi', 'Shinbrot, Eve', 'Wang, Linghua', 'Wang, Min', 'Wheeler, David A', 'Xi, Liu', 'Zhao, Fengmei', 'Hess, Julian', 'Appelbaum, Elizabeth L', 'Bailey, Matthew', 'Cordes, Matthew G', 'Ding, Li', 'Fronick, Catrina C', 'Fulton, Lucinda A', 'Fulton, Robert S', 'Kandoth, Cyriac', 'Mardis, Elaine R', 'McLellan, Michael D', 'Miller, Christopher A', 'Schmidt, Heather K', 'Wilson, Richard K', 'Crain, Daniel', 'Curley, Erin', 'Gardner, Johanna', 'Lau, Kevin', 'Mallery, David', 'Morris, Scott', 'Paulauskis, Joseph', 'Penny, Robert', 'Shelton, Candace', 'Shelton, Troy', 'Sherman, Mark', 'Thompson, Eric', 'Yena, Peggy', 'Bowen, Jay', 'Gastier-Foster, Julie M', 'Gerken, Mark', 'Leraas, Kristen M', 'Lichtenberg, Tara M', 'Ramirez, Nilsa C', 'Wise, Lisa', 'Zmuda, Erik', 'Corcoran, Niall', 'Costello, Tony', 'Hovens, Christopher', 'Carvalho, Andre L', 'de Carvalho, Ana C', 'Fregnani, Jose H', 'Longatto-Filho, Adhemar', 'Reis, Rui M', 'Scapulatempo-Neto, Cristovam', 'Silveira, Henrique C S', 'Vidal, Daniel O', 'Burnette, Andrew', 'Eschbacher, Jennifer', 'Hermes, Beth', 'Noss, Ardene', 'Singh, Rosy', 'Anderson, Matthew L', 'Castro, Patricia D', 'Ittmann, Michael', 'Huntsman, David', 'Kohl, Bernard', 'Le, Xuan', 'Thorp, Richard', 'Andry, Chris', 'Duffy, Elizabeth R', 'Lyadov, Vladimir', 'Paklina, Oxana', 'Setdikova, Galiya', 'Shabunin, Alexey', 'Tavobilov, Mikhail', 'McPherson, Christopher', 'Warnick, Ronald', 'Berkowitz, Ross', 'Cramer, Daniel', 'Feltmate, Colleen', 'Horowitz, Neil', 'Kibel, Adam', 'Muto, Michael', 'Raut, Chandrajit P', 'Malykh, Andrei', 'Barnholtz-Sloan, Jill S', 'Barrett, Wendi', 'Devine, Karen', 'Fulop, Jordonna', 'Ostrom, Quinn T', 'Shimmel, Kristen', 'Wolinsky, Yingli', 'Sloan, Andrew E', 'De Rose, Agostino', 'Giuliante, Felice', 'Goodman, Marc', 'Karlan, Beth Y', 'Hagedorn, Curt H', 'Eckman, John', 'Harr, Jodi', 'Myers, Jerome', 'Tucker, Kelinda', 'Zach, Leigh Anne', 'Deyarmin, Brenda', 'Hu, Hai', 'Kvecher, Leonid', 'Larson, Caroline', 'Mural, Richard J', 'Somiari, Stella', 'Vicha, Ales', 'Zelinka, Tomas', 'Bennett, Joseph', 'Iacocca, Mary', 'Rabeno, Brenda', 'Swanson, Patricia', 'Latour, Mathieu', 'Lacombe, Louis', 'Tetu, Bernard', 'Bergeron, Alain', 'McGraw, Mary', 'Staugaitis, Susan M', 'Chabot, John', 'Hibshoosh, Hanina', 'Sepulveda, Antonia', 'Su, Tao', 'Wang, Timothy', 'Potapova, Olga', 'Voronina, Olga', 'Desjardins, Laurence', 'Mariani, Odette', 'Roman-Roman, Sergio', 'Sastre, Xavier', 'Stern, Marc-Henri', 'Cheng, Feixiong', 'Signoretti, Sabina', 'Berchuck, Andrew', 'Bigner, Darell', 'Lipp, Eric', 'Marks, Jeffrey', 'McCall, Shannon', 'McLendon, Roger', 'Secord, Angeles', 'Sharp, Alexis', 'Behera, Madhusmita', 'Brat, Daniel J', 'Chen, Amy', 'Delman, Keith', 'Force, Seth', 'Khuri, Fadlo', 'Magliocca, Kelly', 'Maithel, Shishir', 'Olson, Jeffrey J', 'Owonikoko, Taofeek', 'Pickens, Alan', 'Ramalingam, Suresh', 'Shin, Dong M', 'Sica, Gabriel', 'Van Meir, Erwin G', 'Zhang, Hongzheng', 'Eijckenboom, Wil', 'Gillis, Ad', 'Korpershoek, Esther', 'Looijenga, Leendert', 'Oosterhuis, Wolter', 'Stoop, Hans', 'van Kessel, Kim E', 'Zwarthoff, Ellen C', 'Calatozzolo, Chiara', 'Cuppini, Lucia', 'Cuzzubbo, Stefania', 'DiMeco, Francesco', 'Finocchiaro, Gaetano', 'Mattei, Luca', 'Perin, Alessandro', 'Pollo, Bianca', 'Chen, Chu', 'Houck, John', 'Lohavanichbutr, Pawadee', 'Hartmann, Arndt', 'Stoehr, Christine', 'Stoehr, Robert', 'Taubert, Helge', 'Wach, Sven', 'Wullich, Bernd', 'Kycler, Witold', 'Murawa, Dawid', 'Wiznerowicz, Maciej', 'Chung, Ki', 'Edenfield, W Jeffrey', 'Martin, Julie', 'Baudin, Eric', 'Bubley, Glenn', 'Bueno, Raphael', 'De Rienzo, Assunta', 'Richards, William G', 'Kalkanis, Steven', 'Mikkelsen, Tom', 'Noushmehr, Houtan', 'Scarpace, Lisa', 'Girard, Nicolas', 'Aymerich, Marta', 'Campo, Elias', 'Gine, Eva', 'Guillermo, Armando Lopez', 'Van Bang, Nguyen', 'Hanh, Phan Thi', 'Phu, Bui Duc', 'Tang, Yufang', 'Colman, Howard', 'Evason, Kimberley', 'Dottino, Peter R', 'Martignetti, John A', 'Gabra, Hani', 'Juhl, Hartmut', 'Akeredolu, Teniola', 'Stepa, Serghei', 'Hoon, Dave', 'Ahn, Keunsoo', 'Kang, Koo Jeong', 'Beuschlein, Felix', 'Breggia, Anne', 'Birrer, Michael', 'Bell, Debra', 'Borad, Mitesh', 'Bryce, Alan H', 'Castle, Erik', 'Chandan, Vishal', 'Cheville, John', 'Copland, John A', 'Farnell, Michael', 'Flotte, Thomas', 'Giama, Nasra', 'Ho, Thai', 'Kendrick, Michael', 'Kocher, Jean-Pierre', 'Kopp, Karla', 'Moser, Catherine', 'Nagorney, David', ""O'Brien, Daniel"", ""O'Neill, Brian Patrick"", 'Patel, Tushar', 'Petersen, Gloria', 'Que, Florencia', 'Rivera, Michael', 'Roberts, Lewis', 'Smallridge, Robert', 'Smyrk, Thomas', 'Stanton, Melissa', 'Thompson, R Houston', 'Torbenson, Michael', 'Yang, Ju Dong', 'Zhang, Lizhi', 'Brimo, Fadi', 'Ajani, Jaffer A', 'Gonzalez, Ana Maria Angulo', 'Behrens, Carmen', 'Bondaruk, Jolanta', 'Broaddus, Russell', 'Czerniak, Bogdan', 'Esmaeli, Bita', 'Fujimoto, Junya', 'Gershenwald, Jeffrey', 'Guo, Charles', 'Lazar, Alexander J', 'Logothetis, Christopher', 'Meric-Bernstam, Funda', 'Moran, Cesar', 'Ramondetta, Lois', 'Rice, David', 'Sood, Anil', 'Tamboli, Pheroze', 'Thompson, Timothy', 'Troncoso, Patricia', 'Tsao, Anne', 'Wistuba, Ignacio', 'Carter, Candace', 'Haydu, Lauren', 'Hersey, Peter', 'Jakrot, Valerie', 'Kakavand, Hojabr', 'Kefford, Richard', 'Lee, Kenneth', 'Long, Georgina', 'Mann, Graham', 'Quinn, Michael', 'Saw, Robyn', 'Scolyer, Richard', 'Shannon, Kerwin', 'Spillane, Andrew', 'Stretch, Onathan', 'Synott, Maria', 'Thompson, John', 'Wilmott, James', 'Al-Ahmadie, Hikmat', 'Chan, Timothy A', 'Ghossein, Ronald', 'Gopalan, Anuradha', 'Levine, Douglas A', 'Reuter, Victor', 'Singer, Samuel', 'Singh, Bhuvanesh', 'Tien, Nguyen Viet', 'Broudy, Thomas', 'Mirsaidi, Cyrus', 'Nair, Praveen', 'Drwiega, Paul', 'Miller, Judy', 'Smith, Jennifer', 'Zaren, Howard', 'Park, Joong-Won', 'Hung, Nguyen Phi', 'Kebebew, Electron', 'Linehan, W Marston', 'Metwalli, Adam R', 'Pacak, Karel', 'Pinto, Peter A', 'Schiffman, Mark', 'Schmidt, Laura S', 'Vocke, Cathy D', 'Wentzensen, Nicolas', 'Worrell, Robert', 'Yang, Hannah', 'Moncrieff, Marc', 'Goparaju, Chandra', 'Melamed, Jonathan', 'Pass, Harvey', 'Botnariuc, Natalia', 'Caraman, Irina', 'Cernat, Mircea', 'Chemencedji, Inga', 'Clipca, Adrian', 'Doruc, Serghei', 'Gorincioi, Ghenadie', 'Mura, Sergiu', 'Pirtac, Maria', 'Stancul, Irina', 'Tcaciuc, Diana', 'Albert, Monique', 'Alexopoulou, Iakovina', 'Arnaout, Angel', 'Bartlett, John', 'Engel, Jay', 'Gilbert, Sebastien', 'Parfitt, Jeremy', 'Sekhon, Harman', 'Thomas, George', 'Rassl, Doris M', 'Rintoul, Robert C', 'Bifulco, Carlo', 'Tamakawa, Raina', 'Urba, Walter', 'Hayward, Nicholas', 'Timmers, Henri', 'Antenucci, Anna', 'Facciolo, Francesco', 'Grazi, Gianluca', 'Marino, Mirella', 'Merola, Roberta', 'de Krijger, Ronald', 'Gimenez-Roqueplo, Anne-Paule', 'Piche, Alain', 'Chevalier, Simone', 'McKercher, Ginette', 'Birsoy, Kivanc', 'Barnett, Gene', 'Brewer, Cathy', 'Farver, Carol', 'Naska, Theresa', 'Pennell, Nathan A', 'Raymond, Daniel', 'Schilero, Cathy', 'Smolenski, Kathy', 'Williams, Felicia', 'Morrison, Carl', 'Borgia, Jeffrey A', 'Liptay, Michael J', 'Pool, Mark', 'Seder, Christopher W', 'Junker, Kerstin', 'Omberg, Larsson', 'Dinkin, Mikhail', 'Manikhas, George', 'Alvaro, Domenico', 'Bragazzi, Maria Consiglia', 'Cardinale, Vincenzo', 'Carpino, Guido', 'Gaudio, Eugenio', 'Chesla, David', 'Cottingham, Sandra', 'Dubina, Michael', 'Moiseenko, Fedor', 'Dhanasekaran, Renumathy', 'Becker, Karl-Friedrich', 'Janssen, Klaus-Peter', 'Slotta-Huspenina, Julia', 'Abdel-Rahman, Mohamed H', 'Aziz, Dina', 'Bell, Sue', 'Cebulla, Colleen M', 'Davis, Amy', 'Duell, Rebecca', 'Elder, J Bradley', 'Hilty, Joe', 'Kumar, Bahavna', 'Lang, James', 'Lehman, Norman L', 'Mandt, Randy', 'Nguyen, Phuong', 'Pilarski, Robert', 'Rai, Karan', 'Schoenfield, Lynn', 'Senecal, Kelly', 'Wakely, Paul', 'Hansen, Paul', 'Lechan, Ronald', 'Powers, James', 'Tischler, Arthur', 'Grizzle, William E', 'Sexton, Katherine C', 'Kastl, Alison', 'Henderson, Joel', 'Porten, Sima', 'Waldmann, Jens', 'Fassnacht, Martin', 'Asa, Sylvia L', 'Schadendorf, Dirk', 'Couce, Marta', 'Graefen, Markus', 'Huland, Hartwig', 'Sauter, Guido', 'Schlomm, Thorsten', 'Simon, Ronald', 'Tennstedt, Pierre', 'Olabode, Oluwole', 'Nelson, Mark', 'Bathe, Oliver', 'Carroll, Peter R', 'Chan, June M', 'Disaia, Philip', 'Glenn, Pat', 'Kelley, Robin K', 'Landen, Charles N', 'Phillips, Joanna', 'Prados, Michael', 'Simko, Jeffry', 'Smith-McCune, Karen', 'VandenBerg, Scott', 'Roggin, Kevin', 'Fehrenbach, Ashley', 'Kendler, Ady', 'Sifri, Suzanne', 'Steele, Ruth', 'Jimeno, Antonio', 'Carey, Francis', 'Forgie, Ian', 'Mannelli, Massimo', 'Carney, Michael', 'Hernandez, Brenda', 'Campos, Benito', 'Herold-Mende, Christel', 'Jungk, Christin', 'Unterberg, Andreas', 'von Deimling, Andreas', 'Bossler, Aaron', 'Galbraith, Joseph', 'Jacobus, Laura', 'Knudson, Michael', 'Knutson, Tina', 'Ma, Deqin', 'Milhem, Mohammed', 'Sigmund, Rita', 'Godwin, Andrew K', 'Madan, Rashna', 'Rosenthal, Howard G', 'Adebamowo, Clement', 'Adebamowo, Sally N', 'Boussioutas, Alex', 'Beer, David', 'Giordano, Thomas', 'Mes-Masson, Anne-Marie', 'Saad, Fred', 'Bocklage, Therese', 'Landrum, Lisa', 'Mannel, Robert', 'Moore, Kathleen', 'Moxley, Katherine', 'Postier, Russel', 'Walker, Joan', 'Zuna, Rosemary', 'Feldman, Michael', 'Valdivieso, Federico', 'Dhir, Rajiv', 'Luketich, James', 'Pinero, Edna M Mora', 'Quintero-Aguilo, Mario', 'Carlotti, Carlos Gilberto Jr', 'Dos Santos, Jose Sebastiao', 'Kemp, Rafael', 'Sankarankuty, Ajith', 'Tirapelli, Daniela', 'Catto, James', 'Agnew, Kathy', 'Swisher, Elizabeth', 'Creaney, Jenette', 'Robinson, Bruce', 'Shelley, Carl Simon', 'Godwin, Eryn M', 'Kendall, Sara', 'Shipman, Cassaundra', 'Bradford, Carol', 'Carey, Thomas', 'Haddad, Andrea', 'Moyer, Jeffey', 'Peterson, Lisa', 'Prince, Mark', 'Rozek, Laura', 'Wolf, Gregory', 'Bowman, Rayleen', 'Fong, Kwun M', 'Yang, Ian', 'Korst, Robert', 'Rathmell, W Kimryn', 'Fantacone-Campbell, J Leigh', 'Hooke, Jeffrey A', 'Kovatich, Albert J', 'Shriver, Craig D', 'DiPersio, John', 'Drake, Bettina', 'Govindan, Ramaswamy', 'Heath, Sharon', 'Ley, Timothy', 'Van Tine, Brian', 'Westervelt, Peter', 'Rubin, Mark A', 'Lee, Jung Il', 'Aredes, Natalia D', 'Mariamidze, Armaz']"	['U24 CA210950/CA/NCI NIH HHS/United States', 'P30 CA016672/CA/NCI NIH HHS/United States', 'U24 CA143882/CA/NCI NIH HHS/United States', 'U54 HG003067/HG/NHGRI NIH HHS/United States', 'U24 CA143835/CA/NCI NIH HHS/United States', 'R01 LM009239/LM/NLM NIH HHS/United States', 'U24 CA180924/CA/NCI NIH HHS/United States', 'U24 CA143866/CA/NCI NIH HHS/United States', 'U24 CA143845/CA/NCI NIH HHS/United States', 'U24 CA143799/CA/NCI NIH HHS/United States', 'U54 HG003273/HG/NHGRI NIH HHS/United States', 'U24 CA144025/CA/NCI NIH HHS/United States', 'U24 CA143840/CA/NCI NIH HHS/United States', 'U24 CA143843/CA/NCI NIH HHS/United States', 'HHSN261201400007C/CA/NCI NIH HHS/United States', 'U24 CA143858/CA/NCI NIH HHS/United States', 'U24 CA143848/CA/NCI NIH HHS/United States', 'U24 CA210957/CA/NCI NIH HHS/United States', 'U54 HG003079/HG/NHGRI NIH HHS/United States', 'U24 CA210949/CA/NCI NIH HHS/United States', 'U24 CA143883/CA/NCI NIH HHS/United States', 'R01 CA163722/CA/NCI NIH HHS/United States', 'U24 CA143867/CA/NCI NIH HHS/United States', 'R50 CA221675/CA/NCI NIH HHS/United States', 'U24 CA215109/CA/NCI NIH HHS/United States', 'U24 CA199461/CA/NCI NIH HHS/United States', 'U24 CA210990/CA/NCI NIH HHS/United States']	1	"['Caesar-Johnson SJ', 'Demchok JA', 'Felau I', 'Kasapi M', 'Ferguson ML', 'Hutter CM', 'Sofia HJ', 'Tarnuzzer R', 'Wang Z', 'Yang L', 'Zenklusen JC', 'Zhang JJ', 'Chudamani S', 'Liu J', 'Lolla L', 'Naresh R', 'Pihl T', 'Sun Q', 'Wan Y', 'Wu Y', 'Cho J', 'DeFreitas T', 'Frazer S', 'Gehlenborg N', 'Getz G', 'Heiman DI', 'Kim J', 'Lawrence MS', 'Lin P', 'Meier S', 'Noble MS', 'Saksena G', 'Voet D', 'Zhang H', 'Bernard B', 'Chambwe N', 'Dhankani V', 'Knijnenburg T', 'Kramer R', 'Leinonen K', 'Liu Y', 'Miller M', 'Reynolds S', 'Shmulevich I', 'Thorsson V', 'Zhang W', 'Akbani R', 'Broom BM', 'Hegde AM', 'Ju Z', 'Kanchi RS', 'Korkut A', 'Li J', 'Liang H', 'Ling S', 'Liu W', 'Lu Y', 'Mills GB', 'Ng KS', 'Rao A', 'Ryan M', 'Wang J', 'Weinstein JN', 'Zhang J', 'Abeshouse A', 'Armenia J', 'Chakravarty D', 'Chatila WK', 'de Bruijn I', 'Gao J', 'Gross BE', 'Heins ZJ', 'Kundra R', 'La K', 'Ladanyi M', 'Luna A', 'Nissan MG', 'Ochoa A', 'Phillips SM', 'Reznik E', 'Sanchez-Vega F', 'Sander C', 'Schultz N', 'Sheridan R', 'Sumer SO', 'Sun Y', 'Taylor BS', 'Wang J', 'Zhang H', 'Anur P', 'Peto M', 'Spellman P', 'Benz C', 'Stuart JM', 'Wong CK', 'Yau C', 'Hayes DN', 'Parker JS', 'Wilkerson MD', 'Ally A', 'Balasundaram M', 'Bowlby R', 'Brooks D', 'Carlsen R', 'Chuah E', 'Dhalla N', 'Holt R', 'Jones SJM', 'Kasaian K', 'Lee D', 'Ma Y', 'Marra MA', 'Mayo M', 'Moore RA', 'Mungall AJ', 'Mungall K', 'Robertson AG', 'Sadeghi S', 'Schein JE', 'Sipahimalani P', 'Tam A', 'Thiessen N', 'Tse K', 'Wong T', 'Berger AC', 'Beroukhim R', 'Cherniack AD', 'Cibulskis C', 'Gabriel SB', 'Gao GF', 'Ha G', 'Meyerson M', 'Schumacher SE', 'Shih J', 'Kucherlapati MH', 'Kucherlapati RS', 'Baylin S', 'Cope L', 'Danilova L', 'Bootwalla MS', 'Lai PH', 'Maglinte DT', 'Van Den Berg DJ', 'Weisenberger DJ', 'Auman JT', 'Balu S', 'Bodenheimer T', 'Fan C', 'Hoadley KA', 'Hoyle AP', 'Jefferys SR', 'Jones CD', 'Meng S', 'Mieczkowski PA', 'Mose LE', 'Perou AH', 'Perou CM', 'Roach J', 'Shi Y', 'Simons JV', 'Skelly T', 'Soloway MG', 'Tan D', 'Veluvolu U', 'Fan H', 'Hinoue T', 'Laird PW', 'Shen H', 'Zhou W', 'Bellair M', 'Chang K', 'Covington K', 'Creighton CJ', 'Dinh H', 'Doddapaneni H', 'Donehower LA', 'Drummond J', 'Gibbs RA', 'Glenn R', 'Hale W', 'Han Y', 'Hu J', 'Korchina V', 'Lee S', 'Lewis L', 'Li W', 'Liu X', 'Morgan M', 'Morton D', 'Muzny D', 'Santibanez J', 'Sheth M', 'Shinbrot E', 'Wang L', 'Wang M', 'Wheeler DA', 'Xi L', 'Zhao F', 'Hess J', 'Appelbaum EL', 'Bailey M', 'Cordes MG', 'Ding L', 'Fronick CC', 'Fulton LA', 'Fulton RS', 'Kandoth C', 'Mardis ER', 'McLellan MD', 'Miller CA', 'Schmidt HK', 'Wilson RK', 'Crain D', 'Curley E', 'Gardner J', 'Lau K', 'Mallery D', 'Morris S', 'Paulauskis J', 'Penny R', 'Shelton C', 'Shelton T', 'Sherman M', 'Thompson E', 'Yena P', 'Bowen J', 'Gastier-Foster JM', 'Gerken M', 'Leraas KM', 'Lichtenberg TM', 'Ramirez NC', 'Wise L', 'Zmuda E', 'Corcoran N', 'Costello T', 'Hovens C', 'Carvalho AL', 'de Carvalho AC', 'Fregnani JH', 'Longatto-Filho A', 'Reis RM', 'Scapulatempo-Neto C', 'Silveira HCS', 'Vidal DO', 'Burnette A', 'Eschbacher J', 'Hermes B', 'Noss A', 'Singh R', 'Anderson ML', 'Castro PD', 'Ittmann M', 'Huntsman D', 'Kohl B', 'Le X', 'Thorp R', 'Andry C', 'Duffy ER', 'Lyadov V', 'Paklina O', 'Setdikova G', 'Shabunin A', 'Tavobilov M', 'McPherson C', 'Warnick R', 'Berkowitz R', 'Cramer D', 'Feltmate C', 'Horowitz N', 'Kibel A', 'Muto M', 'Raut CP', 'Malykh A', 'Barnholtz-Sloan JS', 'Barrett W', 'Devine K', 'Fulop J', 'Ostrom QT', 'Shimmel K', 'Wolinsky Y', 'Sloan AE', 'De Rose A', 'Giuliante F', 'Goodman M', 'Karlan BY', 'Hagedorn CH', 'Eckman J', 'Harr J', 'Myers J', 'Tucker K', 'Zach LA', 'Deyarmin B', 'Hu H', 'Kvecher L', 'Larson C', 'Mural RJ', 'Somiari S', 'Vicha A', 'Zelinka T', 'Bennett J', 'Iacocca M', 'Rabeno B', 'Swanson P', 'Latour M', 'Lacombe L', 'Tetu B', 'Bergeron A', 'McGraw M', 'Staugaitis SM', 'Chabot J', 'Hibshoosh H', 'Sepulveda A', 'Su T', 'Wang T', 'Potapova O', 'Voronina O', 'Desjardins L', 'Mariani O', 'Roman-Roman S', 'Sastre X', 'Stern MH', 'Cheng F', 'Signoretti S', 'Berchuck A', 'Bigner D', 'Lipp E', 'Marks J', 'McCall S', 'McLendon R', 'Secord A', 'Sharp A', 'Behera M', 'Brat DJ', 'Chen A', 'Delman K', 'Force S', 'Khuri F', 'Magliocca K', 'Maithel S', 'Olson JJ', 'Owonikoko T', 'Pickens A', 'Ramalingam S', 'Shin DM', 'Sica G', 'Van Meir EG', 'Zhang H', 'Eijckenboom W', 'Gillis A', 'Korpershoek E', 'Looijenga L', 'Oosterhuis W', 'Stoop H', 'van Kessel KE', 'Zwarthoff EC', 'Calatozzolo C', 'Cuppini L', 'Cuzzubbo S', 'DiMeco F', 'Finocchiaro G', 'Mattei L', 'Perin A', 'Pollo B', 'Chen C', 'Houck J', 'Lohavanichbutr P', 'Hartmann A', 'Stoehr C', 'Stoehr R', 'Taubert H', 'Wach S', 'Wullich B', 'Kycler W', 'Murawa D', 'Wiznerowicz M', 'Chung K', 'Edenfield WJ', 'Martin J', 'Baudin E', 'Bubley G', 'Bueno R', 'De Rienzo A', 'Richards WG', 'Kalkanis S', 'Mikkelsen T', 'Noushmehr H', 'Scarpace L', 'Girard N', 'Aymerich M', 'Campo E', 'Gine E', 'Guillermo AL', 'Van Bang N', 'Hanh PT', 'Phu BD', 'Tang Y', 'Colman H', 'Evason K', 'Dottino PR', 'Martignetti JA', 'Gabra H', 'Juhl H', 'Akeredolu T', 'Stepa S', 'Hoon D', 'Ahn K', 'Kang KJ', 'Beuschlein F', 'Breggia A', 'Birrer M', 'Bell D', 'Borad M', 'Bryce AH', 'Castle E', 'Chandan V', 'Cheville J', 'Copland JA', 'Farnell M', 'Flotte T', 'Giama N', 'Ho T', 'Kendrick M', 'Kocher JP', 'Kopp K', 'Moser C', 'Nagorney D', ""O'Brien D"", ""O'Neill BP"", 'Patel T', 'Petersen G', 'Que F', 'Rivera M', 'Roberts L', 'Smallridge R', 'Smyrk T', 'Stanton M', 'Thompson RH', 'Torbenson M', 'Yang JD', 'Zhang L', 'Brimo F', 'Ajani JA', 'Gonzalez AMA', 'Behrens C', 'Bondaruk J', 'Broaddus R', 'Czerniak B', 'Esmaeli B', 'Fujimoto J', 'Gershenwald J', 'Guo C', 'Lazar AJ', 'Logothetis C', 'Meric-Bernstam F', 'Moran C', 'Ramondetta L', 'Rice D', 'Sood A', 'Tamboli P', 'Thompson T', 'Troncoso P', 'Tsao A', 'Wistuba I', 'Carter C', 'Haydu L', 'Hersey P', 'Jakrot V', 'Kakavand H', 'Kefford R', 'Lee K', 'Long G', 'Mann G', 'Quinn M', 'Saw R', 'Scolyer R', 'Shannon K', 'Spillane A', 'Stretch O', 'Synott M', 'Thompson J', 'Wilmott J', 'Al-Ahmadie H', 'Chan TA', 'Ghossein R', 'Gopalan A', 'Levine DA', 'Reuter V', 'Singer S', 'Singh B', 'Tien NV', 'Broudy T', 'Mirsaidi C', 'Nair P', 'Drwiega P', 'Miller J', 'Smith J', 'Zaren H', 'Park JW', 'Hung NP', 'Kebebew E', 'Linehan WM', 'Metwalli AR', 'Pacak K', 'Pinto PA', 'Schiffman M', 'Schmidt LS', 'Vocke CD', 'Wentzensen N', 'Worrell R', 'Yang H', 'Moncrieff M', 'Goparaju C', 'Melamed J', 'Pass H', 'Botnariuc N', 'Caraman I', 'Cernat M', 'Chemencedji I', 'Clipca A', 'Doruc S', 'Gorincioi G', 'Mura S', 'Pirtac M', 'Stancul I', 'Tcaciuc D', 'Albert M', 'Alexopoulou I', 'Arnaout A', 'Bartlett J', 'Engel J', 'Gilbert S', 'Parfitt J', 'Sekhon H', 'Thomas G', 'Rassl DM', 'Rintoul RC', 'Bifulco C', 'Tamakawa R', 'Urba W', 'Hayward N', 'Timmers H', 'Antenucci A', 'Facciolo F', 'Grazi G', 'Marino M', 'Merola R', 'de Krijger R', 'Gimenez-Roqueplo AP', 'Piche A', 'Chevalier S', 'McKercher G', 'Birsoy K', 'Barnett G', 'Brewer C', 'Farver C', 'Naska T', 'Pennell NA', 'Raymond D', 'Schilero C', 'Smolenski K', 'Williams F', 'Morrison C', 'Borgia JA', 'Liptay MJ', 'Pool M', 'Seder CW', 'Junker K', 'Omberg L', 'Dinkin M', 'Manikhas G', 'Alvaro D', 'Bragazzi MC', 'Cardinale V', 'Carpino G', 'Gaudio E', 'Chesla D', 'Cottingham S', 'Dubina M', 'Moiseenko F', 'Dhanasekaran R', 'Becker KF', 'Janssen KP', 'Slotta-Huspenina J', 'Abdel-Rahman MH', 'Aziz D', 'Bell S', 'Cebulla CM', 'Davis A', 'Duell R', 'Elder JB', 'Hilty J', 'Kumar B', 'Lang J', 'Lehman NL', 'Mandt R', 'Nguyen P', 'Pilarski R', 'Rai K', 'Schoenfield L', 'Senecal K', 'Wakely P', 'Hansen P', 'Lechan R', 'Powers J', 'Tischler A', 'Grizzle WE', 'Sexton KC', 'Kastl A', 'Henderson J', 'Porten S', 'Waldmann J', 'Fassnacht M', 'Asa SL', 'Schadendorf D', 'Couce M', 'Graefen M', 'Huland H', 'Sauter G', 'Schlomm T', 'Simon R', 'Tennstedt P', 'Olabode O', 'Nelson M', 'Bathe O', 'Carroll PR', 'Chan JM', 'Disaia P', 'Glenn P', 'Kelley RK', 'Landen CN', 'Phillips J', 'Prados M', 'Simko J', 'Smith-McCune K', 'VandenBerg S', 'Roggin K', 'Fehrenbach A', 'Kendler A', 'Sifri S', 'Steele R', 'Jimeno A', 'Carey F', 'Forgie I', 'Mannelli M', 'Carney M', 'Hernandez B', 'Campos B', 'Herold-Mende C', 'Jungk C', 'Unterberg A', 'von Deimling A', 'Bossler A', 'Galbraith J', 'Jacobus L', 'Knudson M', 'Knutson T', 'Ma D', 'Milhem M', 'Sigmund R', 'Godwin AK', 'Madan R', 'Rosenthal HG', 'Adebamowo C', 'Adebamowo SN', 'Boussioutas A', 'Beer D', 'Giordano T', 'Mes-Masson AM', 'Saad F', 'Bocklage T', 'Landrum L', 'Mannel R', 'Moore K', 'Moxley K', 'Postier R', 'Walker J', 'Zuna R', 'Feldman M', 'Valdivieso F', 'Dhir R', 'Luketich J', 'Pinero EMM', 'Quintero-Aguilo M', 'Carlotti CG Jr', 'Dos Santos JS', 'Kemp R', 'Sankarankuty A', 'Tirapelli D', 'Catto J', 'Agnew K', 'Swisher E', 'Creaney J', 'Robinson B', 'Shelley CS', 'Godwin EM', 'Kendall S', 'Shipman C', 'Bradford C', 'Carey T', 'Haddad A', 'Moyer J', 'Peterson L', 'Prince M', 'Rozek L', 'Wolf G', 'Bowman R', 'Fong KM', 'Yang I', 'Korst R', 'Rathmell WK', 'Fantacone-Campbell JL', 'Hooke JA', 'Kovatich AJ', 'Shriver CD', 'DiPersio J', 'Drake B', 'Govindan R', 'Heath S', 'Ley T', 'Van Tine B', 'Westervelt P', 'Rubin MA', 'Lee JI', 'Aredes ND', 'Mariamidze A']"	2211-1247 (Electronic)	101573691	Cell reports	['eng']	S2211-1247(18)30447-9 [pii] 10.1016/j.celrep.2018.03.086 [doi]	20190903	['*Deep Learning', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Lymphocytes, Tumor-Infiltrating/metabolism/*pathology', 'Neoplasms/*pathology']	2019/09/04 06:00	['NIHMS958989']	['*artificial intelligence', '*bioinformatics', '*computer vision', '*deep learning', '*digital pathology', '*immuno-oncology', '*lymphocytes', '*machine learning', '*tumor microenvironment', '*tumor-infiltrating lymphocytes']	['NOTNLM']	NLM	181-193.e7	['2018/01/11 00:00 [received]', '2018/02/27 00:00 [revised]', '2018/03/20 00:00 [accepted]', '2018/04/05 06:00 [entrez]', '2018/04/05 06:00 [pubmed]', '2019/09/04 06:00 [medline]']	United States	PMC5943714		29617659	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Cell Rep. 2018 Apr 3;23(1):181-193.e7. doi: 10.1016/j.celrep.2018.03.086.	MEDLINE	Cell Rep	Spatial Organization and Molecular Correlation of Tumor-Infiltrating Lymphocytes Using Deep Learning on Pathology Images.		23	Spatial Organization and Molecular Correlation of Tumor-Infiltrating Lymphocytes Using Deep Learning on Pathology Images.
Motivation: Bacterial resistance to antibiotics is a growing concern. Antimicrobial peptides (AMPs), natural components of innate immunity, are popular targets for developing new drugs. Machine learning methods are now commonly adopted by wet-laboratory researchers to screen for promising candidates. Results: In this work, we utilize deep learning to recognize antimicrobial activity. We propose a neural network model with convolutional and recurrent layers that leverage primary sequence composition. Results show that the proposed model outperforms state-of-the-art classification models on a comprehensive dataset. By utilizing the embedding weights, we also present a reduced-alphabet representation and show that reasonable AMP recognition can be maintained using nine amino acid types. Availability and implementation: Models and datasets are made freely available through the Antimicrobial Peptide Scanner vr.2 web server at www.ampscanner.com. Supplementary information: Supplementary data are available at Bioinformatics online.	['Bioinformatics and Computational Biosciences Branch, Office of Cyber Infrastructure and Computational Biology, National Institute of Allergy and Infectious Diseases, U.S. National Institutes of Health, Rockville, MD, USA.', 'Medical Science & Computing, LLC, Rockville, MD, USA.', 'Digital Reasoning, McLean, VA, USA.', 'Department of Computer Science, George Mason University, Fairfax, VA, USA.', 'Department of Bioengineering, George Mason University, Fairfax, VA, USA.', 'School of Systems Biology, George Mason University, Manassas, VA, USA.']	['4953367 [pii]', '10.1093/bioinformatics/bty179 [doi]']	['Veltri D', 'Kamath U', 'Shehu A']							['2018/03/29 06:00']	20190917		2018 Aug 15	2018/03/29 06:00		['Veltri, Daniel', 'Kamath, Uday', 'Shehu, Amarda']			16		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty179 [doi]	20190917	['Anti-Infective Agents/*pharmacology', 'Computational Biology/*methods', '*Deep Learning', 'Peptides/*pharmacology', 'Sequence Analysis, Protein/*methods']	2019/09/19 06:00				NLM	2740-2747	['2017/12/14 00:00 [received]', '2018/03/28 00:00 [accepted]', '2018/03/29 06:00 [pubmed]', '2019/09/19 06:00 [medline]', '2018/03/29 06:00 [entrez]']	England	PMC6084614		29590297	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Anti-Infective Agents)', '0 (Peptides)']	IM		Bioinformatics. 2018 Aug 15;34(16):2740-2747. doi: 10.1093/bioinformatics/bty179.	MEDLINE	Bioinformatics	Deep learning improves antimicrobial peptide recognition.		34	Deep learning improves antimicrobial peptide recognition.
Spatial resolution is one of the key parameters of magnetic resonance imaging (MRI). The image super-resolution (SR) technique offers an alternative approach to improve the spatial resolution of MRI due to its simplicity. Convolutional neural networks (CNN)-based SR algorithms have achieved state-of-the-art performance, in which the global residual learning (GRL) strategy is now commonly used due to its effectiveness for learning image details for SR. However, the partial loss of image details usually happens in a very deep network due to the degradation problem. In this work, we propose a novel residual learning-based SR algorithm for MRI, which combines both multi-scale GRL and shallow network block-based local residual learning (LRL). The proposed LRL module works effectively in capturing high-frequency details by learning local residuals. One simulated MRI dataset and two real MRI datasets have been used to evaluate our algorithm. The experimental results show that the proposed SR algorithm achieves superior performance to all of the other compared CNN-based SR algorithms in this work.	"[""Shanghai Institute for Advanced Communication and Data Science, Shanghai University, 200444 Shanghai, People's Republic of China. School of Communication and Information Engineering, Shanghai University, 200444 Shanghai, People's Republic of China.""]"	['10.1088/1361-6560/aab9e9 [doi]']	['Shi J', 'Liu Q', 'Wang C', 'Zhang Q', 'Ying S', 'Xu H']							['2018/03/28 06:00']	20190422	20180419	2018 Apr 19	2018/03/28 06:00		['Shi, Jun', 'Liu, Qingping', 'Wang, Chaofeng', 'Zhang, Qi', 'Ying, Shihui', 'Xu, Haoyu']			8		1361-6560 (Electronic) 0031-9155 (Linking)	0401220	Physics in medicine and biology	['eng']	10.1088/1361-6560/aab9e9 [doi]	20190422	['*Algorithms', 'Brain/diagnostic imaging', 'Computer Simulation', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Magnetic Resonance Imaging/*methods', '*Neural Networks (Computer)']	2019/04/23 06:00				NLM	085011	['2018/03/28 06:00 [pubmed]', '2019/04/23 06:00 [medline]', '2018/03/28 06:00 [entrez]']	England			29583134	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Phys Med Biol. 2018 Apr 19;63(8):085011. doi: 10.1088/1361-6560/aab9e9.	MEDLINE	Phys Med Biol	Super-resolution reconstruction of MR image with a novel residual learning network algorithm.		63	Super-resolution reconstruction of MR image with a novel residual learning network algorithm.
We present 'UBO Detector', a cluster-based, fully automated pipeline for extracting and calculating variables for regions of white matter hyperintensities (WMH) (available for download at https://cheba.unsw.edu.au/group/neuroimaging-pipeline). It takes T1-weighted and fluid attenuated inversion recovery (FLAIR) scans as input, and SPM12 and FSL functions are utilised for pre-processing. The candidate clusters are then generated by FMRIB's Automated Segmentation Tool (FAST). A supervised machine learning algorithm, k-nearest neighbor (k-NN), is applied to determine whether the candidate clusters are WMH or non-WMH. UBO Detector generates both image and text (volumes and the number of WMH clusters) outputs for whole brain, periventricular, deep, and lobar WMH, as well as WMH in arterial territories. The computation time for each brain is approximately 15min. We validated the performance of UBO Detector by showing a) high segmentation (similarity index (SI)=0.848) and volumetric (intraclass correlation coefficient (ICC)=0.985) agreement between the UBO Detector-derived and manually traced WMH; b) highly correlated (r(2)>0.9) and a steady increase of WMH volumes over time; and c) significant associations of periventricular (t=22.591, p<0.001) and deep (t=14.523, p<0.001) WMH volumes generated by UBO Detector with Fazekas rating scores. With parallel computing enabled in UBO Detector, the processing can take advantage of multi-core CPU's that are commonly available on workstations. In conclusion, UBO Detector is a reliable, efficient and fully automated WMH segmentation pipeline.	['Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia.', 'School of Biological Science and Medical Engineering, Beihang University, Beijing, China. Electronic address: tao.liu@buaa.edu.cn.', 'Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; School of Biological Science and Medical Engineering, Beihang University, Beijing, China.', 'Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia.', 'School of Biological Science and Medical Engineering, Beihang University, Beijing, China.', 'Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia.', 'Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia.', 'Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia. Electronic address: w.wen@unsw.edu.au.']	['S1053-8119(18)30260-X [pii]', '10.1016/j.neuroimage.2018.03.050 [doi]']	['Jiang J', 'Liu T', 'Zhu W', 'Koncz R', 'Liu H', 'Lee T', 'Sachdev PS', 'Wen W']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/03/27 06:00']	20190111	20180322	2018 Jul 1	2018/03/27 06:00		['Jiang, Jiyang', 'Liu, Tao', 'Zhu, Wanlin', 'Koncz, Rebecca', 'Liu, Hao', 'Lee, Teresa', 'Sachdev, Perminder S', 'Wen, Wei']					1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(18)30260-X [pii] 10.1016/j.neuroimage.2018.03.050 [doi]	20190111	['Aged', 'Algorithms', 'Brain/*diagnostic imaging/*pathology', 'Cluster Analysis', 'Cross-Sectional Studies', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Magnetic Resonance Imaging/methods', 'Male', 'Pattern Recognition, Automated/*methods', 'Software', 'White Matter/*diagnostic imaging/*pathology']	2019/01/12 06:00		['*Automated segmentation pipeline', '*White matter hyperintensities', '*k-nearest neighbours']	['NOTNLM']	NLM	539-549	['2018/02/09 00:00 [received]', '2018/03/16 00:00 [revised]', '2018/03/21 00:00 [accepted]', '2018/03/27 06:00 [pubmed]', '2019/01/12 06:00 [medline]', '2018/03/27 06:00 [entrez]']	United States			29578029	ppublish	"['Journal Article', 'Multicenter Study', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroimage. 2018 Jul 1;174:539-549. doi: 10.1016/j.neuroimage.2018.03.050. Epub 2018 Mar 22.	MEDLINE	Neuroimage	UBO Detector - A cluster-based, fully automated pipeline for extracting white matter hyperintensities.		174	UBO Detector - A cluster-based, fully automated pipeline for extracting white matter hyperintensities.
OBJECTIVES: To realize the automated bone age assessment by applying deep learning to digital radiography DR image recognition of left wrist joint in Uyghur teenagers, and explore its practical application value in forensic medicine bone age assessment. METHODS: The X-ray films of left wrist joint after pretreatment, which were taken from 245 male and 227 female Uyghur nationality teenagers in Uygur Autonomous Region aged from 13.0 to 19.0 years old, were chosen as subjects. And AlexNet was as a regression model of image recognition. From the total samples above, 60 of male and female DR images of left wrist joint were selected as net train set, and 10 of samples were selected as validation set. As test set, the rest 30 were used to obtain the image recognition accuracy with an error range in +/-1.0 and +/-0.7 age respectively, compared to the real age. RESULTS: The modelling results of deep learning algorithm showed that when the error range was in +/-1.0 and +/-0.7 age respectively, the accuracy of the net train set was 81.4% and 75.6% in male, and 80.5% and 74.8% in female, respectively. When the error range was in +/-1.0 and +/-0.7 age respectively, the accuracy of the test set was 79.5% and 71.2% in male, and 79.4% and 66.2% in female, respectively. CONCLUSIONS: The combination of bone age research on teenagers' left wrist joint and deep learning, which has high accuracy and good feasibility, can be the research basis of bone age automatic assessment system for the rest joints of body.	"['Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.', ""Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an 710061, China."", ""People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi 830000, China."", 'Shanghai Fanyang Information Technology Co., LTD., Shanghai 200444, China.', ""People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi 830000, China."", 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.', ""Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an 710061, China."", 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.']"	['j33/1/27 [pii]', '10.3969/j.issn.1004-5619.2018.01.006 [doi]']	['Hu TH', 'Huo Z', 'Liu TA', 'Wang F', 'Wan L', 'Wang MW', 'Chen T', 'Wang YH']		['Copyright(c) by the Editorial Department of Journal of Forensic Medicine.']			['The authors of this article and the planning committee members and staff have no', 'relevant financial relationships with commercial interests to disclose.']		['2018/03/27 06:00']	20180604	20180225	2018 Feb	2018/03/27 06:00		['Hu, T H', 'Huo, Z', 'Liu, T A', 'Wang, F', 'Wan, L', 'Wang, M W', 'Chen, T', 'Wang, Y H']			1		1004-5619 (Print) 1004-5619 (Linking)	9426151	Fa yi xue za zhi	['chi']	10.3969/j.issn.1004-5619.2018.01.006 [doi]	20180604	['Adolescent', 'Age Determination by Skeleton/*methods', 'Algorithms', 'Artificial Intelligence', 'Asian Continental Ancestry Group/ethnology', 'China', 'Female', '*Forensic Medicine', 'Humans', '*Image Processing, Computer-Assisted', '*Machine Learning', 'Male', 'Neural Networks (Computer)', 'Wrist Joint/*diagnostic imaging/pathology', 'X-Ray Film']	2018/06/05 06:00		['* X-ray', '*Uyghur nationality', '*adolescent', '*age determination by skeleton', '*carpal joints', '*deep learning', '*forensic anthropology', '*tomography']	['NOTNLM']	NLM	27-32	['2017/11/20 00:00 [received]', '2018/03/27 06:00 [entrez]', '2018/03/27 06:00 [pubmed]', '2018/06/05 06:00 [medline]']	China			29577701	ppublish	['Journal Article']			IM		Fa Yi Xue Za Zhi. 2018 Feb;34(1):27-32. doi: 10.3969/j.issn.1004-5619.2018.01.006. Epub 2018 Feb 25.	MEDLINE	Fa Yi Xue Za Zhi	[Automated Assessment for Bone Age of Left Wrist Joint in Uyghur Teenagers by Deep Learning].		34	[Automated Assessment for Bone Age of Left Wrist Joint in Uyghur Teenagers by Deep Learning].
Alzheimer's disease (AD) is a progressive brain disease. The goal of this study is to provide a new computer-vision based technique to detect it in an efficient way. The brain-imaging data of 98 AD patients and 98 healthy controls was collected using data augmentation method. Then, convolutional neural network (CNN) was used, CNN is the most successful tool in deep learning. An 8-layer CNN was created with optimal structure obtained by experiences. Three activation functions (AFs): sigmoid, rectified linear unit (ReLU), and leaky ReLU. The three pooling-functions were also tested: average pooling, max pooling, and stochastic pooling. The numerical experiments demonstrated that leaky ReLU and max pooling gave the greatest result in terms of performance. It achieved a sensitivity of 97.96%, a specificity of 97.35%, and an accuracy of 97.65%, respectively. In addition, the proposed approach was compared with eight state-of-the-art approaches. The method increased the classification accuracy by approximately 5% compared to state-of-the-art methods.	"['Department of Informatics, University of Leicester, Leicester, LE1 7RH, UK. shuihuawang@ieee.org.', 'Department of Electrical Engineering, The City College of New York, CUNY, New York, NY, 10031, USA. shuihuawang@ieee.org.', 'West Virginia School of Osteopathic Medicine, 400 N Lee St, Lewisburg, WV, 24901, USA. pphillips@osteo.wvsom.edu.', ""Department of Psychiatry, Affiliated Nanjing Brain Hospital of Nanjing Medical University, Nanjing, People's Republic of China."", 'Department of Radiology, Zhong-Da Hospital of Southeast University, Nanjing, 210009, China.', ""Department of Radiology, Children's Hospital of Nanjing Medical University, Nanjing, 210008, People's Republic of China."", 'Department of Neurology, First Affiliated Hospital of Nanjing Medical University, Nanjing, 210029, China. ch8706@sohu.com.']"	['10.1007/s10916-018-0932-7 [doi]', '10.1007/s10916-018-0932-7 [pii]']	['Wang SH', 'Phillips P', 'Sui Y', 'Liu B', 'Yang M', 'Cheng H']							['2018/03/27 06:00']	20180919	20180326	2018 Mar 26	2018/03/27 06:00		['Wang, Shui-Hua', 'Phillips, Preetha', 'Sui, Yuxiu', 'Liu, Bin', 'Yang, Ming', 'Cheng, Hong']		['61602250/Natural Science Foundation of China']	5		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-018-0932-7 [doi]	20181114	['Aged', 'Aged, 80 and over', 'Alzheimer Disease/diagnosis/*diagnostic imaging', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Male', '*Neural Networks (Computer)', 'Sensitivity and Specificity']	2018/09/20 06:00		"['Activation function', ""Alzheimer's disease"", 'Convolutional neural network', 'Data augmentation', 'Leaky rectified linear unit', 'Max pooling']"	['NOTNLM']	NLM	85	['2017/12/29 00:00 [received]', '2018/03/06 00:00 [accepted]', '2018/03/27 06:00 [entrez]', '2018/03/27 06:00 [pubmed]', '2018/09/20 06:00 [medline]']	United States			29577169	epublish	['Journal Article']			IM		J Med Syst. 2018 Mar 26;42(5):85. doi: 10.1007/s10916-018-0932-7.	MEDLINE	J Med Syst	Classification of Alzheimer's Disease Based on Eight-Layer Convolutional Neural Network with Leaky Rectified Linear Unit and Max Pooling.		42	Classification of Alzheimer's Disease Based on Eight-Layer Convolutional Neural Network with Leaky Rectified Linear Unit and Max Pooling.
Accurate and early diagnosis of Alzheimer's disease (AD) plays important role for patient care and development of future treatment. Structural and functional neuroimages, such as magnetic resonance images (MRI) and positron emission tomography (PET), are providing powerful imaging modalities to help understand the anatomical and functional neural changes related to AD. In recent years, machine learning methods have been widely studied on analysis of multi-modality neuroimages for quantitative evaluation and computer-aided-diagnosis (CAD) of AD. Most existing methods extract the hand-craft imaging features after image preprocessing such as registration and segmentation, and then train a classifier to distinguish AD subjects from other groups. This paper proposes to construct cascaded convolutional neural networks (CNNs) to learn the multi-level and multimodal features of MRI and PET brain images for AD classification. First, multiple deep 3D-CNNs are constructed on different local image patches to transform the local brain image into more compact high-level features. Then, an upper high-level 2D-CNN followed by softmax layer is cascaded to ensemble the high-level features learned from the multi-modality and generate the latent multimodal correlation features of the corresponding image patches for classification task. Finally, these learned features are combined by a fully connected layer followed by softmax layer for AD classification. The proposed method can automatically learn the generic multi-level and multimodal features from multiple imaging modalities for classification, which are robust to the scale and rotation variations to some extent. No image segmentation and rigid registration are required in pre-processing the brain images. Our method is evaluated on the baseline MRI and PET images of 397 subjects including 93 AD patients, 204 mild cognitive impairment (MCI, 76 pMCI +128 sMCI) and 100 normal controls (NC) from Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an accuracy of 93.26% for classification of AD vs. NC and 82.95% for classification pMCI vs. NC, demonstrating the promising classification performance.	['Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China. mhliu@sjtu.edu.cn.', 'Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, 200240, China. mhliu@sjtu.edu.cn.', 'Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China.', 'Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China.', 'School of Information Engineering, Zhengzhou University, Zhengzhou, China. ieypwang@zzu.edu.cn.']	['10.1007/s12021-018-9370-4 [doi]', '10.1007/s12021-018-9370-4 [pii]']	['Liu M', 'Cheng D', 'Wang K', 'Wang Y']	['ORCID: 0000-0001-6496-670X']			"[""Alzheimer's Disease Neuroimaging Initiative""]"			['2018/03/25 06:00']	20190311		2018 Oct	2018/03/25 06:00		['Liu, Manhua', 'Cheng, Danni', 'Wang, Kundong', 'Wang, Yaping']		['61375112, 61773263, U1504606/Natural Science Foundation of China/International', '2016YFC0100903/the National Key Research and Development Program of', 'China/International']	3-4		1559-0089 (Electronic) 1539-2791 (Linking)	101142069	Neuroinformatics	['eng']	10.1007/s12021-018-9370-4 [doi]	20190311	['Aged', 'Aged, 80 and over', 'Alzheimer Disease/*diagnostic imaging/*epidemiology', 'Databases, Factual/trends', 'Female', 'Humans', 'Machine Learning/trends', 'Magnetic Resonance Imaging/*methods/trends', 'Male', 'Multimodal Imaging/methods/trends', '*Neural Networks (Computer)', 'Positron-Emission Tomography/*methods/trends']	2019/03/12 06:00		"[""*Alzheimer's disease diagnosis"", '*Cascaded CNNs', '*Convolutional neural networks (CNNs)', '*Image classification', '*Multi-modality brain images']"	['NOTNLM']	NLM	295-308	['2018/03/25 06:00 [pubmed]', '2019/03/12 06:00 [medline]', '2018/03/25 06:00 [entrez]']	United States			29572601	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroinformatics. 2018 Oct;16(3-4):295-308. doi: 10.1007/s12021-018-9370-4.	MEDLINE	Neuroinformatics	Multi-Modality Cascaded Convolutional Neural Networks for Alzheimer's Disease Diagnosis.		16	Multi-Modality Cascaded Convolutional Neural Networks for Alzheimer's Disease Diagnosis.
Positron emission tomography (PET) is a widely used imaging modality, providing insight into both the biochemical and physiological processes of human body. Usually, a full dose radioactive tracer is required to obtain high-quality PET images for clinical needs. This inevitably raises concerns about potential health hazards. On the other hand, dose reduction may cause the increased noise in the reconstructed PET images, which impacts the image quality to a certain extent. In this paper, in order to reduce the radiation exposure while maintaining the high quality of PET images, we propose a novel method based on 3D conditional generative adversarial networks (3D c-GANs) to estimate the high-quality full-dose PET images from low-dose ones. Generative adversarial networks (GANs) include a generator network and a discriminator network which are trained simultaneously with the goal of one beating the other. Similar to GANs, in the proposed 3D c-GANs, we condition the model on an input low-dose PET image and generate a corresponding output full-dose PET image. Specifically, to render the same underlying information between the low-dose and full-dose PET images, a 3D U-net-like deep architecture which can combine hierarchical features by using skip connection is designed as the generator network to synthesize the full-dose image. In order to guarantee the synthesized PET image to be close to the real one, we take into account of the estimation error loss in addition to the discriminator feedback to train the generator network. Furthermore, a concatenated 3D c-GANs based progressive refinement scheme is also proposed to further improve the quality of estimated images. Validation was done on a real human brain dataset including both the normal subjects and the subjects diagnosed as mild cognitive impairment (MCI). Experimental results show that our proposed 3D c-GANs method outperforms the benchmark methods and achieves much better performance than the state-of-the-art methods in both qualitative and quantitative measures.	['School of Computer Science, Sichuan University, China.', 'School of Computing and Information Technology, University of Wollongong, Australia.', 'School of Computing and Information Technology, University of Wollongong, Australia.', 'School of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China.', 'Joint Department of Biomedical Engineering, University of North Carolina at Chapel Hill and North Carolina State University, NC, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, USA.', 'School of Computer Science, Chengdu University of Information Technology, China.', 'School of Computer Science, Sichuan University, China; School of Computer Science, Chengdu University of Information Technology, China.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, USA; Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea. Electronic address: dinggang_shen@med.unc.edu.', 'School of Electrical and Information Engineering, University of Sydney, Australia; School of Computing and Information Technology, University of Wollongong, Australia. Electronic address: luping.zhou.jane@googlemail.com.']	['S1053-8119(18)30250-7 [pii]', '10.1016/j.neuroimage.2018.03.045 [doi]']	['Wang Y', 'Yu B', 'Wang L', 'Zu C', 'Lalush DS', 'Lin W', 'Wu X', 'Zhou J', 'Shen D', 'Zhou L']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/03/25 06:00']	20190111	20180320	2018 Jul 1	2018/03/25 06:00		['Wang, Yan', 'Yu, Biting', 'Wang, Lei', 'Zu, Chen', 'Lalush, David S', 'Lin, Weili', 'Wu, Xi', 'Zhou, Jiliu', 'Shen, Dinggang', 'Zhou, Luping']		['R01 EB006733/EB/NIBIB NIH HHS/United States']			1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(18)30250-7 [pii] 10.1016/j.neuroimage.2018.03.045 [doi]	20190312	['Adult', 'Brain/*diagnostic imaging', 'Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'Positron-Emission Tomography/*methods', 'Radiation Dosage', 'Reproducibility of Results', 'Signal-To-Noise Ratio', 'Young Adult']	2019/01/12 06:00	['NIHMS1014363']	['*3D conditional GANs (3D c-GANs)', '*Generative adversarial networks (GANs)', '*Image estimation', '*Low-dose PET', '*Positron emission tomography (PET)']	['NOTNLM']	NLM	550-562	['2017/10/06 00:00 [received]', '2018/03/11 00:00 [revised]', '2018/03/17 00:00 [accepted]', '2018/03/25 06:00 [pubmed]', '2019/01/12 06:00 [medline]', '2018/03/25 06:00 [entrez]']	United States	PMC6410574		29571715	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroimage. 2018 Jul 1;174:550-562. doi: 10.1016/j.neuroimage.2018.03.045. Epub 2018 Mar 20.	MEDLINE	Neuroimage	3D conditional generative adversarial networks for high-quality PET image estimation at low dose.		174	3D conditional generative adversarial networks for high-quality PET image estimation at low dose.
In this article, we propose the deep neural network Adversarial Threshold Neural Computer (ATNC). The ATNC model is intended for the de novo design of novel small-molecule organic structures. The model is based on generative adversarial network architecture and reinforcement learning. ATNC uses a Differentiable Neural Computer as a generator and has a new specific block, called adversarial threshold (AT). AT acts as a filter between the agent (generator) and the environment (discriminator + objective reward functions). Furthermore, to generate more diverse molecules we introduce a new objective reward function named Internal Diversity Clustering (IDC). In this work, ATNC is tested and compared with the ORGANIC model. Both models were trained on the SMILES string representation of the molecules, using four objective functions (internal similarity, Muegge druglikeness filter, presence or absence of sp(3)-rich fragments, and IDC). The SMILES representations of 15K druglike molecules from the ChemDiv collection were used as a training data set. For the different functions, ATNC outperforms ORGANIC. Combined with the IDC, ATNC generates 72% of valid and 77% of unique SMILES strings, while ORGANIC generates only 7% of valid and 86% of unique SMILES strings. For each set of molecules generated by ATNC and ORGANIC, we analyzed distributions of four molecular descriptors (number of atoms, molecular weight, logP, and tpsa) and calculated five chemical statistical features (internal diversity, number of unique heterocycles, number of clusters, number of singletons, and number of compounds that have not been passed through medicinal chemistry filters). Analysis of key molecular descriptors and chemical statistical features demonstrated that the molecules generated by ATNC elicited better druglikeness properties. We also performed in vitro validation of the molecules generated by ATNC; results indicated that ATNC is an effective method for producing hit compounds.	['Pharma.AI Department , Insilico Medicine, Inc. , Baltimore , Maryland 21218 , United States.', 'Computer Technologies Lab , ITMO University , St. Petersburg 197101 , Russia.', 'Computer Technologies Lab , ITMO University , St. Petersburg 197101 , Russia.', 'Pharma.AI Department , Insilico Medicine, Inc. , Baltimore , Maryland 21218 , United States.', 'Pharma.AI Department , Insilico Medicine, Inc. , Baltimore , Maryland 21218 , United States.', 'Moscow Institute of Physics and Technology (State University) , 9 Institutskiy Lane , Dolgoprudny City , Moscow Region 141700 , Russian Federation.', 'Institute of Biochemistry and Genetics Russian Academy of Science (IBG RAS) Ufa Scientific Centre , Oktyabrya Prospekt 71 , 450054 Ufa , Russian Federation.', 'Pharma.AI Department , Insilico Medicine, Inc. , Baltimore , Maryland 21218 , United States.', 'Moscow Institute of Physics and Technology (State University) , 9 Institutskiy Lane , Dolgoprudny City , Moscow Region 141700 , Russian Federation.', 'Pharma.AI Department , Insilico Medicine, Inc. , Baltimore , Maryland 21218 , United States.', 'Pharma.AI Department , Insilico Medicine, Inc. , Baltimore , Maryland 21218 , United States.', 'The Biogerontology Research Foundation , OX1 1RU Oxford , U.K.']	['10.1021/acs.molpharmaceut.7b01137 [doi]']	['Putin E', 'Asadulaev A', 'Vanhaelen Q', 'Ivanenkov Y', 'Aladinskaya AV', 'Aliper A', 'Zhavoronkov A']	['ORCID: 0000-0002-4611-2046', 'ORCID: 0000-0001-7067-8966']						['2018/03/24 06:00']	20190819	20180330	2018 Oct 1	2018/03/24 06:00		['Putin, Evgeny', 'Asadulaev, Arip', 'Vanhaelen, Quentin', 'Ivanenkov, Yan', 'Aladinskaya, Anastasia V', 'Aliper, Alex', 'Zhavoronkov, Alex']			10		1543-8392 (Electronic) 1543-8384 (Linking)	101197791	Molecular pharmaceutics	['eng']	10.1021/acs.molpharmaceut.7b01137 [doi]	20190819	['*Machine Learning', '*Neural Networks (Computer)']	2019/08/20 06:00		['*deep neural network', '*generative adversarial network', '*molecular de novo design', '*reinforcement learning']	['NOTNLM']	NLM	4386-4397	['2018/03/24 06:00 [pubmed]', '2019/08/20 06:00 [medline]', '2018/03/24 06:00 [entrez]']	United States			29569445	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					Mol Pharm. 2018 Oct 1;15(10):4386-4397. doi: 10.1021/acs.molpharmaceut.7b01137. Epub 2018 Mar 30.	MEDLINE	Mol Pharm	Adversarial Threshold Neural Computer for Molecular de Novo Design.		15	Adversarial Threshold Neural Computer for Molecular de Novo Design.
"Deep learning has demonstrated tremendous revolutionary changes in the computing industry and its effects in radiology and imaging sciences have begun to dramatically change screening paradigms. Specifically, these advances have influenced the development of computer-aided detection and diagnosis (CAD) systems. These technologies have long been thought of as ""second-opinion"" tools for radiologists and clinicians. However, with significant improvements in deep neural networks, the diagnostic capabilities of learning algorithms are approaching levels of human expertise (radiologists, clinicians etc.), shifting the CAD paradigm from a ""second opinion"" tool to a more collaborative utility. This paper reviews recently developed CAD systems based on deep learning technologies for breast cancer diagnosis, explains their superiorities with respect to previously established systems, defines the methodologies behind the improved achievements including algorithmic developments, and describes remaining challenges in breast cancer screening and diagnosis. We also discuss possible future directions for new CAD models that continue to change as artificial intelligence algorithms evolve."	['1 Department of Radiology, Florida Hospital , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.', '1 Department of Radiology, Florida Hospital , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.', '2 Department of Computer Science, Center for Research in Computer Vision, University of Central Florida (UCF) , Orlando, FL , USA.']	['10.1259/bjr.20170545 [doi]']	['Burt JR', 'Torosdagli N', 'Khosravan N', 'RaviPrakash H', 'Mortazi A', 'Tissavirasingham F', 'Hussein S', 'Bagci U']	['ORCID: http://orcid.org/0000-0001-7379-6829']						['2018/03/23 06:00']	20180914	20180410	2018 Sep	2018/03/23 06:00		['Burt, Jeremy R', 'Torosdagli, Neslisah', 'Khosravan, Naji', 'RaviPrakash, Harish', 'Mortazi, Aliasghar', 'Tissavirasingham, Fiona', 'Hussein, Sarfaraz', 'Bagci, Ulas']			1089		1748-880X (Electronic) 0007-1285 (Linking)	0373125	The British journal of radiology	['eng']	10.1259/bjr.20170545 [doi]	20190901	['Algorithms', 'Breast Neoplasms/*diagnostic imaging', '*Diagnosis, Computer-Assisted', 'Female', 'Humans', '*Machine Learning', 'Magnetic Resonance Imaging', 'Mammography', '*Neural Networks (Computer)', 'Ultrasonography, Mammary']	2018/09/15 06:00				NLM	20170545	['2018/03/23 06:00 [pubmed]', '2018/09/15 06:00 [medline]', '2018/03/23 06:00 [entrez]']	England	PMC6223155		29565644	ppublish	['Journal Article', 'Review']			AIM IM		Br J Radiol. 2018 Sep;91(1089):20170545. doi: 10.1259/bjr.20170545. Epub 2018 Apr 10.	MEDLINE	Br J Radiol	Deep learning beyond cats and dogs: recent advances in diagnosing breast cancer with deep neural networks.		91	Deep learning beyond cats and dogs: recent advances in diagnosing breast cancer with deep neural networks.
OBJECTIVE: A drug-drug interaction (DDI) is a situation in which a drug affects the activity of another drug synergistically or antagonistically when being administered together. The information of DDIs is crucial for healthcare professionals to prevent adverse drug events. Although some known DDIs can be found in purposely-built databases such as DrugBank, most information is still buried in scientific publications. Therefore, automatically extracting DDIs from biomedical texts is sorely needed. METHODS AND MATERIAL: In this paper, we propose a novel position-aware deep multi-task learning approach for extracting DDIs from biomedical texts. In particular, sentences are represented as a sequence of word embeddings and position embeddings. An attention-based bidirectional long short-term memory (BiLSTM) network is used to encode each sentence. The relative position information of words with the target drugs in text is combined with the hidden states of BiLSTM to generate the position-aware attention weights. Moreover, the tasks of predicting whether or not two drugs interact with each other and further distinguishing the types of interactions are learned jointly in multi-task learning framework. RESULTS: The proposed approach has been evaluated on the DDIExtraction challenge 2013 corpus and the results show that with the position-aware attention only, our proposed approach outperforms the state-of-the-art method by 0.99% for binary DDI classification, and with both position-aware attention and multi-task learning, our approach achieves a micro F-score of 72.99% on interaction type identification, outperforming the state-of-the-art approach by 1.51%, which demonstrates the effectiveness of the proposed approach.	['School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing 210096, China. Electronic address: d.zhou@seu.edu.cn.', 'School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing 210096, China. Electronic address: miaolei@seu.edu.cn.', 'School of Engineering and Applied Science, Aston University, UK. Electronic address: y.he@cantab.net.']	['S0933-3657(17)30631-0 [pii]', '10.1016/j.artmed.2018.03.001 [doi]']	['Zhou D', 'Miao L', 'He Y']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/03/22 06:00']	20190624	20180317	2018 May	2018/03/22 06:00		['Zhou, Deyu', 'Miao, Lei', 'He, Yulan']					1873-2860 (Electronic) 0933-3657 (Linking)	8915031	Artificial intelligence in medicine	['eng']	S0933-3657(17)30631-0 [pii] 10.1016/j.artmed.2018.03.001 [doi]	20190624	['*Data Mining', 'Databases, Factual', '*Deep Learning', '*Drug Interactions', 'Drug-Related Side Effects and Adverse Reactions']	2019/06/25 06:00		['*Classification', '*Drug-drug interaction extraction', '*Long short-term memory network', '*Multi-task learning']	['NOTNLM']	NLM	1-8	['2017/11/19 00:00 [received]', '2018/02/26 00:00 [revised]', '2018/03/11 00:00 [accepted]', '2018/03/22 06:00 [pubmed]', '2019/06/25 06:00 [medline]', '2018/03/22 06:00 [entrez]']	Netherlands			29559249	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Artif Intell Med. 2018 May;87:1-8. doi: 10.1016/j.artmed.2018.03.001. Epub 2018 Mar 17.	MEDLINE	Artif Intell Med	Position-aware deep multi-task learning for drug-drug interaction extraction.		87	Position-aware deep multi-task learning for drug-drug interaction extraction.
Recently telecom fraud has become a serious problem especially in developing countries such as China. At present, it can be very difficult to coordinate different agencies to prevent fraud completely. In this paper we study how to detect large transfers that are sent from victims deceived by fraudsters at the receiving bank. We propose a new generative adversarial network (GAN) based model to calculate for each large transfer a probability that it is fraudulent, such that the bank can take appropriate measures to prevent potential fraudsters to take the money if the probability exceeds a threshold. The inference model uses a deep denoising autoencoder to effectively learn the complex probabilistic relationship among the input features, and employs adversarial training that establishes a minimax game between a discriminator and a generator to accurately discriminate between positive samples and negative samples in the data distribution. We show that the model outperforms a set of well-known classification methods in experiments, and its applications in two commercial banks have reduced losses of about 10 million RMB in twelve weeks and significantly improved their business reputation.	['Institute of Service Engineering, Hangzhou Normal University, Hangzhou 311121, China; College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou 310023, China. Electronic address: yujun.zheng@computer.org.', 'College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou 310023, China.', 'Institute of Service Engineering, Hangzhou Normal University, Hangzhou 311121, China.', 'School of Engineering and Computer Science, Victoria University of Wellington, Wellington 6140, New Zealand.', 'College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou 310023, China.']	['S0893-6080(18)30069-8 [pii]', '10.1016/j.neunet.2018.02.015 [doi]']	['Zheng YJ', 'Zhou XH', 'Sheng WG', 'Xue Y', 'Chen SY']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/03/21 06:00']	20180814	20180305	2018 Jun	2018/03/21 06:00		['Zheng, Yu-Jun', 'Zhou, Xiao-Han', 'Sheng, Wei-Guo', 'Xue, Yu', 'Chen, Sheng-Yong']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30069-8 [pii] 10.1016/j.neunet.2018.02.015 [doi]	20181202	['Computer Communication Networks/*standards', 'Fraud/*prevention & control', 'Humans', '*Machine Learning']	2018/08/15 06:00		['Deep learning', 'Denoising autoencoder', 'Fraud detection', 'Generative adversarial network (GAN)', 'Intelligent data analysis']	['NOTNLM']	NLM	78-86	['2017/12/29 00:00 [received]', '2018/02/22 00:00 [revised]', '2018/02/26 00:00 [accepted]', '2018/03/21 06:00 [pubmed]', '2018/08/15 06:00 [medline]', '2018/03/21 06:00 [entrez]']	United States			29558653	ppublish	['Journal Article']			IM		Neural Netw. 2018 Jun;102:78-86. doi: 10.1016/j.neunet.2018.02.015. Epub 2018 Mar 5.	MEDLINE	Neural Netw	Generative adversarial network based telecom fraud detection at the receiving bank.		102	Generative adversarial network based telecom fraud detection at the receiving bank.
In this paper, we propose the first deep reinforcement learning framework to estimate the optimal Dynamic Treatment Regimes from observational medical data. This framework is more flexible and adaptive for high dimensional action and state spaces than existing reinforcement learning methods to model real life complexity in heterogeneous disease progression and treatment choices, with the goal to provide doctor and patients the data-driven personalized decision recommendations. The proposed deep reinforcement learning framework contains a supervised learning step to predict the most possible expert actions; and a deep reinforcement learning step to estimate the long term value function of Dynamic Treatment Regimes. We motivated and implemented the proposed framework on a data set from the Center for International Bone Marrow Transplant Research (CIBMTR) registry database, focusing on the sequence of prevention and treatments for acute and chronic graft versus host disease. We showed results of the initial implementation that demonstrates promising accuracy in predicting human expert decisions and initial implementation for the reinforcement learning step.	['Division of Biostatistics, Medical College of Wisconsin, Milwaukee, WI, 53226.', 'Division of Biostatistics, Medical College of Wisconsin, Milwaukee, WI, 53226.', 'Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13210.', 'Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13210.', 'Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13210.', 'Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, 13210.']	['10.1109/ICHI.2017.45 [doi]']	['Liu Y', 'Logan B', 'Liu N', 'Xu Z', 'Tang J', 'Wang Y']							['2018/03/21 06:00']	20180712		2017 Aug	2018/03/21 06:00		['Liu, Ying', 'Logan, Brent', 'Liu, Ning', 'Xu, Zhiyuan', 'Tang, Jian', 'Wang, Yanzhi']		['U24 CA076518/CA/NCI NIH HHS/United States']			1050-9135 (Print) 1050-9135 (Linking)	9004557	Healthcare informatics : the business magazine for information and communication systems	['eng']	10.1109/ICHI.2017.45 [doi]	20181202	['Humans', '*Machine Learning', '*Registries', 'Statistics as Topic']	2018/07/13 06:00	['NIHMS947679']			NLM	380-385	['2018/03/21 06:00 [entrez]', '2018/03/21 06:00 [pubmed]', '2018/07/13 06:00 [medline]']	United States	PMC5856473		29556119	ppublish	['Journal Article']			H		Healthc Inform. 2017 Aug;2017:380-385. doi: 10.1109/ICHI.2017.45.	MEDLINE	Healthc Inform	Deep Reinforcement Learning for Dynamic Treatment Regimes on Medical Registry Data.		2017	Deep Reinforcement Learning for Dynamic Treatment Regimes on Medical Registry Data.
Functional magnetic resonance imaging is capable of estimating functional activation and connectivity in the human brain, and lately there has been increased interest in the use of these functional modalities combined with machine learning for identification of psychiatric traits. While these methods bear great potential for early diagnosis and better understanding of disease processes, there are wide ranges of processing choices and pitfalls that may severely hamper interpretation and generalization performance unless carefully considered. In this perspective article, we aim to motivate the use of machine learning schizotypy research. To this end, we describe common data processing steps while commenting on best practices and procedures. First, we introduce the important role of schizotypy to motivate the importance of reliable classification, and summarize existing machine learning literature on schizotypy. Then, we describe procedures for extraction of features based on fMRI data, including statistical parametric mapping, parcellation, complex network analysis, and decomposition methods, as well as classification with a special focus on support vector classification and deep learning. We provide more detailed descriptions and software as supplementary material. Finally, we present current challenges in machine learning for classification of schizotypy and comment on future trends and perspectives.	['Danish Research Centre for Magnetic Resonance, Centre for Functional and Diagnostic Imaging and Research, Copenhagen University Hospital Hvidovre, Hvidovre, Denmark.', 'Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark.', 'Danish Research Centre for Magnetic Resonance, Centre for Functional and Diagnostic Imaging and Research, Copenhagen University Hospital Hvidovre, Hvidovre, Denmark.', 'Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kongens Lyngby, Denmark.', 'Neuropsychology and Applied Cognitive Neuroscience Laboratory, CAS Key Laboratory of Mental Health, Institute of Psychology, Chinese Academy of Sciences, Beijing, China.', 'Neuropsychology and Applied Cognitive Neuroscience Laboratory, CAS Key Laboratory of Mental Health, Institute of Psychology, Chinese Academy of Sciences, Beijing, China.', 'Department of Psychology, University of Chinese Academy of Sciences, Beijing, China.', 'Sino-Danish College, University of Chinese Academy of Sciences, Beijing, China.', 'Neuropsychology and Applied Cognitive Neuroscience Laboratory, CAS Key Laboratory of Mental Health, Institute of Psychology, Chinese Academy of Sciences, Beijing, China.', 'Department of Psychology, University of Chinese Academy of Sciences, Beijing, China.', 'Sino-Danish College, University of Chinese Academy of Sciences, Beijing, China.']	['4938816 [pii]', '10.1093/schbul/sby026 [doi]']	['Madsen KH', 'Krohne LG', 'Cai XL', 'Wang Y', 'Chan RCK']							['2018/03/20 06:00']	20181219		2018 Oct 15	2018/03/20 06:00		['Madsen, Kristoffer H', 'Krohne, Laerke G', 'Cai, Xin-Lu', 'Wang, Yi', 'Chan, Raymond C K']			suppl_2		1745-1701 (Electronic) 0586-7614 (Linking)	0236760	Schizophrenia bulletin	['eng']	10.1093/schbul/sby026 [doi]	20191023	['Brain/diagnostic imaging/*physiopathology', '*Deep Learning', 'Functional Neuroimaging/methods/*statistics & numerical data', 'Humans', 'Magnetic Resonance Imaging/methods/*statistics & numerical data', 'Schizotypal Personality Disorder/*classification/diagnostic imaging/physiopathology', '*Supervised Machine Learning']	2018/12/20 06:00				NLM	S480-S490	['2018/03/20 06:00 [pubmed]', '2018/12/20 06:00 [medline]', '2018/03/20 06:00 [entrez]']	United States	PMC6188516		29554367	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Schizophr Bull. 2018 Oct 15;44(suppl_2):S480-S490. doi: 10.1093/schbul/sby026.	MEDLINE	Schizophr Bull	Perspectives on Machine Learning for Classification of Schizotypy Using fMRI Data.		44	Perspectives on Machine Learning for Classification of Schizotypy Using fMRI Data.
Motivation: Protein solubility plays a vital role in pharmaceutical research and production yield. For a given protein, the extent of its solubility can represent the quality of its function, and is ultimately defined by its sequence. Thus, it is imperative to develop novel, highly accurate in silico sequence-based protein solubility predictors. In this work we propose, DeepSol, a novel Deep Learning-based protein solubility predictor. The backbone of our framework is a convolutional neural network that exploits k-mer structure and additional sequence and structural features extracted from the protein sequence. Results: DeepSol outperformed all known sequence-based state-of-the-art solubility prediction methods and attained an accuracy of 0.77 and Matthew's correlation coefficient of 0.55. The superior prediction accuracy of DeepSol allows to screen for sequences with enhanced production capacity and can more reliably predict solubility of novel proteins. Availability and implementation: DeepSol's best performing models and results are publicly deposited at https://doi.org/10.5281/zenodo.1162886 (Khurana and Mall, 2018). Supplementary information: Supplementary data are available at Bioinformatics online.	['Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA.', 'Vaccine Research Center, National Institute of Allergy and Infectious Diseases, National Institute of Health, Bethesda, MD, USA.', 'Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar.', 'Vaccine Research Center, National Institute of Allergy and Infectious Diseases, National Institute of Health, Bethesda, MD, USA.', 'Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar.', 'Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar.']	['4938490 [pii]', '10.1093/bioinformatics/bty166 [doi]']	['Khurana S', 'Rawi R', 'Kunji K', 'Chuang GY', 'Bensmail H', 'Mall R']							['2018/03/20 06:00']	20190827		2018 Aug 1	2018/03/20 06:00		['Khurana, Sameer', 'Rawi, Reda', 'Kunji, Khalid', 'Chuang, Gwo-Yu', 'Bensmail, Halima', 'Mall, Raghvendra']			15		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty166 [doi]	20190827	['Amino Acid Sequence', 'Computational Biology/*methods', 'Computer Simulation', '*Deep Learning', 'Proteins/*chemistry', 'Solubility']	2019/08/28 06:00				NLM	2605-2613	['2017/11/14 00:00 [received]', '2018/03/13 00:00 [accepted]', '2018/03/20 06:00 [pubmed]', '2019/08/28 06:00 [medline]', '2018/03/20 06:00 [entrez]']	England	PMC6355112		29554211	ppublish	['Journal Article']		['0 (Proteins)']	IM		Bioinformatics. 2018 Aug 1;34(15):2605-2613. doi: 10.1093/bioinformatics/bty166.	MEDLINE	Bioinformatics	DeepSol: a deep learning framework for sequence-based protein solubility prediction.		34	DeepSol: a deep learning framework for sequence-based protein solubility prediction.
Motivation: Automated selection of signals in protein NMR spectra, known as peak picking, has been studied for over 20 years, nevertheless existing peak picking methods are still largely deficient. Accurate and precise automated peak picking would accelerate the structure calculation, and analysis of dynamics and interactions of macromolecules. Recent advancement in handling big data, together with an outburst of machine learning techniques, offer an opportunity to tackle the peak picking problem substantially faster than manual picking and on par with human accuracy. In particular, deep learning has proven to systematically achieve human-level performance in various recognition tasks, and thus emerges as an ideal tool to address automated identification of NMR signals. Results: We have applied a convolutional neural network for visual analysis of multidimensional NMR spectra. A comprehensive test on 31 manually annotated spectra has demonstrated top-tier average precision (AP) of 0.9596, 0.9058 and 0.8271 for backbone, side-chain and NOESY spectra, respectively. Furthermore, a combination of extracted peak lists with automated assignment routine, FLYA, outperformed other methods, including the manual one, and led to correct resonance assignment at the levels of 90.40%, 89.90% and 90.20% for three benchmark proteins. Availability and implementation: The proposed model is a part of a Dumpling software (platform for protein NMR data analysis), and is available at https://dumpling.bio/. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, Faculty of Computer Science and Management, Wroclaw University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclaw, Poland.', 'Department of Computer Science, Faculty of Computer Science and Management, Wroclaw University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclaw, Poland.', 'Department of Computer Science, Faculty of Computer Science and Management, Wroclaw University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclaw, Poland.', 'Department of Computer Science, Faculty of Computer Science and Management, Wroclaw University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclaw, Poland.', 'Department of Computer Science, Faculty of Computer Science and Management, Wroclaw University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclaw, Poland.', 'Alphamoon Ltd., ul. Wlodkowica 21/3, Wroclaw, Poland.', 'Captor Therapeutics Ltd., ul. Dunska 11, Wroclaw, Poland.', 'Alphamoon Ltd., ul. Wlodkowica 21/3, Wroclaw, Poland.']	['4934937 [pii]', '10.1093/bioinformatics/bty134 [doi]']	['Klukowski P', 'Augoff M', 'Zieba M', 'Drwal M', 'Gonczarek A', 'Walczak MJ']							['2018/03/17 06:00']	20190911		2018 Aug 1	2018/03/17 06:00		['Klukowski, Piotr', 'Augoff, Michal', 'Zieba, Maciej', 'Drwal, Maciej', 'Gonczarek, Adam', 'Walczak, Michal J']			15		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty134 [doi]	20190911	['*Deep Learning', 'Macromolecular Substances/chemistry', 'Nuclear Magnetic Resonance, Biomolecular/*methods', 'Proteins/*chemistry', '*Software']	2019/09/12 06:00				NLM	2590-2597	['2017/08/30 00:00 [received]', '2018/03/09 00:00 [accepted]', '2018/03/17 06:00 [pubmed]', '2019/09/12 06:00 [medline]', '2018/03/17 06:00 [entrez]']	England			29547986	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Macromolecular Substances)', '0 (Proteins)']	IM		Bioinformatics. 2018 Aug 1;34(15):2590-2597. doi: 10.1093/bioinformatics/bty134.	MEDLINE	Bioinformatics	NMRNet: a deep learning approach to automated peak picking of protein NMR spectra.		34	NMRNet: a deep learning approach to automated peak picking of protein NMR spectra.
BACKGROUND AND OBJECTIVES: The traditional biomedical image retrieval methods as well as content-based image retrieval (CBIR) methods originally designed for non-biomedical images either only consider using pixel and low-level features to describe an image or use deep features to describe images but still leave a lot of room for improving both accuracy and efficiency. In this work, we propose a new approach, which exploits deep learning technology to extract the high-level and compact features from biomedical images. The deep feature extraction process leverages multiple hidden layers to capture substantial feature structures of high-resolution images and represent them at different levels of abstraction, leading to an improved performance for indexing and retrieval of biomedical images. METHODS: We exploit the current popular and multi-layered deep neural networks, namely, stacked denoising autoencoders (SDAE) and convolutional neural networks (CNN) to represent the discriminative features of biomedical images by transferring the feature representations and parameters of pre-trained deep neural networks from another domain. Moreover, in order to index all the images for finding the similarly referenced images, we also introduce preference learning technology to train and learn a kind of a preference model for the query image, which can output the similarity ranking list of images from a biomedical image database. To the best of our knowledge, this paper introduces preference learning technology for the first time into biomedical image retrieval. RESULTS: We evaluate the performance of two powerful algorithms based on our proposed system and compare them with those of popular biomedical image indexing approaches and existing regular image retrieval methods with detailed experiments over several well-known public biomedical image databases. Based on different criteria for the evaluation of retrieval performance, experimental results demonstrate that our proposed algorithms outperform the state-of-the-art techniques in indexing biomedical images. CONCLUSIONS: We propose a novel and automated indexing system based on deep preference learning to characterize biomedical images for developing computer aided diagnosis (CAD) systems in healthcare. Our proposed system shows an outstanding indexing ability and high efficiency for biomedical image retrieval applications and it can be used to collect and annotate the high-resolution images in a biomedical database for further biomedical image research and applications.	['College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, NSW 2109, Australia. Electronic address: pangshuchao1212@sina.com.', 'Department of Computing, Macquarie University, Sydney, NSW 2109, Australia. Electronic address: mehmet.orgun@mq.edu.au.', 'College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China. Electronic address: yuzz@jlu.edu.cn.']	['S0169-2607(17)30543-6 [pii]', '10.1016/j.cmpb.2018.02.003 [doi]']	['Pang S', 'Orgun MA', 'Yu Z']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/03/17 06:00']	20180924	20180206	2018 May	2018/03/17 06:00		['Pang, Shuchao', 'Orgun, Mehmet A', 'Yu, Zhezhou']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(17)30543-6 [pii] 10.1016/j.cmpb.2018.02.003 [doi]	20180924	['Algorithms', 'Databases, Factual', 'Diagnostic Imaging', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Information Storage and Retrieval/*methods', '*Machine Learning', 'Neural Networks (Computer)', '*Radiology Information Systems']	2018/09/25 06:00		['Biomedical image retrieval', 'Convolutional neural network', 'Deep learning', 'Preference learning']	['NOTNLM']	NLM	53-69	['2017/05/01 00:00 [received]', '2017/11/23 00:00 [revised]', '2018/02/02 00:00 [accepted]', '2018/03/17 06:00 [entrez]', '2018/03/17 06:00 [pubmed]', '2018/09/25 06:00 [medline]']	Ireland			29544790	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 May;158:53-69. doi: 10.1016/j.cmpb.2018.02.003. Epub 2018 Feb 6.	MEDLINE	Comput Methods Programs Biomed	A novel biomedical image indexing and retrieval system via deep preference learning.		158	A novel biomedical image indexing and retrieval system via deep preference learning.
BACKGROUND AND OBJECTIVES: Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this domain of application requires substantial implementation effort. Consequently, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. METHODS: The NiftyNet infrastructure provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on the TensorFlow framework and supports features such as TensorBoard visualization of 2D and 3D images and computational graphs by default. RESULTS: We present three illustrative medical image analysis applications built using NiftyNet infrastructure: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses. CONCLUSIONS: The NiftyNet infrastructure enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications.	['Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK; Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK. Electronic address: wenqi.li@ucl.ac.uk.', 'Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK.', 'Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Institute of Neurology, University College London, UK; National Hospital for Neurology and Neurosurgery, London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK.', 'Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Institute of Neurology, University College London, UK; National Hospital for Neurology and Neurosurgery, London, UK.', 'Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK; Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK.', 'Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, UK.', 'Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, UK.']	['S0169-2607(17)31182-3 [pii]', '10.1016/j.cmpb.2018.01.025 [doi]']	['Gibson E', 'Li W', 'Sudre C', 'Fidon L', 'Shakir DI', 'Wang G', 'Eaton-Rosen Z', 'Gray R', 'Doel T', 'Hu Y', 'Whyntie T', 'Nachev P', 'Modat M', 'Barratt DC', 'Ourselin S', 'Cardoso MJ', 'Vercauteren T']		['Copyright (c) 2018 The Authors. Published by Elsevier B.V. All rights reserved.']					['2018/03/17 06:00']	20180924	20180131	2018 May	2018/03/17 06:00		['Gibson, Eli', 'Li, Wenqi', 'Sudre, Carole', 'Fidon, Lucas', 'Shakir, Dzhoshkun I', 'Wang, Guotai', 'Eaton-Rosen, Zach', 'Gray, Robert', 'Doel, Tom', 'Hu, Yipeng', 'Whyntie, Tom', 'Nachev, Parashkev', 'Modat, Marc', 'Barratt, Dean C', 'Ourselin, Sebastien', 'Cardoso, M Jorge', 'Vercauteren, Tom']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(17)31182-3 [pii] 10.1016/j.cmpb.2018.01.025 [doi]	20181114	['Abdomen/diagnostic imaging', 'Brain/diagnostic imaging', 'Computer Simulation', 'Databases, Factual', 'Diagnostic Imaging/instrumentation/*methods', 'Humans', 'Image Processing, Computer-Assisted/instrumentation/methods', '*Machine Learning', 'Magnetic Resonance Imaging', 'Neural Networks (Computer)', 'Ultrasonography']	2018/09/25 06:00		['Convolutional neural network', 'Deep learning', 'Generative adversarial network', 'Image regression', 'Medical image analysis', 'Segmentation']	['NOTNLM']	NLM	113-122	['2017/10/02 00:00 [received]', '2018/01/08 00:00 [revised]', '2018/01/24 00:00 [accepted]', '2018/03/17 06:00 [entrez]', '2018/03/17 06:00 [pubmed]', '2018/09/25 06:00 [medline]']	Ireland	PMC5869052		29544777	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 May;158:113-122. doi: 10.1016/j.cmpb.2018.01.025. Epub 2018 Jan 31.	MEDLINE	Comput Methods Programs Biomed	NiftyNet: a deep-learning platform for medical imaging.		158	NiftyNet: a deep-learning platform for medical imaging.
Motivation: Gene Ontology (GO) has been widely used to annotate functions of proteins and understand their biological roles. Currently only <1% of >70 million proteins in UniProtKB have experimental GO annotations, implying the strong necessity of automated function prediction (AFP) of proteins, where AFP is a hard multilabel classification problem due to one protein with a diverse number of GO terms. Most of these proteins have only sequences as input information, indicating the importance of sequence-based AFP (SAFP: sequences are the only input). Furthermore, homology-based SAFP tools are competitive in AFP competitions, while they do not necessarily work well for so-called difficult proteins, which have <60% sequence identity to proteins with annotations already. Thus, the vital and challenging problem now is how to develop a method for SAFP, particularly for difficult proteins. Methods: The key of this method is to extract not only homology information but also diverse, deep-rooted information/evidence from sequence inputs and integrate them into a predictor in a both effective and efficient manner. We propose GOLabeler, which integrates five component classifiers, trained from different features, including GO term frequency, sequence alignment, amino acid trigram, domains and motifs, and biophysical properties, etc., in the framework of learning to rank (LTR), a paradigm of machine learning, especially powerful for multilabel classification. Results: The empirical results obtained by examining GOLabeler extensively and thoroughly by using large-scale datasets revealed numerous favorable aspects of GOLabeler, including significant performance advantage over state-of-the-art AFP methods. Availability and implementation: http://datamining-iip.fudan.edu.cn/golabeler. Supplementary information: Supplementary data are available at Bioinformatics online.	['School of Computer Science and Shanghai Key Lab of Intelligent Information Processing.', 'Center for Computational System Biology, ISTBI, Fudan University, Shanghai, China.', 'School of Computer Science and Shanghai Key Lab of Intelligent Information Processing.', 'Center for Computational System Biology, ISTBI, Fudan University, Shanghai, China.', 'Department of Bioinformatics and Biostatistics, Shanghai Jiaotong University, Shanghai, China.', 'Center for Computational System Biology, ISTBI, Fudan University, Shanghai, China.', 'Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California, Los Angeles, USA.', 'Bioinformatics Center, Institute for Chemical Research, Kyoto University, Uji, Kyoto Prefecture, Japan.', 'Department of Computer Science, Aalto University, Helsinki, Finland.', 'School of Computer Science and Shanghai Key Lab of Intelligent Information Processing.', 'Center for Computational System Biology, ISTBI, Fudan University, Shanghai, China.']	['4924212 [pii]', '10.1093/bioinformatics/bty130 [doi]']	['You R', 'Zhang Z', 'Xiong Y', 'Sun F', 'Mamitsuka H', 'Zhu S']							['2018/03/10 06:00']	20190911		2018 Jul 15	2018/03/10 06:00		['You, Ronghui', 'Zhang, Zihan', 'Xiong, Yi', 'Sun, Fengzhu', 'Mamitsuka, Hiroshi', 'Zhu, Shanfeng']			14		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/bty130 [doi]	20190911	['Amino Acid Sequence', 'Animals', 'Computational Biology/*methods', 'Eukaryota/metabolism', 'Gene Ontology', 'Humans', 'Machine Learning', 'Molecular Sequence Annotation', 'Protein Structural Elements', 'Proteins/*metabolism/physiology', 'Sequence Alignment', 'Sequence Analysis, Protein/*methods', '*Software']	2019/09/12 06:00				NLM	2465-2473	['2017/08/17 00:00 [received]', '2018/03/06 00:00 [accepted]', '2018/03/10 06:00 [pubmed]', '2019/09/12 06:00 [medline]', '2018/03/10 06:00 [entrez]']	England			29522145	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		Bioinformatics. 2018 Jul 15;34(14):2465-2473. doi: 10.1093/bioinformatics/bty130.	MEDLINE	Bioinformatics	GOLabeler: improving sequence-based large-scale protein function prediction by learning to rank.		34	GOLabeler: improving sequence-based large-scale protein function prediction by learning to rank.
PURPOSE: Proton MRSI is a noninvasive modality capable of generating volumetric maps of in vivo tissue metabolism without the need for ionizing radiation or injected contrast agent. Magnetic resonance spectroscopic imaging has been shown to be a viable imaging modality for studying several neuropathologies. However, a key hurdle in the routine clinical adoption of MRSI is the presence of spectral artifacts that can arise from a number of sources, possibly leading to false information. METHODS: A deep learning model was developed that was capable of identifying and filtering out poor quality spectra. The core of the model used a tiled convolutional neural network that analyzed frequency-domain spectra to detect artifacts. RESULTS: When compared with a panel of MRS experts, our convolutional neural network achieved high sensitivity and specificity with an area under the curve of 0.95. A visualization scheme was implemented to better understand how the convolutional neural network made its judgement on single-voxel or multivoxel MRSI, and the convolutional neural network was embedded into a pipeline capable of producing whole-brain spectroscopic MRI volumes in real time. CONCLUSION: The fully automated method for assessment of spectral quality provides a valuable tool to support clinical MRSI or spectroscopic MRI studies for use in fields such as adaptive radiation therapy planning.	['Department of Radiation Oncology, Emory University, Atlanta, Georgia.', 'Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, Georgia.', 'Winship Cancer Institute of Emory University, Atlanta, Georgia.', 'Department of Radiation Oncology, Emory University, Atlanta, Georgia.', 'Winship Cancer Institute of Emory University, Atlanta, Georgia.', 'Department of Radiology, University of Miami Miller School of Medicine, Miami, Florida.', 'Department of Radiation Oncology, Emory University, Atlanta, Georgia.', 'Winship Cancer Institute of Emory University, Atlanta, Georgia.', 'Department of Radiology, Duke University School of Medicine, Durham, North Carolina.', 'Institute of Translational Medicine, University of Liverpool, Liverpool, United Kingdom.', 'Department of Radiology, Icahn School of Medicine at Mt. Sinai, New York, New York.', 'Department of Radiology and Radiological Science, The Johns Hopkins University, Baltimore, Maryland.', 'Department of Radiation Oncology, Emory University, Atlanta, Georgia.', 'Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, Georgia.', 'Winship Cancer Institute of Emory University, Atlanta, Georgia.', 'Department of Radiology and Imaging Sciences, Emory University, Atlanta, Georgia.', 'Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, Georgia.', 'Winship Cancer Institute of Emory University, Atlanta, Georgia.', 'Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, Georgia.']	['10.1002/mrm.27166 [doi]']	['Gurbani SS', 'Schreibmann E', 'Maudsley AA', 'Cordova JS', 'Soher BJ', 'Poptani H', 'Verma G', 'Barker PB', 'Shim H', 'Cooper LAD']		['(c) 2018 International Society for Magnetic Resonance in Medicine.']					['2018/03/10 06:00']	20190923	20180309	2018 Nov	2018/03/10 06:00		['Gurbani, Saumya S', 'Schreibmann, Eduard', 'Maudsley, Andrew A', 'Cordova, James Scott', 'Soher, Brian J', 'Poptani, Harish', 'Verma, Gaurav', 'Barker, Peter B', 'Shim, Hyunsuk', 'Cooper, Lee A D']		['R01 EB016064/EB/NIBIB NIH HHS/United States', 'T32 GM008602/GM/NIGMS NIH HHS/United States', 'T32 GM008169/GM/NIGMS NIH HHS/United States', 'F30 CA206291/CA/NCI NIH HHS/United States', 'R21 NS100244/NS/NINDS NIH HHS/United States', 'U01 CA172027/CA/NCI NIH HHS/United States']	5		1522-2594 (Electronic) 0740-3194 (Linking)	8505245	Magnetic resonance in medicine	['eng']	10.1002/mrm.27166 [doi]	20191101	['Algorithms', 'Artifacts', 'Brain/diagnostic imaging', 'Brain Neoplasms/diagnostic imaging', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/*methods']	2019/09/24 06:00	['NIHMS943359']	['*MR spectroscopic imaging', '*deep learning', '*machine learning', '*spectroscopic MRI']	['NOTNLM']	NLM	1765-1775	['2017/12/15 00:00 [received]', '2018/02/12 00:00 [revised]', '2018/02/12 00:00 [accepted]', '2018/03/10 06:00 [pubmed]', '2019/09/24 06:00 [medline]', '2018/03/10 06:00 [entrez]']	United States	PMC6107370		29520831	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Magn Reson Med. 2018 Nov;80(5):1765-1775. doi: 10.1002/mrm.27166. Epub 2018 Mar 9.	MEDLINE	Magn Reson Med	A convolutional neural network to filter artifacts in spectroscopic MRI.		80	A convolutional neural network to filter artifacts in spectroscopic MRI.
Passive acoustic sensing has emerged as a powerful tool for quantifying anthropogenic impacts on biodiversity, especially for echolocating bat species. To better assess bat population trends there is a critical need for accurate, reliable, and open source tools that allow the detection and classification of bat calls in large collections of audio recordings. The majority of existing tools are commercial or have focused on the species classification task, neglecting the important problem of first localizing echolocation calls in audio which is particularly problematic in noisy recordings. We developed a convolutional neural network based open-source pipeline for detecting ultrasonic, full-spectrum, search-phase calls produced by echolocating bats. Our deep learning algorithms were trained on full-spectrum ultrasonic audio collected along road-transects across Europe and labelled by citizen scientists from www.batdetective.org. When compared to other existing algorithms and commercial systems, we show significantly higher detection performance of search-phase echolocation calls with our test sets. As an example application, we ran our detection pipeline on bat monitoring data collected over five years from Jersey (UK), and compared results to a widely-used commercial system. Our detection pipeline can be used for the automatic detection and monitoring of bat populations, and further facilitates their use as indicator species on a large scale. Our proposed pipeline makes only a small number of bat specific design decisions, and with appropriate training data it could be applied to detecting other species in audio. A crucial novelty of our work is showing that with careful, non-trivial, design and implementation considerations, state-of-the-art deep learning methods can be used for accurate and efficient monitoring in audio.	"['Department of Computer Science, University College London, London, United Kingdom.', 'Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom.', 'Bat Conservation Trust, Quadrant House, London, United Kingdom.', 'Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom.', ""Institute of Zoology, Zoological Society of London, Regent's Park, London, United Kingdom."", 'Department of Computer Science, University College London, London, United Kingdom.', ""Institute of Zoology, Zoological Society of London, Regent's Park, London, United Kingdom."", 'Bellevue, Washington, United States of America.', 'Department of Computer Science, University College London, London, United Kingdom.', 'Wickford, Essex, United Kingdom.', 'British Trust for Ornithology, The Nunnery, Thetford, Norfolk, United Kingdom.', 'Institute of Biodiversity and Ecosystem Research, Bulgaria Academy of Sciences, Sofia, Bulgaria.', 'School of Earth, Environmental and Biological Sciences, Queensland University of Technology (QUT), Brisbane, QLD, Australia.', 'Ridgeway Ecology, Warwick, United Kingdom.', 'Romanian Bat Protection Association, Satu Mare, Romania.', 'Romanian Bat Protection Association, Satu Mare, Romania.', 'Green Balkans-Stara Zagora, Stara Zagora, Bulgaria.', 'Department of Mathematics, Imperial College London, London, United Kingdom.', 'Department of Computer Science, University College London, London, United Kingdom.', 'Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom.', ""Institute of Zoology, Zoological Society of London, Regent's Park, London, United Kingdom.""]"	['10.1371/journal.pcbi.1005995 [doi]', 'PCOMPBIOL-D-17-01346 [pii]']	['Mac Aodha O', 'Gibb R', 'Barlow KE', 'Browning E', 'Firman M', 'Freeman R', 'Harder B', 'Kinsey L', 'Mead GR', 'Newson SE', 'Pandourski I', 'Parsons S', 'Russ J', 'Szodoray-Paradi A', 'Szodoray-Paradi F', 'Tilova E', 'Girolami M', 'Brostow G', 'Jones KE']	['ORCID: 0000-0002-5787-5073', 'ORCID: 0000-0002-0965-1649', 'ORCID: 0000-0002-7959-9292', 'ORCID: 0000-0003-1025-5616', 'ORCID: 0000-0003-2994-0074', 'ORCID: 0000-0001-8472-3828']						['2018/03/09 06:00']	20180622	20180308	2018 Mar	2018/03/09 06:00		['Mac Aodha, Oisin', 'Gibb, Rory', 'Barlow, Kate E', 'Browning, Ella', 'Firman, Michael', 'Freeman, Robin', 'Harder, Briana', 'Kinsey, Libby', 'Mead, Gary R', 'Newson, Stuart E', 'Pandourski, Ivan', 'Parsons, Stuart', 'Russ, Jon', 'Szodoray-Paradi, Abigel', 'Szodoray-Paradi, Farkas', 'Tilova, Elena', 'Girolami, Mark', 'Brostow, Gabriel', 'Jones, Kate E']			3		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1005995 [doi]	20181114	['Algorithms', 'Animals', 'Chiroptera/classification/*physiology', 'Computational Biology', 'Echolocation/classification/*physiology', 'Endangered Species', 'Environmental Monitoring/*methods', '*Machine Learning', 'Neural Networks (Computer)', '*Signal Processing, Computer-Assisted', 'Zoology']	2018/06/23 06:00				NLM	e1005995	['2017/08/09 00:00 [received]', '2018/01/21 00:00 [accepted]', '2018/03/09 06:00 [entrez]', '2018/03/09 06:00 [pubmed]', '2018/06/23 06:00 [medline]']	United States	PMC5843167		29518076	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS Comput Biol. 2018 Mar 8;14(3):e1005995. doi: 10.1371/journal.pcbi.1005995. eCollection 2018 Mar.	MEDLINE	PLoS Comput Biol	Bat detective-Deep learning tools for bat acoustic signal detection.		14	Bat detective-Deep learning tools for bat acoustic signal detection.
Background and Objective Fatty Liver Disease (FLD) - a disease caused by deposition of fat in liver cells, is predecessor to terminal diseases such as liver cancer. The machine learning (ML) techniques applied for FLD detection and risk stratification using ultrasound (US) have limitations in computing tissue characterization features, thereby limiting the accuracy. Methods Under the class of Symtosis for FLD detection and risk stratification, this study presents a Deep Learning (DL)-based paradigm that computes nearly seven million weights per image when passed through a 22 layered neural network during the cross-validation (training and testing) paradigm. The DL architecture consists of cascaded layers of operations such as: convolution, pooling, rectified linear unit, dropout and a special block called inception model that provides speed and efficiency. All data analysis is performed in optimized tissue region, obtained by removing background information. We benchmark the DL system against the conventional ML protocols: support vector machine (SVM) and extreme learning machine (ELM). Results The liver US data consists of 63 patients (27 normal/36 abnormal). Using the K10 cross-validation protocol (90% training and 10% testing), the detection and risk stratification accuracies are: 82%, 92% and 100% for SVM, ELM and DL systems, respectively. The corresponding area under the curve is: 0.79, 0.92 and 1.0, respectively. We further validate our DL system using two class biometric facial data that yields an accuracy of 99%. Conclusion DL system shows a superior performance for liver detection and risk stratification compared to conventional machine learning systems: SVM and ELM.	['Department of Computer Science and Engineering, NIT, Goa, India.', 'Department of Computer Science and Engineering, NIT, Goa, India.', 'Department of Computer Science and Engineering, NIT, Goa, India.', 'Brown University, Providence, RI, USA; Monitoring and Diagnostic Division, AtheroPoint, Roseville, CA, USA.', 'Department of Radiology, A.O.U., Italy.', 'Liver Unit, Department of Gastroenterology and Hepatology, Hospital de Santa Maria, Medical School of Lisbon, Lisbon 1629-049, Portugal.', 'Bioengineering Department, IST, University of Lisbon, Portugal.', 'Advanced Knowledge Engineering Center, Global Biomedical Technologies, Inc., Roseville, CA, USA. Electronic address: jsuri@comcast.net.']	['S0169-2607(17)30841-6 [pii]', '10.1016/j.cmpb.2017.12.016 [doi]']	['Biswas M', 'Kuppili V', 'Edla DR', 'Suri HS', 'Saba L', 'Marinhoe RT', 'Sanches JM', 'Suri JS']							['2018/03/08 06:00']	20180904	20171216	2018 Mar	2018/03/08 06:00		['Biswas, Mainak', 'Kuppili, Venkatanareshbabu', 'Edla, Damodar Reddy', 'Suri, Harman S', 'Saba, Luca', 'Marinhoe, Rui Tato', 'Sanches, J Miguel', 'Suri, Jasjit S']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(17)30841-6 [pii] 10.1016/j.cmpb.2017.12.016 [doi]	20180904	['Benchmarking', 'Computational Biology', '*Diagnosis, Computer-Assisted', 'Fatty Liver/diagnosis/*diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted', '*Machine Learning', 'Neural Networks (Computer)', 'ROC Curve', 'Reproducibility of Results', 'Risk Factors', 'Support Vector Machine', 'Ultrasonography']	2018/09/05 06:00				NLM	165-177	['2017/07/01 00:00 [received]', '2017/11/11 00:00 [revised]', '2017/12/12 00:00 [accepted]', '2018/03/08 06:00 [entrez]', '2018/03/08 06:00 [pubmed]', '2018/09/05 06:00 [medline]']	Ireland			29512496	ppublish	['Evaluation Studies', 'Journal Article']			IM		Comput Methods Programs Biomed. 2018 Mar;155:165-177. doi: 10.1016/j.cmpb.2017.12.016. Epub 2017 Dec 16.	MEDLINE	Comput Methods Programs Biomed	Symtosis: A liver ultrasound tissue characterization and risk stratification in optimized deep learning paradigm.		155	Symtosis: A liver ultrasound tissue characterization and risk stratification in optimized deep learning paradigm.
Although artificial neural networks are powerful classifiers, their internal structures are hard to interpret. In the life sciences, extensive knowledge of cell biology provides an opportunity to design visible neural networks (VNNs) that couple the model's inner workings to those of real systems. Here we develop DCell, a VNN embedded in the hierarchical structure of 2,526 subsystems comprising a eukaryotic cell (http://d-cell.ucsd.edu/). Trained on several million genotypes, DCell simulates cellular growth nearly as accurately as laboratory observations. During simulation, genotypes induce patterns of subsystem activities, enabling in silico investigations of the molecular mechanisms underlying genotype-phenotype associations. These mechanisms can be validated, and many are unexpected; some are governed by Boolean logic. Cumulatively, 80% of the importance for growth prediction is captured by 484 subsystems (21%), reflecting the emergence of a complex phenotype. DCell provides a foundation for decoding the genetics of disease, drug resistance and synthetic life.	['Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Program in Bioinformatics, University of California San Diego, La Jolla, California, USA.', 'Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Department of Bioengineering, University of California San Diego, La Jolla, California, USA.', 'Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Blavatnik School of Computer Science, Tel Aviv University, Tel Aviv, Israel.', 'Department of Medicine, University of California San Diego, La Jolla, California, USA.', 'Program in Bioinformatics, University of California San Diego, La Jolla, California, USA.', 'Department of Bioengineering, University of California San Diego, La Jolla, California, USA.']	['nmeth.4627 [pii]', '10.1038/nmeth.4627 [doi]']	['Ma J', 'Yu MK', 'Fong S', 'Ono K', 'Sage E', 'Demchak B', 'Sharan R', 'Ideker T']	['ORCID: 0000-0002-8236-6609', 'ORCID: 0000-0002-1708-8454']		['Nat Methods. 2018 Apr 3;15(4):253-254. PMID: 29614064']				['2018/03/06 06:00']	20190510	20180305	2018 Apr	2018/03/06 06:00		['Ma, Jianzhu', 'Yu, Michael Ku', 'Fong, Samson', 'Ono, Keiichiro', 'Sage, Eric', 'Demchak, Barry', 'Sharan, Roded', 'Ideker, Trey']		['OT3 TR002026/TR/NCATS NIH HHS/United States', 'P41 GM103504/GM/NIGMS NIH HHS/United States', 'R01 ES014811/ES/NIEHS NIH HHS/United States', 'R01 HG009979/HG/NHGRI NIH HHS/United States', 'U54 CA209891/CA/NCI NIH HHS/United States', 'R01 GM084279/GM/NIGMS NIH HHS/United States']	4		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/nmeth.4627 [doi]	20190703	['*Cell Physiological Phenomena', 'Computer Simulation', '*Deep Learning', 'Gene Expression Regulation', 'Genotype', 'Humans', '*Neural Networks (Computer)']	2019/05/11 06:00	['NIHMS941151']			NLM	290-298	['2017/07/19 00:00 [received]', '2018/02/07 00:00 [accepted]', '2018/03/06 06:00 [pubmed]', '2019/05/11 06:00 [medline]', '2018/03/06 06:00 [entrez]']	United States	PMC5882547		29505029	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Nat Methods. 2018 Apr;15(4):290-298. doi: 10.1038/nmeth.4627. Epub 2018 Mar 5.	MEDLINE	Nat Methods	Using deep learning to model the hierarchical structure and function of a cell.		15	Using deep learning to model the hierarchical structure and function of a cell.
Deep learning with a convolutional neural network (CNN) is gaining attention recently for its high performance in image recognition. Images themselves can be utilized in a learning process with this technique, and feature extraction in advance of the learning process is not required. Important features can be automatically learned. Thanks to the development of hardware and software in addition to techniques regarding deep learning, application of this technique to radiological images for predicting clinically useful information, such as the detection and the evaluation of lesions, etc., are beginning to be investigated. This article illustrates basic technical knowledge regarding deep learning with CNNs along the actual course (collecting data, implementing CNNs, and training and testing phases). Pitfalls regarding this technique and how to manage them are also illustrated. We also described some advanced topics of deep learning, results of recent clinical studies, and the future directions of clinical application of deep learning techniques.	['Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan. koyasaka@gmail.com.', 'Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan.', 'Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan.', 'Department of Radiology, Graduate School of Medical Sciences, International University of Health and Welfare, 4-3 Kozunomori, Narita, Chiba, Japan.', 'Department of Radiology, Graduate School of Medicine, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan.']	['10.1007/s11604-018-0726-3 [doi]', '10.1007/s11604-018-0726-3 [pii]']	['Yasaka K', 'Akai H', 'Kunimatsu A', 'Kiryu S', 'Abe O']	['ORCID: http://orcid.org/0000-0002-0324-6562']						['2018/03/03 06:00']	20180910	20180301	2018 Apr	2018/03/03 06:00		['Yasaka, Koichiro', 'Akai, Hiroyuki', 'Kunimatsu, Akira', 'Kiryu, Shigeru', 'Abe, Osamu']			4		1867-108X (Electronic) 1867-1071 (Linking)	101490689	Japanese journal of radiology	['eng']	10.1007/s11604-018-0726-3 [doi]	20181202	['*Diagnostic Imaging', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', 'Radiology', 'Software']	2018/09/11 06:00		['CT', 'Convolutional neural network', 'Deep learning', 'MRI', 'PET']	['NOTNLM']	NLM	257-272	['2017/12/28 00:00 [received]', '2018/02/26 00:00 [accepted]', '2018/03/03 06:00 [pubmed]', '2018/09/11 06:00 [medline]', '2018/03/03 06:00 [entrez]']	Japan			29498017	ppublish	['Journal Article', 'Review']			IM		Jpn J Radiol. 2018 Apr;36(4):257-272. doi: 10.1007/s11604-018-0726-3. Epub 2018 Mar 1.	MEDLINE	Jpn J Radiol	Deep learning with convolutional neural network in radiology.		36	Deep learning with convolutional neural network in radiology.
From the start, Kurt Godel observed that computer and brain paradigms were considered on a par by researchers and that researchers had misunderstood his theorems. He hailed with displeasure that the brain transcends computers. In this brief article, we point out that Artificial Intelligence (AI) comprises multitudes of human-made methodologies, systems, and languages, and implemented with computer technology. These advances enhance development in the electron and quantum realms. In the biological realm, animal neurons function, also utilizing electron flow, and are products of evolution. Mirror neurons are an important paradigm in neuroscience research. Moreover, the paradigm shift proposed here - 'hall of mirror neurons' - is a potentially further productive research tactic. These concepts further expand AI and brain research.	['Division of Infectious Diseases and International Health, Department of Internal Medicine, University of South Florida, Morsani College of Medicine, Tampa, FL 33606, USA.']	['10.6026/97320630014038 [doi]', '97320630014038 [pii]']	['Shapshak P']							['2018/03/03 06:00']		20180131	2018	2018/03/03 06:00		['Shapshak, Paul']			1		0973-2063 (Print) 0973-2063 (Linking)	101258255	Bioinformation	['eng']	10.6026/97320630014038 [doi]	20191120		2018/03/03 06:01		['Artificial Intelligence (AI)', 'Godel', 'awareness', 'biomedicine', 'brain', 'co-robotics (cobots)', 'cognition', 'cognitive architecture', 'cognitive science', 'computer', 'consciousness', 'deep learning', 'development', 'ecosystem', 'event schemata', 'fiber bundle', 'games', 'gene expression', 'hall of mirror neurons', 'language grounding', 'machine', 'manifold', 'mirror neuron', 'neuron colony', 'neuron group', 'neuron manifold', 'neuropsychiatric disease', 'neuroscience', 'paradigm shift', 'quantum computers', 'research', 'robotics', 'self-motivated behavior', 'shadow neuron', 'symbol grounding', 'topology']	['NOTNLM']	NLM	38-41	['2017/12/19 00:00 [received]', '2018/01/24 00:00 [revised]', '2018/01/24 00:00 [accepted]', '2018/03/03 06:00 [entrez]', '2018/03/03 06:00 [pubmed]', '2018/03/03 06:01 [medline]']	Singapore	PMC5818638		29497259	epublish	['Journal Article']					Bioinformation. 2018 Jan 31;14(1):38-41. doi: 10.6026/97320630014038. eCollection 2018.	PubMed-not-MEDLINE	Bioinformation	Artificial Intelligence and brain.		14	Artificial Intelligence and brain.
A method that uses an adaptive learning rate is presented for training neural networks. Unlike most conventional updating methods in which the learning rate gradually decreases during training, the proposed method increases or decreases the learning rate adaptively so that the training loss (the sum of cross-entropy losses for all training samples) decreases as much as possible. It thus provides a wider search range for solutions and thus a lower test error rate. The experiments with some well-known datasets to train a multilayer perceptron show that the proposed method is effective for obtaining a better test accuracy under certain conditions.	['Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan. Electronic address: takase_t@complex.ist.hokudai.ac.jp.', 'Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan. Electronic address: oyama@ist.hokudai.ac.jp.', 'Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan. Electronic address: kurihara@ist.hokudai.ac.jp.']	['S0893-6080(18)30030-3 [pii]', '10.1016/j.neunet.2018.01.016 [doi]']	['Takase T', 'Oyama S', 'Kurihara M']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/03/02 06:00']	20180808	20180213	2018 May	2018/03/02 06:00		['Takase, Tomoumi', 'Oyama, Satoshi', 'Kurihara, Masahito']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(18)30030-3 [pii] 10.1016/j.neunet.2018.01.016 [doi]	20181202	['Entropy', '*Machine Learning', '*Neural Networks (Computer)']	2018/08/09 06:00		['Beam search', 'Deep learning', 'Learning rate', 'Multilayer perceptron', 'Neural network training', 'Stochastic gradient descent']	['NOTNLM']	NLM	68-78	['2017/04/14 00:00 [received]', '2017/12/17 00:00 [revised]', '2018/01/29 00:00 [accepted]', '2018/03/02 06:00 [pubmed]', '2018/08/09 06:00 [medline]', '2018/03/02 06:00 [entrez]']	United States			29494873	ppublish	['Journal Article']			IM		Neural Netw. 2018 May;101:68-78. doi: 10.1016/j.neunet.2018.01.016. Epub 2018 Feb 13.	MEDLINE	Neural Netw	Effective neural network training with adaptive learning rate based on training loss.		101	Effective neural network training with adaptive learning rate based on training loss.
Protein secondary structure prediction can provide important information for protein 3D structure prediction and protein functions. Deep learning offers a new opportunity to significantly improve prediction accuracy. In this article, a new deep neural network architecture, named the Deep inception-inside-inception (Deep3I) network, is proposed for protein secondary structure prediction and implemented as a software tool MUFOLD-SS. The input to MUFOLD-SS is a carefully designed feature matrix corresponding to the primary amino acid sequence of a protein, which consists of a rich set of information derived from individual amino acid, as well as the context of the protein sequence. Specifically, the feature matrix is a composition of physio-chemical properties of amino acids, PSI-BLAST profile, and HHBlits profile. MUFOLD-SS is composed of a sequence of nested inception modules and maps the input matrix to either eight states or three states of secondary structures. The architecture of MUFOLD-SS enables effective processing of local and global interactions between amino acids in making accurate prediction. In extensive experiments on multiple datasets, MUFOLD-SS outperformed the best existing methods and other deep neural networks significantly. MUFold-SS can be downloaded from http://dslsrv8.cs.missouri.edu/~cf797/MUFoldSS/download.html.	['Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, Missouri.', 'Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, Missouri.', 'Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, Missouri.', 'Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, Missouri.']	['10.1002/prot.25487 [doi]']	['Fang C', 'Shang Y', 'Xu D']	['ORCID: 0000-0002-4809-0514']	['(c) 2018 Wiley Periodicals, Inc.']					['2018/03/02 06:00']	20191002	20180312	2018 May	2018/03/02 06:00		['Fang, Chao', 'Shang, Yi', 'Xu, Dong']		['R01 GM100701/GM/NIGMS NIH HHS/United States']	5		1097-0134 (Electronic) 0887-3585 (Linking)	8700181	Proteins	['eng']	10.1002/prot.25487 [doi]	20191002	['Algorithms', 'Amino Acid Sequence', 'Amino Acids/chemistry', 'Binding Sites', '*Deep Learning', '*Models, Molecular', 'Protein Binding', '*Protein Structure, Secondary', 'Proteins/chemistry', '*Software']	2019/10/03 06:00	['NIHMS986826']	['*deep learning', '*deep neural networks', '*protein secondary structure', '*protein structure prediction']	['NOTNLM']	NLM	592-598	['2017/10/24 00:00 [received]', '2018/02/25 00:00 [revised]', '2018/02/27 00:00 [accepted]', '2018/03/02 06:00 [pubmed]', '2019/10/03 06:00 [medline]', '2018/03/02 06:00 [entrez]']	United States	PMC6120586		29492997	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Amino Acids)', '0 (Proteins)']	IM		Proteins. 2018 May;86(5):592-598. doi: 10.1002/prot.25487. Epub 2018 Mar 12.	MEDLINE	Proteins	MUFOLD-SS: New deep inception-inside-inception networks for protein secondary structure prediction.		86	MUFOLD-SS: New deep inception-inside-inception networks for protein secondary structure prediction.
OBJECTIVE: Most current electroencephalography (EEG)-based brain-computer interfaces (BCIs) are based on machine learning algorithms. There is a large diversity of classifier types that are used in this field, as described in our 2007 review paper. Now, approximately ten years after this review publication, many new algorithms have been developed and tested to classify EEG signals in BCIs. The time is therefore ripe for an updated review of EEG classification algorithms for BCIs. APPROACH: We surveyed the BCI and machine learning literature from 2007 to 2017 to identify the new classification approaches that have been investigated to design BCIs. We synthesize these studies in order to present such algorithms, to report how they were used for BCIs, what were the outcomes, and to identify their pros and cons. MAIN RESULTS: We found that the recently designed classification algorithms for EEG-based BCIs can be divided into four main categories: adaptive classifiers, matrix and tensor classifiers, transfer learning and deep learning, plus a few other miscellaneous classifiers. Among these, adaptive classifiers were demonstrated to be generally superior to static ones, even with unsupervised adaptation. Transfer learning can also prove useful although the benefits of transfer learning remain unpredictable. Riemannian geometry-based methods have reached state-of-the-art performances on multiple BCI problems and deserve to be explored more thoroughly, along with tensor-based methods. Shrinkage linear discriminant analysis and random forests also appear particularly useful for small training samples settings. On the other hand, deep learning methods have not yet shown convincing improvement over state-of-the-art BCI methods. SIGNIFICANCE: This paper provides a comprehensive overview of the modern classification algorithms used in EEG-based BCIs, presents the principles of these methods and guidelines on when and how to use them. It also identifies a number of challenges to further advance EEG classification in BCI.	['Inria, LaBRI (CNRS/Univ. Bordeaux /INP), Talence, France. RIKEN Brain Science Insitute, Wakoshi, Japan.']	['10.1088/1741-2552/aab2f2 [doi]']	['Lotte F', 'Bougrain L', 'Cichocki A', 'Clerc M', 'Congedo M', 'Rakotomamonjy A', 'Yger F']							['2018/03/01 06:00']	20190926	20180228	2018 Jun	2018/03/01 06:00		['Lotte, F', 'Bougrain, L', 'Cichocki, A', 'Clerc, M', 'Congedo, M', 'Rakotomamonjy, A', 'Yger, F']			3		1741-2552 (Electronic) 1741-2552 (Linking)	101217933	Journal of neural engineering	['eng']	10.1088/1741-2552/aab2f2 [doi]	20190926	['*Algorithms', 'Animals', 'Brain/*physiology', 'Brain-Computer Interfaces/*trends', 'Deep Learning/trends', 'Electroencephalography/methods/*trends', 'Humans', '*Signal Processing, Computer-Assisted', 'Time Factors']	2019/09/27 06:00				NLM	031005	['2018/03/01 06:00 [pubmed]', '2019/09/27 06:00 [medline]', '2018/03/01 06:00 [entrez]']	England			29488902	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		J Neural Eng. 2018 Jun;15(3):031005. doi: 10.1088/1741-2552/aab2f2. Epub 2018 Feb 28.	MEDLINE	J Neural Eng	A review of classification algorithms for EEG-based brain-computer interfaces: a 10 year update.		15	A review of classification algorithms for EEG-based brain-computer interfaces: a 10 year update.
OBJECTIVE: Non-invasive foetal electrocardiography (NI-FECG) has the potential to provide more additional clinical information for detecting and diagnosing fetal diseases. We propose and demonstrate a deep learning approach for fetal QRS complex detection from raw NI-FECG signals by using a convolutional neural network (CNN) model. The main objective is to investigate whether reliable fetal QRS complex detection performance can still be obtained from features of single-channel NI-FECG signals, without canceling maternal ECG (MECG) signals. APPROACH: A deep learning method is proposed for recognizing fetal QRS complexes. Firstly, we collect data from set-a of the PhysioNet/computing in Cardiology Challenge database. The sample entropy method is used for signal quality assessment. Part of the bad quality signals is excluded in the further analysis. Secondly, in the proposed method, the features of raw NI-FECG signals are normalized before they are fed to a CNN classifier to perform fetal QRS complex detection. We use precision, recall, F-measure and accuracy as the evaluation metrics to assess the performance of fetal QRS complex detection. MAIN RESULTS: The proposed deep learning method can achieve relatively high precision (75.33%), recall (80.54%), and F-measure scores (77.85%) compared with three other well-known pattern classification methods, namely KNN, naive Bayes and SVM. SIGNIFICANCE: the proposed deep learning method can attain reliable fetal QRS complex detection performance from the raw NI-FECG signals without canceling MECG signals. In addition, the influence of different activation functions and signal quality assessment on classification performance are evaluated, and results show that Relu outperforms the Sigmoid and Tanh on this particular task, and better classification performance is obtained with the signal quality assessment step in this study.	"[""School of Data and Computer Science, Sun Yat-sen University, Guangzhou, 510006, People's Republic of China.""]"	['10.1088/1361-6579/aab297 [doi]']	['Zhong W', 'Liao L', 'Guo X', 'Wang G']							['2018/02/28 06:00']	20190225	20180420	2018 Apr 20	2018/02/28 06:00		['Zhong, Wei', 'Liao, Lijuan', 'Guo, Xuemei', 'Wang, Guoli']			4		1361-6579 (Electronic) 0967-3334 (Linking)	9306921	Physiological measurement	['eng']	10.1088/1361-6579/aab297 [doi]	20190225	['*Deep Learning', '*Electrocardiography', 'Fetus/*physiology', 'Humans', 'Neural Networks (Computer)', 'Signal Processing, Computer-Assisted']	2019/02/26 06:00				NLM	045004	['2018/02/28 06:00 [pubmed]', '2019/02/26 06:00 [medline]', '2018/02/28 06:00 [entrez]']	England			29485406	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Physiol Meas. 2018 Apr 20;39(4):045004. doi: 10.1088/1361-6579/aab297.	MEDLINE	Physiol Meas	A deep learning approach for fetal QRS complex detection.		39	A deep learning approach for fetal QRS complex detection.
The primary objective of this study is to compare the accuracy of two risk models, International Heart Transplantation Survival Algorithm (IHTSA), developed using deep learning technique, and Index for Mortality Prediction After Cardiac Transplantation (IMPACT), to predict survival after heart transplantation. Data from adult heart transplanted patients between January 1997 to December 2011 were collected from the UNOS registry. The study included 27,860 heart transplantations, corresponding to 27,705 patients. The study cohorts were divided into patients transplanted before 2009 (derivation cohort) and from 2009 (test cohort). The receiver operating characteristic (ROC) values, for the validation cohort, computed for one-year mortality, were 0.654 (95% CI: 0.629-0.679) for IHTSA and 0.608 (0.583-0.634) for the IMPACT model. The discrimination reached a C-index for long-term survival of 0.627 (0.608-0.646) for IHTSA, compared with 0.584 (0.564-0.605) for the IMPACT model. These figures correspond to an error reduction of 12% for ROC and 10% for C-index by using deep learning technique. The predicted one-year mortality rates for were 12% and 22% for IHTSA and IMPACT, respectively, versus an actual mortality rate of 10%. The IHTSA model showed superior discriminatory power to predict one-year mortality and survival over time after heart transplantation compared to the IMPACT model.	['Department of Computer Science, Lund University, Lund, Sweden.', 'Department of Astronomy and Theoretical Physics, Computational Biology and Biological Physics, Lund University, Lund, Sweden.', 'Department of Laboratory Medicine Lund, Clinical Chemistry and Pharmacology, Lund University, Lund, Sweden.', 'Department of Clinical Sciences Lund, Surgery, Lund University and Skane University Hospital, Lund, Sweden.', 'Department of Computer Science, Lund University, Lund, Sweden.', 'Department of Clinical Sciences Lund, Cardiothoracic Surgery, Lund University and Skane University Hospital, Lund, Sweden. johan.nilsson@med.lu.se.']	['10.1038/s41598-018-21417-7 [doi]', '10.1038/s41598-018-21417-7 [pii]']	['Medved D', 'Ohlsson M', 'Hoglund P', 'Andersson B', 'Nugues P', 'Nilsson J']	['ORCID: 0000-0002-8395-922X', 'ORCID: 0000-0001-6860-6090']						['2018/02/28 06:00']	20190923	20180226	2018 Feb 26	2018/02/28 06:00		['Medved, Dennis', 'Ohlsson, Mattias', 'Hoglund, Peter', 'Andersson, Bodil', 'Nugues, Pierre', 'Nilsson, Johan']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-21417-7 [doi]	20190923	['Adolescent', 'Adult', 'Aged', 'Algorithms', '*Deep Learning', 'Heart Transplantation/*methods', 'Humans', 'Middle Aged', 'Young Adult']	2019/09/24 06:00				NLM	3613	['2017/10/10 00:00 [received]', '2018/02/01 00:00 [accepted]', '2018/02/28 06:00 [entrez]', '2018/02/28 06:00 [pubmed]', '2019/09/24 06:00 [medline]']	England	PMC5827028		29483521	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Feb 26;8(1):3613. doi: 10.1038/s41598-018-21417-7.	MEDLINE	Sci Rep	Improving prediction of heart transplantation outcome using deep learning techniques.		8	Improving prediction of heart transplantation outcome using deep learning techniques.
BACKGROUND AND OBJECTIVE: Radiologists often have a hard time classifying mammography mass lesions which leads to unnecessary breast biopsies to remove suspicions and this ends up adding exorbitant expenses to an already burdened patient and health care system. METHODS: In this paper we developed a Computer-aided Diagnosis (CAD) system based on deep Convolutional Neural Networks (CNN) that aims to help the radiologist classify mammography mass lesions. Deep learning usually requires large datasets to train networks of a certain depth from scratch. Transfer learning is an effective method to deal with relatively small datasets as in the case of medical images, although it can be tricky as we can easily start overfitting. RESULTS: In this work, we explore the importance of transfer learning and we experimentally determine the best fine-tuning strategy to adopt when training a CNN model. We were able to successfully fine-tune some of the recent, most powerful CNNs and achieved better results compared to other state-of-the-art methods which classified the same public datasets. For instance we achieved 97.35% accuracy and 0.98 AUC on the DDSM database, 95.50% accuracy and 0.97 AUC on the INbreast database and 96.67% accuracy and 0.96 AUC on the BCDR database. Furthermore, after pre-processing and normalizing all the extracted Regions of Interest (ROIs) from the full mammograms, we merged all the datasets to build one large set of images and used it to fine-tune our CNNs. The CNN model which achieved the best results, a 98.94% accuracy, was used as a baseline to build the Breast Cancer Screening Framework. To evaluate the proposed CAD system and its efficiency to classify new images, we tested it on an independent database (MIAS) and got 98.23% accuracy and 0.99 AUC. CONCLUSION: The results obtained demonstrate that the proposed framework is performant and can indeed be used to predict if the mass lesions are benign or malignant.	['Laboratory of Computer Science and Mathematics and their Applications (LIMA), Faculty of science, University Chouaib Doukkali, El Jadida 24000, Morocco. Electronic address: chougrad.h@ucd.ac.ma.', 'Laboratory of Computer Science and Mathematics and their Applications (LIMA), Faculty of science, University Chouaib Doukkali, El Jadida 24000, Morocco.', 'Laboratory of Fundamental Mathematics (LMF), Faculty of science, University Chouaib Doukkali, El Jadida 24000, Morocco.']	['S0169-2607(17)30145-1 [pii]', '10.1016/j.cmpb.2018.01.011 [doi]']	['Chougrad H', 'Zouaki H', 'Alheyane O']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/02/26 06:00']	20180924	20180111	2018 Apr	2018/02/27 06:00		['Chougrad, Hiba', 'Zouaki, Hamid', 'Alheyane, Omar']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(17)30145-1 [pii] 10.1016/j.cmpb.2018.01.011 [doi]	20180924	['Breast Neoplasms/classification/*diagnostic imaging/pathology', 'Databases, Factual', '*Diagnosis, Computer-Assisted', 'Early Detection of Cancer', 'Female', 'Humans', 'Machine Learning', 'Mammography/*methods', '*Neural Networks (Computer)', 'Reproducibility of Results']	2018/09/25 06:00		['Breast cancer', 'Breast mass lesion classification', 'Computer-aided Diagnosis', 'Convolutional Neural Network', 'Deep learning', 'Transfer learning']	['NOTNLM']	NLM	19-30	['2017/02/10 00:00 [received]', '2017/12/24 00:00 [revised]', '2018/01/10 00:00 [accepted]', '2018/02/26 06:00 [entrez]', '2018/02/27 06:00 [pubmed]', '2018/09/25 06:00 [medline]']	Ireland			29477427	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2018 Apr;157:19-30. doi: 10.1016/j.cmpb.2018.01.011. Epub 2018 Jan 11.	MEDLINE	Comput Methods Programs Biomed	Deep Convolutional Neural Networks for breast cancer screening.		157	Deep Convolutional Neural Networks for breast cancer screening.
Kermany et al. report an application of a neural network trained on millions of everyday images to a database of thousands of retinal tomography images that they gathered and expert labeled, resulting in a rapid and accurate diagnosis of retinal diseases.	['University of Toronto, Department of Computer Science, Toronto, ON, Canada; The Hospital for Sick Children, Toronto, ON, Canada; Vector Institute, Toronto, ON, Canada.', 'University of Toronto, Department of Computer Science, Toronto, ON, Canada; The Hospital for Sick Children, Toronto, ON, Canada; Vector Institute, Toronto, ON, Canada. Electronic address: anna.goldenberg@utoronto.ca.']	['S0092-8674(18)30157-0 [pii]', '10.1016/j.cell.2018.02.013 [doi]']	['Rampasek L', 'Goldenberg A']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']				['Cell. 2018 Feb 22;172(5):1122-1131.e9. PMID: 29474911']	['2018/02/24 06:00']	20190111		2018 Feb 22	2018/02/24 06:00		['Rampasek, Ladislav', 'Goldenberg, Anna']			5		1097-4172 (Electronic) 0092-8674 (Linking)	0413066	Cell	['eng']	S0092-8674(18)30157-0 [pii] 10.1016/j.cell.2018.02.013 [doi]	20190111	['*Deep Learning', 'Humans', 'Neural Networks (Computer)', '*Retinal Diseases']	2019/01/12 06:00				NLM	893-895	['2018/02/24 06:00 [entrez]', '2018/02/24 06:00 [pubmed]', '2019/01/12 06:00 [medline]']	United States			29474917	ppublish	['Journal Article', 'Comment']			IM		Cell. 2018 Feb 22;172(5):893-895. doi: 10.1016/j.cell.2018.02.013.	MEDLINE	Cell	Learning from Everyday Images Enables Expert-like Diagnosis of Retinal Diseases.		172	Learning from Everyday Images Enables Expert-like Diagnosis of Retinal Diseases.
The implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, we establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases. Our framework utilizes transfer learning, which trains a neural network with a fraction of the data of conventional approaches. Applying this approach to a dataset of optical coherence tomography images, we demonstrate performance comparable to that of human experts in classifying age-related macular degeneration and diabetic macular edema. We also provide a more transparent and interpretable diagnosis by highlighting the regions recognized by the neural network. We further demonstrate the general applicability of our AI system for diagnosis of pediatric pneumonia using chest X-ray images. This tool may ultimately aid in expediting the diagnosis and referral of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes. VIDEO ABSTRACT.	"[""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'Heidelberg Engineering, Heidelberg, Germany.', 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China.', 'Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Guangzhou KangRui Biological Pharmaceutical Technology Company, 510005 Guangzhou, China."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', 'YouHealth AI, 510005 Guangzhou, China.', 'Guangzhou KangRui Biological Pharmaceutical Technology Company, 510005 Guangzhou, China.', 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", 'Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA."", 'Beihai Hospital, Dalian, 116021, China.', 'Department of Ophthalmology, University of Texas Health Science Center, San Antonio, TX 78229, USA.', 'Shanghai Key Laboratory of Ocular Fundus Diseases, Shanghai General Hospital, Shanghai JiaoTong University, 200080 Shanghai, China.', 'Beijing Instute of Ophthalmology, Beijing Tongren Eye Center, Beijing Tongren Hospital, Capital Medical University, Beijing, China.', 'Heidelberg Engineering, Heidelberg, Germany.', 'Qualcomm, San Diego, CA 92121, USA.', ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China."", ""Guangzhou Women and Children's Medical Center, Guangzhou Medical University, 510005 Guangzhou, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, CA 92093, USA; Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, 510005 Guangzhou, China; Veterans Administration Healthcare System, San Diego, CA 92037, USA. Electronic address: kang.zhang@gmail.com.""]"	['S0092-8674(18)30154-5 [pii]', '10.1016/j.cell.2018.02.010 [doi]']	['Kermany DS', 'Goldbaum M', 'Cai W', 'Valentim CCS', 'Liang H', 'Baxter SL', 'McKeown A', 'Yang G', 'Wu X', 'Yan F', 'Dong J', 'Prasadha MK', 'Pei J', 'Ting MYL', 'Zhu J', 'Li C', 'Hewett S', 'Dong J', 'Ziyar I', 'Shi A', 'Zhang R', 'Zheng L', 'Hou R', 'Shi W', 'Fu X', 'Duan Y', 'Huu VAN', 'Wen C', 'Zhang ED', 'Zhang CL', 'Li O', 'Wang X', 'Singer MA', 'Sun X', 'Xu J', 'Tafreshi A', 'Lewis MA', 'Xia H', 'Zhang K']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']	['Cell. 2018 Feb 22;172(5):893-895. PMID: 29474917']				['2018/02/24 06:00']	20190121		2018 Feb 22	2018/02/24 06:00		['Kermany, Daniel S', 'Goldbaum, Michael', 'Cai, Wenjia', 'Valentim, Carolina C S', 'Liang, Huiying', 'Baxter, Sally L', 'McKeown, Alex', 'Yang, Ge', 'Wu, Xiaokang', 'Yan, Fangbing', 'Dong, Justin', 'Prasadha, Made K', 'Pei, Jacqueline', 'Ting, Magdalene Y L', 'Zhu, Jie', 'Li, Christina', 'Hewett, Sierra', 'Dong, Jason', 'Ziyar, Ian', 'Shi, Alexander', 'Zhang, Runze', 'Zheng, Lianghong', 'Hou, Rui', 'Shi, William', 'Fu, Xin', 'Duan, Yaou', 'Huu, Viet A N', 'Wen, Cindy', 'Zhang, Edward D', 'Zhang, Charlotte L', 'Li, Oulan', 'Wang, Xiaobo', 'Singer, Michael A', 'Sun, Xiaodong', 'Xu, Jie', 'Tafreshi, Ali', 'Lewis, M Anthony', 'Xia, Huimin', 'Zhang, Kang']			5		1097-4172 (Electronic) 0092-8674 (Linking)	0413066	Cell	['eng']	S0092-8674(18)30154-5 [pii] 10.1016/j.cell.2018.02.010 [doi]	20190121	['Child', '*Deep Learning', '*Diagnostic Imaging', 'Humans', 'Neural Networks (Computer)', 'Pneumonia/*diagnosis/diagnostic imaging', 'ROC Curve', 'Reproducibility of Results', 'Tomography, Optical Coherence']	2019/01/22 06:00		['*age-related macular degeneration', '*artificial intelligence', '*choroidal neovascularization', '*deep learning', '*diabetic macular edema', '*diabetic retinopathy', '*optical coherence tomography', '*pneumonia', '*screening', '*transfer learning']	['NOTNLM']	NLM	1122-1131.e9	['2017/11/01 00:00 [received]', '2017/12/31 00:00 [revised]', '2018/02/01 00:00 [accepted]', '2018/02/24 06:00 [entrez]', '2018/02/24 06:00 [pubmed]', '2019/01/22 06:00 [medline]']	United States			29474911	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Cell. 2018 Feb 22;172(5):1122-1131.e9. doi: 10.1016/j.cell.2018.02.010.	MEDLINE	Cell	Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning.		172	Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning.
PURPOSE: To develop an automatic deep feature classification (DFC) method for distinguishing benign angiomyolipoma without visible fat (AMLwvf) from malignant clear cell renal cell carcinoma (ccRCC) from abdominal contrast-enhanced computer tomography (CE CT) images. METHODS: A dataset including 80 abdominal CT images of 39 AMLwvf and 41 ccRCC patients was used. We proposed a DFC method for differentiating the small renal masses (SRM) into AMLwvf and ccRCC using the combination of hand-crafted and deep features, and machine learning classifiers. First, 71-dimensional hand-crafted features (HCF) of texture and shape were extracted from the SRM contours. Second, 1000-4000-dimensional deep features (DF) were extracted from the ImageNet pretrained deep learning model with the SRM image patches. In DF extraction, we proposed the texture image patches (TIP) to emphasize the texture information inside the mass in DFs and reduce the mass size variability. Finally, the two features were concatenated and the random forest (RF) classifier was trained on these concatenated features to classify the types of SRMs. The proposed method was tested on our dataset using leave-one-out cross-validation and evaluated using accuracy, sensitivity, specificity, positive predictive values (PPV), negative predictive values (NPV), and area under receiver operating characteristics curve (AUC). In experiments, the combinations of four deep learning models, AlexNet, VGGNet, GoogleNet, and ResNet, and four input image patches, including original, masked, mass-size, and texture image patches, were compared and analyzed. RESULTS: In qualitative evaluation, we observed the change in feature distributions between the proposed and comparative methods using tSNE method. In quantitative evaluation, we evaluated and compared the classification results, and observed that (a) the proposed HCF + DF outperformed HCF-only and DF-only, (b) AlexNet showed generally the best performances among the CNN models, and (c) the proposed TIPs not only achieved the competitive performances among the input patches, but also steady performance regardless of CNN models. As a result, the proposed method achieved the accuracy of 76.6 +/- 1.4% for the proposed HCF + DF with AlexNet and TIPs, which improved the accuracy by 6.6%p and 8.3%p compared to HCF-only and DF-only, respectively. CONCLUSIONS: The proposed shape features and TIPs improved the HCFs and DFs, respectively, and the feature concatenation further enhanced the quality of features for differentiating AMLwvf from ccRCC in abdominal CE CT images.	"['School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Korea.', ""Department of Software Convergence, College of Interdisciplinary Studies for Emerging Industries, Seoul Women's University, 621 Hwarang-ro, Nowon-gu, Seoul, 01797, Korea."", 'School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Korea.', 'Department of Radiology, Severance Hospital, Research Institute of Radiological Science, Yonsei University College of Medicine, 50-1 Yonsei-ro, Seodaemun-gu, Seoul, 03722, Korea.']"	['10.1002/mp.12828 [doi]']	['Lee H', 'Hong H', 'Kim J', 'Jung DC']		['(c) 2018 American Association of Physicists in Medicine.']					['2018/02/24 06:00']	20180831	20180325	2018 Apr	2018/02/24 06:00		['Lee, Hansang', 'Hong, Helen', 'Kim, Junmo', 'Jung, Dae Chul']			4		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.12828 [doi]	20180831	['Angiomyolipoma/*diagnostic imaging', 'Carcinoma, Renal Cell/*diagnostic imaging', '*Contrast Media', 'Diagnosis, Differential', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Kidney Neoplasms/*diagnostic imaging', '*Machine Learning', 'Radiography, Abdominal', 'Sensitivity and Specificity', '*Tomography, X-Ray Computed']	2018/09/01 06:00		['angiomyolipoma without visible fat (AMLwvf)', 'clear cell renal cell carcinoma (ccRCC)', 'computed tomography (CT)', 'computer-aided diagnosis (CAD)', 'deep feature classification']	['NOTNLM']	NLM	1550-1561	['2017/08/02 00:00 [received]', '2017/12/20 00:00 [revised]', '2018/02/07 00:00 [accepted]', '2018/02/24 06:00 [pubmed]', '2018/09/01 06:00 [medline]', '2018/02/24 06:00 [entrez]']	United States			29474742	ppublish	['Journal Article']		['0 (Contrast Media)']	IM		Med Phys. 2018 Apr;45(4):1550-1561. doi: 10.1002/mp.12828. Epub 2018 Mar 25.	MEDLINE	Med Phys	Deep feature classification of angiomyolipoma without visible fat and renal cell carcinoma in abdominal contrast-enhanced CT images with texture image patches and hand-crafted feature concatenation.		45	Deep feature classification of angiomyolipoma without visible fat and renal cell carcinoma in abdominal contrast-enhanced CT images with texture image patches and hand-crafted feature concatenation.
Image-based machine learning and deep learning in particular has recently shown expert-level accuracy in medical image classification. In this study, we combine convolutional and recurrent architectures to train a deep network to predict colorectal cancer outcome based on images of tumour tissue samples. The novelty of our approach is that we directly predict patient outcome, without any intermediate tissue classification. We evaluate a set of digitized haematoxylin-eosin-stained tumour tissue microarray (TMA) samples from 420 colorectal cancer patients with clinicopathological and outcome data available. The results show that deep learning-based outcome prediction with only small tissue areas as input outperforms (hazard ratio 2.3; CI 95% 1.79-3.03; AUC 0.69) visual histological assessment performed by human experts on both TMA spot (HR 1.67; CI 95% 1.28-2.19; AUC 0.58) and whole-slide level (HR 1.65; CI 95% 1.30-2.15; AUC 0.57) in the stratification into low- and high-risk patients. Our results suggest that state-of-the-art deep learning techniques can extract more prognostic information from the tissue morphology of colorectal cancer than an experienced human observer.	"['Institute for Molecular Medicine Finland FIMM, Helsinki Institute for Life Science HiLIFE, University of Helsinki, Helsinki, Finland. dmitrii.bychkov@helsinki.fi.', 'Institute for Molecular Medicine Finland FIMM, Helsinki Institute for Life Science HiLIFE, University of Helsinki, Helsinki, Finland.', ""Department of Women's and Children's Health, International Maternal and Child Health (IMCH), Uppsala University, Uppsala, Sweden."", 'Institute for Molecular Medicine Finland FIMM, Helsinki Institute for Life Science HiLIFE, University of Helsinki, Helsinki, Finland.', 'Department of Pathology, Medicum, University of Helsinki, Helsinki, Finland.', 'Department of Pathology, University of Helsinki and HUSLAB, Helsinki University Hospital, Helsinki, Finland.', 'Nuffield Department of Surgical Sciences, NIHR Oxford Biomedical Research Centre, University of Oxford, Oxford, UK.', 'Institute for Molecular Medicine Finland FIMM, Helsinki Institute for Life Science HiLIFE, University of Helsinki, Helsinki, Finland.', 'Institute for Molecular Medicine Finland FIMM, Helsinki Institute for Life Science HiLIFE, University of Helsinki, Helsinki, Finland.', 'Department of Surgery, University of Helsinki and Helsinki University Hospital, Helsinki, Finland.', 'Research Programs Unit, Translational Cancer Biology, University of Helsinki, Helsinki, Finland.', 'Institute for Molecular Medicine Finland FIMM, Helsinki Institute for Life Science HiLIFE, University of Helsinki, Helsinki, Finland.', 'Department of Public Health Sciences, Global Health/IHCAR, Karolinska Institutet, Stockholm, Sweden.']"	['10.1038/s41598-018-21758-3 [doi]', '10.1038/s41598-018-21758-3 [pii]']	['Bychkov D', 'Linder N', 'Turkki R', 'Nordling S', 'Kovanen PE', 'Verrill C', 'Walliander M', 'Lundin M', 'Haglund C', 'Lundin J']	['ORCID: 0000-0002-8690-6983']						['2018/02/23 06:00']	20190906	20180221	2018 Feb 21	2018/02/23 06:00		['Bychkov, Dmitrii', 'Linder, Nina', 'Turkki, Riku', 'Nordling, Stig', 'Kovanen, Panu E', 'Verrill, Clare', 'Walliander, Margarita', 'Lundin, Mikael', 'Haglund, Caj', 'Lundin, Johan']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-21758-3 [doi]	20190906	['Aged', 'Algorithms', 'Colorectal Neoplasms/*pathology', 'Deep Learning', 'Eosine Yellowish-(YS)/administration & dosage', 'Female', 'Hematoxylin/administration & dosage', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Machine Learning', 'Male', 'Middle Aged', 'Prognosis', 'Retrospective Studies']	2019/09/07 06:00				NLM	3395	['2017/08/16 00:00 [received]', '2018/02/12 00:00 [accepted]', '2018/02/23 06:00 [entrez]', '2018/02/23 06:00 [pubmed]', '2019/09/07 06:00 [medline]']	England	PMC5821847		29467373	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['TDQ283MPCW (Eosine Yellowish-(YS))', 'YKM8PY2Z55 (Hematoxylin)']	IM		Sci Rep. 2018 Feb 21;8(1):3395. doi: 10.1038/s41598-018-21758-3.	MEDLINE	Sci Rep	Deep learning based tissue analysis predicts outcome in colorectal cancer.		8	Deep learning based tissue analysis predicts outcome in colorectal cancer.
Although Hi-C technology is one of the most popular tools for studying 3D genome organization, due to sequencing cost, the resolution of most Hi-C datasets are coarse and cannot be used to link distal regulatory elements to their target genes. Here we develop HiCPlus, a computational approach based on deep convolutional neural network, to infer high-resolution Hi-C interaction matrices from low-resolution Hi-C data. We demonstrate that HiCPlus can impute interaction matrices highly similar to the original ones, while only using 1/16 of the original sequencing reads. We show that the models learned from one cell type can be applied to make predictions in other cell or tissue types. Our work not only provides a computational framework to enhance Hi-C data resolution but also reveals features underlying the formation of 3D chromatin interactions.	['Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, 29208, USA.', 'Bioinformatics and Genomics Program, Huck Institutes of the Life Sciences, The Pennsylvania State University, University Park, PA, 16802, USA.', 'Department of Biochemistry and Molecular Biology, College of Medicine, The Pennsylvania State University, Hershey, PA, 17033, USA.', 'Bioinformatics and Genomics Program, Huck Institutes of the Life Sciences, The Pennsylvania State University, University Park, PA, 16802, USA.', 'School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, 77030, USA.', 'Department of Quantitative Health Sciences, Lerner Research Institute, Cleveland Clinic Foundation, Cleveland, OH, 44195, USA.', 'Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, 29208, USA. JTang@cse.sc.edu.', 'School of Computer Science and Technology, Tianjin University, 300072, Tianjin, China. JTang@cse.sc.edu.', 'Tianjin University Institute of Computational Biology, Tianjin University, 300072, Tianjin, China. JTang@cse.sc.edu.', 'Bioinformatics and Genomics Program, Huck Institutes of the Life Sciences, The Pennsylvania State University, University Park, PA, 16802, USA. fyue@hmc.psu.edu.', 'Department of Biochemistry and Molecular Biology, College of Medicine, The Pennsylvania State University, Hershey, PA, 17033, USA. fyue@hmc.psu.edu.']	['10.1038/s41467-018-03113-2 [doi]', '10.1038/s41467-018-03113-2 [pii]']	['Zhang Y', 'An L', 'Xu J', 'Zhang B', 'Zheng WJ', 'Hu M', 'Tang J', 'Yue F']	['ORCID: http://orcid.org/0000-0003-0987-2916']						['2018/02/23 06:00']	20181212	20180221	2018 Feb 21	2018/02/23 06:00		['Zhang, Yan', 'An, Lin', 'Xu, Jie', 'Zhang, Bo', 'Zheng, W Jim', 'Hu, Ming', 'Tang, Jijun', 'Yue, Feng']		['R24 DK106766/DK/NIDDK NIH HHS/United States', 'T32 GM102057/GM/NIGMS NIH HHS/United States']	1		2041-1723 (Electronic) 2041-1723 (Linking)	101528555	Nature communications	['eng']	10.1038/s41467-018-03113-2 [doi]	20190610	['*Chromatin Assembly and Disassembly', '*Chromosomes', '*Deep Learning', 'High-Throughput Nucleotide Sequencing', 'Humans']	2018/12/13 06:00				NLM	750	['2017/05/07 00:00 [received]', '2018/01/19 00:00 [accepted]', '2018/02/23 06:00 [entrez]', '2018/02/23 06:00 [pubmed]', '2018/12/13 06:00 [medline]']	England	PMC5821732		29467363	epublish	"['Evaluation Studies', 'Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Nat Commun. 2018 Feb 21;9(1):750. doi: 10.1038/s41467-018-03113-2.	MEDLINE	Nat Commun	Enhancing Hi-C data resolution with deep convolutional neural network HiCPlus.		9	Enhancing Hi-C data resolution with deep convolutional neural network HiCPlus.
Histopathological image classification is one of the most important steps for disease diagnosis. We proposed a method for multiclass histopathological image classification based on deep convolutional neural network referred to as coding network. It can gain better representation for the histopathological image than only using coding network. The main process is that training a deep convolutional neural network is to extract high-level feature and fuse two convolutional layers' high-level feature as multiscale high-level feature. In order to gain better performance and high efficiency, we would employ sparse autoencoder (SAE) and principal components analysis (PCA) to reduce the dimensionality of multiscale high-level feature. We evaluate the proposed method on a real histopathological image dataset. Our results suggest that the proposed method is effective and outperforms the coding network.	['Department of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.', 'Department of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.']	['10.1155/2017/7521846 [doi]']	['Lai Z', 'Deng H']	['ORCID: 0000-0003-3998-7466']						['2018/02/22 06:00']	20181005	20171231	2017	2018/02/22 06:00		['Lai, ZhiFei', 'Deng, HuiFang']					1748-6718 (Electronic) 1748-670X (Linking)	101277751	Computational and mathematical methods in medicine	['eng']	10.1155/2017/7521846 [doi]	20181113	['Algorithms', 'Area Under Curve', 'Diagnosis, Computer-Assisted', '*Diagnostic Imaging', 'False Positive Reactions', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Models, Statistical', '*Neural Networks (Computer)', 'Principal Component Analysis', 'ROC Curve', 'Reproducibility of Results', 'Software']	2018/10/06 06:00				NLM	7521846	['2017/09/27 00:00 [received]', '2017/12/06 00:00 [accepted]', '2018/02/22 06:00 [entrez]', '2018/02/22 06:00 [pubmed]', '2018/10/06 06:00 [medline]']	United States	PMC5804108		29463986	ppublish	['Journal Article']			IM		Comput Math Methods Med. 2017;2017:7521846. doi: 10.1155/2017/7521846. Epub 2017 Dec 31.	MEDLINE	Comput Math Methods Med	Multiscale High-Level Feature Fusion for Histopathological Image Classification.		2017	Multiscale High-Level Feature Fusion for Histopathological Image Classification.
In yeast and in some mammals the frequencies of recombination are high in some genomic locations which are known as recombination hotspots and in the locations where the recombination is below average are consequently known as coldspots. Knowledge of the hotspot regions gives clues about understanding the meiotic process and also in understanding the possible effects of sequence variation in these regions. Moreover, accurate information about the hotspot and coldspot regions can reveal insights into the genome evolution. In the present work, we have used class specific autoencoders for feature extraction and reduction. Subsequently the deep features that are extracted from the autoencoders were used to train three different classifiers, namely: gradient boosting machines, random forest and deep learning neural networks for predicting the hotspot and coldspot regions. A comparative performance analysis was carried out by experimenting on deep features extracted from different sets of the training data using autoencoders for selecting the best set of deep features. It was observed that learning algorithms trained on features extracted from the combined class specific autoencoder out performed when compared with the performances of these learning algorithms trained with other sets of deep features. So the combined class-specific autoencoder based feature extraction can be applied to a growing range of biological problems to achieve superior prediction performance.	['Department of Computer Science, Banaras Hindu University, Varanasi 221005, India. Electronic address: abhigyannath01@gmail.com.', 'Department of Computer Science, Banaras Hindu University, Varanasi 221005, India.']	['S0022-5193(18)30076-6 [pii]', '10.1016/j.jtbi.2018.02.016 [doi]']	['Nath A', 'Karthikeyan S']		['Copyright (c) 2018 Elsevier Ltd. All rights reserved.']					['2018/02/21 06:00']	20190820	20180217	2018 May 7	2018/02/21 06:00		['Nath, Abhigyan', 'Karthikeyan, S']					1095-8541 (Electronic) 0022-5193 (Linking)	0376342	Journal of theoretical biology	['eng']	S0022-5193(18)30076-6 [pii] 10.1016/j.jtbi.2018.02.016 [doi]	20190820	['Algorithms', 'Base Sequence', 'Classification', '*Deep Learning', 'Neural Networks (Computer)', 'Recombination, Genetic/*genetics', 'Saccharomyces cerevisiae/genetics']	2019/08/21 06:00		['*Autoencoders', '*Deep features', '*Deep learning', '*Recombination hotspots']	['NOTNLM']	NLM	73-82	['2017/08/16 00:00 [received]', '2018/01/12 00:00 [revised]', '2018/02/16 00:00 [accepted]', '2018/02/21 06:00 [pubmed]', '2019/08/21 06:00 [medline]', '2018/02/21 06:00 [entrez]']	England			29462625	ppublish	['Journal Article']					J Theor Biol. 2018 May 7;444:73-82. doi: 10.1016/j.jtbi.2018.02.016. Epub 2018 Feb 17.	MEDLINE	J Theor Biol	Enhanced prediction of recombination hotspots using input features extracted by class specific autoencoders.		444	Enhanced prediction of recombination hotspots using input features extracted by class specific autoencoders.
Mitotic count is a critical predictor of tumor aggressiveness in the breast cancer diagnosis. Nowadays mitosis counting is mainly performed by pathologists manually, which is extremely arduous and time-consuming. In this paper, we propose an accurate method for detecting the mitotic cells from histopathological slides using a novel multi-stage deep learning framework. Our method consists of a deep segmentation network for generating mitosis region when only a weak label is given (i.e., only the centroid pixel of mitosis is annotated), an elaborately designed deep detection network for localizing mitosis by using contextual region information, and a deep verification network for improving detection accuracy by removing false positives. We validate the proposed deep learning method on two widely used Mitosis Detection in Breast Cancer Histological Images (MITOSIS) datasets. Experimental results show that we can achieve the highest F-score on the MITOSIS dataset from ICPR 2012 grand challenge merely using the deep detection network. For the ICPR 2014 MITOSIS dataset that only provides the centroid location of mitosis, we employ the segmentation model to estimate the bounding box annotation for training the deep detection network. We also apply the verification model to eliminate some false positives produced from the detection model. By fusing scores of the detection and verification models, we achieve the state-of-the-art results. Moreover, our method is very fast with GPU computing, which makes it feasible for clinical practice.	['School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, PR China. Electronic address: chaol@hust.edu.cn.', 'School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, PR China. Electronic address: xgwang@hust.edu.cn.', 'School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, PR China. Electronic address: liuwy@hust.edu.cn.', 'CIS Department, Temple University, Philadelphia, PA 19122, USA. Electronic address: latecki@temple.edu.']	['S1361-8415(17)30183-4 [pii]', '10.1016/j.media.2017.12.002 [doi]']	['Li C', 'Wang X', 'Liu W', 'Latecki LJ']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/02/19 06:00']	20190506	20180131	2018 Apr	2018/02/20 06:00		['Li, Chao', 'Wang, Xinggang', 'Liu, Wenyu', 'Latecki, Longin Jan']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(17)30183-4 [pii] 10.1016/j.media.2017.12.002 [doi]	20190506	['Algorithms', 'Breast Neoplasms/*diagnostic imaging/*pathology', '*Deep Learning', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Mitosis']	2019/05/07 06:00		['*Breast cancer grading', '*Faster R-CNN', '*Fully convolutional network', '*Mitosis detection']	['NOTNLM']	NLM	121-133	['2017/04/30 00:00 [received]', '2017/10/11 00:00 [revised]', '2017/12/02 00:00 [accepted]', '2018/02/20 06:00 [pubmed]', '2019/05/07 06:00 [medline]', '2018/02/19 06:00 [entrez]']	Netherlands			29455111	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Med Image Anal. 2018 Apr;45:121-133. doi: 10.1016/j.media.2017.12.002. Epub 2018 Jan 31.	MEDLINE	Med Image Anal	DeepMitosis: Mitosis detection via deep detection, verification and segmentation networks.		45	DeepMitosis: Mitosis detection via deep detection, verification and segmentation networks.
For effective treatment of Alzheimer's disease (AD), it is important to identify subjects who are most likely to exhibit rapid cognitive decline. We aimed to develop an automatic image interpretation system based on a deep convolutional neural network (CNN) which can accurately predict future cognitive decline in mild cognitive impairment (MCI) patients using flurodeoxyglucose and florbetapir positron emission tomography (PET). PET images of 139 patients with AD, 171 patients with MCI and 182 normal subjects obtained from Alzheimer's Disease Neuroimaging Initiative database were used. Deep CNN was trained using 3-dimensional PET volumes of AD and normal controls as inputs. Manually defined image feature extraction such as quantification using predefined region-of-interests was unnecessary for our approach. Furthermore, it used minimally processed images without spatial normalization which has been commonly used in conventional quantitative analyses. Cognitive outcome of MCI subjects was predicted using this network. The prediction accuracy of the conversion of mild cognitive impairment to AD was compared with the conventional feature-based quantification approach. Accuracy of prediction (84.2%) for conversion to AD in MCI patients outperformed conventional feature-based quantification approaches. ROC analyses revealed that performance of CNN-based approach was significantly higher than that of the conventional quantification methods (p<0.05). Output scores of the network were strongly correlated with the longitudinal change in cognitive measurements (p<0.05). These results show the feasibility of deep learning as a practical tool for developing predictive neuroimaging biomarker.	['Cheonan Public Health Center, Chungnam, Republic of Korea. Electronic address: chy1000@snu.ac.kr.', 'Biomedical Imaging Group, Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea. Electronic address: kyong.jin@epfl.ch.']	['S0166-4328(18)30101-3 [pii]', '10.1016/j.bbr.2018.02.017 [doi]']	['Choi H', 'Jin KH']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']		"[""Alzheimer's Disease Neuroimaging Initiative""]"			['2018/02/18 06:00']	20180904	20180214	2018 May 15	2018/02/18 06:00		['Choi, Hongyoon', 'Jin, Kyong Hwan']					1872-7549 (Electronic) 0166-4328 (Linking)	8004872	Behavioural brain research	['eng']	S0166-4328(18)30101-3 [pii] 10.1016/j.bbr.2018.02.017 [doi]	20180904	['Aged', 'Alzheimer Disease/classification/*diagnostic imaging/metabolism', 'Amyloid/*metabolism', 'Aniline Compounds', 'Brain/*diagnostic imaging/metabolism', 'Cognitive Dysfunction/*diagnostic imaging/metabolism', 'Ethylene Glycols', 'Female', 'Fluorodeoxyglucose F18', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Imaging, Three-Dimensional', 'Male', '*Positron-Emission Tomography/methods', 'Prognosis', 'Radiopharmaceuticals', 'Sensitivity and Specificity', 'Support Vector Machine']	2018/09/05 06:00		"[""*Alzheimer's disease"", '*Amyloid', '*Brain PET', '*Convolutional neural network', '*Deep learning']"	['NOTNLM']	NLM	103-109	['2018/01/30 00:00 [received]', '2018/02/02 00:00 [revised]', '2018/02/13 00:00 [accepted]', '2018/02/18 06:00 [pubmed]', '2018/09/05 06:00 [medline]', '2018/02/18 06:00 [entrez]']	Netherlands			29454006	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Amyloid)', '0 (Aniline Compounds)', '0 (Ethylene Glycols)', '0 (Radiopharmaceuticals)', '0Z5B2CJX4D (Fluorodeoxyglucose F18)', '6867Q6IKOD (florbetapir)']	IM		Behav Brain Res. 2018 May 15;344:103-109. doi: 10.1016/j.bbr.2018.02.017. Epub 2018 Feb 14.	MEDLINE	Behav Brain Res	Predicting cognitive decline with deep learning of brain metabolism and amyloid imaging.		344	Predicting cognitive decline with deep learning of brain metabolism and amyloid imaging.
Pathogenesis-based diagnosis is a key step to prevent and control lumbar neural foraminal stenosis (LNFS). It conducts both early diagnosis and comprehensive assessment by drawing crucial pathological links between pathogenic factors and LNFS. Automated pathogenesis-based diagnosis would simultaneously localize and grade multiple spinal organs (neural foramina, vertebrae, intervertebral discs) to diagnose LNFS and discover pathogenic factors. The automated way facilitates planning optimal therapeutic schedules and relieving clinicians from laborious workloads. However, no successful work has been achieved yet due to its extreme challenges since 1) multiple targets: each lumbar spine has at least 17 target organs, 2) multiple scales: each type of target organ has structural complexity and various scales across subjects, and 3) multiple tasks, i.e., simultaneous localization and diagnosis of all lumbar organs, are extremely difficult than individual tasks. To address these huge challenges, we propose a deep multiscale multitask learning network (DMML-Net) integrating a multiscale multi-output learning and a multitask regression learning into a fully convolutional network. 1) DMML-Net merges semantic representations to reinforce the salience of numerous target organs. 2) DMML-Net extends multiscale convolutional layers as multiple output layers to boost the scale-invariance for various organs. 3) DMML-Net joins a multitask regression module and a multitask loss module to prompt the mutual benefit between tasks. Extensive experimental results demonstrate that DMML-Net achieves high performance (0.845 mean average precision) on T1/T2-weighted MRI scans from 200 subjects. This endows our method an efficient tool for clinical LNFS diagnosis.	['College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China.', 'Computational Medicine Lab, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China.', 'Department of Medical Imaging, Western University, London, N6A 4V2, Canada.', 'Digital Image Group (DIG), London, ON, N6A 4V2, Canada.', 'College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China. wbz99@sina.com.', 'Computational Medicine Lab, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China. wbz99@sina.com.', 'Digital Image Group (DIG), London, ON, N6A 4V2, Canada.', 'Digital Image Group (DIG), London, ON, N6A 4V2, Canada.', 'Digital Image Group (DIG), London, ON, N6A 4V2, Canada.', 'Department of Medical Imaging, Western University, London, N6A 4V2, Canada. slishuo@gmail.com.', 'Digital Image Group (DIG), London, ON, N6A 4V2, Canada. slishuo@gmail.com.']	['10.1007/s12021-018-9365-1 [doi]', '10.1007/s12021-018-9365-1 [pii]']	['Han Z', 'Wei B', 'Leung S', 'Nachum IB', 'Laidley D', 'Li S']	['ORCID: 0000-0002-5184-3230']						['2018/02/17 06:00']	20190311		2018 Oct	2018/02/17 06:00		['Han, Zhongyi', 'Wei, Benzheng', 'Leung, Stephanie', 'Nachum, Ilanit Ben', 'Laidley, David', 'Li, Shuo']		['ZR2015FM010/Natural Science Foundation of Shandong Province/International', 'ZR2015FM010/Natural Science Foundation of Shandong Province/International', 'J15LN20/Project of Shandong Province Higher Educational Science and Technology', 'Program in China/International', 'J15LN20/Project of Shandong Province Higher Educational Science and Technology', 'Program in China/International', '2016WS0577/Project of Shandong Province Medical and Health Technology Development', 'Program in China/International', '2016WS0577/Project of Shandong Province Medical and Health Technology Development', 'Program in China/International']	3-4		1559-0089 (Electronic) 1539-2791 (Linking)	101142069	Neuroinformatics	['eng']	10.1007/s12021-018-9365-1 [doi]	20190311	['Aged', 'Female', 'Humans', 'Intervertebral Disc Degeneration/diagnostic imaging', 'Lumbar Vertebrae/*diagnostic imaging', '*Machine Learning', 'Male', 'Middle Aged', '*Multitasking Behavior', '*Neural Networks (Computer)', 'Spinal Nerve Roots/*diagnostic imaging', 'Spinal Stenosis/*diagnostic imaging']	2019/03/12 06:00		['*Deep learning', '*Multiscale learning', '*Multitask learning', '*Neural foraminal stenosis']	['NOTNLM']	NLM	325-337	['2018/02/17 06:00 [pubmed]', '2019/03/12 06:00 [medline]', '2018/02/17 06:00 [entrez]']	United States			29450848	ppublish	"['Journal Article', 'Multicenter Study', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroinformatics. 2018 Oct;16(3-4):325-337. doi: 10.1007/s12021-018-9365-1.	MEDLINE	Neuroinformatics	Automated Pathogenesis-Based Diagnosis of Lumbar Neural Foraminal Stenosis via Deep Multiscale Multitask Learning.		16	Automated Pathogenesis-Based Diagnosis of Lumbar Neural Foraminal Stenosis via Deep Multiscale Multitask Learning.
Simultaneous reconstruction of activity and attenuation using the maximum-likelihood reconstruction of activity and attenuation (MLAA) augmented by time-of-flight information is a promising method for PET attenuation correction. However, it still suffers from several problems, including crosstalk artifacts, slow convergence speed, and noisy attenuation maps (mu-maps). In this work, we developed deep convolutional neural networks (CNNs) to overcome these MLAA limitations, and we verified their feasibility using a clinical brain PET dataset. Methods: We applied the proposed method to one of the most challenging PET cases for simultaneous image reconstruction ((18)F-fluorinated-N-3-fluoropropyl-2-beta-carboxymethoxy-3-beta-(4-iodophenyl)no rtropane [(18)F-FP-CIT] PET scans with highly specific binding to striatum of the brain). Three different CNN architectures (convolutional autoencoder [CAE], Unet, and Hybrid of CAE) were designed and trained to learn a CT-derived mu-map (mu-CT) from the MLAA-generated activity distribution and mu-map (mu-MLAA). The PET/CT data of 40 patients with suspected Parkinson disease were used for 5-fold cross-validation. For the training of CNNs, 800,000 transverse PET and CT slices augmented from 32 patient datasets were used. The similarity to mu-CT of the CNN-generated mu-maps (mu-CAE, mu-Unet, and mu-Hybrid) and mu-MLAA was compared using Dice similarity coefficients. In addition, we compared the activity concentration of specific (striatum) and nonspecific (cerebellum and occipital cortex) binding regions and the binding ratios in the striatum in the PET activity images reconstructed using those mu-maps. Results: The CNNs generated less noisy and more uniform mu-maps than the original mu-MLAA. Moreover, the air cavities and bones were better resolved in the proposed CNN outputs. In addition, the proposed deep learning approach was useful for mitigating the crosstalk problem in the MLAA reconstruction. The Hybrid network of CAE and Unet yielded the most similar mu-maps to mu-CT (Dice similarity coefficient in the whole head = 0.79 in the bone and 0.72 in air cavities), resulting in only about a 5% error in activity and binding ratio quantification. Conclusion: The proposed deep learning approach is promising for accurate attenuation correction of activity distribution in time-of-flight PET systems.	['Department of Biomedical Sciences, Seoul National University, Seoul, Korea.', 'Department of Nuclear Medicine, Seoul National University, Seoul, Korea.', 'Department of Biomedical Sciences, Seoul National University, Seoul, Korea.', 'Department of Nuclear Medicine, Seoul National University, Seoul, Korea.', 'Department of Biomedical Sciences, Seoul National University, Seoul, Korea.', 'Department of Nuclear Medicine, Seoul National University, Seoul, Korea.', 'Department of Neuroscience, College of Medicine, Gachon University, Incheon, Korea.', 'Department of Nuclear Medicine, Seoul National University, Seoul, Korea.', 'Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, Korea; and.', 'Department of Nuclear Medicine, Seoul National University, Seoul, Korea.', 'Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, Korea; and.', 'Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Suwon, Korea.', 'Department of Biomedical Sciences, Seoul National University, Seoul, Korea jaes@snu.ac.kr.', 'Department of Nuclear Medicine, Seoul National University, Seoul, Korea.', 'Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, Korea; and.']	['jnumed.117.202317 [pii]', '10.2967/jnumed.117.202317 [doi]']	['Hwang D', 'Kim KY', 'Kang SK', 'Seo S', 'Paeng JC', 'Lee DS', 'Lee JS']		['(c) 2018 by the Society of Nuclear Medicine and Molecular Imaging.']					['2018/02/17 06:00']	20190708	20180215	2018 Oct	2018/02/17 06:00		['Hwang, Donghwi', 'Kim, Kyeong Yun', 'Kang, Seung Kwan', 'Seo, Seongho', 'Paeng, Jin Chul', 'Lee, Dong Soo', 'Lee, Jae Sung']			10		1535-5667 (Electronic) 0161-5505 (Linking)	0217410	Journal of nuclear medicine : official publication, Society of Nuclear Medicine	['eng']	10.2967/jnumed.117.202317 [doi]	20190708	['Aged', 'Brain/diagnostic imaging/metabolism', '*Deep Learning', 'Dopamine/metabolism', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'Positron Emission Tomography Computed Tomography', 'Time Factors']	2019/07/10 06:00		['*crosstalk', '*deep learning', '*denoising', '*quantification', '*simultaneous reconstruction']	['NOTNLM']	NLM	1624-1629	['2017/09/28 00:00 [received]', '2018/01/25 00:00 [accepted]', '2018/02/17 06:00 [pubmed]', '2019/07/10 06:00 [medline]', '2018/02/17 06:00 [entrez]']	United States			29449446	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['VTD58H1Z2X (Dopamine)']	IM		J Nucl Med. 2018 Oct;59(10):1624-1629. doi: 10.2967/jnumed.117.202317. Epub 2018 Feb 15.	MEDLINE	J Nucl Med	Improving the Accuracy of Simultaneously Reconstructed Activity and Attenuation Maps Using Deep Learning.		59	Improving the Accuracy of Simultaneously Reconstructed Activity and Attenuation Maps Using Deep Learning.
Deep learning and neural network models have been new research directions and hot issues in the fields of machine learning and artificial intelligence in recent years. Deep learning has made a breakthrough in the applications of image and speech recognitions, and also has been extensively used in the fields of face recognition and information retrieval because of its special superiority. Bone X-ray images express different variations in black-white-gray gradations, which have image features of black and white contrasts and level differences. Based on these advantages of deep learning in image recognition, we combine it with the research of bone age assessment to provide basic datum for constructing a forensic automatic system of bone age assessment. This paper reviews the basic concept and network architectures of deep learning, and describes its recent research progress on image recognition in different research fields at home and abroad, and explores its advantages and application prospects in bone age assessment.	"[""Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an 710061, China."", 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.', 'Shanghai Fanyang Information Technology Co., LTD., Shanghai 200444, China.', 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.', ""Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an 710061, China."", 'Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai 200063, China.']"	['j33/6/629 [pii]', '10.3969/j.issn.1004-5619.2017.06.013 [doi]']	['Hu TH', 'Wan L', 'Liu TA', 'Wang MW', 'Chen T', 'Wang YH']		['Copyright(c) by the Editorial Department of Journal of Forensic Medicine.']			['The authors of this article and the planning committee members and staff have no', 'relevant financial relationships with commercial interests to disclose.']		['2018/02/15 06:00']	20180528	20171225	2017 Dec	2018/02/15 06:00		['Hu, T H', 'Wan, L', 'Liu, T A', 'Wang, M W', 'Chen, T', 'Wang, Y H']			6		1004-5619 (Print) 1004-5619 (Linking)	9426151	Fa yi xue za zhi	['chi']	10.3969/j.issn.1004-5619.2017.06.013 [doi]	20181202	['Algorithms', 'Artificial Intelligence', 'Bone and Bones/*diagnostic imaging/pathology', 'Humans', '*Image Processing, Computer-Assisted', '*Machine Learning', 'Neural Networks (Computer)']	2018/05/29 06:00		['age determination by skeleton', 'deep learning', 'forensic anthropology', 'image processing, computer-assisted', 'image recognition', 'neural networks computer', 'review']	['NOTNLM']	NLM	629-634	['2017/09/11 00:00 [received]', '2018/02/15 06:00 [entrez]', '2018/02/15 06:00 [pubmed]', '2018/05/29 06:00 [medline]']	China			29441773	ppublish	['Journal Article', 'Review']			IM		Fa Yi Xue Za Zhi. 2017 Dec;33(6):629-634. doi: 10.3969/j.issn.1004-5619.2017.06.013. Epub 2017 Dec 25.	MEDLINE	Fa Yi Xue Za Zhi	[Advantages and Application Prospects of Deep Learning in Image Recognition and Bone Age Assessment].		33	[Advantages and Application Prospects of Deep Learning in Image Recognition and Bone Age Assessment].
Skin lesions are a severe disease globally. Early detection of melanoma in dermoscopy images significantly increases the survival rate. However, the accurate recognition of melanoma is extremely challenging due to the following reasons: low contrast between lesions and skin, visual similarity between melanoma and non-melanoma lesions, etc. Hence, reliable automatic detection of skin tumors is very useful to increase the accuracy and efficiency of pathologists. In this paper, we proposed two deep learning methods to address three main tasks emerging in the area of skin lesion image processing, i.e., lesion segmentation (task 1), lesion dermoscopic feature extraction (task 2) and lesion classification (task 3). A deep learning framework consisting of two fully convolutional residual networks (FCRN) is proposed to simultaneously produce the segmentation result and the coarse classification result. A lesion index calculation unit (LICU) is developed to refine the coarse classification results by calculating the distance heat-map. A straight-forward CNN is proposed for the dermoscopic feature extraction task. The proposed deep learning frameworks were evaluated on the ISIC 2017 dataset. Experimental results show the promising accuracies of our frameworks, i.e., 0.753 for task 1, 0.848 for task 2 and 0.912 for task 3 were achieved.	['Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China. yuexiang.li@szu.edu.cn.', 'Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China. yuexiang.li@szu.edu.cn.', 'Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China. llshen@szu.edu.cn.', 'Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China. llshen@szu.edu.cn.']	['s18020556 [pii]', '10.3390/s18020556 [doi]']	['Li Y', 'Shen L']							['2018/02/15 06:00']	20180605	20180211	2018 Feb 11	2018/02/15 06:00		['Li, Yuexiang', 'Shen, Linlin']			2		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E556 [pii] 10.3390/s18020556 [doi]	20181202	['Dermoscopy', 'Humans', 'Image Processing, Computer-Assisted', 'Machine Learning', '*Melanoma', 'Skin Neoplasms']	2018/06/06 06:00		['deep convolutional network', 'fully-convolutional residual network', 'melanoma recognition', 'skin lesion classification']	['NOTNLM']	NLM		['2017/12/19 00:00 [received]', '2018/02/08 00:00 [revised]', '2018/02/08 00:00 [accepted]', '2018/02/15 06:00 [entrez]', '2018/02/15 06:00 [pubmed]', '2018/06/06 06:00 [medline]']	Switzerland	PMC5855504		29439500	epublish	['Journal Article']			IM		Sensors (Basel). 2018 Feb 11;18(2). pii: s18020556. doi: 10.3390/s18020556.	MEDLINE	Sensors (Basel)	Skin Lesion Analysis towards Melanoma Detection Using Deep Learning Network.		18	Skin Lesion Analysis towards Melanoma Detection Using Deep Learning Network.
Recently released large-scale neuron morphological data has greatly facilitated the research in neuroinformatics. However, the sheer volume and complexity of these data pose significant challenges for efficient and accurate neuron exploration. In this paper, we propose an effective retrieval framework to address these problems, based on frontier techniques of deep learning and binary coding. For the first time, we develop a deep learning based feature representation method for the neuron morphological data, where the 3D neurons are first projected into binary images and then learned features using an unsupervised deep neural network, i.e., stacked convolutional autoencoders (SCAEs). The deep features are subsequently fused with the hand-crafted features for more accurate representation. Considering the exhaustive search is usually very time-consuming in large-scale databases, we employ a novel binary coding method to compress feature vectors into short binary codes. Our framework is validated on a public data set including 58,000 neurons, showing promising retrieval precision and efficiency compared with state-of-the-art methods. In addition, we develop a novel neuron visualization program based on the techniques of augmented reality (AR), which can help users take a deep exploration of neuron morphologies in an interactive and immersive manner.	['Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, 28223, USA.', 'Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, 28223, USA.', 'Department of Industrial and Systems Engineering, The State University of New Jersey, Piscataway, NJ, 08854, USA.', 'Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, 28223, USA.', 'School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, 99164, USA.', 'Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, 28223, USA. rutgers.shaoting@gmail.com.']	['10.1007/s12021-018-9361-5 [doi]', '10.1007/s12021-018-9361-5 [pii]']	['Li Z', 'Butler E', 'Li K', 'Lu A', 'Ji S', 'Zhang S']	['ORCID: 0000-0002-8719-448X']						['2018/02/14 06:00']	20190311		2018 Oct	2018/02/13 06:00		['Li, Zhongyu', 'Butler, Erik', 'Li, Kang', 'Lu, Aidong', 'Ji, Shuiwang', 'Zhang, Shaoting']		['1629913/Division of Computer and Network Systems/International', '1661280/Division of Biological Infrastructure (US)/International', '1661289/Division of Biological Infrastructure (US)/International']	3-4		1559-0089 (Electronic) 1539-2791 (Linking)	101142069	Neuroinformatics	['eng']	10.1007/s12021-018-9361-5 [doi]	20190311	['*Databases, Factual/trends', '*Deep Learning/trends', 'Humans', 'Imaging, Three-Dimensional/*methods/trends', '*Neural Networks (Computer)', '*Neurons/cytology/physiology', 'Random Allocation']	2019/03/12 06:00		['*Augmented reality', '*Binary coding', '*Deep learning', '*Large-scale retrieval', '*Neuron morphology']	['NOTNLM']	NLM	339-349	['2018/02/13 06:00 [pubmed]', '2019/03/12 06:00 [medline]', '2018/02/14 06:00 [entrez]']	United States			29435954	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Neuroinformatics. 2018 Oct;16(3-4):339-349. doi: 10.1007/s12021-018-9361-5.	MEDLINE	Neuroinformatics	Large-scale Exploration of Neuronal Morphologies Using Deep Learning and Augmented Reality.		16	Large-scale Exploration of Neuronal Morphologies Using Deep Learning and Augmented Reality.
We present two algorithms to predict the activity of AsCpf1 guide RNAs. Indel frequencies for 15,000 target sequences were used in a deep-learning framework based on a convolutional neural network to train Seq-deepCpf1. We then incorporated chromatin accessibility information to create the better-performing DeepCpf1 algorithm for cell lines for which such information is available and show that both algorithms outperform previous machine learning algorithms on our own and published data sets.	['Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Electrical and Computer Engineering, Seoul National University, Seoul, Republic of Korea.', 'Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Graduate School of Biomedical Science and Engineering, Hanyang University, Seoul, Republic of Korea.', 'Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Severance Biomedical Science Institute, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Electrical and Computer Engineering, Seoul National University, Seoul, Republic of Korea.', 'Interdisciplinary Program in Bioinformatics, Seoul National University, Seoul, Republic of Korea.', 'Department of Pharmacology, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Severance Biomedical Science Institute, Yonsei University College of Medicine, Seoul, Republic of Korea.', 'Center for Nanomedicine, Institute for Basic Science (IBS), Seoul, Republic of Korea.', 'Yonsei-IBS Institute, Yonsei University, Seoul, Republic of Korea.']	['nbt.4061 [pii]', '10.1038/nbt.4061 [doi]']	['Kim HK', 'Min S', 'Song M', 'Jung S', 'Choi JW', 'Kim Y', 'Lee S', 'Yoon S', 'Kim HH']	['ORCID: 0000-0002-2367-197X', 'ORCID: 0000-0002-4693-738X']						['2018/02/13 06:00']	20181219	20180129	2018 Mar	2018/02/13 06:00		['Kim, Hui Kwon', 'Min, Seonwoo', 'Song, Myungjae', 'Jung, Soobin', 'Choi, Jae Woo', 'Kim, Younggwang', 'Lee, Sangeun', 'Yoon, Sungroh', 'Kim, Hyongbum Henry']			3		1546-1696 (Electronic) 1087-0156 (Linking)	9604648	Nature biotechnology	['eng']	10.1038/nbt.4061 [doi]	20181219	['Algorithms', 'CRISPR-Cas Systems/*genetics', 'Cell Line', 'Deep Learning', 'Endonucleases/*genetics', 'Neural Networks (Computer)', 'RNA, Guide/*genetics']	2018/12/20 06:00				NLM	239-241	['2017/05/24 00:00 [received]', '2017/12/08 00:00 [accepted]', '2018/02/13 06:00 [pubmed]', '2018/12/20 06:00 [medline]', '2018/02/13 06:00 [entrez]']	United States			29431740	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (RNA, Guide)', 'EC 3.1.- (Endonucleases)']	IM		Nat Biotechnol. 2018 Mar;36(3):239-241. doi: 10.1038/nbt.4061. Epub 2018 Jan 29.	MEDLINE	Nat Biotechnol	Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity.		36	Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity.
We assessed the feasibility of a data-driven imaging biomarker based on weakly supervised learning (DIB; an imaging biomarker derived from large-scale medical image data with deep learning technology) in mammography (DIB-MG). A total of 29,107 digital mammograms from five institutions (4,339 cancer cases and 24,768 normal cases) were included. After matching patients' age, breast density, and equipment, 1,238 and 1,238 cases were chosen as validation and test sets, respectively, and the remainder were used for training. The core algorithm of DIB-MG is a deep convolutional neural network; a deep learning algorithm specialized for images. Each sample (case) is an exam composed of 4-view images (RCC, RMLO, LCC, and LMLO). For each case in a training set, the cancer probability inferred from DIB-MG is compared with the per-case ground-truth label. Then the model parameters in DIB-MG are updated based on the error between the prediction and the ground-truth. At the operating point (threshold) of 0.5, sensitivity was 75.6% and 76.1% when specificity was 90.2% and 88.5%, and AUC was 0.903 and 0.906 for the validation and test sets, respectively. This research showed the potential of DIB-MG as a screening tool for breast cancer.	"['Department of Radiology, Research Institute of Radiological Science and Center for Clinical Image Data Science, Severance Hospital, Yonsei University, Seoul, Korea. ekkim@yuhs.ac.', 'Lunit Inc, Seoul, Korea.', 'Department of Radiology, Research Institute of Radiological Science and Center for Clinical Image Data Science, Severance Hospital, Yonsei University, Seoul, Korea.', ""Department of Radiology, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul, Korea."", 'Department of Radiology, Kyung Hee University Hospital, College of Medicine, Kyung Hee University, Seoul, Korea.', 'Department of Radiology, Korea University Guro Hospital, Seoul, Korea.', 'Department of Radiology, Center for Diagnostic Oncology, National Cancer Center Hospital, National Cancer Center, Gyeonggi, Korea.']"	['10.1038/s41598-018-21215-1 [doi]', '10.1038/s41598-018-21215-1 [pii]']	['Kim EK', 'Kim HE', 'Han K', 'Kang BJ', 'Sohn YM', 'Woo OH', 'Lee CW']	['ORCID: 0000-0002-5991-6035', 'ORCID: 0000-0002-2238-0724']						['2018/02/11 06:00']	20190920	20180209	2018 Feb 9	2018/02/11 06:00		['Kim, Eun-Kyung', 'Kim, Hyo-Eun', 'Han, Kyunghwa', 'Kang, Bong Joo', 'Sohn, Yu-Mee', 'Woo, Ok Hee', 'Lee, Chan Wha']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-018-21215-1 [doi]	20190920	['Adult', 'Algorithms', 'Breast Density', 'Breast Neoplasms/*diagnostic imaging/ultrastructure', 'Databases, Factual', '*Deep Learning', '*Diagnosis, Computer-Assisted', 'Early Detection of Cancer', 'Female', 'Humans', 'Mammography/*methods', 'Middle Aged', 'Pilot Projects', 'Retrospective Studies', 'Supervised Machine Learning']	2019/09/21 06:00				NLM	2762	['2017/06/20 00:00 [received]', '2018/02/01 00:00 [accepted]', '2018/02/11 06:00 [entrez]', '2018/02/11 06:00 [pubmed]', '2019/09/21 06:00 [medline]']	England	PMC5807343		29426948	epublish	"['Evaluation Studies', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2018 Feb 9;8(1):2762. doi: 10.1038/s41598-018-21215-1.	MEDLINE	Sci Rep	Applying Data-driven Imaging Biomarker in Mammography for Breast Cancer Screening: Preliminary Study.		8	Applying Data-driven Imaging Biomarker in Mammography for Breast Cancer Screening: Preliminary Study.
Rich sources of obesity-related data arising from sensors, smartphone apps, electronic medical health records and insurance data can bring new insights for understanding, preventing and treating obesity. For such large datasets, machine learning provides sophisticated and elegant tools to describe, classify and predict obesity-related risks and outcomes. Here, we review machine learning methods that predict and/or classify such as linear and logistic regression, artificial neural networks, deep learning and decision tree analysis. We also review methods that describe and characterize data such as cluster analysis, principal component analysis, network science and topological data analysis. We introduce each method with a high-level overview followed by examples of successful applications. The algorithms were then applied to National Health and Nutrition Examination Survey to demonstrate methodology, utility and outcomes. The strengths and limitations of each method were also evaluated. This summary of machine learning algorithms provides a unique overview of the state of data analysis applied specifically to obesity.	['Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Case Western Reserve University, Cleveland, OH, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Case Western Reserve University, Cleveland, OH, USA.', 'Pennington Biomedical Research Center, Baton Rouge, LA, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.', 'Department of Mathematical Sciences, United States Military Academy, West Point, NY, USA.']	['10.1111/obr.12667 [doi]']	['DeGregory KW', 'Kuiper P', 'DeSilvio T', 'Pleuss JD', 'Miller R', 'Roginski JW', 'Fisher CB', 'Harness D', 'Viswanath S', 'Heymsfield SB', 'Dungan I', 'Thomas DM']		['(c) 2018 World Obesity Federation.']					['2018/02/10 06:00']	20190417	20180209	2018 May	2018/02/10 06:00		['DeGregory, K W', 'Kuiper, P', 'DeSilvio, T', 'Pleuss, J D', 'Miller, R', 'Roginski, J W', 'Fisher, C B', 'Harness, D', 'Viswanath, S', 'Heymsfield, S B', 'Dungan, I', 'Thomas, D M']			5		1467-789X (Electronic) 1467-7881 (Linking)	100897395	Obesity reviews : an official journal of the International Association for the Study of Obesity	['eng']	10.1111/obr.12667 [doi]	20190417	['Algorithms', 'Humans', 'Logistic Models', '*Machine Learning/statistics & numerical data', 'Neural Networks (Computer)', 'Nutrition Surveys', '*Obesity']	2019/04/18 06:00		['*Deep learning', '*National Health and Nutrition Examination Survey', '*machine learning', '*topological data analysis']	['NOTNLM']	NLM	668-685	['2017/10/22 00:00 [received]', '2017/11/18 00:00 [revised]', '2017/11/28 00:00 [accepted]', '2018/02/10 06:00 [pubmed]', '2019/04/18 06:00 [medline]', '2018/02/10 06:00 [entrez]']	England			29426065	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S."", 'Review']"			IM		Obes Rev. 2018 May;19(5):668-685. doi: 10.1111/obr.12667. Epub 2018 Feb 9.	MEDLINE	Obes Rev	A review of machine learning in obesity.		19	A review of machine learning in obesity.
BACKGROUND: Stress recognition using electrocardiogram (ECG) signals requires the intractable long-term heart rate variability (HRV) parameter extraction process. This study proposes a novel deep learning framework to recognize the stressful states, the Deep ECGNet, using ultra short-term raw ECG signals without any feature engineering methods. METHODS: The Deep ECGNet was developed through various experiments and analysis of ECG waveforms. We proposed the optimal recurrent and convolutional neural networks architecture, and also the optimal convolution filter length (related to the P, Q, R, S, and T wave durations of ECG) and pooling length (related to the heart beat period) based on the optimization experiments and analysis on the waveform characteristics of ECG signals. The experiments were also conducted with conventional methods using HRV parameters and frequency features as a benchmark test. The data used in this study were obtained from Kwangwoon University in Korea (13 subjects, Case 1) and KU Leuven University in Belgium (9 subjects, Case 2). Experiments were designed according to various experimental protocols to elicit stressful conditions. RESULTS: The proposed framework to recognize stress conditions, the Deep ECGNet, outperformed the conventional approaches with the highest accuracy of 87.39% for Case 1 and 73.96% for Case 2, respectively, that is, 16.22% and 10.98% improvements compared with those of the conventional HRV method. CONCLUSIONS: We proposed an optimal deep learning architecture and its parameters for stress recognition, and the theoretical consideration on how to design the deep learning structure based on the periodic patterns of the raw ECG data. Experimental results in this study have proved that the proposed deep learning model, the Deep ECGNet, is an optimal structure to recognize the stress conditions using ultra short-term ECG data.	['1 Department of Computer Science and Engineering, Seoul National University , Seoul, Korea.', '2 Department of Computer Engineering, Kwangwoon University , Nowon-gu, Seoul, Korea.', '3 KU Leuven, Department of Neurosciences, Center for Contextual Psychiatry , Leuven, Belgium .', '3 KU Leuven, Department of Neurosciences, Center for Contextual Psychiatry , Leuven, Belgium .', '2 Department of Computer Engineering, Kwangwoon University , Nowon-gu, Seoul, Korea.', '1 Department of Computer Science and Engineering, Seoul National University , Seoul, Korea.']	['10.1089/tmj.2017.0250 [doi]']	['Hwang B', 'You J', 'Vaessen T', 'Myin-Germeys I', 'Park C', 'Zhang BT']							['2018/02/09 06:00']	20190624	20180208	2018 Oct	2018/02/09 06:00		['Hwang, Bosun', 'You, Jiwoo', 'Vaessen, Thomas', 'Myin-Germeys, Inez', 'Park, Cheolsoo', 'Zhang, Byoung-Tak']			10		1556-3669 (Electronic) 1530-5627 (Linking)	100959949	Telemedicine journal and e-health : the official journal of the American Telemedicine Association	['eng']	10.1089/tmj.2017.0250 [doi]	20190624	['Adult', 'Belgium', '*Deep Learning', 'Electrocardiography/*methods', 'Heart Rate/physiology', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Male', 'Neural Networks (Computer)', 'Republic of Korea', 'Stress, Psychological/*physiopathology', 'Young Adult']	2019/06/25 06:00		['*CNNs', '*RNNs', '*deep learning', '*heart rate variability (HRV)', '*stress recognition', '*telehealth', '*telemedicine', '*ultra short-term HRV']	['NOTNLM']	NLM	753-772	['2018/02/09 06:00 [pubmed]', '2019/06/25 06:00 [medline]', '2018/02/09 06:00 [entrez]']	United States			29420125	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Telemed J E Health. 2018 Oct;24(10):753-772. doi: 10.1089/tmj.2017.0250. Epub 2018 Feb 8.	MEDLINE	Telemed J E Health	Deep ECGNet: An Optimal Deep Learning Framework for Monitoring Mental Stress Using Ultra Short-Term ECG Signals.		24	Deep ECGNet: An Optimal Deep Learning Framework for Monitoring Mental Stress Using Ultra Short-Term ECG Signals.
Intervertebral discs (IVDs) are small joints that lie between adjacent vertebrae. The localization and segmentation of IVDs are important for spine disease diagnosis and measurement quantification. However, manual annotation is time-consuming and error-prone with limited reproducibility, particularly for volumetric data. In this work, our goal is to develop an automatic and accurate method based on fully convolutional networks (FCN) for the localization and segmentation of IVDs from multi-modality 3D MR data. Compared with single modality data, multi-modality MR images provide complementary contextual information, which contributes to better recognition performance. However, how to effectively integrate such multi-modality information to generate accurate segmentation results remains to be further explored. In this paper, we present a novel multi-scale and modality dropout learning framework to locate and segment IVDs from four-modality MR images. First, we design a 3D multi-scale context fully convolutional network, which processes the input data in multiple scales of context and then merges the high-level features to enhance the representation capability of the network for handling the scale variation of anatomical structures. Second, to harness the complementary information from different modalities, we present a random modality voxel dropout strategy which alleviates the co-adaption issue and increases the discriminative capability of the network. Our method achieved the 1st place in the MICCAI challenge on automatic localization and segmentation of IVDs from multi-modality MR images, with a mean segmentation Dice coefficient of 91.2% and a mean localization error of 0.62mm. We further conduct extensive experiments on the extended dataset to validate our method. We demonstrate that the proposed modality dropout strategy with multi-modality images as contextual information improved the segmentation accuracy significantly. Furthermore, experiments conducted on extended data collected from two different time points demonstrate the efficacy of our method on tracking the morphological changes in a longitudinal study.	['Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China. Electronic address: hchen@cse.cuhk.edu.hk.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Institute of Physical Activity and Nutrition Research, Deakin University, Burwood, Victoria, Australia; Charite University Medical School, Berlin, Germany.', 'Charite University Medical School, Berlin, Germany.', 'Charite University Medical School, Berlin, Germany.', 'Institute for Surgical Technology and Biomechanics, University of Bern, Switzerland. Electronic address: guoyan.zheng@istb.unibe.ch.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.']	['S1361-8415(18)30013-6 [pii]', '10.1016/j.media.2018.01.004 [doi]']	['Li X', 'Dou Q', 'Chen H', 'Fu CW', 'Qi X', 'Belavy DL', 'Armbrecht G', 'Felsenberg D', 'Zheng G', 'Heng PA']		['Copyright (c) 2018 Elsevier B.V. All rights reserved.']					['2018/02/08 06:00']	20190506	20180202	2018 Apr	2018/02/08 06:00		['Li, Xiaomeng', 'Dou, Qi', 'Chen, Hao', 'Fu, Chi-Wing', 'Qi, Xiaojuan', 'Belavy, Daniel L', 'Armbrecht, Gabriele', 'Felsenberg, Dieter', 'Zheng, Guoyan', 'Heng, Pheng-Ann']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(18)30013-6 [pii] 10.1016/j.media.2018.01.004 [doi]	20190506	['Algorithms', 'Deep Learning', 'Humans', 'Image Enhancement/*methods', 'Image Interpretation, Computer-Assisted/*methods', '*Imaging, Three-Dimensional', 'Intervertebral Disc/*diagnostic imaging', '*Magnetic Resonance Imaging']	2019/05/07 06:00		['*Deep learning', '*Dropout', '*Intervertebral discs', '*Localization', '*Magnetic resonance imaging', '*Multi-modality', '*Segmentation']	['NOTNLM']	NLM	41-54	['2017/05/31 00:00 [received]', '2017/12/23 00:00 [revised]', '2018/01/16 00:00 [accepted]', '2018/02/08 06:00 [pubmed]', '2019/05/07 06:00 [medline]', '2018/02/08 06:00 [entrez]']	Netherlands			29414435	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Med Image Anal. 2018 Apr;45:41-54. doi: 10.1016/j.media.2018.01.004. Epub 2018 Feb 2.	MEDLINE	Med Image Anal	3D multi-scale FCN with random modality voxel dropout learning for Intervertebral Disc Localization and Segmentation from Multi-modality MR Images.		45	3D multi-scale FCN with random modality voxel dropout learning for Intervertebral Disc Localization and Segmentation from Multi-modality MR Images.
Mitosis detection is one of the critical factors of cancer prognosis, carrying significant diagnostic information required for breast cancer grading. It provides vital clues to estimate the aggressiveness and the proliferation rate of the tumour. The manual mitosis quantification from whole slide images is a very labor-intensive and challenging task. The aim of this study is to propose a supervised model to detect mitosis signature from breast histopathology WSI images. The model has been designed using deep learning architecture with handcrafted features. We used handcrafted features issued from previous medical challenges MITOS @ ICPR 2012, AMIDA-13 and projects (MICO ANR TecSan) expertise. The deep learning architecture mainly consists of five convolution layers, four max-pooling layers, four rectified linear units (ReLU), and two fully connected layers. ReLU has been used after each convolution layer as an activation function. Dropout layer has been included after first fully connected layer to avoid overfitting. Handcrafted features mainly consist of morphological, textural and intensity features. The proposed architecture has shown to have an improved 92% precision, 88% recall and 90% F-score. Prospectively, the proposed model will be very beneficial in routine exam, providing pathologists with efficient and - as we will prove - effective second opinion for breast cancer grading from whole slide images. Last but not the least, this model could lead junior and senior pathologists, as medical researchers, to a superior understanding and evaluation of breast cancer stage and genesis.	['School of Medical Science and Technology, Indian Institute of Technology, Kharagpur, West Bengal, India.', 'School of Medical Science and Technology, Indian Institute of Technology, Kharagpur, West Bengal, India.', 'Sorbonne University, Paris, France; Pontifical Catholic University of Peru, Lima, Peru. Electronic address: daniraco@gmail.com.']	['S0895-6111(17)30122-2 [pii]', '10.1016/j.compmedimag.2017.12.001 [doi]']	['Saha M', 'Chakraborty C', 'Racoceanu D']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2018/02/08 06:00']	20190429	20171216	2018 Mar	2018/02/08 06:00		['Saha, Monjoy', 'Chakraborty, Chandan', 'Racoceanu, Daniel']					1879-0771 (Electronic) 0895-6111 (Linking)	8806104	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	['eng']	S0895-6111(17)30122-2 [pii] 10.1016/j.compmedimag.2017.12.001 [doi]	20190429	['Algorithms', 'Breast Neoplasms/*diagnostic imaging/*pathology', 'Coloring Agents', 'Eosine Yellowish-(YS)', 'Female', 'Fluorescent Dyes', 'Hematoxylin', 'Humans', 'Image Processing, Computer-Assisted', '*Mitosis', '*Supervised Machine Learning']	2019/04/30 06:00		['*Breast cancer', '*Convolution', '*Deep neural network', '*Handcrafted features', '*Hematoxylin and eosin', '*Mitosis']	['NOTNLM']	NLM	29-40	['2017/03/03 00:00 [received]', '2017/06/28 00:00 [revised]', '2017/12/07 00:00 [accepted]', '2018/02/08 06:00 [pubmed]', '2019/04/30 06:00 [medline]', '2018/02/08 06:00 [entrez]']	United States			29409716	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Coloring Agents)', '0 (Fluorescent Dyes)', 'TDQ283MPCW (Eosine Yellowish-(YS))', 'YKM8PY2Z55 (Hematoxylin)']	IM		Comput Med Imaging Graph. 2018 Mar;64:29-40. doi: 10.1016/j.compmedimag.2017.12.001. Epub 2017 Dec 16.	MEDLINE	Comput Med Imaging Graph	Efficient deep learning model for mitosis detection using breast histopathology images.		64	Efficient deep learning model for mitosis detection using breast histopathology images.
The integration of the latest breakthroughs in bioinformatics technology from one side and artificial intelligence from another side, enables remarkable advances in the fields of intelligent security guard computational biology, healthcare, and so on. Among them, biometrics based automatic human identification is one of the most fundamental and significant research topic. Human gait, which is a biometric features with the unique capability, has gained significant attentions as the remarkable characteristics of remote accessed, robust and security in the biometrics based human identification. However, the existed methods cannot well handle the indistinctive inter-class differences and large intra-class variations of human gait in real-world situation. In this paper, we have developed an efficient spatial-temporal gait features with deep learning for human identification. First of all, we proposed a gait energy image (GEI) based Siamese neural network to automatically extract robust and discriminative spatial gait features for human identification. Furthermore, we exploit the deep 3-dimensional convolutional networks to learn the human gait convolutional 3D (C3D) as the temporal gait features. Finally, the GEI and C3D gait features are embedded into the null space by the Null Foley-Sammon Transform (NFST). In the new space, the spatial-temporal features are sufficiently combined with distance metric learning to drive the similarity metric to be small for pairs of gait from the same person, and large for pairs from different persons. Consequently, the experiments on the world's largest gait database show our framework impressively outperforms state-of-the-art methods.	['Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, 100876, China. liuwu@bupt.edu.cn.', 'Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, 43210, USA.', 'Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, 100876, China.', 'Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, 100876, China.']	['10.1007/s12021-018-9362-4 [doi]', '10.1007/s12021-018-9362-4 [pii]']	['Liu W', 'Zhang C', 'Ma H', 'Li S']	['ORCID: 0000-0003-1633-7575']						['2018/02/07 06:00']	20190311		2018 Oct	2018/02/07 06:00		['Liu, Wu', 'Zhang, Cheng', 'Ma, Huadong', 'Li, Shuangqun']		['U1501254/NSFC-Guangdong Joint Fund/International', '61602049/National Natural Science Foundation of China/International', '61720106007/the Funds for International Cooperation and Exchange of the National', 'Natural Science Foundation of China/International']	3-4		1559-0089 (Electronic) 1539-2791 (Linking)	101142069	Neuroinformatics	['eng']	10.1007/s12021-018-9362-4 [doi]	20190311	['*Deep Learning', '*Gait/physiology', 'Humans', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', '*Spatial Behavior/physiology', 'Time Factors']	2019/03/12 06:00		['*Gait recognition', '*Human identification', '*Metric learning', '*Siamese neural network', '*Spatio-temporal features']	['NOTNLM']	NLM	457-471	['2018/02/07 06:00 [pubmed]', '2019/03/12 06:00 [medline]', '2018/02/07 06:00 [entrez]']	United States			29404933	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroinformatics. 2018 Oct;16(3-4):457-471. doi: 10.1007/s12021-018-9362-4.	MEDLINE	Neuroinformatics	Learning Efficient Spatial-Temporal Gait Features with Deep Learning for Human Identification.		16	Learning Efficient Spatial-Temporal Gait Features with Deep Learning for Human Identification.
	['Department of Bio and Brain Engineering, Korea Advanced Institute of Science & Technology (KAIST), Daejeon, Republic of Korea.', 'Department of Bio and Brain Engineering, Korea Advanced Institute of Science & Technology (KAIST), Daejeon, Republic of Korea.', 'Department of Radiology, Research Institute of Radiology, Asan Medical Center, College of Medicine, University of Ulsan, Seoul, Republic of Korea.', 'Department of Radiology, Research Institute of Radiology, Asan Medical Center, College of Medicine, University of Ulsan, Seoul, Republic of Korea.', 'Department of Radiological Sciences, University of California Los Angeles, Los Angeles, California.', 'Department of Bio and Brain Engineering, Korea Advanced Institute of Science & Technology (KAIST), Daejeon, Republic of Korea.']	['10.1002/mrm.27106 [doi]']	['Han Y', 'Yoo J', 'Kim HH', 'Shin HJ', 'Sung K', 'Ye JC']							['2018/02/06 06:00']	20190930	20180204	2018 Sep	2018/02/06 06:00		['Han, Yoseob', 'Yoo, Jaejun', 'Kim, Hak Hee', 'Shin, Hee Jung', 'Sung, Kyunghyun', 'Ye, Jong Chul']		['U01 MH093765/MH/NIMH NIH HHS/United States', 'P41 EB015896/EB/NIBIB NIH HHS/United States', 'R00 EB012107/EB/NIBIB NIH HHS/United States', 'K99 EB012107/EB/NIBIB NIH HHS/United States']	3		1522-2594 (Electronic) 0740-3194 (Linking)	8505245	Magnetic resonance in medicine	['eng']	10.1002/mrm.27106 [doi]	20190930	['Algorithms', '*Deep Learning', 'Fourier Analysis', 'Healthy Volunteers', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Liver/diagnostic imaging', '*Magnetic Resonance Imaging', 'Neural Networks (Computer)', 'Reproducibility of Results', 'Software', 'Tomography, X-Ray Computed']	2019/10/01 06:00		['*compressed sensing', '*convolutional neural network', '*deep learning', '*domain adaptation', '*projection reconstruction MRI']	['NOTNLM']	NLM	1189-1205	['2017/05/25 00:00 [received]', '2017/12/20 00:00 [revised]', '2018/01/04 00:00 [accepted]', '2018/02/06 06:00 [pubmed]', '2019/10/01 06:00 [medline]', '2018/02/06 06:00 [entrez]']	United States			29399869	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Magn Reson Med. 2018 Sep;80(3):1189-1205. doi: 10.1002/mrm.27106. Epub 2018 Feb 4.	MEDLINE	Magn Reson Med	Deep learning with domain adaptation for accelerated projection-reconstruction MR.		80	Deep learning with domain adaptation for accelerated projection-reconstruction MR.
	['The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University School of Medicine, Baltimore, Maryland. Electronic address: Pyi10@jhmi.edu.', 'The Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University School of Medicine, Baltimore, Maryland.', 'Department of Ophthalmology, Wilmer Eye Institute, Johns Hopkins University School of Medicine, Baltimore, Maryland; Singapore National Eye Center, SingHealth, Duke-NUS Medical School, National University of Singapore, Singapore.']	['S1546-1440(18)30001-2 [pii]', '10.1016/j.jacr.2017.12.037 [doi]']	['Yi PH', 'Hui FK', 'Ting DSW']							['2018/02/06 06:00']	20190123	20180202	2018 May	2018/02/06 06:00		['Yi, Paul H', 'Hui, Ferdinand K', 'Ting, Daniel S W']			5		1558-349X (Electronic) 1546-1440 (Linking)	101190326	Journal of the American College of Radiology : JACR	['eng']	S1546-1440(18)30001-2 [pii] 10.1016/j.jacr.2017.12.037 [doi]	20190123	['Algorithms', 'Artificial Intelligence/*trends', 'Decision Support Techniques', 'Deep Learning/trends', 'Forecasting', 'Humans', 'Optimism', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Radiology Information Systems']	2019/01/24 06:00				NLM	781-783	['2017/12/10 00:00 [received]', '2017/12/25 00:00 [revised]', '2017/12/29 00:00 [accepted]', '2018/02/06 06:00 [pubmed]', '2019/01/24 06:00 [medline]', '2018/02/06 06:00 [entrez]']	United States			29398492	ppublish	['Journal Article']			IM		J Am Coll Radiol. 2018 May;15(5):781-783. doi: 10.1016/j.jacr.2017.12.037. Epub 2018 Feb 2.	MEDLINE	J Am Coll Radiol	Artificial Intelligence and Radiology: Collaboration Is Key.		15	Artificial Intelligence and Radiology: Collaboration Is Key.
In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility traces, instead of experience replay, and softmax action selection can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10 x 10 board, using TD(lambda) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(lambda) agent with SiLU and dSiLU hidden units.	['Department of Brain Robot Interface, ATR Computational Neuroscience Laboratories, 2-2-2 Hikaridai, Seikacho, Soraku-gun, Kyoto 619-0288, Japan. Electronic address: elfwing@atr.jp.', 'Department of Brain Robot Interface, ATR Computational Neuroscience Laboratories, 2-2-2 Hikaridai, Seikacho, Soraku-gun, Kyoto 619-0288, Japan; Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa 904-0495, Japan. Electronic address: uchibe@atr.jp.', 'Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa 904-0495, Japan. Electronic address: doya@oist.jp.']	['S0893-6080(17)30297-6 [pii]', '10.1016/j.neunet.2017.12.012 [doi]']	['Elfwing S', 'Uchibe E', 'Doya K']		['Copyright (c) 2017 The Author(s). Published by Elsevier Ltd.. All rights', 'reserved.']					['2018/02/04 06:00']	20181211	20180111	2018 Nov	2018/02/06 06:00		['Elfwing, Stefan', 'Uchibe, Eiji', 'Doya, Kenji']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30297-6 [pii] 10.1016/j.neunet.2017.12.012 [doi]	20181211	['*Deep Learning', '*Neural Networks (Computer)']	2018/12/12 06:00		['Atari 2600', 'Deep learning', 'Function approximation', 'Reinforcement learning', 'Sigmoid-weighted linear unit', 'Tetris']	['NOTNLM']	NLM	3-11	['2017/06/30 00:00 [received]', '2017/12/11 00:00 [revised]', '2017/12/25 00:00 [accepted]', '2018/02/06 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2018/02/04 06:00 [entrez]']	United States			29395652	ppublish	['Journal Article']			IM		Neural Netw. 2018 Nov;107:3-11. doi: 10.1016/j.neunet.2017.12.012. Epub 2018 Jan 11.	MEDLINE	Neural Netw	Sigmoid-weighted linear units for neural network function approximation in reinforcement learning.		107	Sigmoid-weighted linear units for neural network function approximation in reinforcement learning.
Imaging flow cytometry (IFC) captures multichannel images of hundreds of thousands of single cells within minutes. IFC is seeing a paradigm shift from low- to high-information-content analysis, driven partly by deep learning algorithms. We predict a wealth of applications with potential translation into clinical practice.	"['Imaging Platform at the Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, MA 02142, USA.', 'School of Science and Technology, Nazarbayev University, Kababnbay batyr avenue 53, 010000, Astana, Kazakhstan; A.N. Belozersky Institute of Physico-Chemical Biology/Biological Faculty, M.V. Lomonosov Moscow State University, 119991, Moscow, Russian Federation.', 'Imaging Platform at the Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, MA 02142, USA; College of Engineering, Swansea University, Singleton Park, Swansea SA2 8PP, UK.', 'Flow Cytometry Core Facility, Faculty of Medical Sciences, Newcastle University, Newcastle upon Tyne NE1 7RU, UK.', 'Department of Systems Biology and Bioinformatics, University of Rostock, 18051 Rostock, Germany; Stellenbosch Institute for Advanced Study (STIAS), Stellenbosch, 7600, South Africa.', ""Program in Cellular and Molecular Medicine, Boston Children's Hospital and Department of Pediatrics, Harvard Medical School, Boston, MA 02115, USA."", ""Program in Cellular and Molecular Medicine, Boston Children's Hospital and Department of Pediatrics, Harvard Medical School, Boston, MA 02115, USA."", ""Program in Cellular and Molecular Medicine, Boston Children's Hospital and Department of Pediatrics, Harvard Medical School, Boston, MA 02115, USA."", 'Imaging Platform at the Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, MA 02142, USA.', 'Imaging Platform at the Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, MA 02142, USA; Department of Systems Biology and Bioinformatics, University of Rostock, 18051 Rostock, Germany. Electronic address: holgerh@broadinstitute.org.']"	['S0167-7799(18)30003-9 [pii]', '10.1016/j.tibtech.2017.12.008 [doi]']	['Doan M', 'Vorobjev I', 'Rees P', 'Filby A', 'Wolkenhauer O', 'Goldfeld AE', 'Lieberman J', 'Barteneva N', 'Carpenter AE', 'Hennig H']		['Copyright (c) 2018 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2018/02/04 06:00']	20190705	20180131	2018 Jul	2018/02/06 06:00		['Doan, Minh', 'Vorobjev, Ivan', 'Rees, Paul', 'Filby, Andrew', 'Wolkenhauer, Olaf', 'Goldfeld, Anne E', 'Lieberman, Judy', 'Barteneva, Natasha', 'Carpenter, Anne E', 'Hennig, Holger']		['BB/N005163/Biotechnology and Biological Sciences Research Council/United Kingdom']	7		1879-3096 (Electronic) 0167-7799 (Linking)	8310903	Trends in biotechnology	['eng']	S0167-7799(18)30003-9 [pii] 10.1016/j.tibtech.2017.12.008 [doi]	20190705	['Data Analysis', 'Deep Learning', 'Flow Cytometry/instrumentation/*methods', 'Humans', 'Image Processing, Computer-Assisted', 'Leukemia, Myeloid/blood/diagnostic imaging', 'Microscopy, Fluorescence/instrumentation/*methods', 'Neoplastic Cells, Circulating/classification', 'Precision Medicine/instrumentation/*methods', 'Prognosis', 'Single Molecule Imaging/instrumentation/*methods', 'Single-Cell Analysis/instrumentation/*methods']	2019/07/06 06:00		['*deep learning', '*disease diagnostics', '*high-content analysis', '*imaging flow cytometry', '*translational medicine']	['NOTNLM']	NLM	649-652	['2017/10/05 00:00 [received]', '2017/12/21 00:00 [revised]', '2017/12/28 00:00 [accepted]', '2018/02/06 06:00 [pubmed]', '2019/07/06 06:00 [medline]', '2018/02/04 06:00 [entrez]']	England			29395345	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Trends Biotechnol. 2018 Jul;36(7):649-652. doi: 10.1016/j.tibtech.2017.12.008. Epub 2018 Jan 31.	MEDLINE	Trends Biotechnol	Diagnostic Potential of Imaging Flow Cytometry.		36	Diagnostic Potential of Imaging Flow Cytometry.
"BACKGROUND: Growing concerns about increasing rates of antibiotic resistance call for expanded and comprehensive global monitoring. Advancing methods for monitoring of environmental media (e.g., wastewater, agricultural waste, food, and water) is especially needed for identifying potential resources of novel antibiotic resistance genes (ARGs), hot spots for gene exchange, and as pathways for the spread of ARGs and human exposure. Next-generation sequencing now enables direct access and profiling of the total metagenomic DNA pool, where ARGs are typically identified or predicted based on the ""best hits"" of sequence searches against existing databases. Unfortunately, this approach produces a high rate of false negatives. To address such limitations, we propose here a deep learning approach, taking into account a dissimilarity matrix created using all known categories of ARGs. Two deep learning models, DeepARG-SS and DeepARG-LS, were constructed for short read sequences and full gene length sequences, respectively. RESULTS: Evaluation of the deep learning models over 30 antibiotic resistance categories demonstrates that the DeepARG models can predict ARGs with both high precision (> 0.97) and recall (> 0.90). The models displayed an advantage over the typical best hit approach, yielding consistently lower false negative rates and thus higher overall recall (> 0.9). As more data become available for under-represented ARG categories, the DeepARG models' performance can be expected to be further enhanced due to the nature of the underlying neural networks. Our newly developed ARG database, DeepARG-DB, encompasses ARGs predicted with a high degree of confidence and extensive manual inspection, greatly expanding current ARG repositories. CONCLUSIONS: The deep learning models developed here offer more accurate antimicrobial resistance annotation relative to current bioinformatics practice. DeepARG does not require strict cutoffs, which enables identification of a much broader diversity of ARGs. The DeepARG models and database are available as a command line version and as a Web service at http://bench.cs.vt.edu/deeparg ."	['Department of Computer Science, Virginia Tech, Blacksburg, VA, USA.', 'Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, USA.', 'Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, USA.', 'Department of Computer Science, Virginia Tech, Blacksburg, VA, USA.', 'Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, USA.', 'Department of Computer Science, Virginia Tech, Blacksburg, VA, USA. lqzhang@cs.vt.edu.']	['10.1186/s40168-018-0401-z [doi]', '10.1186/s40168-018-0401-z [pii]']	['Arango-Argoty G', 'Garner E', 'Pruden A', 'Heath LS', 'Vikesland P', 'Zhang L']							['2018/02/03 06:00']	20181026	20180201	2018 Feb 1	2018/02/03 06:00		['Arango-Argoty, Gustavo', 'Garner, Emily', 'Pruden, Amy', 'Heath, Lenwood S', 'Vikesland, Peter', 'Zhang, Liqing']		['2015-68003-23050/U.S. Department of Agriculture/International', '1545756/National Science Foundation/International']	1		2049-2618 (Electronic) 2049-2618 (Linking)	101615147	Microbiome	['eng']	10.1186/s40168-018-0401-z [doi]	20181113	['Computational Biology/*methods', '*Drug Resistance, Microbial', 'Gene Regulatory Networks', 'High-Throughput Nucleotide Sequencing', 'Humans', 'Machine Learning', '*Metagenome', 'Software']	2018/10/27 06:00		['*Antibiotic resistance', '*Deep learning', '*Machine learning', '*Metagenomics']	['NOTNLM']	NLM	23	['2017/06/29 00:00 [received]', '2018/01/10 00:00 [accepted]', '2018/02/03 06:00 [entrez]', '2018/02/03 06:00 [pubmed]', '2018/10/27 06:00 [medline]']	England	PMC5796597		29391044	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Microbiome. 2018 Feb 1;6(1):23. doi: 10.1186/s40168-018-0401-z.	MEDLINE	Microbiome	DeepARG: a deep learning approach for predicting antibiotic resistance genes from metagenomic data.		6	DeepARG: a deep learning approach for predicting antibiotic resistance genes from metagenomic data.
OBJECTIVE: The aim of this review was to summarize major topics in artificial intelligence (AI), including their applications and limitations in surgery. This paper reviews the key capabilities of AI to help surgeons understand and critically evaluate new AI applications and to contribute to new developments. SUMMARY BACKGROUND DATA: AI is composed of various subfields that each provide potential solutions to clinical problems. Each of the core subfields of AI reviewed in this piece has also been used in other industries such as the autonomous car, social networks, and deep learning computers. METHODS: A review of AI papers across computer science, statistics, and medical sources was conducted to identify key concepts and techniques within AI that are driving innovation across industries, including surgery. Limitations and challenges of working with AI were also reviewed. RESULTS: Four main subfields of AI were defined: (1) machine learning, (2) artificial neural networks, (3) natural language processing, and (4) computer vision. Their current and future applications to surgical practice were introduced, including big data analytics and clinical decision support systems. The implications of AI for surgeons and the role of surgeons in advancing the technology to optimize clinical effectiveness were discussed. CONCLUSIONS: Surgeons are well positioned to help integrate AI into modern practice. Surgeons should partner with data scientists to capture data across phases of care and to provide clinical context, for AI has the potential to revolutionize the way surgery is taught and practiced with the promise of a future optimized for the highest quality patient care.	['Department of Surgery, Massachusetts General Hospital, Boston, MA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Boston, MA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Boston, MA.', 'Department of Surgery, Massachusetts General Hospital, Boston, MA.']	['10.1097/SLA.0000000000002693 [doi]']	['Hashimoto DA', 'Rosman G', 'Rus D', 'Meireles OR']							['2018/02/02 06:00']	20190903		2018 Jul	2018/02/02 06:00		['Hashimoto, Daniel A', 'Rosman, Guy', 'Rus, Daniela', 'Meireles, Ozanan R']		['T32 DK007754/DK/NIDDK NIH HHS/United States']	1		1528-1140 (Electronic) 0003-4932 (Linking)	0372354	Annals of surgery	['eng']	10.1097/SLA.0000000000002693 [doi]	20190903	"['*Artificial Intelligence', 'Humans', ""Physician's Role"", 'Surgeons', 'Surgical Procedures, Operative/*methods']"	2019/09/04 06:00	['NIHMS951789']			NLM	70-76	['2018/02/02 06:00 [pubmed]', '2019/09/04 06:00 [medline]', '2018/02/02 06:00 [entrez]']	United States	PMC5995666		29389679	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", 'Review']"			AIM IM		Ann Surg. 2018 Jul;268(1):70-76. doi: 10.1097/SLA.0000000000002693.	MEDLINE	Ann Surg	Artificial Intelligence in Surgery: Promises and Perils.		268	Artificial Intelligence in Surgery: Promises and Perils.
Predicting how a point mutation alters a protein's stability can guide pharmaceutical drug design initiatives which aim to counter the effects of serious diseases. Conducting mutagenesis studies in physical proteins can give insights about the effects of amino acid substitutions, but such wet-lab work is prohibitive due to the time as well as financial resources needed to assess the effect of even a single amino acid substitution. Computational methods for predicting the effects of a mutation on a protein structure can complement wet-lab work, and varying approaches are available with promising accuracy rates. In this work we compare and assess the utility of several machine learning methods and their ability to predict the effects of single and double mutations. We in silico generate mutant protein structures, and compute several rigidity metrics for each of them. We use these as features for our Support Vector Regression (SVR), Random Forest (RF), and Deep Neural Network (DNN) methods. We validate the predictions of our in silico mutations against experimental Delta Delta G stability data, and attain Pearson Correlation values upwards of 0.71 for single mutations, and 0.81 for double mutations. We perform ablation studies to assess which features contribute most to a model's success, and also introduce a voting scheme to synthesize a single prediction from the individual predictions of the three models.	['Department of Computer Science, University of Massachusetts Boston, Boston, MA 02125, USA. ramin.dehghanpoor001@umb.edu.', 'Department of Computer Science, Western Washington University, Bellingham, WA 98225, USA. rickse2@wwu.edu.', 'Department of Computer Science, Western Washington University, Bellingham, WA 98225, USA. hurshk@wwu.edu.', 'Department of Computer Science, Western Washington University, Bellingham, WA 98225, USA. gunders7@wwu.edu.', 'Department of Computer Science, University of Massachusetts Boston, Boston, MA 02125, USA. rfarhoodi@gmail.com.', 'Department of Computer Science, University of Massachusetts Boston, Boston, MA 02125, USA. nurit.haspel@umb.edu.', 'Department of Computer Science, Western Washington University, Bellingham, WA 98225, USA. Brian.Hutchinson@wwu.edu.', 'Computing and Analytics Division, Pacific Northwest National Laboratory; Richland, WA 99354, USA. Brian.Hutchinson@wwu.edu.', 'Department of Computer Science, Western Washington University, Bellingham, WA 98225, USA. filip.jagodzinski@wwu.edu.']	['molecules23020251 [pii]', '10.3390/molecules23020251 [doi]']	['Dehghanpoor R', 'Ricks E', 'Hursh K', 'Gunderson S', 'Farhoodi R', 'Haspel N', 'Hutchinson B', 'Jagodzinski F']					['The authors declare no conflict of interest.']		['2018/02/01 06:00']	20180810	20180127	2018 Jan 27	2018/02/01 06:00		['Dehghanpoor, Ramin', 'Ricks, Evan', 'Hursh, Katie', 'Gunderson, Sarah', 'Farhoodi, Roshanak', 'Haspel, Nurit', 'Hutchinson, Brian', 'Jagodzinski, Filip']			2		1420-3049 (Electronic) 1420-3049 (Linking)	100964009	Molecules (Basel, Switzerland)	['eng']	E251 [pii] 10.3390/molecules23020251 [doi]	20181207	['Amino Acid Substitution', 'Computer Simulation', '*Decision Trees', '*Mutation', '*Neural Networks (Computer)', 'Protein Conformation', 'Protein Stability', 'Proteins/*chemistry', '*Support Vector Machine', 'Thermodynamics']	2018/08/11 06:00		['DNN', 'RF', 'SVR', 'machine learning', 'protein mutational study', 'rigidity analysis']	['NOTNLM']	NLM		['2017/12/24 00:00 [received]', '2018/01/15 00:00 [revised]', '2018/01/19 00:00 [accepted]', '2018/02/01 06:00 [entrez]', '2018/02/01 06:00 [pubmed]', '2018/08/11 06:00 [medline]']	Switzerland	PMC6017198		29382060	epublish	['Journal Article']		['0 (Proteins)']	IM		Molecules. 2018 Jan 27;23(2). pii: molecules23020251. doi: 10.3390/molecules23020251.	MEDLINE	Molecules	Predicting the Effect of Single and Multiple Mutations on Protein Structural Stability.		23	Predicting the Effect of Single and Multiple Mutations on Protein Structural Stability.
Purpose: To develop an automated method of localizing and discerning multiple types of findings in retinal images using a limited set of training data without hard-coded feature extraction as a step toward generalizing these methods to rare disease detection in which a limited number of training data are available. Methods: Two ophthalmologists verified 243 retinal images, labeling important subsections of the image to generate 1324 image patches containing either hemorrhages, microaneurysms, exudates, retinal neovascularization, or normal-appearing structures from the Kaggle dataset. These image patches were used to train one standard convolutional neural network to predict the presence of these five classes. A sliding window method was used to generate probability maps across the entire image. Results: The method was validated on the eOphta dataset of 148 whole retinal images for microaneurysms and 47 for exudates. A pixel-wise classification of the area under the curve of the receiver operating characteristic of 0.94 and 0.95, as well as a lesion-wise area under the precision recall curve of 0.86 and 0.64, was achieved for microaneurysms and exudates, respectively. Conclusions: Regionally trained convolutional neural networks can generate lesion-specific probability maps able to detect and distinguish between subtle pathologic lesions with only a few hundred training examples per lesion.	['Department of Biomedical Data Science, Stanford University, Stanford, California, United States.', 'Department of Ophthalmology, Santa Clara Valley Medical Center, San Jose, California, United States.', 'Stanford University School of Medicine, Stanford, California, United States.', 'Department of Ophthalmology, Stanford University School of Medicine, Stanford, California, United States.', 'Department of Biomedical Data Science, Stanford University, Stanford, California, United States.', 'Department of Ophthalmology, Stanford University School of Medicine, Stanford, California, United States.', 'Department of Radiology, Stanford University School of Medicine, Stanford, California, United States.']	['2670996 [pii]', '10.1167/iovs.17-22721 [doi]']	['Lam C', 'Yu C', 'Huang L', 'Rubin D']							['2018/01/27 06:00']	20180727		2018 Jan 1	2018/01/27 06:00		['Lam, Carson', 'Yu, Caroline', 'Huang, Laura', 'Rubin, Daniel']		['T15 LM007033/LM/NLM NIH HHS/United States', 'U01 CA142555/CA/NCI NIH HHS/United States', 'U01 CA187947/CA/NCI NIH HHS/United States', 'U01 CA190214/CA/NCI NIH HHS/United States']	1		1552-5783 (Electronic) 0146-0404 (Linking)	7703701	Investigative ophthalmology & visual science	['eng']	10.1167/iovs.17-22721 [doi]	20181113	['Algorithms', 'Exudates and Transudates', 'Humans', '*Image Interpretation, Computer-Assisted', 'Machine Learning', '*Neural Networks (Computer)', 'Probability', 'ROC Curve', 'Reproducibility of Results', 'Retinal Diseases/*diagnostic imaging']	2018/07/28 06:00				NLM	590-596	['2018/01/27 06:00 [entrez]', '2018/01/27 06:00 [pubmed]', '2018/07/28 06:00 [medline]']	United States	PMC5788045		29372258	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Invest Ophthalmol Vis Sci. 2018 Jan 1;59(1):590-596. doi: 10.1167/iovs.17-22721.	MEDLINE	Invest Ophthalmol Vis Sci	Retinal Lesion Detection With Deep Learning Using Image Patches.		59	Retinal Lesion Detection With Deep Learning Using Image Patches.
BACKGROUND: Molecular biomarkers that can predict drug efficacy in cancer patients are crucial components for the advancement of precision medicine. However, identifying these molecular biomarkers remains a laborious and challenging task. Next-generation sequencing of patients and preclinical models have increasingly led to the identification of novel gene-mutation-drug relations, and these results have been reported and published in the scientific literature. RESULTS: Here, we present two new computational methods that utilize all the PubMed articles as domain specific background knowledge to assist in the extraction and curation of gene-mutation-drug relations from the literature. The first method uses the Biomedical Entity Search Tool (BEST) scoring results as some of the features to train the machine learning classifiers. The second method uses not only the BEST scoring results, but also word vectors in a deep convolutional neural network model that are constructed from and trained on numerous documents such as PubMed abstracts and Google News articles. Using the features obtained from both the BEST search engine scores and word vectors, we extract mutation-gene and mutation-drug relations from the literature using machine learning classifiers such as random forest and deep convolutional neural networks. Our methods achieved better results compared with the state-of-the-art methods. We used our proposed features in a simple machine learning model, and obtained F1-scores of 0.96 and 0.82 for mutation-gene and mutation-drug relation classification, respectively. We also developed a deep learning classification model using convolutional neural networks, BEST scores, and the word embeddings that are pre-trained on PubMed or Google News data. Using deep learning, the classification accuracy improved, and F1-scores of 0.96 and 0.86 were obtained for the mutation-gene and mutation-drug relations, respectively. CONCLUSION: We believe that our computational methods described in this research could be used as an important tool in identifying molecular biomarkers that predict drug responses in cancer patients. We also built a database of these mutation-gene-drug relations that were extracted from all the PubMed abstracts. We believe that our database can prove to be a valuable resource for precision medicine researchers.	['Department of Computer Science and Engineering, Korea University, Seoul, South Korea.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, South Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, South Korea.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, South Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, South Korea.', 'Department of Computer Science and Engineering, Korea University, Seoul, South Korea.', 'Translational Bioinformatics and Cancer Systems Biology Laboratory, Division of Medical Oncology, Department of Medicine, University of Colorado Anschutz Medical Campus, Aurora, CO, 80045, USA. aikchoon.tan@ucdenver.edu.', 'Department of Computer Science and Engineering, Korea University, Seoul, South Korea. kangj@korea.ac.kr.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea. kangj@korea.ac.kr.']	['10.1186/s12859-018-2029-1 [doi]', '10.1186/s12859-018-2029-1 [pii]']	['Lee K', 'Kim B', 'Choi Y', 'Kim S', 'Shin W', 'Lee S', 'Park S', 'Kim S', 'Tan AC', 'Kang J']							['2018/01/26 06:00']	20181107	20180125	2018 Jan 25	2018/01/26 06:00		['Lee, Kyubum', 'Kim, Byounggun', 'Choi, Yonghwa', 'Kim, Sunkyu', 'Shin, Wonho', 'Lee, Sunwon', 'Park, Sungjoon', 'Kim, Seongsoon', 'Tan, Aik Choon', 'Kang, Jaewoo']		['P30 CA046934/CA/NCI NIH HHS/United States', 'NRF-2016M3A9A7916996/National Research Foundation of Korea/International', 'NRF-2014R1A2A1A10051238/National Research Foundation of Korea/International']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-018-2029-1 [doi]	20181113	['Antineoplastic Agents/therapeutic use', 'Databases, Factual', 'Drug Resistance, Neoplasm/*genetics', 'Humans', 'Mutation', 'Neoplasms/drug therapy/genetics/pathology', 'Neural Networks (Computer)', 'Precision Medicine', '*Search Engine']	2018/11/08 06:00		['*BioNLP', '*Convolutional neural networks', '*Deep learning', '*Information extraction', '*Mutation', '*NLP', '*Precision medicine', '*Text mining']	['NOTNLM']	NLM	21	['2017/04/25 00:00 [received]', '2018/01/17 00:00 [accepted]', '2018/01/26 06:00 [entrez]', '2018/01/26 06:00 [pubmed]', '2018/11/08 06:00 [medline]']	England	PMC5784504		29368597	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Antineoplastic Agents)']	IM		BMC Bioinformatics. 2018 Jan 25;19(1):21. doi: 10.1186/s12859-018-2029-1.	MEDLINE	BMC Bioinformatics	Deep learning of mutation-gene-drug relations from the literature.		19	Deep learning of mutation-gene-drug relations from the literature.
Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.	['Hit Discovery, Discovery Sciences, Innovative Medicines and Early Development Biotech Unit, AstraZeneca R&D Gothenburg, Molndal 43183, Sweden. Electronic address: hongming.chen@astrazeneca.com.', 'Hit Discovery, Discovery Sciences, Innovative Medicines and Early Development Biotech Unit, AstraZeneca R&D Gothenburg, Molndal 43183, Sweden.', 'Quantitative Biology, Discovery Sciences, Innovative Medicines and Early Development Biotech Unit, AstraZeneca, Unit 310, Cambridge Science Park, Milton Road, Cambridge CB4 0WG, UK.', 'Hit Discovery, Discovery Sciences, Innovative Medicines and Early Development Biotech Unit, AstraZeneca R&D Gothenburg, Molndal 43183, Sweden.', 'Hit Discovery, Discovery Sciences, Innovative Medicines and Early Development Biotech Unit, AstraZeneca R&D Gothenburg, Molndal 43183, Sweden.']	['S1359-6446(17)30359-8 [pii]', '10.1016/j.drudis.2018.01.039 [doi]']	['Chen H', 'Engkvist O', 'Wang Y', 'Olivecrona M', 'Blaschke T']		['Copyright (c) 2018 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2018/01/26 06:00']	20181112	20180131	2018 Jun	2018/01/26 06:00		['Chen, Hongming', 'Engkvist, Ola', 'Wang, Yinhai', 'Olivecrona, Marcus', 'Blaschke, Thomas']			6		1878-5832 (Electronic) 1359-6446 (Linking)	9604391	Drug discovery today	['eng']	S1359-6446(17)30359-8 [pii] 10.1016/j.drudis.2018.01.039 [doi]	20181112	['Datasets as Topic', 'Diagnostic Imaging', '*Drug Discovery', '*Machine Learning', 'Neural Networks (Computer)']	2018/11/13 06:00				NLM	1241-1250	['2017/10/20 00:00 [received]', '2017/12/04 00:00 [revised]', '2018/01/16 00:00 [accepted]', '2018/01/26 06:00 [pubmed]', '2018/11/13 06:00 [medline]', '2018/01/26 06:00 [entrez]']	England			29366762	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Drug Discov Today. 2018 Jun;23(6):1241-1250. doi: 10.1016/j.drudis.2018.01.039. Epub 2018 Jan 31.	MEDLINE	Drug Discov Today	The rise of deep learning in drug discovery.		23	The rise of deep learning in drug discovery.
Pulmonary cancer is considered as one of the major causes of death worldwide. For the detection of lung cancer, computer-assisted diagnosis (CADx) systems have been designed. Internet-of-Things (IoT) has enabled ubiquitous internet access to biomedical datasets and techniques; in result, the progress in CADx is significant. Unlike the conventional CADx, deep learning techniques have the basic advantage of an automatic exploitation feature as they have the ability to learn mid and high level image representations. We proposed a Computer-Assisted Decision Support System in Pulmonary Cancer by using the novel deep learning based model and metastasis information obtained from MBAN (Medical Body Area Network). The proposed model, DFCNet, is based on the deep fully convolutional neural network (FCNN) which is used for classification of each detected pulmonary nodule into four lung cancer stages. The performance of proposed work is evaluated on different datasets with varying scan conditions. Comparison of proposed classifier is done with the existing CNN techniques. Overall accuracy of CNN and DFCNet was 77.6% and 84.58%, respectively. Experimental results illustrate the effectiveness of proposed method for the detection and classification of lung cancer nodules. These results demonstrate the potential for the proposed technique in helping the radiologists in improving nodule detection accuracy with efficiency.	"['Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China; Dept. of Computer Science, COMSATS Institute of Information Technology, Pakistan.', 'Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China. Electronic address: shengbin@sjtu.edu.cn.', 'Faculty of Information Technology, Macau University of Science and Technology, Macau.', ""Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China."", ""Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China."", 'School of Nursing, The Hong Kong Polytechnic University, Hong Kong.', 'School of Information Technologies, The University of Sydney, Australia.']"	['S1532-0464(18)30007-8 [pii]', '10.1016/j.jbi.2018.01.005 [doi]']	['Masood A', 'Sheng B', 'Li P', 'Hou X', 'Wei X', 'Qin J', 'Feng D']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2018/01/26 06:00']	20190514	20180131	2018 Mar	2018/01/26 06:00		['Masood, Anum', 'Sheng, Bin', 'Li, Ping', 'Hou, Xuhong', 'Wei, Xiaoer', 'Qin, Jing', 'Feng, Dagan']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(18)30007-8 [pii] 10.1016/j.jbi.2018.01.005 [doi]	20190514	['Algorithms', 'Databases, Factual', 'Decision Making', '*Decision Support Systems, Clinical', 'Diagnosis, Computer-Assisted/*methods', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Internet', 'Lung/diagnostic imaging', 'Lung Neoplasms/*diagnostic imaging', 'Machine Learning', 'Neoplasm Staging/*methods', 'Neural Networks (Computer)', 'Pattern Recognition, Automated', 'Software', 'Solitary Pulmonary Nodule/diagnostic imaging', 'Symptom Assessment', '*Tomography, X-Ray Computed']	2019/05/15 06:00		['*Convolutional neural networks (CNN)', '*Deep learning', '*Lung cancer stages', '*MBAN (Medical Body Area Network)', '*Nodule detection', '*mIoT (medical Internet of Things)']	['NOTNLM']	NLM	117-128	['2017/06/23 00:00 [received]', '2017/12/12 00:00 [revised]', '2018/01/15 00:00 [accepted]', '2018/01/26 06:00 [pubmed]', '2019/05/15 06:00 [medline]', '2018/01/26 06:00 [entrez]']	United States			29366586	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Biomed Inform. 2018 Mar;79:117-128. doi: 10.1016/j.jbi.2018.01.005. Epub 2018 Jan 31.	MEDLINE	J Biomed Inform	Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images.		79	Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images.
OBJECTIVE: We investigate the clinical effectiveness of a novel deep learning-based noise reduction (NR) approach under noisy conditions with challenging noise types at low signal to noise ratio (SNR) levels for Mandarin-speaking cochlear implant (CI) recipients. DESIGN: The deep learning-based NR approach used in this study consists of two modules: noise classifier (NC) and deep denoising autoencoder (DDAE), thus termed (NC + DDAE). In a series of comprehensive experiments, we conduct qualitative and quantitative analyses on the NC module and the overall NC + DDAE approach. Moreover, we evaluate the speech recognition performance of the NC + DDAE NR and classical single-microphone NR approaches for Mandarin-speaking CI recipients under different noisy conditions. The testing set contains Mandarin sentences corrupted by two types of maskers, two-talker babble noise, and a construction jackhammer noise, at 0 and 5 dB SNR levels. Two conventional NR techniques and the proposed deep learning-based approach are used to process the noisy utterances. We qualitatively compare the NR approaches by the amplitude envelope and spectrogram plots of the processed utterances. Quantitative objective measures include (1) normalized covariance measure to test the intelligibility of the utterances processed by each of the NR approaches; and (2) speech recognition tests conducted by nine Mandarin-speaking CI recipients. These nine CI recipients use their own clinical speech processors during testing. RESULTS: The experimental results of objective evaluation and listening test indicate that under challenging listening conditions, the proposed NC + DDAE NR approach yields higher intelligibility scores than the two compared classical NR techniques, under both matched and mismatched training-testing conditions. CONCLUSIONS: When compared to the two well-known conventional NR techniques under challenging listening condition, the proposed NC + DDAE NR approach has superior noise suppression capabilities and gives less distortion for the key speech envelope information, thus, improving speech recognition more effectively for Mandarin CI recipients. The results suggest that the proposed deep learning-based NR approach can potentially be integrated into existing CI signal processors to overcome the degradation of speech perception caused by noise.	['Department of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan.', 'Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan.', 'National Institute of Information and Communications Technology, Japan.', 'Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China.', 'Department of Mechatronic Engineering, National Taiwan Normal University, Taipei, Taiwan.', 'Department of Otolaryngology, Far Eastern Memorial Hospital, New Taipei, Taiwan.', 'Department of Otolaryngology, Cheng Hsin General Hospital, Taipei, Taiwan.', 'Department of Internal Medicine, Cheng Hsin General Hospital, Taipei, Taiwan.', 'Department of Otolaryngology, Cheng Hsin General Hospital, Taipei, Taiwan.', 'Department of Otolaryngology, Cheng Hsin General Hospital, Taipei, Taiwan.', 'Faculty of Medicine, School of Medicine, National Yang Ming University, Taipei, Taiwan.', 'School of Electrical and Computer Engineering, Georgia Institute of Technology, Georgia, USA.']	['10.1097/AUD.0000000000000537 [doi]']	['Lai YH', 'Tsao Y', 'Lu X', 'Chen F', 'Su YT', 'Chen KC', 'Chen YH', 'Chen LC', 'Po-Hung Li L', 'Lee CH']							['2018/01/24 06:00']	20190314		2018 Jul/Aug	2018/01/24 06:00		['Lai, Ying-Hui', 'Tsao, Yu', 'Lu, Xugang', 'Chen, Fei', 'Su, Yu-Ting', 'Chen, Kuang-Chao', 'Chen, Yu-Hsuan', 'Chen, Li-Ching', 'Po-Hung Li, Lieber', 'Lee, Chin-Hui']			4		1538-4667 (Electronic) 0196-0202 (Linking)	8005585	Ear and hearing	['eng']	10.1097/AUD.0000000000000537 [doi]	20190314	['Adult', 'Child', '*Cochlear Implantation', '*Cochlear Implants', 'Deafness/*rehabilitation', '*Deep Learning', 'Female', 'Humans', 'Male', 'Middle Aged', '*Noise', 'Signal-To-Noise Ratio', '*Speech Perception', 'Young Adult']	2019/03/15 06:00				NLM	795-809	['2018/01/24 06:00 [pubmed]', '2019/03/15 06:00 [medline]', '2018/01/24 06:00 [entrez]']	United States			29360687	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Ear Hear. 2018 Jul/Aug;39(4):795-809. doi: 10.1097/AUD.0000000000000537.	MEDLINE	Ear Hear	Deep Learning-Based Noise Reduction Approach to Improve Speech Intelligibility for Cochlear Implant Recipients.		39	Deep Learning-Based Noise Reduction Approach to Improve Speech Intelligibility for Cochlear Implant Recipients.
PURPOSE: Technical advancements have been part of modern medical solutions as they promote better surgical alternatives that serve to the benefit of patients. Particularly with cardiovascular surgeries, robotic surgical systems enable surgeons to perform delicate procedures on a beating heart, avoiding the complications of cardiac arrest. This advantage comes with the price of having to deal with a dynamic target which presents technical challenges for the surgical system. In this work, we propose a solution for cardiac motion estimation. METHODS: Our estimation approach uses a variational framework that guarantees preservation of the complex anatomy of the heart. An advantage of our approach is that it takes into account different disturbances, such as specular reflections and occlusion events. This is achieved by performing a preprocessing step that eliminates the specular highlights and a predicting step, based on a conditional restricted Boltzmann machine, that recovers missing information caused by partial occlusions. RESULTS: We carried out exhaustive experimentations on two datasets, one from a phantom and the other from an in vivo procedure. The results show that our visual approach reaches an average minima in the order of magnitude of [Formula: see text] while preserving the heart's anatomical structure and providing stable values for the Jacobian determinant ranging from 0.917 to 1.015. We also show that our specular elimination approach reaches an accuracy of 99% compared to a ground truth. In terms of prediction, our approach compared favorably against two well-known predictors, NARX and EKF, giving the lowest average RMSE of 0.071. CONCLUSION: Our approach avoids the risks of using mechanical stabilizers and can also be effective for acquiring the motion of organs other than the heart, such as the lung or other deformable objects.	['Department of Pure Mathematics & Mathematical Statistics, University of Cambridge, Cambridge, UK. ai323@cam.ac.uk.', 'Department of Computer Science, The Institute for Biomedical Engineering, George Washington University, Washington, DC, USA.', 'The Research Center of Biomedical Engineering (CREB), Universitat Politecnica de Cataluya, Barcelona, Spain.']	['10.1007/s11548-018-1702-1 [doi]', '10.1007/s11548-018-1702-1 [pii]']	['Aviles-Rivero AI', 'Alsaleh SM', 'Casals A']							['2018/01/20 06:00']	20180806	20180119	2018 Mar	2018/01/20 06:00		['Aviles-Rivero, Angelica I', 'Alsaleh, Samar M', 'Casals, Alicia']			3		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-018-1702-1 [doi]	20181202	['Algorithms', 'Cardiac Surgical Procedures/*methods', '*Diagnostic Techniques, Cardiovascular', 'Heart Diseases/diagnosis/physiopathology/*surgery', 'Humans', '*Imaging, Three-Dimensional', 'Motion', 'Myocardial Contraction/*physiology', '*Phantoms, Imaging', 'Robotics/*methods']	2018/08/07 06:00		['Deep learning', 'Motion estimation and prediction', 'Robotic surgery']	['NOTNLM']	NLM	353-361	['2017/08/04 00:00 [received]', '2018/01/02 00:00 [accepted]', '2018/01/20 06:00 [pubmed]', '2018/08/07 06:00 [medline]', '2018/01/20 06:00 [entrez]']	Germany			29350321	ppublish	['Journal Article']			IM		Int J Comput Assist Radiol Surg. 2018 Mar;13(3):353-361. doi: 10.1007/s11548-018-1702-1. Epub 2018 Jan 19.	MEDLINE	Int J Comput Assist Radiol Surg	Sliding to predict: vision-based beating heart motion estimation by modeling temporal interactions.		13	Sliding to predict: vision-based beating heart motion estimation by modeling temporal interactions.
Accurate and physiologically meaningful biomarkers for human aging are key to assessing antiaging therapies. Given ethnic differences in health, diet, lifestyle, behavior, environmental exposures, and even average rate of biological aging, it stands to reason that aging clocks trained on datasets obtained from specific ethnic populations are more likely to account for these potential confounding factors, resulting in an enhanced capacity to predict chronological age and quantify biological age. Here, we present a deep learning-based hematological aging clock modeled using the large combined dataset of Canadian, South Korean, and Eastern European population blood samples that show increased predictive accuracy in individual populations compared to population specific hematologic aging clocks. The performance of models was also evaluated on publicly available samples of the American population from the National Health and Nutrition Examination Survey (NHANES). In addition, we explored the association between age predicted by both population specific and combined hematological clocks and all-cause mortality. Overall, this study suggests (a) the population specificity of aging patterns and (b) hematologic clocks predicts all-cause mortality. The proposed models were added to the freely-available Aging.AI system expanding the range of tools for analysis of human aging.	"['Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, Maryland.', 'Computer Science Department, University of Oxford, UK.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, Maryland.', 'Computer Technologies Lab, ITMO University, St. Petersburg, Russia.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, Maryland.', 'Computer Technologies Lab, ITMO University, St. Petersburg, Russia.', ""Department of Biomedical and Molecular Sciences, Queen's University School of Medicine, Queen's University, Kingston, Ontario, Canada."", 'Biogerontology Research Foundation, Oxford, UK.', 'Canadian Longevity Alliance, Ontario, Canada.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, Maryland.', 'Gachon University Gil Medical Center, Incheon, South Korea.', 'Gachon University Gil Medical Center, Incheon, South Korea.', 'Gachon University Gil Medical Center, Incheon, South Korea.', 'Canada Cancer and Aging Research Laboratories, Lethbridge, Alberta, Canada.', 'University of Lethbridge, Alberta, Canada.', 'Canada Cancer and Aging Research Laboratories, Lethbridge, Alberta, Canada.', 'University of Lethbridge, Alberta, Canada.', 'Center for Healthy Aging, Department of Cellular and Molecular Medicine, University of Copenhagen, Denmark.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, Maryland.', 'Biogerontology Research Foundation, Oxford, UK.']"	['4801287 [pii]', '10.1093/gerona/gly005 [doi]']	['Mamoshina P', 'Kochetov K', 'Putin E', 'Cortese F', 'Aliper A', 'Lee WS', 'Ahn SM', 'Uhn L', 'Skjodt N', 'Kovalchuk O', 'Scheibye-Knudsen M', 'Zhavoronkov A']							['2018/01/18 06:00']	20190916		2018 Oct 8	2018/01/18 06:00		['Mamoshina, Polina', 'Kochetov, Kirill', 'Putin, Evgeny', 'Cortese, Franco', 'Aliper, Alexander', 'Lee, Won-Suk', 'Ahn, Sung-Min', 'Uhn, Lee', 'Skjodt, Neil', 'Kovalchuk, Olga', 'Scheibye-Knudsen, Morten', 'Zhavoronkov, Alex']			11		1758-535X (Electronic) 1079-5006 (Linking)	9502837	The journals of gerontology. Series A, Biological sciences and medical sciences	['eng']	10.1093/gerona/gly005 [doi]	20190916	['Adult', 'Aged', 'Aged, 80 and over', 'Aging/*blood', 'Biomarkers/*blood', 'Blood Glucose', 'Canada', 'Cholesterol/blood', 'Datasets as Topic', 'Deep Learning', 'Erythrocytes', 'Europe, Eastern', 'Female', 'Health Surveys', 'Hemoglobins', 'Humans', 'Male', 'Middle Aged', 'Models, Statistical', 'Neural Networks (Computer)', 'Republic of Korea', 'Serum Albumin', 'Sex Factors', 'Sodium/blood', 'Triglycerides/blood', 'Urea/blood', 'Young Adult']	2019/09/17 06:00				NLM	1482-1490	['2017/06/05 00:00 [received]', '2018/01/18 06:00 [pubmed]', '2019/09/17 06:00 [medline]', '2018/01/18 06:00 [entrez]']	United States	PMC6175034		29340580	ppublish	['Journal Article']		['0 (Biomarkers)', '0 (Blood Glucose)', '0 (Hemoglobins)', '0 (Serum Albumin)', '0 (Triglycerides)', '8W8T17847W (Urea)', '97C5T2UQ7J (Cholesterol)', '9NEZ333N27 (Sodium)']	AIM IM		J Gerontol A Biol Sci Med Sci. 2018 Oct 8;73(11):1482-1490. doi: 10.1093/gerona/gly005.	MEDLINE	J Gerontol A Biol Sci Med Sci	Population Specific Biomarkers of Human Aging: A Big Data Study Using South Korean, Canadian, and Eastern European Patient Populations.		73	Population Specific Biomarkers of Human Aging: A Big Data Study Using South Korean, Canadian, and Eastern European Patient Populations.
The war on cancer is progressing globally but slowly as researchers around the world continue to seek and discover more innovative and effective ways of curing this catastrophic disease. Organizing biological information, representing it, and making it accessible, or biocuration, is an important aspect of biomedical research and discovery. However, because maintaining sophisticated biocuration is highly resource dependent, it continues to lag behind the continually being generated biomedical data. Another critical aspect of cancer research, pathway analysis, has proven to be an efficient method for gaining insight into the underlying biology associated with cancer. We propose a deep-learning-based model, Stacked Denoising Autoencoder Multi-Label Learning (SdaMLL), for facilitating gene multi-function discovery and pathway completion. SdaMLL can capture intermediate representations robust to partial corruption of the input pattern and generate low-dimensional codes superior to conditional dimension reduction tools. Experimental results indicate that SdaMLL outperforms existing classical multi-label algorithms. Moreover, we found some gene functions, such as Fused in Sarcoma (FUS, which may be part of transcriptional misregulation in cancer) and p27 (which we expect will become a member viral carcinogenesis), that can be used to complete the related pathways. We provide a visual tool ( https://www.keaml.cn/gpvisual ) to view the new gene functions in cancer pathways.	['Key Laboratory for Symbol Computation and Knowledge Engineering of National Education Ministry, College of Computer Science and Technology, Jilin University, Changchun, 130012, China.', 'MidSouth Bioinformatics Center and Joint Bioinformatics Ph.D. Program of University of Arkansas at Little Rock and Univ. of Arkansas Medical Sciences, Little Rock, AR, 72204, USA.', 'Key Laboratory for Symbol Computation and Knowledge Engineering of National Education Ministry, College of Computer Science and Technology, Jilin University, Changchun, 130012, China.', 'MidSouth Bioinformatics Center and Joint Bioinformatics Ph.D. Program of University of Arkansas at Little Rock and Univ. of Arkansas Medical Sciences, Little Rock, AR, 72204, USA.', 'Key Laboratory for Symbol Computation and Knowledge Engineering of National Education Ministry, College of Computer Science and Technology, Jilin University, Changchun, 130012, China.', 'Institute of Information Engineering, Chinese Academy of Sciences School of Cyber Security, University of Chinese Academy of Sciences, Beijing, 100093, China.', 'Key Laboratory for Symbol Computation and Knowledge Engineering of National Education Ministry, College of Computer Science and Technology, Jilin University, Changchun, 130012, China.', 'College of Earth Sciences, Jilin University, Changchun, 130061, China. yangc616@jlu.edu.cn.', 'Key Laboratory for Symbol Computation and Knowledge Engineering of National Education Ministry, College of Computer Science and Technology, Jilin University, Changchun, 130012, China. ycliang@jlu.edu.cn.', 'Zhuhai Laboratory of Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Zhuhai College of Jilin University, Zhuhai, 519041, China. ycliang@jlu.edu.cn.']	['10.1038/s41598-017-17842-9 [doi]', '10.1038/s41598-017-17842-9 [pii]']	['Guan R', 'Wang X', 'Yang MQ', 'Zhang Y', 'Zhou F', 'Yang C', 'Liang Y']	['ORCID: http://orcid.org/0000-0002-7162-7826', 'ORCID: http://orcid.org/0000-0002-8108-6007']						['2018/01/12 06:00']	20181116	20180110	2018 Jan 10	2018/01/13 06:00	['Sci Rep. 2018 Jun 7;8(1):8995. PMID: 29875368']	['Guan, Renchu', 'Wang, Xu', 'Yang, Mary Qu', 'Zhang, Yu', 'Zhou, Fengfeng', 'Yang, Chen', 'Liang, Yanchun']		['P20 GM103429/GM/NIGMS NIH HHS/United States', 'R15 GM114739/GM/NIGMS NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-17842-9 [doi]	20181116	['Algorithms', 'Computational Biology/*methods', 'Databases, Genetic', '*Genetic Association Studies/methods', '*Genetic Predisposition to Disease', 'Humans', '*Machine Learning', '*Molecular Sequence Annotation', 'Neoplasms/*genetics/metabolism/pathology']	2018/11/18 06:00				NLM	267	['2017/08/31 00:00 [received]', '2017/11/27 00:00 [accepted]', '2018/01/12 06:00 [entrez]', '2018/01/13 06:00 [pubmed]', '2018/11/18 06:00 [medline]']	England	PMC5762767		29321535	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, P.H.S.""]"			IM		Sci Rep. 2018 Jan 10;8(1):267. doi: 10.1038/s41598-017-17842-9.	MEDLINE	Sci Rep	Multi-label Deep Learning for Gene Function Annotation in Cancer Pathways.		8	Multi-label Deep Learning for Gene Function Annotation in Cancer Pathways.
"Deep learning methods applied to problems in chemoinformatics often require the use of recursive neural networks to handle data with graphical structure and variable size. We present a useful classification of recursive neural network approaches into two classes, the inner and outer approach. The inner approach uses recursion inside the underlying graph, to essentially ""crawl"" the edges of the graph, while the outer approach uses recursion outside the underlying graph, to aggregate information over progressively longer distances in an orthogonal direction. We illustrate the inner and outer approaches on several examples. More importantly, we provide open-source implementations [available at www.github.com/Chemoinformatics/InnerOuterRNN and cdb.ics.uci.edu ] for both approaches in Tensorflow which can be used in combination with training data to produce efficient models for predicting the physical, chemical, and biological properties of small molecules."	['Department of Computer Science, University of California, Irvine , Irvine, California 92697, United States.', 'ExxonMobil Research and Engineering , Annandale, New Jersey 08801, United States.', 'Department of Computer Science, University of California, Irvine , Irvine, California 92697, United States.']	['10.1021/acs.jcim.7b00384 [doi]']	['Urban G', 'Subrahmanya N', 'Baldi P']	['ORCID: 0000-0001-8752-4664']						['2018/01/11 06:00']	20190124	20180126	2018 Feb 26	2018/01/11 06:00		['Urban, Gregor', 'Subrahmanya, Niranjan', 'Baldi, Pierre']			2		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.7b00384 [doi]	20190124	['Algorithms', 'Bayes Theorem', '*Databases, Chemical', '*Deep Learning', 'Small Molecule Libraries/chemistry', 'Software']	2019/01/25 06:00				NLM	207-211	['2018/01/11 06:00 [pubmed]', '2019/01/25 06:00 [medline]', '2018/01/11 06:00 [entrez]']	United States			29320180	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Small Molecule Libraries)']	IM		J Chem Inf Model. 2018 Feb 26;58(2):207-211. doi: 10.1021/acs.jcim.7b00384. Epub 2018 Jan 26.	MEDLINE	J Chem Inf Model	Inner and Outer Recursive Neural Networks for Chemoinformatics Applications.		58	Inner and Outer Recursive Neural Networks for Chemoinformatics Applications.
Vascular structures of skin are important biomarkers in diagnosis and assessment of cutaneous conditions. Presence and distribution of lesional vessels are associated with specific abnormalities. Therefore, detection and localization of cutaneous vessels provide critical information towards diagnosis and stage status of diseases. However, cutaneous vessels are highly variable in shape, size, color and architecture, which complicate the detection task. Considering the large variability of these structures, conventional vessel detection techniques lack the generalizability to detect different vessel types and require separate algorithms to be designed for each type. Furthermore, such techniques are highly dependent on precise hand-crafted features which are time-consuming and computationally inefficient. As a solution, we propose a data-driven feature learning framework based on stacked sparse auto-encoders (SSAE) for comprehensive detection of cutaneous vessels. Each training image is divided into small patches of either containing or non-containing vasculature. A multilayer SSAE is designed to learn hidden features of the data in hierarchical layers in an unsupervised manner. The high-level learned features are subsequently fed into a classifier which categorizes each patch into absence or presence of vasculature and localizes vessels within the lesion. Over a test set of 3095 patches derived from 200 images, the proposed framework demonstrated superior performance of 95.4% detection accuracy over a variety of vessel patterns; outperforming other techniques by achieving the highest positive predictive value of 94.7%. The proposed Computer-Aided Diagnosis (CAD) framework can serve as a decision support system assisting dermatologists for more accurate diagnosis, especially in teledermatology applications in remote areas.	['Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada. pkharazmi@bccrc.ca.', 'Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada.', 'Department of Dermatology and Skin Science, University of British Columbia, Vancouver, BC, Canada.', 'Departments of Cancer Control Research and Integrative Oncology, British Columbia Cancer Agency, Vancouver, BC, Canada.', 'Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada.', 'Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada.', 'Department of Dermatology and Skin Science, University of British Columbia, Vancouver, BC, Canada.', 'Departments of Cancer Control Research and Integrative Oncology, British Columbia Cancer Agency, Vancouver, BC, Canada.']	['10.1007/s10916-017-0885-2 [doi]', '10.1007/s10916-017-0885-2 [pii]']	['Kharazmi P', 'Zheng J', 'Lui H', 'Jane Wang Z', 'Lee TK']	['ORCID: http://orcid.org/0000-0002-5997-6900']						['2018/01/11 06:00']	20180827	20180109	2018 Jan 9	2018/01/11 06:00		['Kharazmi, Pegah', 'Zheng, Jiannan', 'Lui, Harvey', 'Jane Wang, Z', 'Lee, Tim K']		['288194-11/Natural Sciences and Engineering Research Council of Canada']	2		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-017-0885-2 [doi]	20181113	['Biomarkers', 'Dermoscopy/*methods', 'Diagnosis, Computer-Assisted/*methods', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Machine Learning', 'Pattern Recognition, Automated/*methods', 'Skin/*blood supply/*diagnostic imaging']	2018/08/28 06:00		['Automated skin vessel detection', 'Deep learning', 'Dermoscopy', 'Stacked sparse autoencoders']	['NOTNLM']	NLM	33	['2017/05/15 00:00 [received]', '2017/12/18 00:00 [accepted]', '2018/01/11 06:00 [entrez]', '2018/01/11 06:00 [pubmed]', '2018/08/28 06:00 [medline]']	United States			29318397	epublish	['Journal Article']		['0 (Biomarkers)']	IM		J Med Syst. 2018 Jan 9;42(2):33. doi: 10.1007/s10916-017-0885-2.	MEDLINE	J Med Syst	A Computer-Aided Decision Support System for Detection and Localization of Cutaneous Vasculature in Dermoscopy Images Via Deep Feature Learning.		42	A Computer-Aided Decision Support System for Detection and Localization of Cutaneous Vasculature in Dermoscopy Images Via Deep Feature Learning.
In silico prediction for toxicity of chemicals is required to reduce cost, time, and animal testing. However, predicting hepatocellular hypertrophy, which often affects the derivation of the No-Observed-Adverse-Effect Level in repeated dose toxicity studies, is difficult because pathological findings are diverse, mechanisms are largely unknown, and a wide variety of chemical structures exists. Therefore, a method for predicting the hepatocellular hypertrophy of diverse chemicals without complete understanding of their mechanisms is necessary. In this study, we developed predictive classification models of hepatocellular hypertrophy using machine learning-specifically, deep learning, random forest, and support vector machine. We extracted hepatocellular hypertrophy data on rats from 2 toxicological databases, our original database developed from risk assessment reports such as pesticides, and the Hazard Evaluation Support System Integrated Platform. Then, we constructed prediction models based on molecular descriptors and evaluated their performance using independent test chemicals datasets, which differed from the training chemicals datasets. Further, we defined the applicability domain (AD), which generally limits the application for chemicals, as structurally similar to the training chemicals dataset. The best model was found to be the support vector machine model using the Hazard Evaluation Support System Integrated Platform dataset, which was trained with 251 chemicals and predicted 214 test chemicals inside the applicability domain. It afforded a prediction accuracy of 0.76, sensitivity of 0.90, and area under the curve of 0.81. These in silico predictive classification models could be reliable tools for hepatocellular hypertrophy assessments and can facilitate the development of in silico models for toxicity prediction.	['Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya 467-8603, Japan.', 'Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya 467-8603, Japan.', 'Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya 467-8603, Japan.', 'Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya 467-8603, Japan.', 'Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya 467-8603, Japan.', 'Division of Pathology, National Institute of Health Sciences, Kawasaki 1210-9501, Japan.', 'Food Safety Commission, Cabinet Office, Tokyo 107-6122, Japan.', 'Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya 467-8603, Japan.']	['4772558 [pii]', '10.1093/toxsci/kfx287 [doi]']	['Ambe K', 'Ishihara K', 'Ochibe T', 'Ohya K', 'Tamura S', 'Inoue K', 'Yoshida M', 'Tohkin M']							['2018/01/09 06:00']	20190225		2018 Apr 1	2018/01/09 06:00		['Ambe, Kaori', 'Ishihara, Kana', 'Ochibe, Tatsuya', 'Ohya, Kazuyuki', 'Tamura, Sorami', 'Inoue, Kaoru', 'Yoshida, Midori', 'Tohkin, Masahiro']			2		1096-0929 (Electronic) 1096-0929 (Linking)	9805461	Toxicological sciences : an official journal of the Society of Toxicology	['eng']	10.1093/toxsci/kfx287 [doi]	20190225	['Animal Testing Alternatives', 'Animals', '*Computer Simulation', 'Deep Learning', 'Food Additives/chemistry/toxicity', 'Hepatocytes/*drug effects/*pathology', 'Hypertrophy', 'Liver/*drug effects/*pathology', '*Models, Biological', 'Molecular Structure', 'Pesticides/chemistry/toxicity', 'Quantitative Structure-Activity Relationship', 'Rats', 'Support Vector Machine', 'Toxicity Tests/*methods', 'Veterinary Drugs/chemistry/toxicity']	2019/02/26 06:00				NLM	667-675	['2018/01/09 06:00 [pubmed]', '2019/02/26 06:00 [medline]', '2018/01/09 06:00 [entrez]']	United States			29309657	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Food Additives)', '0 (Pesticides)', '0 (Veterinary Drugs)']	IM		Toxicol Sci. 2018 Apr 1;162(2):667-675. doi: 10.1093/toxsci/kfx287.	MEDLINE	Toxicol Sci	In Silico Prediction of Chemical-Induced Hepatocellular Hypertrophy Using Molecular Descriptors.		162	In Silico Prediction of Chemical-Induced Hepatocellular Hypertrophy Using Molecular Descriptors.
This work introduces a number of algebraic topology approaches, including multi-component persistent homology, multi-level persistent homology, and electrostatic persistence for the representation, characterization, and description of small molecules and biomolecular complexes. In contrast to the conventional persistent homology, multi-component persistent homology retains critical chemical and biological information during the topological simplification of biomolecular geometric complexity. Multi-level persistent homology enables a tailored topological description of inter- and/or intra-molecular interactions of interest. Electrostatic persistence incorporates partial charge information into topological invariants. These topological methods are paired with Wasserstein distance to characterize similarities between molecules and are further integrated with a variety of machine learning algorithms, including k-nearest neighbors, ensemble of trees, and deep convolutional neural networks, to manifest their descriptive and predictive powers for protein-ligand binding analysis and virtual screening of small molecules. Extensive numerical experiments involving 4,414 protein-ligand complexes from the PDBBind database and 128,374 ligand-target and decoy-target pairs in the DUD database are performed to test respectively the scoring power and the discriminatory power of the proposed topological learning strategies. It is demonstrated that the present topological learning outperforms other existing methods in protein-ligand binding affinity prediction and ligand-decoy discrimination.	['Department of Mathematics, Michigan State University, East Lansing, Michigan, United States of America.', 'Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, Tennessee, United States of America.', 'Department of Mathematics, Michigan State University, East Lansing, Michigan, United States of America.', 'Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, Michigan, United States of America.', 'Department of Electrical and Computer Engineering, Michigan State University, East Lansing, Michigan, United States of America.']	['10.1371/journal.pcbi.1005929 [doi]', 'PCOMPBIOL-D-17-01481 [pii]']	['Cang Z', 'Mu L', 'Wei GW']	['ORCID: 0000-0002-9951-5586', 'ORCID: 0000-0001-8132-5998']						['2018/01/09 06:00']	20180618	20180108	2018 Jan	2018/01/09 06:00		['Cang, Zixuan', 'Mu, Lin', 'Wei, Guo-Wei']			1		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1005929 [doi]	20190118	['Algorithms', 'Area Under Curve', 'Computational Biology/*methods', 'Databases, Protein', 'Humans', 'Ligands', '*Machine Learning', 'Models, Neurological', '*Molecular Dynamics Simulation', 'Neural Networks (Computer)', 'Nucleic Acids/chemistry', 'Protein Binding', 'Protein Interaction Mapping', 'Proteins/*chemistry', '*Static Electricity']	2018/06/19 06:00				NLM	e1005929	['2017/09/01 00:00 [received]', '2017/12/15 00:00 [accepted]', '2018/01/19 00:00 [revised]', '2018/01/09 06:00 [pubmed]', '2018/06/19 06:00 [medline]', '2018/01/09 06:00 [entrez]']	United States	PMC5774846		29309403	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Ligands)', '0 (Nucleic Acids)', '0 (Proteins)']	IM		PLoS Comput Biol. 2018 Jan 8;14(1):e1005929. doi: 10.1371/journal.pcbi.1005929. eCollection 2018 Jan.	MEDLINE	PLoS Comput Biol	Representability of algebraic topology for biomolecules in machine learning based scoring and virtual screening.		14	Representability of algebraic topology for biomolecules in machine learning based scoring and virtual screening.
BACKGROUND: With the development of artificial intelligence (AI) technology centered on deep-learning, the computer has evolved to a point where it can read a given text and answer a question based on the context of the text. Such a specific task is known as the task of machine comprehension. Existing machine comprehension tasks mostly use datasets of general texts, such as news articles or elementary school-level storybooks. However, no attempt has been made to determine whether an up-to-date deep learning-based machine comprehension model can also process scientific literature containing expert-level knowledge, especially in the biomedical domain. OBJECTIVE: This study aims to investigate whether a machine comprehension model can process biomedical articles as well as general texts. Since there is no dataset for the biomedical literature comprehension task, our work includes generating a large-scale question answering dataset using PubMed and manually evaluating the generated dataset. METHODS: We present an attention-based deep neural model tailored to the biomedical domain. To further enhance the performance of our model, we used a pretrained word vector and biomedical entity type embedding. We also developed an ensemble method of combining the results of several independent models to reduce the variance of the answers from the models. RESULTS: The experimental results showed that our proposed deep neural network model outperformed the baseline model by more than 7% on the new dataset. We also evaluated human performance on the new dataset. The human evaluation result showed that our deep neural model outperformed humans in comprehension by 22% on average. CONCLUSIONS: In this work, we introduced a new task of machine comprehension in the biomedical domain using a deep neural model. Since there was no large-scale dataset for training deep neural models in the biomedical domain, we created the new cloze-style datasets Biomedical Knowledge Comprehension Title (BMKC_T) and Biomedical Knowledge Comprehension Last Sentence (BMKC_LS) (together referred to as BioMedical Knowledge Comprehension) using the PubMed corpus. The experimental results showed that the performance of our model is much higher than that of humans. We observed that our model performed consistently better regardless of the degree of difficulty of a text, whereas humans have difficulty when performing biomedical literature comprehension tasks that require expert level knowledge.	['Department of Computer Science and Engineering, College of Informatics, Korea University, Seoul, Republic Of Korea.', 'Department of Computer Science and Engineering, College of Informatics, Korea University, Seoul, Republic Of Korea.', 'Department of Computer Science and Engineering, College of Informatics, Korea University, Seoul, Republic Of Korea.', 'Department of Computer Science and Engineering, College of Informatics, Korea University, Seoul, Republic Of Korea.', 'Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, Republic Of Korea.', 'Department of Computer Science and Engineering, College of Informatics, Korea University, Seoul, Republic Of Korea.', 'Division of Medical Oncology, Department of Medicine, Translational Bioinformatics and Cancer Systems Biology Laboratory, University of Colorado Anschutz Medical Campus, Aurora, CO, United States.', 'Division of Medical Oncology, Department of Medicine, Translational Bioinformatics and Cancer Systems Biology Laboratory, University of Colorado Anschutz Medical Campus, Aurora, CO, United States.', 'Department of Computer Science and Engineering, College of Informatics, Korea University, Seoul, Republic Of Korea.']	['v6i1e2 [pii]', '10.2196/medinform.8751 [doi]']	['Kim S', 'Park D', 'Choi Y', 'Lee K', 'Kim B', 'Jeon M', 'Kim J', 'Tan AC', 'Kang J']	['ORCID: http://orcid.org/0000-0002-9872-0430', 'ORCID: http://orcid.org/0000-0003-2762-3737', 'ORCID: http://orcid.org/0000-0001-5709-9898', 'ORCID: http://orcid.org/0000-0003-2015-3939', 'ORCID: http://orcid.org/0000-0002-3212-3385', 'ORCID: http://orcid.org/0000-0001-5731-6186', 'ORCID: http://orcid.org/0000-0002-0338-2329', 'ORCID: http://orcid.org/0000-0003-2955-8369', 'ORCID: http://orcid.org/0000-0001-6798-9106']	['(c)Seongsoon Kim, Donghyeon Park, Yonghwa Choi, Kyubum Lee, Byounggun Kim, Minji', 'Jeon, Jihye Kim, Aik Choon Tan, Jaewoo Kang. Originally published in JMIR Medical', 'Informatics (http://medinform.jmir.org), 05.01.2018.']					['2018/01/07 06:00']		20180105	2018 Jan 5	2018/01/07 06:00		['Kim, Seongsoon', 'Park, Donghyeon', 'Choi, Yonghwa', 'Lee, Kyubum', 'Kim, Byounggun', 'Jeon, Minji', 'Kim, Jihye', 'Tan, Aik Choon', 'Kang, Jaewoo']			1		2291-9694 (Print)	101645109	JMIR medical informatics	['eng']	10.2196/medinform.8751 [doi]	20191120		2018/01/07 06:01		['biomedical text comprehension', 'deep learning', 'machine comprehension', 'machine comprehension dataset']	['NOTNLM']	NLM	e2	['2017/08/15 00:00 [received]', '2017/11/16 00:00 [accepted]', '2017/10/25 00:00 [revised]', '2018/01/07 06:00 [entrez]', '2018/01/07 06:00 [pubmed]', '2018/01/07 06:01 [medline]']	Canada	PMC5783222		29305341	epublish	['Journal Article']					JMIR Med Inform. 2018 Jan 5;6(1):e2. doi: 10.2196/medinform.8751.	PubMed-not-MEDLINE	JMIR Med Inform	A Pilot Study of Biomedical Text Comprehension using an Attention-Based Deep Neural Reader: Design and Experimental Analysis.		6	A Pilot Study of Biomedical Text Comprehension using an Attention-Based Deep Neural Reader: Design and Experimental Analysis.
BACKGROUND: Plankton, including phytoplankton and zooplankton, are the main source of food for organisms in the ocean and form the base of marine food chain. As the fundamental components of marine ecosystems, plankton is very sensitive to environment changes, and the study of plankton abundance and distribution is crucial, in order to understand environment changes and protect marine ecosystems. This study was carried out to develop an extensive applicable plankton classification system with high accuracy for the increasing number of various imaging devices. Literature shows that most plankton image classification systems were limited to only one specific imaging device and a relatively narrow taxonomic scope. The real practical system for automatic plankton classification is even non-existent and this study is partly to fill this gap. RESULTS: Inspired by the analysis of literature and development of technology, we focused on the requirements of practical application and proposed an automatic system for plankton image classification combining multiple view features via multiple kernel learning (MKL). For one thing, in order to describe the biomorphic characteristics of plankton more completely and comprehensively, we combined general features with robust features, especially by adding features like Inner-Distance Shape Context for morphological representation. For another, we divided all the features into different types from multiple views and feed them to multiple classifiers instead of only one by combining different kernel matrices computed from different types of features optimally via multiple kernel learning. Moreover, we also applied feature selection method to choose the optimal feature subsets from redundant features for satisfying different datasets from different imaging devices. We implemented our proposed classification system on three different datasets across more than 20 categories from phytoplankton to zooplankton. The experimental results validated that our system outperforms state-of-the-art plankton image classification systems in terms of accuracy and robustness. CONCLUSIONS: This study demonstrated automatic plankton image classification system combining multiple view features using multiple kernel learning. The results indicated that multiple view features combined by NLMKL using three kernel functions (linear, polynomial and Gaussian kernel functions) can describe and use information of features better so that achieve a higher classification accuracy.	['Department of Electronic Engineering, Ocean University of China, No. 238 Songling Road, Qingdao, 266100, China.', 'Department of Electronic Engineering, Ocean University of China, No. 238 Songling Road, Qingdao, 266100, China.', 'Department of Electronic Engineering, Ocean University of China, No. 238 Songling Road, Qingdao, 266100, China.', 'Department of Electronic Engineering, Ocean University of China, No. 238 Songling Road, Qingdao, 266100, China.', 'Department of Electronic Engineering, Ocean University of China, No. 238 Songling Road, Qingdao, 266100, China.', 'College of Information Science and Engineering, Ocean University of China, No. 238 Songling Road, Qingdao, 266100, China. bingzh@ouc.edu.cn.']	['10.1186/s12859-017-1954-8 [doi]', '10.1186/s12859-017-1954-8 [pii]']	['Zheng H', 'Wang R', 'Yu Z', 'Wang N', 'Gu Z', 'Zheng B']							['2018/01/04 06:00']	20181211	20171228	2017 Dec 28	2018/01/04 06:00		['Zheng, Haiyong', 'Wang, Ruchen', 'Yu, Zhibin', 'Wang, Nan', 'Gu, Zhaorui', 'Zheng, Bing']			Suppl 16		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-017-1954-8 [doi]	20181211	['*Algorithms', 'Automation', 'Databases as Topic', 'Deep Learning', '*Image Processing, Computer-Assisted', 'Plankton/*cytology', 'Support Vector Machine']	2018/12/12 06:00		['*Feature selection', '*Image classification', '*Multiple kernel learning', '*Multiple view features', '*Plankton classification']	['NOTNLM']	NLM	570	['2018/01/04 06:00 [entrez]', '2018/01/04 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	England	PMC5751094		29297354	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Bioinformatics. 2017 Dec 28;18(Suppl 16):570. doi: 10.1186/s12859-017-1954-8.	MEDLINE	BMC Bioinformatics	Automatic plankton image classification combining multiple view features via multiple kernel learning.		18	Automatic plankton image classification combining multiple view features via multiple kernel learning.
BACKGROUND: Biomedical event extraction is one of the most frontier domains in biomedical research. The two main subtasks of biomedical event extraction are trigger identification and arguments detection which can both be considered as classification problems. However, traditional state-of-the-art methods are based on support vector machine (SVM) with massive manually designed one-hot represented features, which require enormous work but lack semantic relation among words. METHODS: In this paper, we propose a multiple distributed representation method for biomedical event extraction. The method combines context consisting of dependency-based word embedding, and task-based features represented in a distributed way as the input of deep learning models to train deep learning models. Finally, we used softmax classifier to label the example candidates. RESULTS: The experimental results on Multi-Level Event Extraction (MLEE) corpus show higher F-scores of 77.97% in trigger identification and 58.31% in overall compared to the state-of-the-art SVM method. CONCLUSIONS: Our distributed representation method for biomedical event extraction avoids the problems of semantic gap and dimension disaster from traditional one-hot representation methods. The promising results demonstrate that our proposed method is effective for biomedical event extraction.	['School of Computer Science and Technology, Dalian University of Technology, Dalian, China.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, China. wangjian@dlut.edu.cn.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, China.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, China.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, China.', 'School of Computer Science and Technology, Dalian University of Technology, Dalian, China.']	['10.1186/s12911-017-0563-9 [doi]', '10.1186/s12911-017-0563-9 [pii]']	['Wang A', 'Wang J', 'Lin H', 'Zhang J', 'Yang Z', 'Xu K']							['2018/01/04 06:00']	20180820	20171220	2017 Dec 20	2018/01/04 06:00		['Wang, Anran', 'Wang, Jian', 'Lin, Hongfei', 'Zhang, Jianhai', 'Yang, Zhihao', 'Xu, Kan']			Suppl 3		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-017-0563-9 [doi]	20181113	['Biomedical Research/*methods', 'Humans', '*Machine Learning', '*Models, Theoretical', '*Neural Networks (Computer)']	2018/08/21 06:00		['*Biomedical event extraction', '*Convolutional neural network', '*Deep learning', '*Distributed representation']	['NOTNLM']	NLM	171	['2018/01/04 06:00 [entrez]', '2018/01/04 06:00 [pubmed]', '2018/08/21 06:00 [medline]']	England	PMC5751641		29297321	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Med Inform Decis Mak. 2017 Dec 20;17(Suppl 3):171. doi: 10.1186/s12911-017-0563-9.	MEDLINE	BMC Med Inform Decis Mak	A multiple distributed representation method based on neural network for biomedical event extraction.		17	A multiple distributed representation method based on neural network for biomedical event extraction.
BACKGROUND: Direct prediction of the three-dimensional (3D) structures of proteins from one-dimensional (1D) sequences is a challenging problem. Significant structural characteristics such as solvent accessibility and contact number are essential for deriving restrains in modeling protein folding and protein 3D structure. Thus, accurately predicting these features is a critical step for 3D protein structure building. RESULTS: In this study, we present DeepSacon, a computational method that can effectively predict protein solvent accessibility and contact number by using a deep neural network, which is built based on stacked autoencoder and a dropout method. The results demonstrate that our proposed DeepSacon achieves a significant improvement in the prediction quality compared with the state-of-the-art methods. We obtain 0.70 three-state accuracy for solvent accessibility, 0.33 15-state accuracy and 0.74 Pearson Correlation Coefficient (PCC) for the contact number on the 5729 monomeric soluble globular protein dataset. We also evaluate the performance on the CASP11 benchmark dataset, DeepSacon achieves 0.68 three-state accuracy and 0.69 PCC for solvent accessibility and contact number, respectively. CONCLUSIONS: We have shown that DeepSacon can reliably predict solvent accessibility and contact number with stacked sparse autoencoder and a dropout approach.	['School of Software, Central South University, No.22 Shaoshan South Road, Changsha, 410075, China.', 'School of Software, Central South University, No.22 Shaoshan South Road, Changsha, 410075, China.', 'School of Information Science and Engineering, Central South University, No.932 South Lushan Road, Changsha, 410083, China. zengzhiwen@csu.edu.cn.']	['10.1186/s12859-017-1971-7 [doi]', '10.1186/s12859-017-1971-7 [pii]']	['Deng L', 'Fan C', 'Zeng Z']							['2018/01/04 06:00']	20181211	20171228	2017 Dec 28	2018/01/04 06:00		['Deng, Lei', 'Fan, Chao', 'Zeng, Zhiwen']			Suppl 16		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-017-1971-7 [doi]	20181211	['*Algorithms', 'Machine Learning', 'Models, Molecular', '*Neural Networks (Computer)', 'Proteins/*chemistry', 'Solvents/*chemistry']	2018/12/12 06:00		['*Contact number', '*Deep neural network', '*Sequence-derived features', '*Solvent accessibility']	['NOTNLM']	NLM	569	['2018/01/04 06:00 [entrez]', '2018/01/04 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	England	PMC5751690		29297299	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)', '0 (Solvents)']	IM		BMC Bioinformatics. 2017 Dec 28;18(Suppl 16):569. doi: 10.1186/s12859-017-1971-7.	MEDLINE	BMC Bioinformatics	A sparse autoencoder-based deep neural network for protein solvent accessibility and contact number prediction.		18	A sparse autoencoder-based deep neural network for protein solvent accessibility and contact number prediction.
There is an increasing demand for computing the relevant structures, equilibria, and long-timescale kinetics of biomolecular processes, such as protein-drug binding, from high-throughput molecular dynamics simulations. Current methods employ transformation of simulated coordinates into structural features, dimension reduction, clustering the dimension-reduced data, and estimation of a Markov state model or related model of the interconversion rates between molecular structures. This handcrafted approach demands a substantial amount of modeling expertise, as poor decisions at any step will lead to large modeling errors. Here we employ the variational approach for Markov processes (VAMP) to develop a deep learning framework for molecular kinetics using neural networks, dubbed VAMPnets. A VAMPnet encodes the entire mapping from molecular coordinates to Markov states, thus combining the whole data processing pipeline in a single end-to-end framework. Our method performs equally or better than state-of-the-art Markov modeling methods and provides easily interpretable few-state kinetic models.	['Department of Mathematics and Computer Science, Freie Universitat Berlin, Arnimallee 6, 14195, Berlin, Germany.', 'Department of Mathematics and Computer Science, Freie Universitat Berlin, Arnimallee 6, 14195, Berlin, Germany.', 'Department of Mathematics and Computer Science, Freie Universitat Berlin, Arnimallee 6, 14195, Berlin, Germany.', 'Department of Mathematics and Computer Science, Freie Universitat Berlin, Arnimallee 6, 14195, Berlin, Germany. frank.noe@fu-berlin.de.']	['10.1038/s41467-017-02388-1 [doi]', '10.1038/s41467-017-02388-1 [pii]']	['Mardt A', 'Pasquali L', 'Wu H', 'Noe F']	['ORCID: http://orcid.org/0000-0003-4169-9324']						['2018/01/04 06:00']	20180306	20180102	2018 Jan 2	2018/01/04 06:00	['Nat Commun. 2018 Oct 22;9(1):4443. PMID: 30349135']	['Mardt, Andreas', 'Pasquali, Luca', 'Wu, Hao', 'Noe, Frank']		['ERC STG 307494/European Research Council/International']	1		2041-1723 (Electronic) 2041-1723 (Linking)	101528555	Nature communications	['eng']	10.1038/s41467-017-02388-1 [doi]	20181113	['*Algorithms', 'Kinetics', '*Machine Learning', '*Markov Chains', '*Molecular Dynamics Simulation', '*Neural Networks (Computer)', 'Protein Binding', 'Protein Folding']	2018/03/07 06:00				NLM	5	['2017/07/14 00:00 [received]', '2017/11/22 00:00 [accepted]', '2018/01/04 06:00 [entrez]', '2018/01/04 06:00 [pubmed]', '2018/03/07 06:00 [medline]']	England	PMC5750224		29295994	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Nat Commun. 2018 Jan 2;9(1):5. doi: 10.1038/s41467-017-02388-1.	MEDLINE	Nat Commun	VAMPnets for deep learning of molecular kinetics.		9	VAMPnets for deep learning of molecular kinetics.
"In healthcare, applying deep learning models to electronic health records (EHRs) has drawn considerable attention. This sequential nature of EHR data make them wellmatched for the power of Recurrent Neural Network (RNN). In this poster, we propose ""Deep Diabetologist"" - using RNNs for EHR sequential data modeling to provide personalized hypoglycemic medication prediction for diabetic patients. Our results demonstrate improved performance compared with a baseline classifier using logistic regression."	['IBM Research China, Beijing, China.', 'IBM Research China, Beijing, China.', 'IBM Research China, Beijing, China.', 'Department of Computer Science, Peking University, Beijing, China.', 'IBM Research China, Beijing, China.', 'IBM Research China, Beijing, China.', 'IBM Research China, Beijing, China.', 'Department of Endocrinology and Diabetes, the First Affiliated Hospital, Xiamen University, Xiamen, China.', 'Pfizer Investment Co. Ltd., Beijing, China.']		['Mei J', 'Zhao S', 'Jin F', 'Zhang L', 'Liu H', 'Li X', 'Xie G', 'Li X', 'Xu M']							['2018/01/04 06:00']	20180604		2017	2018/01/04 06:00		['Mei, Jing', 'Zhao, Shiwan', 'Jin, Feng', 'Zhang, Lingxiao', 'Liu, Haifeng', 'Li, Xiang', 'Xie, Guotong', 'Li, Xuejun', 'Xu, Meilin']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']		20181202	['Clinical Decision-Making', 'Diabetes Mellitus/*drug therapy', 'Humans', '*Hypoglycemic Agents', 'Learning', 'Logistic Models', '*Machine Learning', '*Neural Networks (Computer)']	2018/06/05 06:00		['Clinical', 'Decision Support Systems', 'Electronic Health Records', 'Neural Networks (Computer)']	['NOTNLM']	NLM	1277	['2018/01/04 06:00 [entrez]', '2018/01/04 06:00 [pubmed]', '2018/06/05 06:00 [medline]']	Netherlands			29295362	ppublish	['Journal Article']		['0 (Hypoglycemic Agents)']	T		Stud Health Technol Inform. 2017;245:1277.	MEDLINE	Stud Health Technol Inform	Deep Diabetologist: Learning to Prescribe Hypoglycemic Medications with Recurrent Neural Networks.		245	Deep Diabetologist: Learning to Prescribe Hypoglycemic Medications with Recurrent Neural Networks.
This paper proposes an automatic classification method to detect glaucoma in fundus images. The method is based on training a neural network using public image databases. The network used in this paper is the GoogLeNet, adapted for this proposal. The methodology was divided into two stages, namely: (1) detection of the region of interest (ROI); (2) image classification. We first used a sliding-window approach combined with the GoogLeNet network. This network was trained using manually extracted ROIs and other fundus image structures. Afterwards, another GoogLeNet model was trained using the previous resulting images. Then those images were used to train another GoogLeNet model to automatically detect glaucoma. To prevent overfitting, data augmentation techniques were used on smaller databases. The results demonstrated that the network had a good accuracy, even with poor quality images found in some databases or generated by the data augmentation algorithm.	['Graduate Program in Computer Science (PPGI), Department of Applied Computing (DCOM), Santa Maria, Rio Grande do Sul, Brazil.', 'Graduate Program in Computer Science (PPGI), Department of Applied Computing (DCOM), Santa Maria, Rio Grande do Sul, Brazil.', 'Graduate Program in Computer Science (PPGI), Department of Applied Computing (DCOM), Santa Maria, Rio Grande do Sul, Brazil.', 'Department of Clinical Medicine, Santa Maria University Hospital, Federal University of Santa Maria (UFSM), Rio Grande do Sul, Brazil.', 'Department of Clinical Medicine, Santa Maria University Hospital, Federal University of Santa Maria (UFSM), Rio Grande do Sul, Brazil.']		"['Cerentini A', 'Welfer D', ""Cordeiro d'Ornellas M"", 'Pereira Haygert CJ', 'Dotto GN']"							['2018/01/04 06:00']	20180605		2017	2018/01/04 06:00		"['Cerentini, Allan', 'Welfer, Daniel', ""Cordeiro d'Ornellas, Marcos"", 'Pereira Haygert, Carlos Jesus', 'Dotto, Gustavo Nogara']"					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']		20181202	['Algorithms', 'Fundus Oculi', 'Glaucoma/*diagnosis', 'Humans', '*Machine Learning', '*Neural Networks (Computer)']	2018/06/06 06:00		['Glaucoma', 'Neural Network (Computer)', 'Retina']	['NOTNLM']	NLM	318-321	['2018/01/04 06:00 [entrez]', '2018/01/04 06:00 [pubmed]', '2018/06/06 06:00 [medline]']	Netherlands			29295107	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2017;245:318-321.	MEDLINE	Stud Health Technol Inform	Automatic Identification of Glaucoma Using Deep Learning Methods.		245	Automatic Identification of Glaucoma Using Deep Learning Methods.
	['The Russell H. Morgan Department of Radiology and Radiologic Science, Johns Hopkins School of Medicine, Baltimore, Maryland.', 'Department of Molecular Biology and Genetics, Johns Hopkins School of Medicine, Baltimore, Maryland.', 'Department of Cognitive Science, Johns Hopkins School of Medicine, Baltimore, Maryland.', 'The Russell H. Morgan Department of Radiology and Radiologic Science, Johns Hopkins School of Medicine, Baltimore, Maryland. Electronic address: efishman@jhmi.edu.']	['S1546-1440(17)30969-9 [pii]', '10.1016/j.jacr.2017.08.007 [doi]']	['Lugo-Fagundo C', 'Vogelstein B', 'Yuille A', 'Fishman EK']							['2018/01/02 06:00']	20181226	20171229	2018 Feb	2018/01/02 06:00		['Lugo-Fagundo, Carolina', 'Vogelstein, Bert', 'Yuille, Alan', 'Fishman, Elliot K']			2		1558-349X (Electronic) 1546-1440 (Linking)	101190326	Journal of the American College of Radiology : JACR	['eng']	S1546-1440(17)30969-9 [pii] 10.1016/j.jacr.2017.08.007 [doi]	20181226	['Algorithms', '*Deep Learning', 'Humans', 'Image Interpretation, Computer-Assisted/*standards', 'Magnetic Resonance Imaging', 'Radiology/*standards', 'Tomography, X-Ray Computed', 'User-Computer Interface']	2018/12/27 06:00				NLM	364-367	['2017/06/19 00:00 [received]', '2017/07/28 00:00 [revised]', '2017/08/02 00:00 [accepted]', '2018/01/02 06:00 [pubmed]', '2018/12/27 06:00 [medline]', '2018/01/02 06:00 [entrez]']	United States			29290592	ppublish	['Journal Article']			IM		J Am Coll Radiol. 2018 Feb;15(2):364-367. doi: 10.1016/j.jacr.2017.08.007. Epub 2017 Dec 29.	MEDLINE	J Am Coll Radiol	Deep Learning in Radiology: Now the Real Work Begins.		15	Deep Learning in Radiology: Now the Real Work Begins.
"Robustness to obstacles is the most important factor necessary to achieve accurate tumor tracking without fiducial markers. Some high-density structures, such as bone, are enhanced on X-ray fluoroscopic images, which cause tumor mistracking. Tumor tracking should be performed by controlling ""importance recognition"": the understanding that soft-tissue is an important tracking feature and bone structure is unimportant. We propose a new real-time tumor-contouring method that uses deep learning with importance recognition control. The novelty of the proposed method is the combination of the devised random overlay method and supervised deep learning to induce the recognition of structures in tumor contouring as important or unimportant. This method can be used for tumor contouring because it uses deep learning to perform image segmentation. Our results from a simulated fluoroscopy model showed accurate tracking of a low-visibility tumor with an error of approximately 1 mm, even if enhanced bone structure acted as an obstacle. A high similarity of approximately 0.95 on the Jaccard index was observed between the segmented and ground truth tumor regions. A short processing time of 25 ms was achieved. The results of this simulated fluoroscopy model support the feasibility of robust real-time tumor contouring with fluoroscopy. Further studies using clinical fluoroscopy are highly anticipated."	['Faculty of Medicine, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan. terunuma@pmrc.tsukuba.ac.jp.', 'Proton Medical Research Center (PMRC), University of Tsukuba Hospital, Amakubo 2-1-1, Tsukuba, 305-8576, Japan. terunuma@pmrc.tsukuba.ac.jp.', 'Graduate School of Comprehensive Human Science, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan.', 'Faculty of Medicine, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan.', 'Proton Medical Research Center (PMRC), University of Tsukuba Hospital, Amakubo 2-1-1, Tsukuba, 305-8576, Japan.']	['10.1007/s12194-017-0435-0 [doi]', '10.1007/s12194-017-0435-0 [pii]']	['Terunuma T', 'Tokui A', 'Sakae T']	['ORCID: http://orcid.org/0000-0002-5506-0743']		['Radiol Phys Technol. 2018 Sep;11(3):360-361. PMID: 29512057']				['2017/12/30 06:00']	20180828	20171228	2018 Mar	2017/12/30 06:00		['Terunuma, Toshiyuki', 'Tokui, Aoi', 'Sakae, Takeji']		['KAKENHI 21611002/Japan Society for the Promotion of Science', 'KAKENHI 25461903/Japan Society for the Promotion of Science', 'KAKENHI 17K09054/Japan Society for the Promotion of Science']	1		1865-0341 (Electronic) 1865-0333 (Linking)	101467995	Radiological physics and technology	['eng']	10.1007/s12194-017-0435-0 [doi]	20181113	['*Algorithms', 'Fiducial Markers', 'Fluoroscopy/*methods', 'Humans', 'Lung Neoplasms/*diagnostic imaging', '*Machine Learning', '*Pattern Recognition, Automated', 'Radiographic Image Interpretation, Computer-Assisted/*standards', 'Tomography, X-Ray Computed/methods', 'X-Rays']	2018/08/29 06:00		['Data augmentation', 'Image recognition', 'Markerless tumor tracking', 'Supervised deep learning', 'Tumor contouring', 'X-ray fluoroscopy']	['NOTNLM']	NLM	43-53	['2017/04/24 00:00 [received]', '2017/12/13 00:00 [accepted]', '2017/12/08 00:00 [revised]', '2017/12/30 06:00 [pubmed]', '2018/08/29 06:00 [medline]', '2017/12/30 06:00 [entrez]']	Japan	PMC5840203		29285686	ppublish	['Journal Article']			IM		Radiol Phys Technol. 2018 Mar;11(1):43-53. doi: 10.1007/s12194-017-0435-0. Epub 2017 Dec 28.	MEDLINE	Radiol Phys Technol	Novel real-time tumor-contouring method using deep learning to prevent mistracking in X-ray fluoroscopy.		11	Novel real-time tumor-contouring method using deep learning to prevent mistracking in X-ray fluoroscopy.
Deep neural networks (DNNs), which are kinds of the machine learning approaches, are powerful tools for analyzing big sets of data derived from biological and environmental systems. However, DNNs are not applicable to metabolomics studies because they have difficulty in identifying contribution factors, e.g., biomarkers, in constructed classification and regression models. In this paper, we describe an improved DNN-based analytical approach that incorporates an importance estimation for each variable using a mean decrease accuracy (MDA) calculation, which is based on a permutation algorithm; this approach is called DNN-MDA. The performance of the DNN-MDA approach was evaluated using a data set of metabolic profiles derived from yellowfin goby that lived in various rivers throughout Japan. Its performance was compared with that of conventional multivariate and machine learning methods, and the DNN-MDA approach was found to have the best classification accuracy (97.8%) among the examined methods. In addition to this, the DNN-MDA approach facilitated the identification of important variables such as trimethylamine N-oxide, inosinic acid, and glycine, which were characteristic metabolites that contributed to the discrimination of the geographical differences between fish caught in the Kanto region and those caught in other regions. As a result, the DNN-MDA approach is a useful and powerful tool for determining the geographical origins of specimens and identifying their biomarkers in metabolomics studies that are conducted in biological and environmental systems.	['RIKEN Center for Sustainable Resource Science , 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.', 'Graduate School of Medical Life Science, Yokohama City University , 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.', 'RIKEN Center for Sustainable Resource Science , 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.', 'Graduate School of Medical Life Science, Yokohama City University , 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.', 'Graduate School of Bioagricultural Sciences, Nagoya University , 1 Furo-cho, Chikusa-ku, Nagoya, Aichi 464-8601, Japan.']	['10.1021/acs.analchem.7b03795 [doi]']	['Date Y', 'Kikuchi J']	['ORCID: 0000-0001-9645-4370', 'ORCID: 0000-0002-6809-394X']						['2017/12/27 06:00']	20190207	20180117	2018 Feb 6	2017/12/27 06:00		['Date, Yasuhiro', 'Kikuchi, Jun']			3		1520-6882 (Electronic) 0003-2700 (Linking)	0370536	Analytical chemistry	['eng']	10.1021/acs.analchem.7b03795 [doi]	20190215	['Algorithms', 'Animals', 'Machine Learning', 'Metabolomics/*methods', '*Neural Networks (Computer)', 'Perciformes/classification/metabolism']	2019/02/08 06:00				NLM	1805-1810	['2017/12/27 06:00 [pubmed]', '2019/02/08 06:00 [medline]', '2017/12/27 06:00 [entrez]']	United States			29278490	ppublish	['Journal Article']			IM		Anal Chem. 2018 Feb 6;90(3):1805-1810. doi: 10.1021/acs.analchem.7b03795. Epub 2018 Jan 17.	MEDLINE	Anal Chem	Application of a Deep Neural Network to Metabolomics Studies and Its Performance in Determining Important Variables.		90	Application of a Deep Neural Network to Metabolomics Studies and Its Performance in Determining Important Variables.
While genes are defined by sequence, in biological systems a protein's function is largely determined by its three-dimensional structure. Evolutionary information embedded within multiple sequence alignments provides a rich source of data for inferring structural constraints on macromolecules. Still, many proteins of interest lack sufficient numbers of related sequences, leading to noisy, error-prone residue-residue contact predictions. Here we introduce DeepContact, a convolutional neural network (CNN)-based approach that discovers co-evolutionary motifs and leverages these patterns to enable accurate inference of contact probabilities, particularly when few related sequences are available. DeepContact significantly improves performance over previous methods, including in the CASP12 blind contact prediction task where we achieved top performance with another CNN-based approach. Moreover, our tool converts hard-to-interpret coupling scores into probabilities, moving the field toward a consistent metric to assess contact prediction across diverse proteins. Through substantially improving the precision-recall behavior of contact prediction, DeepContact suggests we are near a paradigm shift in template-free modeling for protein structure prediction.	['Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, IL 61801, USA.', 'Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA 02139, USA; Department of Mathematics, MIT, Cambridge, MA 02139, USA; Division of Medical Sciences, Harvard University, Cambridge, MA 02138, USA.', 'Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, IL 61801, USA.', 'Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA 02139, USA; Department of Mathematics, MIT, Cambridge, MA 02139, USA. Electronic address: bab@mit.edu.', 'Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, IL 61801, USA. Electronic address: jianpeng@illinois.edu.']	['S2405-4712(17)30542-2 [pii]', '10.1016/j.cels.2017.11.014 [doi]']	['Liu Y', 'Palmedo P', 'Ye Q', 'Berger B', 'Peng J']		['Copyright (c) 2017 The Authors. Published by Elsevier Inc. All rights reserved.']					['2017/12/25 06:00']	20190923	20171220	2018 Jan 24	2017/12/25 06:00		['Liu, Yang', 'Palmedo, Perry', 'Ye, Qing', 'Berger, Bonnie', 'Peng, Jian']		['R01 GM081871/GM/NIGMS NIH HHS/United States', 'T32 HG002295/HG/NHGRI NIH HHS/United States']	1		2405-4712 (Print) 2405-4712 (Linking)	101656080	Cell systems	['eng']	S2405-4712(17)30542-2 [pii] 10.1016/j.cels.2017.11.014 [doi]	20190923	['Algorithms', 'Animals', 'Computational Biology/*methods', 'Databases, Protein', 'Forecasting/*methods', 'Humans', 'Machine Learning', 'Models, Molecular', '*Neural Networks (Computer)', 'Probability', 'Protein Conformation', 'Protein Folding', 'Proteins/*chemistry', 'Sequence Alignment/methods']	2019/09/24 06:00	['NIHMS930472']	['*co-evolution', '*contact prediction', '*convolutional neural networks', '*deep learning', '*evolutionary couplings', '*protein structure prediction', '*structure prediction']	['NOTNLM']	NLM	65-74.e3	['2017/06/21 00:00 [received]', '2017/10/04 00:00 [revised]', '2017/11/22 00:00 [accepted]', '2017/12/25 06:00 [pubmed]', '2019/09/24 06:00 [medline]', '2017/12/25 06:00 [entrez]']	United States	PMC5808454		29275173	ppublish	['Journal Article']		['0 (Proteins)']	IM		Cell Syst. 2018 Jan 24;6(1):65-74.e3. doi: 10.1016/j.cels.2017.11.014. Epub 2017 Dec 20.	MEDLINE	Cell Syst	Enhancing Evolutionary Couplings with Deep Convolutional Neural Networks.		6	Enhancing Evolutionary Couplings with Deep Convolutional Neural Networks.
Motivation: Best performing named entity recognition (NER) methods for biomedical literature are based on hand-crafted features or task-specific rules, which are costly to produce and difficult to generalize to other corpora. End-to-end neural networks achieve state-of-the-art performance without hand-crafted features and task-specific knowledge in non-biomedical NER tasks. However, in the biomedical domain, using the same architecture does not yield competitive performance compared with conventional machine learning models. Results: We propose a novel end-to-end deep learning approach for biomedical NER tasks that leverages the local contexts based on n-gram character and word embeddings via Convolutional Neural Network (CNN). We call this approach GRAM-CNN. To automatically label a word, this method uses the local information around a word. Therefore, the GRAM-CNN method does not require any specific knowledge or feature engineering and can be theoretically applied to a wide range of existing NER problems. The GRAM-CNN approach was evaluated on three well-known biomedical datasets containing different BioNER entities. It obtained an F1-score of 87.26% on the Biocreative II dataset, 87.26% on the NCBI dataset and 72.57% on the JNLPBA dataset. Those results put GRAM-CNN in the lead of the biological NER methods. To the best of our knowledge, we are the first to apply CNN based structures to BioNER problems. Availability and implementation: The GRAM-CNN source code, datasets and pre-trained model are available online at: https://github.com/valdersoul/GRAM-CNN. Contact: andyli@ece.ufl.edu or aconesa@ufl.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL 32611, USA.', 'Department of Computer & Information Science & Engineering, University of Florida, Gainesville, FL 32611, USA.', 'National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL 32611, USA.', 'Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL 32611, USA.', 'Department of Microbiology and Cell Science, Institute for Food and Agricultural Sciences, University of Florida, Gainesville, FL 32611, USA.', 'Genomics of Gene Expression Laboratory, Centro de Investigacion Principe Felipe, Valencia 42012, Spain.', 'Department of Microbiology and Cell Science, Institute for Food and Agricultural Sciences, University of Florida, Gainesville, FL 32611, USA.']	['4764002 [pii]', '10.1093/bioinformatics/btx815 [doi]']	['Zhu Q', 'Li X', 'Conesa A', 'Pereira C']							['2017/12/23 06:00']	20190624		2018 May 1	2017/12/23 06:00		['Zhu, Qile', 'Li, Xiaolin', 'Conesa, Ana', 'Pereira, Cecile']		['R01 GM110240/GM/NIGMS NIH HHS/United States']	9		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx815 [doi]	20190624	['Computational Biology/*methods', '*Deep Learning', 'Software']	2019/06/25 06:00				NLM	1547-1554	['2017/06/02 00:00 [received]', '2017/12/19 00:00 [accepted]', '2017/12/23 06:00 [pubmed]', '2019/06/25 06:00 [medline]', '2017/12/23 06:00 [entrez]']	England	PMC5925775		29272325	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Bioinformatics. 2018 May 1;34(9):1547-1554. doi: 10.1093/bioinformatics/btx815.	MEDLINE	Bioinformatics	GRAM-CNN: a deep learning approach with local context for named entity recognition in biomedical text.		34	GRAM-CNN: a deep learning approach with local context for named entity recognition in biomedical text.
Although we now routinely sequence human genomes, we can confidently identify only a fraction of the sequence variants that have a functional impact. Here, we developed a deep mutational scanning framework that produces exhaustive maps for human missense variants by combining random codon mutagenesis and multiplexed functional variation assays with computational imputation and refinement. We applied this framework to four proteins corresponding to six human genes: UBE2I (encoding SUMO E2 conjugase), SUMO1 (small ubiquitin-like modifier), TPK1 (thiamin pyrophosphokinase), and CALM1/2/3 (three genes encoding the protein calmodulin). The resulting maps recapitulate known protein features and confidently identify pathogenic variation. Assays potentially amenable to deep mutational scanning are already available for 57% of human disease genes, suggesting that DMS could ultimately map functional variation for all human disease genes.	['Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Department of Computer Science, University of Toronto, Toronto, ON, Canada.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Department of Computer Science, University of Toronto, Toronto, ON, Canada.', 'Department of Medical Biochemistry and Microbiology, Uppsala University, Uppsala, Sweden.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'SeqWell Inc, Boston, MA, USA.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Department of Computer Science, University of Toronto, Toronto, ON, Canada.', 'Institute for Research in Biomedicine (IRB Barcelona), The Barcelona Institute for Science and Technology, Barcelona, Catalonia, Spain.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Department of Computer Science, University of Toronto, Toronto, ON, Canada.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Department of Computer Science, University of Toronto, Toronto, ON, Canada.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Invitae Corp., San Francisco, CA, USA.', 'Department of Genome Sciences, University of Washington, Seattle, WA, USA.', 'Invitae Corp., San Francisco, CA, USA.', 'Fred Hutchinson Research Center, Seattle, WA, USA.', 'Center for Cancer Systems Biology (CCSB), Dana-Farber Cancer Institute, Boston, MA, USA.', 'Department of Genetics, Harvard Medical School, Boston, MA, USA.', 'Center for Cancer Systems Biology (CCSB), Dana-Farber Cancer Institute, Boston, MA, USA.', 'Institute for Research in Biomedicine (IRB Barcelona), The Barcelona Institute for Science and Technology, Barcelona, Catalonia, Spain.', 'Institucio Catalana de Recerca I Estudis Avancats (ICREA), Barcelona, Catalonia, Spain.', 'Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada fritz.roth@utoronto.ca.', 'The Donnelly Centre, University of Toronto, Toronto, ON, Canada.', 'Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada.', 'Department of Computer Science, University of Toronto, Toronto, ON, Canada.', 'Canadian Institute for Advanced Research, Toronto, ON, Canada.']	['10.15252/msb.20177908 [doi]']	['Weile J', 'Sun S', 'Cote AG', 'Knapp J', 'Verby M', 'Mellor JC', 'Wu Y', 'Pons C', 'Wong C', 'van Lieshout N', 'Yang F', 'Tasan M', 'Tan G', 'Yang S', 'Fowler DM', 'Nussbaum R', 'Bloom JD', 'Vidal M', 'Hill DE', 'Aloy P', 'Roth FP']	['ORCID: 0000-0003-1628-9390', 'ORCID: 0000-0003-3391-5410', 'ORCID: 0000-0001-5192-0921', 'ORCID: 0000-0002-6628-649X']	['(c) 2017 The Authors. Published under the terms of the CC BY 4.0 license.']					['2017/12/23 06:00']	20181015	20171221	2017 Dec 21	2017/12/23 06:00		['Weile, Jochen', 'Sun, Song', 'Cote, Atina G', 'Knapp, Jennifer', 'Verby, Marta', 'Mellor, Joseph C', 'Wu, Yingzhou', 'Pons, Carles', 'Wong, Cassandra', 'van Lieshout, Natascha', 'Yang, Fan', 'Tasan, Murat', 'Tan, Guihong', 'Yang, Shan', 'Fowler, Douglas M', 'Nussbaum, Robert', 'Bloom, Jesse D', 'Vidal, Marc', 'Hill, David E', 'Aloy, Patrick', 'Roth, Frederick P']		['P50 HG004233/HG/NHGRI NIH HHS/United States', 'R01 GM109110/GM/NIGMS NIH HHS/United States']	12		1744-4292 (Electronic) 1744-4292 (Linking)	101235389	Molecular systems biology	['eng']	10.15252/msb.20177908 [doi]	20190118	['Calmodulin/genetics', 'DNA Mutational Analysis/*methods', 'Disease/genetics', 'Humans', 'Machine Learning', 'Mutation, Missense/*genetics', 'Phenotype', 'Phylogeny', 'Reproducibility of Results', 'SUMO-1 Protein/genetics', 'Ubiquitin-Conjugating Enzymes/genetics/metabolism']	2018/10/16 06:00		['*complementation', '*deep mutational scanning', '*genotype-phenotype', '*variants of uncertain significance']	['NOTNLM']	NLM	957	['2017/12/23 06:00 [entrez]', '2017/12/23 06:00 [pubmed]', '2018/10/16 06:00 [medline]']	England	PMC5740498		29269382	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (Calmodulin)', '0 (SUMO-1 Protein)', 'EC 2.3.2.23 (Ubiquitin-Conjugating Enzymes)', 'EC 6.3.2.- (ubiquitin-conjugating enzyme UBC9)']	IM		Mol Syst Biol. 2017 Dec 21;13(12):957. doi: 10.15252/msb.20177908.	MEDLINE	Mol Syst Biol	A framework for exhaustively mapping functional missense variants.		13	A framework for exhaustively mapping functional missense variants.
Current cancer diagnosis employs various nuclear morphometric measures. While these have allowed accurate late-stage prognosis, early diagnosis is still a major challenge. Recent evidence highlights the importance of alterations in mechanical properties of single cells and their nuclei as critical drivers for the onset of cancer. We here present a method to detect subtle changes in nuclear morphometrics at single-cell resolution by combining fluorescence imaging and deep learning. This assay includes a convolutional neural net pipeline and allows us to discriminate between normal and human breast cancer cell lines (fibrocystic and metastatic states) as well as normal and cancer cells in tissue slices with high accuracy. Further, we establish the sensitivity of our pipeline by detecting subtle alterations in normal cells when subjected to small mechano-chemical perturbations that mimic tumor microenvironments. In addition, our assay provides interpretable features that could aid pathological inspections. This pipeline opens new avenues for early disease diagnostics and drug discovery.	['Department of Electrical Engineering and Computer Science, Laboratory for Information and Decision Systems, Institute for Data, Systems and Society, MIT, Cambridge, MA, USA.', 'Mechanobiology Institute and Department of Biological Sciences, National University of Singapore, Singapore, Singapore.', 'Department of Electrical Engineering and Computer Science, Laboratory for Information and Decision Systems, Institute for Data, Systems and Society, MIT, Cambridge, MA, USA.', 'Department of Electrical Engineering and Computer Science, Laboratory for Information and Decision Systems, Institute for Data, Systems and Society, MIT, Cambridge, MA, USA. cuhler@mit.edu.', 'Mechanobiology Institute and Department of Biological Sciences, National University of Singapore, Singapore, Singapore. shiva.gvs@gmail.com.', 'FIRC Institute for Molecular Oncology (IFOM), Milan, Italy. shiva.gvs@gmail.com.']	['10.1038/s41598-017-17858-1 [doi]', '10.1038/s41598-017-17858-1 [pii]']	['Radhakrishnan A', 'Damodaran K', 'Soylemezoglu AC', 'Uhler C', 'Shivashankar GV']							['2017/12/22 06:00']	20190802	20171220	2017 Dec 20	2017/12/22 06:00		['Radhakrishnan, Adityanarayanan', 'Damodaran, Karthik', 'Soylemezoglu, Ali C', 'Uhler, Caroline', 'Shivashankar, G V']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-17858-1 [doi]	20190802	['Biomarkers, Tumor', 'Cell Line, Tumor/ultrastructure', 'Cell Nucleus/*ultrastructure', '*Deep Learning', 'Humans', 'Image Interpretation, Computer-Assisted/methods', 'Neoplasms/*diagnosis/diagnostic imaging/ultrastructure', 'Neural Networks (Computer)', 'Optical Imaging/methods']	2019/08/03 06:00				NLM	17946	['2017/09/14 00:00 [received]', '2017/11/30 00:00 [accepted]', '2017/12/22 06:00 [entrez]', '2017/12/22 06:00 [pubmed]', '2019/08/03 06:00 [medline]']	England	PMC5738417		29263424	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Biomarkers, Tumor)']			Sci Rep. 2017 Dec 20;7(1):17946. doi: 10.1038/s41598-017-17858-1.	MEDLINE	Sci Rep	Machine Learning for Nuclear Mechano-Morphometric Biomarkers in Cancer Diagnosis.		7	Machine Learning for Nuclear Mechano-Morphometric Biomarkers in Cancer Diagnosis.
While tuberculosis (TB) disease was discovered more than a century ago, it has not been eradicated yet. Quite contrary, at present, TB constitutes one of the top 10 causes of death and has shown signs of increasing. To complement the conventional diagnostic procedure of applying microbiological culture that takes several weeks and remains expensive, high resolution computer tomography (CT) of pulmonary images has been resorted to not only for aiding clinicians to expedite the process of diagnosis but also for monitoring prognosis when administering antibiotic drugs. This research undertakes the investigation of predicting multidrug-resistant (MDR) patients from drug-sensitive (DS) ones based on CT lung images to monitor the effectiveness of treatment. To contend with smaller data sets (i.e., hundreds) and the characteristics of CT TB images with limited regions capturing abnormities, patch-based deep convolutional neural network (CNN) allied to support vector machine (SVM) classifier is implemented on a collection of data sets from 230 patients obtained from the ImageCLEF 2017 competition. As a result, the proposed architecture of CNN + SVM + patch performs the best with classification accuracy rate at 91.11% (79.80% in terms of patches). In addition, a hand-crafted SIFT based approach accomplishes 88.88% in terms of subject and 83.56% with reference to patches, the highest in this study, which can be explained away by the fact that the data sets are in small numbers. Significantly, during the Tuberculosis Competition at ImageCLEF 2017, the authors took part in the task of classification of 5 types of TB disease and achieved the top one with regard to averaged classification accuracy (i.e., ACC = 0.4067), which is also premised on the approach of CNN + SVM + patch. On the other hand, when the whole slices of 3D TB data sets are applied to train a CNN network, the best result is achieved through the application of CNN coupled with orderless pooling and SVM at 64.71% accuracy rate.	['Department of Computer Science , Middlesex University , London NW4 4BT , U.K.', 'Cortexica Vision Systems , London , U.K.']	['10.1021/acs.molpharmaceut.7b00875 [doi]']	['Gao XW', 'Qian Y']	['ORCID: 0000-0002-8103-6624']						['2017/12/20 06:00']	20190819	20180129	2018 Oct 1	2017/12/20 06:00		['Gao, Xiaohong W', 'Qian, Yu']			10		1543-8392 (Electronic) 1543-8384 (Linking)	101197791	Molecular pharmaceutics	['eng']	10.1021/acs.molpharmaceut.7b00875 [doi]	20190819	['*Deep Learning', 'Humans', 'Neural Networks (Computer)', 'Support Vector Machine', 'Tomography, X-Ray Computed/*methods', 'Tuberculosis, Multidrug-Resistant/*diagnostic imaging']	2019/08/20 06:00		['*SVM', '*classification', '*deep learning', '*multidrug-resistant TB', '*patch-based image classification', '*tuberculosis (TB)']	['NOTNLM']	NLM	4326-4335	['2017/12/20 06:00 [pubmed]', '2019/08/20 06:00 [medline]', '2017/12/20 06:00 [entrez]']	United States			29257894	ppublish	['Journal Article']					Mol Pharm. 2018 Oct 1;15(10):4326-4335. doi: 10.1021/acs.molpharmaceut.7b00875. Epub 2018 Jan 29.	MEDLINE	Mol Pharm	Prediction of Multidrug-Resistant TB from CT Pulmonary Images Based on Deep Learning Techniques.		15	Prediction of Multidrug-Resistant TB from CT Pulmonary Images Based on Deep Learning Techniques.
BACKGROUND: RNA sequencing technique (RNA-seq) enables scientists to develop novel data-driven methods for discovering more unidentified lincRNAs. Meantime, knowledge-based technologies are experiencing a potential revolution ignited by the new deep learning methods. By scanning the newly found data set from RNA-seq, scientists have found that: (1) the expression of lincRNAs appears to be regulated, that is, the relevance exists along the DNA sequences; (2) lincRNAs contain some conversed patterns/motifs tethered together by non-conserved regions. The two evidences give the reasoning for adopting knowledge-based deep learning methods in lincRNA detection. Similar to coding region transcription, non-coding regions are split at transcriptional sites. However, regulatory RNAs rather than message RNAs are generated. That is, the transcribed RNAs participate the biological process as regulatory units instead of generating proteins. Identifying these transcriptional regions from non-coding regions is the first step towards lincRNA recognition. RESULTS: The auto-encoder method achieves 100% and 92.4% prediction accuracy on transcription sites over the putative data sets. The experimental results also show the excellent performance of predictive deep neural network on the lincRNA data sets compared with support vector machine and traditional neural network. In addition, it is validated through the newly discovered lincRNA data set and one unreported transcription site is found by feeding the whole annotated sequences through the deep learning machine, which indicates that deep learning method has the extensive ability for lincRNA prediction. CONCLUSIONS: The transcriptional sequences of lincRNAs are collected from the annotated human DNA genome data. Subsequently, a two-layer deep neural network is developed for the lincRNA detection, which adopts the auto-encoder algorithm and utilizes different encoding schemes to obtain the best performance over intergenic DNA sequence data. Driven by those newly annotated lincRNA data, deep learning methods based on auto-encoder algorithm can exert their capability in knowledge learning in order to capture the useful features and the information correlation along DNA genome sequences for lincRNA detection. As our knowledge, this is the first application to adopt the deep learning techniques for identifying lincRNA transcription sequences.	['Department of Computing Sciences, The College at Brockport, State University of New York, 350 New Campus Drive, Brockport, 14420, NY, USA. nyu@brockport.edu.', 'School of Information Science and Technology, Southwest Jiaotong University, Chengdu, 610031, Sihuan, China.', 'Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, USA.']	['10.1186/s12859-017-1922-3 [doi]', '10.1186/s12859-017-1922-3 [pii]']	['Yu N', 'Yu Z', 'Pan Y']							['2017/12/16 06:00']	20180307	20171206	2017 Dec 6	2017/12/16 06:00		['Yu, Ning', 'Yu, Zeng', 'Pan, Yi']			Suppl 15		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-017-1922-3 [doi]	20181202	['*Algorithms', 'Computational Biology/*methods', 'Humans', '*Machine Learning', 'RNA, Long Noncoding/*genetics', 'Sequence Analysis, RNA/*methods']	2018/03/08 06:00		['Auto-encoder', 'Deep learning', 'Knowledge-based discovery', 'Long intergenic non-coding RNA (lincRNA)', 'RNA-seq', 'Transcription sites']	['NOTNLM']	NLM	511	['2017/12/16 06:00 [entrez]', '2017/12/16 06:00 [pubmed]', '2018/03/08 06:00 [medline]']	England	PMC5731497		29244011	epublish	['Journal Article']		['0 (RNA, Long Noncoding)']	IM		BMC Bioinformatics. 2017 Dec 6;18(Suppl 15):511. doi: 10.1186/s12859-017-1922-3.	MEDLINE	BMC Bioinformatics	A deep learning method for lincRNA detection using auto-encoder algorithm.		18	A deep learning method for lincRNA detection using auto-encoder algorithm.
Deep learning has revolutionized research in image processing, speech recognition, natural language processing, game playing, and will soon revolutionize research in proteomics and genomics. Through three examples in genomics, protein structure prediction, and proteomics, we demonstrate that deep learning is changing bioinformatics research, shifting from algorithm-centric to data-centric approaches.	['David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada.', 'David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada.', 'State Key Laboratory of Pathogen and Biosecurity, Beijing Institute of Microbiology and Epidemiology, Beijing, P.R. China.', 'David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada.']	['10.1002/pmic.201700319 [doi]']	['Tran NH', 'Zhang X', 'Li M']		['(c) 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.']					['2017/12/15 06:00']	20190212	20171229	2018 Jan	2017/12/15 06:00		['Tran, Ngoc Hieu', 'Zhang, Xianglilan', 'Li, Ming']			2		1615-9861 (Electronic) 1615-9853 (Linking)	101092707	Proteomics	['eng']	10.1002/pmic.201700319 [doi]	20190215	['*Algorithms', 'Computational Biology/*methods', 'Genomics/*methods', 'Humans', 'Machine Learning', 'Natural Language Processing', 'Proteins/genetics/metabolism', 'Proteomics/*methods']	2019/02/13 06:00		['*big data', '*bioinformatics', '*deep learning', '*genomics', '*neural networks', '*proteomics']	['NOTNLM']	NLM		['2017/10/05 00:00 [received]', '2017/11/21 00:00 [revised]', '2017/12/15 06:00 [pubmed]', '2019/02/13 06:00 [medline]', '2017/12/15 06:00 [entrez]']	Germany			29239117	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		Proteomics. 2018 Jan;18(2). doi: 10.1002/pmic.201700319. Epub 2017 Dec 29.	MEDLINE	Proteomics	Deep Omics.		18	Deep Omics.
Importance: Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency. Objective: Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin-stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists' diagnoses in a diagnostic setting. Design, Setting, and Participants: Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). Exposures: Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. Main Outcomes and Measures: The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. Results: The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P < .001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95% CI, 0.927-0.998] for the pathologist WOTC). Conclusions and Relevance: In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.	"['Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Medical Image Analysis Group, Eindhoven University of Technology, Eindhoven, the Netherlands.', 'Department of Pathology, University Medical Center Utrecht, Utrecht, the Netherlands.', 'Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Department of Pathology, University Medical Center Utrecht, Utrecht, the Netherlands.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Laboratorium Pathologie Oost Nederland, Hengelo, the Netherlands.', 'Department of Pathology, University Medical Center Utrecht, Utrecht, the Netherlands.', 'Rijnstate Hospital, Arnhem, the Netherlands.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, Massachusetts.', 'BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, Massachusetts.', 'PathAI, Cambridge, Massachusetts.', 'BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, Massachusetts.', 'PathAI, Cambridge, Massachusetts.', 'PathAI, Cambridge, Massachusetts.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts.', 'Harker School, San Jose, California.', 'BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, Massachusetts.', 'Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, Massachusetts.', 'Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, Massachusetts.', 'Chinese University of Hong Kong, Hong Kong, China.', 'Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, Massachusetts.', 'Chinese University of Hong Kong, Hong Kong, China.', 'Chinese University of Hong Kong, Hong Kong, China.', 'Chinese University of Hong Kong, Hong Kong, China.', 'ExB Research and Development GmbH, Munich, Germany.', 'ExB Research and Development GmbH, Munich, Germany.', 'Munich Business School, Munich, Germany.', 'Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey.', 'Neuroscience and Neurotechnology, Graduate School of Natural and Applied Sciences, Middle East Technical University, Ankara, Turkey.', 'Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey.', 'Cancer System Biology Laboratory, Graduate School of Informatics, Middle East Technical University, Ankara, Turkey.', 'NLP LOGIX, Jacksonville, Florida.', 'Smart Imaging Technologies, Houston, Texas.', 'Smart Imaging Technologies, Houston, Texas.', 'Department of Electrical and Computer Engineering, University of Toronto, Toronto, Ontario, Canada.', 'Tissue Image Analytics Lab, Department of Computer Science, University of Warwick, Coventry, United Kingdom.', 'Tissue Image Analytics Lab, Department of Computer Science, University of Warwick, Coventry, United Kingdom.', 'Department of Pathology, University Hospitals Coventry and Warwickshire National Health Service Foundation Trust, Coventry, United Kingdom.', 'Department of Computer Science and Engineering, Qatar University, Doha, Qatar.', 'Tissue Image Analytics Lab, Department of Computer Science, University of Warwick, Coventry, United Kingdom.', 'Tissue Image Analytics Lab, Department of Computer Science, University of Warwick, Coventry, United Kingdom.', 'Department of Pathology, University Hospitals Coventry and Warwickshire National Health Service Foundation Trust, Coventry, United Kingdom.', 'Department of Pathology, Radboud University Medical Center, Nijmegen, the Netherlands.', 'Hochschule fur Technik und Wirtschaft, Berlin, Germany.', 'Hochschule fur Technik und Wirtschaft, Berlin, Germany.', 'BioMediTech Institute and Faculty of Medicine and Life Sciences, Tampere University of Technology, Tampere, Finland.', 'Hochschule fur Technik und Wirtschaft, Berlin, Germany.', 'BioMediTech Institute and Faculty of Biomedical Science and Engineering, Tampere University of Technology, Tampere, Finland.', 'Prostate Cancer Research Center, Faculty of Medicine and Life Sciences and BioMediTech, University of Tampere, Tampere, Finland.', 'Hochschule fur Technik und Wirtschaft, Berlin, Germany.', 'Faculty of Computing and Electrical Engineering, Tampere University of Technology, Pori, Finland.', 'Hochschule fur Technik und Wirtschaft, Berlin, Germany.', 'Technical University of Munich, Munich, Germany.', 'Technical University of Munich, Munich, Germany.', 'Technical University of Munich, Munich, Germany.', 'Technical University of Munich, Munich, Germany.', 'Technical University of Munich, Munich, Germany.', 'Department of Bioinformatic Engineering, Osaka University.', 'Department of Bioinformatic Engineering, Osaka University.', 'Department of Bioinformatic Engineering, Osaka University.', 'Department of Bioinformatic Engineering, Osaka University.', 'University of South Florida, Tampa, Florida.', 'Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus.', 'Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus.', 'Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus.', 'Visilab, University of Castilla-La Mancha, Ciudad Real, Spain.', 'Visilab, University of Castilla-La Mancha, Ciudad Real, Spain.', 'Visilab, University of Castilla-La Mancha, Ciudad Real, Spain.', 'Visilab, University of Castilla-La Mancha, Ciudad Real, Spain.', ""INSERM, Laboratoire d'Imagerie Biomedicale, Sorbonne Universites, Pierre and Marie Curie University, Paris, France."", 'Pontifical Catholic University of Peru, San Miguel, Lima, Peru.', 'Sorbonne University, Pierre and Marie Curie University, Paris, France.']"	['2665774 [pii]', '10.1001/jama.2017.14585 [doi]']	['Ehteshami Bejnordi B', 'Veta M', 'Johannes van Diest P', 'van Ginneken B', 'Karssemeijer N', 'Litjens G', 'van der Laak JAWM', 'Hermsen M', 'Manson QF', 'Balkenhol M', 'Geessink O', 'Stathonikos N', 'van Dijk MC', 'Bult P', 'Beca F', 'Beck AH', 'Wang D', 'Khosla A', 'Gargeya R', 'Irshad H', 'Zhong A', 'Dou Q', 'Li Q', 'Chen H', 'Lin HJ', 'Heng PA', 'Hass C', 'Bruni E', 'Wong Q', 'Halici U', 'Oner MU', 'Cetin-Atalay R', 'Berseth M', 'Khvatkov V', 'Vylegzhanin A', 'Kraus O', 'Shaban M', 'Rajpoot N', 'Awan R', 'Sirinukunwattana K', 'Qaiser T', 'Tsang YW', 'Tellez D', 'Annuscheit J', 'Hufnagl P', 'Valkonen M', 'Kartasalo K', 'Latonen L', 'Ruusuvuori P', 'Liimatainen K', 'Albarqouni S', 'Mungal B', 'George A', 'Demirci S', 'Navab N', 'Watanabe S', 'Seno S', 'Takenaka Y', 'Matsuda H', 'Ahmady Phoulady H', 'Kovalev V', 'Kalinovsky A', 'Liauchuk V', 'Bueno G', 'Fernandez-Carrobles MM', 'Serrano I', 'Deniz O', 'Racoceanu D', 'Venancio R']			['JAMA. 2017 Dec 12;318(22):2184-2186. PMID: 29234791', 'JAMA. 2017 Dec 12;318(22):2250-2251. PMID: 29234793', 'JAMA Oncol. 2018 Mar 1;4(3):403-404. PMID: 29392271', 'Nature. 2018 Mar 15;555(7696):285. PMID: 29542717', 'JAMA. 2018 Apr 24;319(16):1725-1726. PMID: 29710156']	['the CAMELYON16 Consortium']			['2017/12/14 06:00']	20171222		2017 Dec 12	2017/12/14 06:00		['Ehteshami Bejnordi, Babak', 'Veta, Mitko', 'Johannes van Diest, Paul', 'van Ginneken, Bram', 'Karssemeijer, Nico', 'Litjens, Geert', 'van der Laak, Jeroen A W M', 'Hermsen, Meyke', 'Manson, Quirine F', 'Balkenhol, Maschenka', 'Geessink, Oscar', 'Stathonikos, Nikolaos', 'van Dijk, Marcory Crf', 'Bult, Peter', 'Beca, Francisco', 'Beck, Andrew H', 'Wang, Dayong', 'Khosla, Aditya', 'Gargeya, Rishab', 'Irshad, Humayun', 'Zhong, Aoxiao', 'Dou, Qi', 'Li, Quanzheng', 'Chen, Hao', 'Lin, Huang-Jing', 'Heng, Pheng-Ann', 'Hass, Christian', 'Bruni, Elia', 'Wong, Quincy', 'Halici, Ugur', 'Oner, Mustafa Umit', 'Cetin-Atalay, Rengul', 'Berseth, Matt', 'Khvatkov, Vitali', 'Vylegzhanin, Alexei', 'Kraus, Oren', 'Shaban, Muhammad', 'Rajpoot, Nasir', 'Awan, Ruqayya', 'Sirinukunwattana, Korsuk', 'Qaiser, Talha', 'Tsang, Yee-Wah', 'Tellez, David', 'Annuscheit, Jonas', 'Hufnagl, Peter', 'Valkonen, Mira', 'Kartasalo, Kimmo', 'Latonen, Leena', 'Ruusuvuori, Pekka', 'Liimatainen, Kaisa', 'Albarqouni, Shadi', 'Mungal, Bharti', 'George, Ami', 'Demirci, Stefanie', 'Navab, Nassir', 'Watanabe, Seiryo', 'Seno, Shigeto', 'Takenaka, Yoichi', 'Matsuda, Hideo', 'Ahmady Phoulady, Hady', 'Kovalev, Vassili', 'Kalinovsky, Alexander', 'Liauchuk, Vitali', 'Bueno, Gloria', 'Fernandez-Carrobles, M Milagro', 'Serrano, Ismael', 'Deniz, Oscar', 'Racoceanu, Daniel', 'Venancio, Rui']			22		1538-3598 (Electronic) 0098-7484 (Linking)	7501160	JAMA	['eng']	10.1001/jama.2017.14585 [doi]	20181113	['Algorithms', 'Breast Neoplasms/*pathology', 'Female', 'Humans', 'Lymphatic Metastasis/*diagnosis/pathology', '*Machine Learning', '*Pathologists', 'Pathology, Clinical', 'ROC Curve']	2017/12/23 06:00				NLM	2199-2210	['2017/12/14 06:00 [entrez]', '2017/12/14 06:00 [pubmed]', '2017/12/23 06:00 [medline]']	United States	PMC5820737		29234806	ppublish	['Comparative Study', 'Journal Article']			AIM IM		JAMA. 2017 Dec 12;318(22):2199-2210. doi: 10.1001/jama.2017.14585.	MEDLINE	JAMA	Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer.		318	Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer.
Bullying is an everlasting phenomenon and the first, yet difficult, step towards the solution is its detection. Conventional approaches for bullying incidence identification include questionnaires, conversations and psychological tests. Here, unlike the conventional approaches, two experiments are proposed that involve visual stimuli with cases of bullying- and non-bullying- related ones, set within a 2D (simple video preview) and a Virtual Reality (VR) (immersive video preview) context. In both experimental settings, brain activity is recorded using high density (HD) (256 channels) electroencephalogram (EEG), and analyzed to identify the bullying stimuli type (bullying/non-bullying) and context (2D/VR). The proposed classification analysis uses a convolutional neural network (CNN), applying deep learning on the oscillatory modes (OCMs) embedded within the raw HD EEG data. The extraction of OCMs from the HD EEG data is achieved with swarm decomposition (SWD), which efficiently accounts for the non-stationarity and noise contamination of the raw HD EEG data. Experimental results from 17 subjects indicate that the new SWD/CNN approach achieves high discrimination accuracy (AUC = 0.987 between bullying/non-bullying stimuli type; AUC = 0.975, between bullying/non-bullying stimuli type and 2D/VR context), paving the way for better understanding of how brain's responses could act as indicators of bullying experience within immersive environments.	['Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, GR, 54124, Thessaloniki, Greece.', 'Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, GR, 54124, Thessaloniki, Greece.', 'Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, GR, 54124, Thessaloniki, Greece.', 'Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, GR, 54124, Thessaloniki, Greece. leontios@auth.gr.', 'Department of Electrical and Computer Engineering, Khalifa University of Science and Technology, P. O. BOX 127788, Abu Dhabi, UAE. leontios@auth.gr.']	['10.1038/s41598-017-17562-0 [doi]', '10.1038/s41598-017-17562-0 [pii]']	['Baltatzis V', 'Bintsi KM', 'Apostolidis GK', 'Hadjileontiadis LJ']	['ORCID: 0000-0002-8683-0229']						['2017/12/13 06:00']	20190724	20171211	2017 Dec 11	2017/12/13 06:00		['Baltatzis, Vasileios', 'Bintsi, Kyriaki-Margarita', 'Apostolidis, Georgios K', 'Hadjileontiadis, Leontios J']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-17562-0 [doi]	20190724	['Adult', 'Brain/*physiopathology', 'Bullying/*statistics & numerical data', 'Computer Simulation', '*Deep Learning', 'Electroencephalography/*methods', 'Female', 'Humans', 'Incidence', 'Male', '*Neural Networks (Computer)', '*Virtual Reality', 'Young Adult']	2019/07/25 06:00				NLM	17292	['2017/06/29 00:00 [received]', '2017/11/28 00:00 [accepted]', '2017/12/13 06:00 [entrez]', '2017/12/13 06:00 [pubmed]', '2019/07/25 06:00 [medline]']	England	PMC5725430		29230046	epublish	['Journal Article']					Sci Rep. 2017 Dec 11;7(1):17292. doi: 10.1038/s41598-017-17562-0.	MEDLINE	Sci Rep	Bullying incidences identification within an immersive environment using HD EEG-based analysis: A Swarm Decomposition and Deep Learning approach.		7	Bullying incidences identification within an immersive environment using HD EEG-based analysis: A Swarm Decomposition and Deep Learning approach.
Motivation: Significant improvements in the prediction of protein residue-residue contacts are observed in the recent years. These contacts, predicted using a variety of coevolution-based and machine learning methods, are the key contributors to the recent progress in ab initio protein structure prediction, as demonstrated in the recent CASP experiments. Continuing the development of new methods to reliably predict contact maps is essential to further improve ab initio structure prediction. Results: In this paper we discuss DNCON2, an improved protein contact map predictor based on two-level deep convolutional neural networks. It consists of six convolutional neural networks-the first five predict contacts at 6, 7.5, 8, 8.5 and 10 A distance thresholds, and the last one uses these five predictions as additional features to predict final contact maps. On the free-modeling datasets in CASP10, 11 and 12 experiments, DNCON2 achieves mean precisions of 35, 50 and 53.4%, respectively, higher than 30.6% by MetaPSICOV on CASP10 dataset, 34% by MetaPSICOV on CASP11 dataset and 46.3% by Raptor-X on CASP12 dataset, when top L/5 long-range contacts are evaluated. We attribute the improved performance of DNCON2 to the inclusion of short- and medium-range contacts into training, two-level approach to prediction, use of the state-of-the-art optimization and activation functions, and a novel deep learning architecture that allows each filter in a convolutional layer to access all the input features of a protein of arbitrary length. Availability and implementation: The web server of DNCON2 is at http://sysbio.rnet.missouri.edu/dncon2/ where training and testing datasets as well as the predictions for CASP10, 11 and 12 free-modeling datasets can also be downloaded. Its source code is available at https://github.com/multicom-toolbox/DNCON2/. Contact: chengji@missouri.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, MO 63121, USA.', 'Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, MO 63121, USA.', 'Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, MO 63121, USA.', 'Informatics Institute, University of Missouri, Columbia, MO 65211, USA.']	['4708303 [pii]', '10.1093/bioinformatics/btx781 [doi]']	['Adhikari B', 'Hou J', 'Cheng J']							['2017/12/12 06:00']	20190305		2018 May 1	2017/12/12 06:00		['Adhikari, Badri', 'Hou, Jie', 'Cheng, Jianlin']		['R01 GM093123/GM/NIGMS NIH HHS/United States']	9		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx781 [doi]	20190305	['Caspases/chemistry/metabolism', 'Computational Biology/methods', '*Machine Learning', '*Neural Networks (Computer)', '*Protein Conformation', 'Sequence Analysis, Protein']	2019/03/06 06:00				NLM	1466-1472	['2017/06/30 00:00 [received]', '2017/12/07 00:00 [accepted]', '2017/12/12 06:00 [pubmed]', '2019/03/06 06:00 [medline]', '2017/12/12 06:00 [entrez]']	England	PMC5925776		29228185	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['EC 3.4.22.- (Caspases)']	IM		Bioinformatics. 2018 May 1;34(9):1466-1472. doi: 10.1093/bioinformatics/btx781.	MEDLINE	Bioinformatics	DNCON2: improved protein contact prediction using two-level deep convolutional neural networks.		34	DNCON2: improved protein contact prediction using two-level deep convolutional neural networks.
BACKGROUND: With the rapid development of deep sequencing techniques in the recent years, enhancers have been systematically identified in such projects as FANTOM and ENCODE, forming genome-wide landscapes in a series of human cell lines. Nevertheless, experimental approaches are still costly and time consuming for large scale identification of enhancers across a variety of tissues under different disease status, making computational identification of enhancers indispensable. RESULTS: To facilitate the identification of enhancers, we propose a computational framework, named DeepEnhancer, to distinguish enhancers from background genomic sequences. Our method purely relies on DNA sequences to predict enhancers in an end-to-end manner by using a deep convolutional neural network (CNN). We train our deep learning model on permissive enhancers and then adopt a transfer learning strategy to fine-tune the model on enhancers specific to a cell line. Results demonstrate the effectiveness and efficiency of our method in the classification of enhancers against random sequences, exhibiting advantages of deep learning over traditional sequence-based classifiers. We then construct a variety of neural networks with different architectures and show the usefulness of such techniques as max-pooling and batch normalization in our method. To gain the interpretability of our approach, we further visualize convolutional kernels as sequence logos and successfully identify similar motifs in the JASPAR database. CONCLUSIONS: DeepEnhancer enables the identification of novel enhancers using only DNA sequences via a highly accurate deep learning model. The proposed computational framework can also be applied to similar problems, thereby prompting the use of machine learning methods in life sciences.	['MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China.', 'Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Tsinghua University, Beijing, 100084, China.', 'MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China.', 'Department of Automation, Tsinghua University, Beijing, 100084, China.', 'MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China.', 'Department of Automation, Tsinghua University, Beijing, 100084, China.', 'MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China.', 'Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Tsinghua University, Beijing, 100084, China.', 'MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China.', 'Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Tsinghua University, Beijing, 100084, China.', 'Program in Computational Biology and Bioinformatics, University of Southern California, Los Angeles, CA, 90089, USA.', 'MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China. ruijiang@tsinghua.edu.cn.', 'Department of Automation, Tsinghua University, Beijing, 100084, China. ruijiang@tsinghua.edu.cn.']	['10.1186/s12859-017-1878-3 [doi]', '10.1186/s12859-017-1878-3 [pii]']	['Min X', 'Zeng W', 'Chen S', 'Chen N', 'Chen T', 'Jiang R']							['2017/12/09 06:00']	20180130	20171201	2017 Dec 1	2017/12/09 06:00		['Min, Xu', 'Zeng, Wanwen', 'Chen, Shengquan', 'Chen, Ning', 'Chen, Ting', 'Jiang, Rui']			Suppl 13		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-017-1878-3 [doi]	20181202	['*Algorithms', 'Computational Biology', 'DNA/*chemistry/genetics', 'Databases, Factual', '*Enhancer Elements, Genetic', 'Genome, Human', 'Genomics', 'Humans', 'Machine Learning', '*Models, Genetic', '*Neural Networks (Computer)']	2018/01/31 06:00				NLM	478	['2017/12/09 06:00 [entrez]', '2017/12/09 06:00 [pubmed]', '2018/01/31 06:00 [medline]']	England	PMC5773911		29219068	epublish	['Journal Article']		['9007-49-2 (DNA)']	IM		BMC Bioinformatics. 2017 Dec 1;18(Suppl 13):478. doi: 10.1186/s12859-017-1878-3.	MEDLINE	BMC Bioinformatics	Predicting enhancers with deep convolutional neural networks.		18	Predicting enhancers with deep convolutional neural networks.
The goals of this workshop are to discuss challenges in explainability of current Machine Leaning and Deep Analytics (MLDA) used in biocomputing and to start the discussion on ways to improve it. We define explainability in MLDA as easy to use information explaining why and how the MLDA approach made its decisions. We believe that much greater effort is needed to address the issue of MLDA explainability because of: 1) the ever increasing use and dependence on MLDA in biocomputing including the need for increased adoption by non-MLD experts; 2) the diversity, complexity and scale of biocomputing data and MLDA algorithms; 3) the emerging importance of MLDA-based decisions in patient care, in daily research, as well as in the development of new costly medical procedures and drugs. This workshop aims to: a) analyze and challenge the current level of explainability of MLDA methods and practices in biocomputing; b) explore benefits of improvements in this area; and c) provide useful and practical guidance to the biocomputing community on how to address these challenges and how to develop improvements. The workshop format is designed to encourage a lively discussion with panelists to first motivate and understand the problem and then to define next steps and solutions needed to improve MLDA explainability.	['Computer Science Department, San Francisco State University (SFSU), 1600 Holloway Ave, San Francisco, CA 94132, USA, Petkovic@sfsu.edu.']	['9789813235533_0058 [pii]']	['Petkovic D', 'Kobzik L', 'Re C']							['2017/12/09 06:00']	20180827		2018	2017/12/09 06:00		['Petkovic, Dragutin', 'Kobzik, Lester', 'Re, Christopher']					2335-6936 (Electronic) 2335-6928 (Linking)	9711271	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	['eng']		20181202	['Algorithms', 'Artificial Intelligence', 'Cluster Analysis', 'Computational Biology/*methods', 'Decision Support Techniques', 'Gene Expression Profiling/statistics & numerical data', 'Humans', 'Machine Learning/*statistics & numerical data', 'Neural Networks (Computer)', 'Single-Cell Analysis/statistics & numerical data']	2018/08/28 06:00				NLM	623-627	['2017/12/09 06:00 [entrez]', '2017/12/09 06:00 [pubmed]', '2018/08/28 06:00 [medline]']	United States			29218921	ppublish	['Congress']			IM		Pac Symp Biocomput. 2018;23:623-627.	MEDLINE	Pac Symp Biocomput	Machine learning and deep analytics for biocomputing: call for better explainability.		23	Machine learning and deep analytics for biocomputing: call for better explainability.
Survival prediction is very important in medical treatment. However, recent leading research is challenged by two factors: 1) the datasets usually come with multi-modality; and 2) sample sizes are relatively small. To solve the above challenges, we developed a deep survival learning model to predict patients' survival outcomes by integrating multi-view data. The proposed network contains two sub-networks, one view-specific and one common sub-network. We designated one CNN-based and one FCN-based sub-network to efficiently handle pathological images and molecular profiles, respectively. Our model first explicitly maximizes the correlation among the views and then transfers feature hierarchies from view commonality and specifically fine-tunes on the survival prediction task. We evaluate our method on real lung and brain tumor data sets to demonstrate the effectiveness of the proposed model using data with multiple modalities across different tumor types.	['Colleyville Heritage High School, Colleyville, TX, 76034, USA, (2)Highland Park High School, Dallas, TX, 75205, USA, (3)Department of Clinical Science, The University of Texas Southwestern Medical Center, Dallas, TX, 75390, USA.']	['9789813235533_0032 [pii]']	['Huang C', 'Zhang A', 'Xiao G']							['2017/12/09 06:00']	20180827		2018	2017/12/09 06:00		['Huang, Chenglong', 'Zhang, Albert', 'Xiao, Guanghua']					2335-6936 (Electronic) 2335-6928 (Linking)	9711271	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	['eng']		20180906	['Brain Neoplasms/genetics/pathology', 'Carcinoma, Squamous Cell/genetics/pathology', 'Computational Biology/methods', 'Databases, Factual/statistics & numerical data', 'Databases, Genetic/statistics & numerical data', 'Glioblastoma/genetics/pathology', 'Humans', 'Lung Neoplasms/genetics/pathology', 'Machine Learning', 'Models, Statistical', '*Neural Networks (Computer)', 'Proportional Hazards Models', '*Survival Analysis']	2018/08/28 06:00				NLM	343-352	['2017/12/09 06:00 [entrez]', '2017/12/09 06:00 [pubmed]', '2018/08/28 06:00 [medline]']	United States			29218895	ppublish	['Journal Article']			IM		Pac Symp Biocomput. 2018;23:343-352.	MEDLINE	Pac Symp Biocomput	Deep Integrative Analysis for Survival Prediction.		23	Deep Integrative Analysis for Survival Prediction.
Breast density is one of the most significant factors that is associated with cancer risk. In this study, our purpose was to develop a supervised deep learning approach for automated estimation of percentage density (PD) on digital mammograms (DMs). The input 'for processing' DMs was first log-transformed, enhanced by a multi-resolution preprocessing scheme, and subsampled to a pixel size of 800 microm x 800 microm from 100 microm x 100 microm. A deep convolutional neural network (DCNN) was trained to estimate a probability map of breast density (PMD) by using a domain adaptation resampling method. The PD was estimated as the ratio of the dense area to the breast area based on the PMD. The DCNN approach was compared to a feature-based statistical learning approach. Gray level, texture and morphological features were extracted and a least absolute shrinkage and selection operator was used to combine the features into a feature-based PMD. With approval of the Institutional Review Board, we retrospectively collected a training set of 478 DMs and an independent test set of 183 DMs from patient files in our institution. Two experienced mammography quality standards act radiologists interactively segmented PD as the reference standard. Ten-fold cross-validation was used for model selection and evaluation with the training set. With cross-validation, DCNN obtained a Dice's coefficient (DC) of 0.79 +/- 0.13 and Pearson's correlation (r) of 0.97, whereas feature-based learning obtained DC = 0.72 +/- 0.18 and r = 0.85. For the independent test set, DCNN achieved DC = 0.76 +/- 0.09 and r = 0.94, while feature-based learning achieved DC = 0.62 +/- 0.21 and r = 0.75. Our DCNN approach was significantly better and more robust than the feature-based learning approach for automated PD estimation on DMs, demonstrating its potential use for automated density reporting as well as for model-based risk prediction.	"[""School of Mathematics, Sun Yat-Sen University, Guangzhou 510275, People's Republic of China. School of Data and Computer Science, Sun Yat-Sen University, Guangzhou 510275, People's Republic of China.""]"	['10.1088/1361-6560/aa9f87 [doi]']	['Li S', 'Wei J', 'Chan HP', 'Helvie MA', 'Roubidoux MA', 'Lu Y', 'Zhou C', 'Hadjiiski LM', 'Samala RK']							['2017/12/07 06:00']	20190520	20180109	2018 Jan 9	2017/12/07 06:00		['Li, Songfeng', 'Wei, Jun', 'Chan, Heang-Ping', 'Helvie, Mark A', 'Roubidoux, Marilyn A', 'Lu, Yao', 'Zhou, Chuan', 'Hadjiiski, Lubomir M', 'Samala, Ravi K']		['U01 CA195599/CA/NCI NIH HHS/United States']	2		1361-6560 (Electronic) 0031-9155 (Linking)	0401220	Physics in medicine and biology	['eng']	10.1088/1361-6560/aa9f87 [doi]	20190520	['Adult', 'Aged', 'Aged, 80 and over', 'Breast/*diagnostic imaging', '*Breast Density', 'Breast Neoplasms/*classification/*diagnostic imaging', '*Deep Learning', 'Female', 'Humans', 'Mammography/*methods', 'Middle Aged', '*Models, Statistical', 'Radiographic Image Interpretation, Computer-Assisted/*methods', 'Retrospective Studies']	2019/05/21 06:00	['NIHMS935003']			NLM	025005	['2017/12/07 06:00 [pubmed]', '2019/05/21 06:00 [medline]', '2017/12/07 06:00 [entrez]']	England	PMC5784848		29210358	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Phys Med Biol. 2018 Jan 9;63(2):025005. doi: 10.1088/1361-6560/aa9f87.	MEDLINE	Phys Med Biol	Computer-aided assessment of breast density: comparison of supervised deep learning and feature-based statistical learning.		63	Computer-aided assessment of breast density: comparison of supervised deep learning and feature-based statistical learning.
Cryptography is not only a science of applying complex mathematics and logic to design strong methods to hide data called as encryption, but also to retrieve the original data back, called decryption. The purpose of cryptography is to transmit a message between a sender and receiver such that an eavesdropper is unable to comprehend it. To accomplish this, not only we need a strong algorithm, but a strong key and a strong concept for encryption and decryption process. We have introduced a concept of DNA Deep Learning Cryptography which is defined as a technique of concealing data in terms of DNA sequence and deep learning. In the cryptographic technique, each alphabet of a letter is converted into a different combination of the four bases, namely; Adenine (A), Cytosine (C), Guanine (G) and Thymine (T), which make up the human deoxyribonucleic acid (DNA). Actual implementations with the DNA don't exceed laboratory level and are expensive. To bring DNA computing on a digital level, easy and effective algorithms are proposed in this paper. In proposed work we have introduced firstly, a method and its implementation for key generation based on the theory of natural selection using Genetic Algorithm with Needleman-Wunsch (NW) algorithm and Secondly, a method for implementation of encryption and decryption based on DNA computing using biological operations Transcription, Translation, DNA Sequencing and Deep Learning.	"['Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi, India.', 'Xerox Technology Ltd., 5th-6th Floor, Vatika Business Park, Gurugram, Haryana, India.', 'Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi, India. harleen.unu@gmail.com.', ""International Business School Suzhou, Xi'an Jiaotong Liverpool University, Suzhou, China.""]"	['10.1007/s10916-017-0851-z [doi]', '10.1007/s10916-017-0851-z [pii]']	['Kalsi S', 'Kaur H', 'Chang V']							['2017/12/06 06:00']	20180827	20171205	2017 Dec 5	2017/12/06 06:00		['Kalsi, Shruti', 'Kaur, Harleen', 'Chang, Victor']			1		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-017-0851-z [doi]	20181113	['Algorithms', '*Computer Security', '*DNA', 'Humans', '*Machine Learning']	2018/08/28 06:00		['Cryptography', 'DNA computing', 'DNA cryptography', 'Deep learning', 'Genetic algorithm', 'Needleman-Wunsch algorithm (NW) algorithm']	['NOTNLM']	NLM	17	['2017/08/15 00:00 [received]', '2017/10/25 00:00 [accepted]', '2017/12/06 06:00 [entrez]', '2017/12/06 06:00 [pubmed]', '2018/08/28 06:00 [medline]']	United States			29204890	epublish	['Journal Article']		['9007-49-2 (DNA)']	IM		J Med Syst. 2017 Dec 5;42(1):17. doi: 10.1007/s10916-017-0851-z.	MEDLINE	J Med Syst	DNA Cryptography and Deep Learning using Genetic Algorithm with NW algorithm for Key Generation.		42	DNA Cryptography and Deep Learning using Genetic Algorithm with NW algorithm for Key Generation.
For single-cell experiments, it is important to accurately count the number of viable cells in a nanoliter well. We used a deep learning-based convolutional neural network (CNN) on a large amount of digital data obtained as microscopic images. The training set consisted of 103 019 samples, each representing a microscopic grayscale image. After extensive training, the CNN was able to classify the samples into four categories, i.e., 0, 1, 2, and more than 2 cells per well, with an accuracy of 98.3% when compared to determination by two trained technicians. By analyzing the samples for which judgments were discordant, we found that the judgment by technicians was relatively correct although cell counting was often difficult by the images of discordant samples. Based on the results, the system was further enhanced by introducing a new algorithm in which the highest outputs from CNN were used, increasing the accuracy to higher than 99%. Our system was able to classify the data even from wells with a different shape. No other tested machine learning algorithm showed a performance higher than that of our system. The presented CNN system is expected to be useful for various single-cell experiments, and for high-throughput and high-content screening.	['Pulmonary Division, Department of Medicine, Keio University School of Medicine, 35 Shinanomachi Shinjuku-ku, Tokyo 160-8582, Japan.', 'Pulmonary Division, Department of Medicine, Keio University School of Medicine, 35 Shinanomachi Shinjuku-ku, Tokyo 160-8582, Japan. km-fuku@cpnet.med.keio.ac.jp.', 'Department of Biological Sciences, Graduate School of Science, The University of Tokyo, Bunkyo-ku, Tokyo, Japan.', 'Department of Biological Sciences, Graduate School of Science, The University of Tokyo, Bunkyo-ku, Tokyo, Japan.', 'StaGen Co. Ltd, Taito-ku, Tokyo, Japan.', 'Pulmonary Division, Department of Medicine, Keio University School of Medicine, 35 Shinanomachi Shinjuku-ku, Tokyo 160-8582, Japan.', 'Pulmonary Division, Department of Medicine, Keio University School of Medicine, 35 Shinanomachi Shinjuku-ku, Tokyo 160-8582, Japan.', 'StaGen Co. Ltd, Taito-ku, Tokyo, Japan.', 'RIKEN Center for Integrative Medical Sciences, Tsurumi-ku, Yokohama, Kanagawa, Japan.', 'Pulmonary Division, Department of Medicine, Keio University School of Medicine, 35 Shinanomachi Shinjuku-ku, Tokyo 160-8582, Japan.', 'Department of Biological Sciences, Graduate School of Science, The University of Tokyo, Bunkyo-ku, Tokyo, Japan.']	['10.1038/s41598-017-17012-x [doi]', '10.1038/s41598-017-17012-x [pii]']	['Kamatani T', 'Fukunaga K', 'Miyata K', 'Shirasaki Y', 'Tanaka J', 'Baba R', 'Matsusaka M', 'Kamatani N', 'Moro K', 'Betsuyaku T', 'Uemura S']							['2017/12/06 06:00']	20190705	20171204	2017 Dec 4	2017/12/06 06:00		['Kamatani, Takashi', 'Fukunaga, Koichi', 'Miyata, Kaede', 'Shirasaki, Yoshitaka', 'Tanaka, Junji', 'Baba, Rie', 'Matsusaka, Masako', 'Kamatani, Naoyuki', 'Moro, Kazuyo', 'Betsuyaku, Tomoko', 'Uemura, Sotaro']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-17012-x [doi]	20190705	['Cell Count/*methods', 'Cell Line', '*Deep Learning', 'Humans', 'Image Interpretation, Computer-Assisted', 'Microscopy', 'Neural Networks (Computer)', 'Single-Cell Analysis']	2019/07/06 06:00				NLM	16831	['2017/09/04 00:00 [received]', '2017/11/20 00:00 [accepted]', '2017/12/06 06:00 [entrez]', '2017/12/06 06:00 [pubmed]', '2019/07/06 06:00 [medline]']	England	PMC5715092		29203784	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2017 Dec 4;7(1):16831. doi: 10.1038/s41598-017-17012-x.	MEDLINE	Sci Rep	Construction of a system using a deep learning algorithm to count cell numbers in nanoliter wells for viable single-cell experiments.		7	Construction of a system using a deep learning algorithm to count cell numbers in nanoliter wells for viable single-cell experiments.
Goodness of pronunciation (GOP) is the most widely used method for automatic mispronunciation detection. In this paper, a transfer learning approach to GOP based mispronunciation detection when applying maximum F1-score criterion (MFC) training to deep neural network (DNN)-hidden Markov model based acoustic models is proposed. Rather than train the whole network using MFC, a DNN is used, whose hidden layers are borrowed from native speech recognition with only the softmax layer trained according to the MFC objective function. As a result, significant mispronunciation detection improvement is obtained. In light of this, the two-stage transfer learning based GOP is investigated in depth. The first stage exploits the hidden layer(s) to extract phonetic-discriminating features. The second stage uses a trainable softmax layer to learn the human standard for judgment. The validation is carried out by experimenting with different mispronunciation detection architectures using acoustic models trained by different criteria. It is found that it is preferable to use frame-level cross-entropy to train the hidden layer parameters. Classifier based mispronunciation detection is further experimented with using features computed by transfer learning based GOP and it is shown that it also helps to achieve better results.	['School of Information Science and Engineering, Xinjiang University, Shangli Road, Urumqi 830046, China.', 'Temasek Laboratories, Nanyang Technological University, 50 Nanyang Drive, Singapore 637553, Singapore.', 'School of Information Science and Engineering, Xinjiang University, Shangli Road, Urumqi 830046, China.', 'School of Information Science and Engineering, Xinjiang University, Shangli Road, Urumqi 830046, China.']	['10.1121/1.5011159 [doi]']	['Huang H', 'Xu H', 'Hu Y', 'Zhou G']							['2017/12/03 06:00']	20190716		2017 Nov	2017/12/03 06:00		['Huang, Hao', 'Xu, Haihua', 'Hu, Ying', 'Zhou, Gang']			5		1520-8524 (Electronic) 0001-4966 (Linking)	7503051	The Journal of the Acoustical Society of America	['eng']	10.1121/1.5011159 [doi]	20190716	['*Acoustics', '*Deep Learning', 'Humans', 'Judgment', 'Markov Chains', 'Pattern Recognition, Automated/*methods', '*Phonetics', '*Signal Processing, Computer-Assisted', 'Software', '*Speech Acoustics', '*Speech Perception', 'Speech Production Measurement/*methods', '*Voice Quality']	2019/07/17 06:00				NLM	3165	['2017/12/03 06:00 [entrez]', '2017/12/03 06:00 [pubmed]', '2019/07/17 06:00 [medline]']	United States			29195422	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Acoust Soc Am. 2017 Nov;142(5):3165. doi: 10.1121/1.5011159.	MEDLINE	J Acoust Soc Am	A transfer learning approach to goodness of pronunciation based automatic mispronunciation detection.		142	A transfer learning approach to goodness of pronunciation based automatic mispronunciation detection.
PURPOSE OF REVIEW: The aim of this review is to present an up-to-date overview of the application of machine learning methods in heart failure including diagnosis, classification, readmissions and medication adherence. RECENT FINDINGS: Recent studies have shown that the application of machine learning techniques may have the potential to improve heart failure outcomes and management, including cost savings by improving existing diagnostic and treatment support systems. Recently developed deep learning methods are expected to yield even better performance than traditional machine learning techniques in performing complex tasks by learning the intricate patterns hidden in big medical data. SUMMARY: The review summarizes the recent developments in the application of machine and deep learning methods in heart failure management.	['School of Computer Science and Software Engineering, The University of Western Australia.', 'School of Engineering and Information technology, Murdoch University.', 'School of Population and Global Health.', 'School of Computer Science and Software Engineering, The University of Western Australia.', 'Wesfarmers Chair and Consultant Cardiologist, Harry Perkins Institute of Medical Research and Fiona Stanley Hospital, The University of Western Australia, Perth, Australia.']	['10.1097/HCO.0000000000000491 [doi]']	['Awan SE', 'Sohel F', 'Sanfilippo FM', 'Bennamoun M', 'Dwivedi G']							['2017/12/02 06:00']	20190425		2018 Mar	2017/12/02 06:00		['Awan, Saqib Ejaz', 'Sohel, Ferdous', 'Sanfilippo, Frank Mario', 'Bennamoun, Mohammed', 'Dwivedi, Girish']			2		1531-7080 (Electronic) 0268-4705 (Linking)	8608087	Current opinion in cardiology	['eng']	10.1097/HCO.0000000000000491 [doi]	20190425	['*Deep Learning', 'Disease Management', '*Heart Failure/classification/diagnosis/therapy', 'Humans', '*Machine Learning']	2019/04/26 06:00				NLM	190-195	['2017/12/02 06:00 [pubmed]', '2019/04/26 06:00 [medline]', '2017/12/02 06:00 [entrez]']	United States			29194052	ppublish	['Journal Article', 'Review']			IM		Curr Opin Cardiol. 2018 Mar;33(2):190-195. doi: 10.1097/HCO.0000000000000491.	MEDLINE	Curr Opin Cardiol	Machine learning in heart failure: ready for prime time.		33	Machine learning in heart failure: ready for prime time.
BACKGROUND: The medical subdomain of a clinical note, such as cardiology or neurology, is useful content-derived metadata for developing machine learning downstream applications. To classify the medical subdomain of a note accurately, we have constructed a machine learning-based natural language processing (NLP) pipeline and developed medical subdomain classifiers based on the content of the note. METHODS: We constructed the pipeline using the clinical NLP system, clinical Text Analysis and Knowledge Extraction System (cTAKES), the Unified Medical Language System (UMLS) Metathesaurus, Semantic Network, and learning algorithms to extract features from two datasets - clinical notes from Integrating Data for Analysis, Anonymization, and Sharing (iDASH) data repository (n = 431) and Massachusetts General Hospital (MGH) (n = 91,237), and built medical subdomain classifiers with different combinations of data representation methods and supervised learning algorithms. We evaluated the performance of classifiers and their portability across the two datasets. RESULTS: The convolutional recurrent neural network with neural word embeddings trained-medical subdomain classifier yielded the best performance measurement on iDASH and MGH datasets with area under receiver operating characteristic curve (AUC) of 0.975 and 0.991, and F1 scores of 0.845 and 0.870, respectively. Considering better clinical interpretability, linear support vector machine-trained medical subdomain classifier using hybrid bag-of-words and clinically relevant UMLS concepts as the feature representation, with term frequency-inverse document frequency (tf-idf)-weighting, outperformed other shallow learning classifiers on iDASH and MGH datasets with AUC of 0.957 and 0.964, and F1 scores of 0.932 and 0.934 respectively. We trained classifiers on one dataset, applied to the other dataset and yielded the threshold of F1 score of 0.7 in classifiers for half of the medical subdomains we studied. CONCLUSION: Our study shows that a supervised learning-based NLP approach is useful to develop medical subdomain classifiers. The deep learning algorithm with distributed word representation yields better performance yet shallow learning algorithms with the word and concept representation achieves comparable performance with better clinical interpretability. Portable classifiers may also be used across datasets from different institutions.	['Department of Biomedical Informatics, Harvard Medical School, 10 Shattuck Street, 4th Floor, Boston, MA, 02115, USA. ckbjimmy@mit.edu.', 'Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Suite 750, Boston, MA, 02114, USA. ckbjimmy@mit.edu.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA. ckbjimmy@mit.edu.', 'Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Suite 750, Boston, MA, 02114, USA.', 'Department of Medicine, Massachusetts General Hospital, 55 Fruit St, Boston, MA, 02114, USA.', 'Department of Biomedical Informatics, Harvard Medical School, 10 Shattuck Street, 4th Floor, Boston, MA, 02115, USA.', 'Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA.', 'Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Suite 750, Boston, MA, 02114, USA.', 'Department of Medicine, Massachusetts General Hospital, 55 Fruit St, Boston, MA, 02114, USA.']	['10.1186/s12911-017-0556-8 [doi]', '10.1186/s12911-017-0556-8 [pii]']	['Weng WH', 'Wagholikar KB', 'McCray AT', 'Szolovits P', 'Chueh HC']	['ORCID: http://orcid.org/0000-0003-2232-0390']						['2017/12/02 06:00']	20180725	20171201	2017 Dec 1	2017/12/02 06:00		['Weng, Wei-Hung', 'Wagholikar, Kavishwar B', 'McCray, Alexa T', 'Szolovits, Peter', 'Chueh, Henry C']		['R00 LM011575/LM/NLM NIH HHS/United States', 'U54 HL108460/HL/NHLBI NIH HHS/United States', '5R00LM011575/National Library of Medicine, National Institutes of Health']	1		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-017-0556-8 [doi]	20191008	['*Clinical Decision-Making', 'Humans', '*Machine Learning', '*Medical Records', '*Natural Language Processing', '*Unified Medical Language System']	2018/07/26 06:00		['Deep Learning', 'Distributed Representation', 'Machine Learning', 'Medical Decision Making, Computer-assisted', 'Natural Language Processing', 'Unified Medical Language System']	['NOTNLM']	NLM	155	['2017/06/15 00:00 [received]', '2017/11/19 00:00 [accepted]', '2017/12/02 06:00 [entrez]', '2017/12/02 06:00 [pubmed]', '2018/07/26 06:00 [medline]']	England	PMC5709846		29191207	epublish	['Journal Article']			IM		BMC Med Inform Decis Mak. 2017 Dec 1;17(1):155. doi: 10.1186/s12911-017-0556-8.	MEDLINE	BMC Med Inform Decis Mak	Medical subdomain classification of clinical notes using a machine learning-based natural language processing approach.		17	Medical subdomain classification of clinical notes using a machine learning-based natural language processing approach.
The United States spends more than $250 million each year on the American Community Survey (ACS), a labor-intensive door-to-door study that measures statistics relating to race, gender, education, occupation, unemployment, and other demographic factors. Although a comprehensive source of data, the lag between demographic changes and their appearance in the ACS can exceed several years. As digital imagery becomes ubiquitous and machine vision techniques improve, automated data analysis may become an increasingly practical supplement to the ACS. Here, we present a method that estimates socioeconomic characteristics of regions spanning 200 US cities by using 50 million images of street scenes gathered with Google Street View cars. Using deep learning-based computer vision techniques, we determined the make, model, and year of all motor vehicles encountered in particular neighborhoods. Data from this census of motor vehicles, which enumerated 22 million automobiles in total (8% of all automobiles in the United States), were used to accurately estimate income, race, education, and voting patterns at the zip code and precinct level. (The average US precinct contains approximately 1,000 people.) The resulting associations are surprisingly simple and powerful. For instance, if the number of sedans encountered during a drive through a city is higher than the number of pickup trucks, the city is likely to vote for a Democrat during the next presidential election (88% chance); otherwise, it is likely to vote Republican (82%). Our results suggest that automated systems for monitoring demographics may effectively complement labor-intensive approaches, with the potential to measure demographics with fine spatial resolution, in close to real time.	['Artificial Intelligence Laboratory, Computer Science Department, Stanford University, Stanford, CA 94305; tgebru@stanford.edu.', 'Artificial Intelligence Laboratory, Computer Science Department, Stanford University, Stanford, CA 94305.', 'Artificial Intelligence Laboratory, Computer Science Department, Stanford University, Stanford, CA 94305.', 'Artificial Intelligence Laboratory, Computer Science Department, Stanford University, Stanford, CA 94305.', 'Vision and Learning Laboratory, Computer Science and Engineering Department, University of Michigan, Ann Arbor, MI 48109.', 'The Center for Genome Architecture, Department of Genetics, Baylor College of Medicine, Houston, TX 77030.', 'Department of Computer Science, Rice University, Houston, TX 77005.', 'The Center for Genome Architecture, Department of Computational and Applied Mathematics, Rice University, Houston, TX 77005.', 'Artificial Intelligence Laboratory, Computer Science Department, Stanford University, Stanford, CA 94305.']	['1700035114 [pii]', '10.1073/pnas.1700035114 [doi]']	['Gebru T', 'Krause J', 'Wang Y', 'Chen D', 'Deng J', 'Aiden EL', 'Fei-Fei L']		['Copyright (c) 2017 the Author(s). Published by PNAS.']			['The authors declare no conflict of interest.']		['2017/11/30 06:00']	20180705	20171128	2017 Dec 12	2017/12/01 06:00		['Gebru, Timnit', 'Krause, Jonathan', 'Wang, Yilun', 'Chen, Duyun', 'Deng, Jia', 'Aiden, Erez Lieberman', 'Fei-Fei, Li']			50		1091-6490 (Electronic) 0027-8424 (Linking)	7505876	Proceedings of the National Academy of Sciences of the United States of America	['eng']	10.1073/pnas.1700035114 [doi]	20181113	['Automobiles/*statistics & numerical data', 'Demography/*methods', 'Humans', '*Machine Learning', '*Population', 'Satellite Imagery/*methods', 'Socioeconomic Factors', 'United States']	2018/07/06 06:00		['*computer vision', '*deep learning', '*demography', '*social analysis']	['NOTNLM']	NLM	13108-13113	['2017/12/01 06:00 [pubmed]', '2018/07/06 06:00 [medline]', '2017/11/30 06:00 [entrez]']	United States	PMC5740675		29183967	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Proc Natl Acad Sci U S A. 2017 Dec 12;114(50):13108-13113. doi: 10.1073/pnas.1700035114. Epub 2017 Nov 28.	MEDLINE	Proc Natl Acad Sci U S A	Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States.		114	Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States.
Breast cancer is the most common malignant disease in women worldwide. In recent decades, earlier diagnosis and better adjuvant therapy have substantially improved patient outcome. Diagnosis by histopathology has proven to be instrumental to guide breast cancer treatment, but new challenges have emerged as our increasing understanding of cancer over the years has revealed its complex nature. As patient demand for personalized breast cancer therapy grows, we face an urgent need for more precise biomarker assessment and more accurate histopathologic breast cancer diagnosis to make better therapy decisions. The digitization of pathology data has opened the door to faster, more reproducible, and more precise diagnoses through computerized image analysis. Software to assist diagnostic breast pathology through image processing techniques have been around for years. But recent breakthroughs in artificial intelligence (AI) promise to fundamentally change the way we detect and treat breast cancer in the near future. Machine learning, a subfield of AI that applies statistical methods to learn from data, has seen an explosion of interest in recent years because of its ability to recognize patterns in data with less need for human instruction. One technique in particular, known as deep learning, has produced groundbreaking results in many important problems including image classification and speech recognition. In this review, we will cover the use of AI and deep learning in diagnostic breast pathology, and other recent developments in digital image analysis.	['Department of Oncology-Pathology, Karolinska Institutet, Stockholm, Sweden; Department of Clinical Pathology and Cytology, Karolinska University Laboratory, Stockholm, Sweden.', 'School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, Sweden; Science for Life Laboratory, Stockholm, Sweden.', 'School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, Sweden; Science for Life Laboratory, Stockholm, Sweden.', 'Department of Oncology-Pathology, Karolinska Institutet, Stockholm, Sweden; Department of Clinical Pathology and Cytology, Karolinska University Laboratory, Stockholm, Sweden; Stockholm South General Hospital, Stockholm, Sweden. Electronic address: johan.hartman@ki.se.']	['S1931-5244(17)30295-5 [pii]', '10.1016/j.trsl.2017.10.010 [doi]']	['Robertson S', 'Azizpour H', 'Smith K', 'Hartman J']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/11/28 06:00']	20180731	20171107	2018 Apr	2017/11/28 06:00		['Robertson, Stephanie', 'Azizpour, Hossein', 'Smith, Kevin', 'Hartman, Johan']					1878-1810 (Electronic) 1878-1810 (Linking)	101280339	Translational research : the journal of laboratory and clinical medicine	['eng']	S1931-5244(17)30295-5 [pii] 10.1016/j.trsl.2017.10.010 [doi]	20180731	['*Artificial Intelligence', 'Biomarkers, Tumor', 'Breast/*diagnostic imaging/pathology', 'Breast Neoplasms/*diagnostic imaging/pathology', 'Diagnosis, Computer-Assisted', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning']	2018/08/01 06:00				NLM	19-35	['2017/09/01 00:00 [received]', '2017/10/28 00:00 [revised]', '2017/10/30 00:00 [accepted]', '2017/11/28 06:00 [pubmed]', '2018/08/01 06:00 [medline]', '2017/11/28 06:00 [entrez]']	United States			29175265	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"		['0 (Biomarkers, Tumor)']	AIM IM		Transl Res. 2018 Apr;194:19-35. doi: 10.1016/j.trsl.2017.10.010. Epub 2017 Nov 7.	MEDLINE	Transl Res	Digital image analysis in breast pathology-from image processing techniques to artificial intelligence.		194	Digital image analysis in breast pathology-from image processing techniques to artificial intelligence.
"BACKGROUND AND OBJECTIVES: White blood cells (WBCs) differential counting yields valued information about human health and disease. The current developed automated cell morphology equipments perform differential count which is based on blood smear image analysis. Previous identification systems for WBCs consist of successive dependent stages; pre-processing, segmentation, feature extraction, feature selection, and classification. There is a real need to employ deep learning methodologies so that the performance of previous WBCs identification systems can be increased. Classifying small limited datasets through deep learning systems is a major challenge and should be investigated. METHODS: In this paper, we propose a novel identification system for WBCs based on deep convolutional neural networks. Two methodologies based on transfer learning are followed: transfer learning based on deep activation features and fine-tuning of existed deep networks. Deep acrivation featues are extracted from several pre-trained networks and employed in a traditional identification system. Moreover, a novel end-to-end convolutional deep architecture called ""WBCsNet"" is proposed and built from scratch. Finally, a limited balanced WBCs dataset classification is performed through the WBCsNet as a pre-trained network. RESULTS: During our experiments, three different public WBCs datasets (2551 images) have been used which contain 5 healthy WBCs types. The overall system accuracy achieved by the proposed WBCsNet is (96.1%) which is more than different transfer learning approaches or even the previous traditional identification system. We also present features visualization for the WBCsNet activation which reflects higher response than the pre-trained activated one. CONCLUSION: a novel WBCs identification system based on deep learning theory is proposed and a high performance WBCsNet can be employed as a pre-trained network."	['Department of Biomedical Engineering, Cairo University, Egypt; Department of Biomedical Engineering, HTI, Egypt. Electronic address: ahmed.esmail@hti.edu.eg.', 'Department of Computer Science, University of Illinois at Springfield, Springfield, IL, USA. Electronic address: yguo56@uis.edu.', 'Department of Information Technology, Menoufia University, Egypt.', 'Department of Biomedical Engineering, Cairo University, Egypt.']	['S0169-2607(17)30411-X [pii]', '10.1016/j.cmpb.2017.11.015 [doi]']	['Shahin AI', 'Guo Y', 'Amin KM', 'Sharawi AA']		['Copyright (c) 2017. Published by Elsevier B.V.']					['2017/11/28 06:00']	20190514	20171116	2019 Jan	2017/11/28 06:00		['Shahin, A I', 'Guo, Yanhui', 'Amin, K M', 'Sharawi, Amr A']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(17)30411-X [pii] 10.1016/j.cmpb.2017.11.015 [doi]	20190514	['Basophils/cytology', '*Deep Learning', 'Eosinophils/cytology', 'Humans', '*Image Processing, Computer-Assisted', 'Leukocytes/*cytology', 'Lymphocytes/cytology', 'Medical Informatics', 'Monocytes/cytology', '*Neural Networks (Computer)', 'Neutrophils/cytology', 'Reproducibility of Results']	2019/05/15 06:00		['Blood smear image', 'Deep features visualization', 'Deep learning', 'Transfer deep learning', 'WBCs identification']	['NOTNLM']	NLM	69-80	['2017/03/30 00:00 [received]', '2017/08/24 00:00 [revised]', '2017/11/14 00:00 [accepted]', '2017/11/28 06:00 [pubmed]', '2019/05/15 06:00 [medline]', '2017/11/28 06:00 [entrez]']	Ireland			29173802	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2019 Jan;168:69-80. doi: 10.1016/j.cmpb.2017.11.015. Epub 2017 Nov 16.	MEDLINE	Comput Methods Programs Biomed	White blood cells identification system based on convolutional deep neural learning networks.		168	White blood cells identification system based on convolutional deep neural learning networks.
Aging is now at the forefront of major challenges faced globally, creating an immediate need for safe, widescale interventions to reduce the burden of chronic disease and extend human healthspan. Metformin and rapamycin are two FDA-approved mTOR inhibitors proposed for this purpose, exhibiting significant anti-cancer and anti-aging properties beyond their current clinical applications. However, each faces issues with approval for off-label, prophylactic use due to adverse effects. Here, we initiate an effort to identify nutraceuticals-safer, naturally-occurring compounds-that mimic the anti-aging effects of metformin and rapamycin without adverse effects. We applied several bioinformatic approaches and deep learning methods to the Library of Integrated Network-based Cellular Signatures (LINCS) dataset to map the gene- and pathway-level signatures of metformin and rapamycin and screen for matches among over 800 natural compounds. We then predicted the safety of each compound with an ensemble of deep neural network classifiers. The analysis revealed many novel candidate metformin and rapamycin mimetics, including allantoin and ginsenoside (metformin), epigallocatechin gallate and isoliquiritigenin (rapamycin), and withaferin A (both). Four relatively unexplored compounds also scored well with rapamycin. This work revealed promising candidates for future experimental validation while demonstrating the applications of powerful screening methods for this and similar endeavors.	"['Insilico Medicine, Inc, Research Department, Baltimore, MD 21218, USA.', 'Insilico Medicine, Inc, Research Department, Baltimore, MD 21218, USA.', 'Biogerontology Research Foundation, Research Department, Oxford, United Kingdom.', ""Department of Biomedical and Molecular Science, Queen's University School of Medicine, Queen's University, Kingston, ON K7L 3N6, Canada."", 'Insilico Medicine, Inc, Research Department, Baltimore, MD 21218, USA.', 'Life Extension, Ft. Lauderdale, FL 33308, USA.', 'Laboratory of Molecular Radiobiology and Gerontology, Institute of Biology of Komi Science Center of Ural Branch of Russian Academy of Sciences, Syktyvkar, 167982, Russia.', 'Life Extension, Ft. Lauderdale, FL 33308, USA.', 'Insilico Medicine, Inc, Research Department, Baltimore, MD 21218, USA.', 'Biogerontology Research Foundation, Research Department, Oxford, United Kingdom.']"	['101319 [pii]', '10.18632/aging.101319 [doi]']	['Aliper A', 'Jellen L', 'Cortese F', 'Artemov A', 'Karpinsky-Semper D', 'Moskalev A', 'Swick AG', 'Zhavoronkov A']							['2017/11/23 06:00']	20180205		2017 Nov 15	2017/11/23 06:00		['Aliper, Alexander', 'Jellen, Leslie', 'Cortese, Franco', 'Artemov, Artem', 'Karpinsky-Semper, Darla', 'Moskalev, Alexey', 'Swick, Andrew G', 'Zhavoronkov, Alex']			11		1945-4589 (Electronic) 1945-4589 (Linking)	101508617	Aging	['eng']	10.18632/aging.101319 [doi]	20190124	['Computational Biology', 'Databases, Genetic', '*Dietary Supplements/adverse effects/classification', 'Drug Discovery/*methods', 'Gene Regulatory Networks/drug effects', '*High-Throughput Screening Assays', 'Humans', 'Machine Learning', 'Metformin/adverse effects/chemistry/classification/*pharmacology', '*Molecular Mimicry', 'Molecular Structure', 'Molecular Targeted Therapy', 'Neural Networks (Computer)', 'Protein Interaction Maps/drug effects', 'Protein Kinase Inhibitors/adverse effects/chemistry/classification/*pharmacology', 'Signal Transduction/drug effects', 'Sirolimus/adverse effects/chemistry/classification/*pharmacology', 'Structure-Activity Relationship', 'TOR Serine-Threonine Kinases/*antagonists & inhibitors']	2018/02/06 06:00		['*compound screening', '*deep learning', '*geroprotector', '*metformin', '*natural', '*nutraceutical', '*rapamycin']	['NOTNLM']	NLM	2245-2268	['2017/07/06 00:00 [received]', '2017/11/02 00:00 [accepted]', '2017/11/23 06:00 [pubmed]', '2018/02/06 06:00 [medline]', '2017/11/23 06:00 [entrez]']	United States	PMC5723685		29165314	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Protein Kinase Inhibitors)', '9100L32L2N (Metformin)', 'EC 2.7.1.1 (TOR Serine-Threonine Kinases)', 'W36ZG6FT64 (Sirolimus)']	IM		Aging (Albany NY). 2017 Nov 15;9(11):2245-2268. doi: 10.18632/aging.101319.	MEDLINE	Aging (Albany NY)	Towards natural mimetics of metformin and rapamycin.		9	Towards natural mimetics of metformin and rapamycin.
Nuclei detection in histology images is an essential part of computer aided diagnosis of cancers and tumors. It is a challenging task due to diverse and complicated structures of cells. In this work, we present an automated technique for detection of cellular nuclei in hematoxylin and eosin stained histopathology images. Our proposed approach is based on kernelized correlation filters. Correlation filters have been widely used in object detection and tracking applications but their strength has not been explored in the medical imaging domain up till now. Our experimental results show that the proposed scheme gives state of the art accuracy and can learn complex nuclear morphologies. Like deep learning approaches, the proposed filters do not require engineering of image features as they can operate directly on histopathology images without significant preprocessing. However, unlike deep learning methods, the large-margin correlation filters developed in this work are interpretable, computationally efficient and do not require specialized or expensive computing hardware. AVAILABILITY: A cloud based webserver of the proposed method and its python implementation can be accessed at the following URL: http://faculty.pieas.edu.pk/fayyaz/software.html#corehist .	['Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan. asif.eng007@gmail.com.', 'Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan.', 'Department of Computer Science, University of Warwick, Coventry, UK.', 'Department of Electrical Engineering, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan.', 'Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan.']	['10.1007/s10916-017-0863-8 [doi]', '10.1007/s10916-017-0863-8 [pii]']	['Ahmad A', 'Asif A', 'Rajpoot N', 'Arif M', 'Minhas FUAA']	['ORCID: http://orcid.org/0000-0001-9129-1189']						['2017/11/23 06:00']	20180725	20171121	2017 Nov 21	2017/11/23 06:00		['Ahmad, Asif', 'Asif, Amina', 'Rajpoot, Nasir', 'Arif, Muhammad', 'Minhas, Fayyaz Ul Amir Afsar']			1		1573-689X (Electronic) 0148-5598 (Linking)	7806056	Journal of medical systems	['eng']	10.1007/s10916-017-0863-8 [doi]	20181113	['Cell Nucleus/*pathology', 'Fourier Analysis', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning']	2018/07/26 06:00		['Cell detection', 'Correlation filters', 'Histopathology images', 'Kernelized correlation filters', 'Nuclei detection']	['NOTNLM']	NLM	7	['2016/11/15 00:00 [received]', '2017/11/13 00:00 [accepted]', '2017/11/23 06:00 [entrez]', '2017/11/23 06:00 [pubmed]', '2018/07/26 06:00 [medline]']	United States			29164340	epublish	['Journal Article']			IM		J Med Syst. 2017 Nov 21;42(1):7. doi: 10.1007/s10916-017-0863-8.	MEDLINE	J Med Syst	Correlation Filters for Detection of Cellular Nuclei in Histopathology Images.		42	Correlation Filters for Detection of Cellular Nuclei in Histopathology Images.
"PURPOSE: Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS: In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS: The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS: Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."	['Department of Radiology, University of Pittsburgh School of Medicine, 4200 Fifth Ave, Pittsburgh, PA, 15260, USA.', 'Department of Radiology, University of Pittsburgh School of Medicine, 4200 Fifth Ave, Pittsburgh, PA, 15260, USA.', 'Magee-Womens Hospital of University of Pittsburgh Medical Center, 300 Halket St, Pittsburgh, PA, 15213, USA.', 'Department of Radiology, Chinese PLA General Hospital, 28 Fuxing Rd, Haidian District, Beijing, 100853, China.', 'Department of Radiology, Liaoning Cancer Hospital & Institute, 44 Xiaoheyan Rd, Dadong District, Shenyang City, Liaoning, 110042, China.', 'Magee-Womens Hospital of University of Pittsburgh Medical Center, 300 Halket St, Pittsburgh, PA, 15213, USA.', 'Department of Medicine, School of Medicine, University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, PA, 15260, USA.', 'Departments of Radiology, Biomedical Informatics, Bioengineering, and Computer Science, University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, PA, 15260, USA.']	['10.1002/mp.12683 [doi]']	['Mohamed AA', 'Berg WA', 'Peng H', 'Luo Y', 'Jankowitz RC', 'Wu S']		['(c) 2017 American Association of Physicists in Medicine.']					['2017/11/22 06:00']	20180201	20171222	2018 Jan	2017/11/22 06:00		['Mohamed, Aly A', 'Berg, Wendie A', 'Peng, Hong', 'Luo, Yahong', 'Jankowitz, Rachel C', 'Wu, Shandong']		['R01 CA193603/CA/NCI NIH HHS/United States', 'UL1 TR001857/TR/NCATS NIH HHS/United States']	1		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.12683 [doi]	20190118	['Area Under Curve', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', '*Mammography/methods', '*Neural Networks (Computer)', 'ROC Curve', 'Retrospective Studies']	2018/02/02 06:00	['NIHMS921436']	['BI-RADS', 'breast density', 'convolutional neural network (CNN)', 'deep learning', 'digital mammography', 'transfer learning']	['NOTNLM']	NLM	314-321	['2017/06/27 00:00 [received]', '2017/11/09 00:00 [revised]', '2017/11/12 00:00 [accepted]', '2017/11/22 06:00 [pubmed]', '2018/02/02 06:00 [medline]', '2017/11/22 06:00 [entrez]']	United States	PMC5774233		29159811	ppublish	['Journal Article']			IM		Med Phys. 2018 Jan;45(1):314-321. doi: 10.1002/mp.12683. Epub 2017 Dec 22.	MEDLINE	Med Phys	A deep learning method for classifying mammographic breast density categories.		45	A deep learning method for classifying mammographic breast density categories.
Artificial intelligence (AI), machine learning, and deep learning are terms now seen frequently, all of which refer to computer algorithms that change as they are exposed to more data. Many of these algorithms are surprisingly good at recognizing objects in images. The combination of large amounts of machine-consumable digital data, increased and cheaper computing power, and increasingly sophisticated statistical models combine to enable machines to find patterns in data in ways that are not only cost-effective but also potentially beyond humans' abilities. Building an AI algorithm can be surprisingly easy. Understanding the associated data structures and statistics, on the other hand, is often difficult and obscure. Converting the algorithm into a sophisticated product that works consistently in broad, general clinical use is complex and incompletely understood. To show how these AI products reduce costs and improve outcomes will require clinical translation and industrial-grade integration into routine workflow. Radiology has the chance to leverage AI to become a center of intelligently aggregated, quantitative, diagnostic information. Centaur radiologists, formed as a synergy of human plus computer, will provide interpretations using data extracted from images by humans and image-analysis computer algorithms, as well as the electronic health record, genomics, and other disparate sources. These interpretations will form the foundation of precision health care, or care customized to an individual patient. ((c)) RSNA, 2017.	['From the Department of Radiology, Massachusetts General Hospital, Center for Clinical Data Science, Partners Healthcare, Boston, Mass (K.J.D.); and Department of Radiology, University of Colorado School of Medicine, Aurora, Colo (J.R.G.).', 'From the Department of Radiology, Massachusetts General Hospital, Center for Clinical Data Science, Partners Healthcare, Boston, Mass (K.J.D.); and Department of Radiology, University of Colorado School of Medicine, Aurora, Colo (J.R.G.).']	['10.1148/radiol.2017171183 [doi]']	['Dreyer KJ', 'Geis JR']							['2017/11/21 06:00']	20171127		2017 Dec	2017/11/21 06:00		['Dreyer, Keith J', 'Geis, J Raymond']			3		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2017171183 [doi]	20180416	['Algorithms', 'Decision Support Systems, Clinical/*trends', 'Diagnostic Imaging/*trends', '*Forecasting', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Machine Learning/*trends', 'Pattern Recognition, Automated/trends', 'Radiology/*trends', 'Software']	2017/11/29 06:00				NLM	713-718	['2017/11/21 06:00 [entrez]', '2017/11/21 06:00 [pubmed]', '2017/11/29 06:00 [medline]']	United States			29155639	ppublish	['Journal Article', 'Review']			AIM IM		Radiology. 2017 Dec;285(3):713-718. doi: 10.1148/radiol.2017171183.	MEDLINE	Radiology	When Machines Think: Radiology's Next Frontier.		285	When Machines Think: Radiology's Next Frontier.
Sequence classification is crucial in predicting the function of newly discovered sequences. In recent years, the prediction of the incremental large-scale and diversity of sequences has heavily relied on the involvement of machine-learning algorithms. To improve prediction accuracy, these algorithms must confront the key challenge of extracting valuable features. In this work, we propose a feature-enhanced protein classification approach, considering the rich generation of multiple sequence alignment algorithms, N-gram probabilistic language model and the deep learning technique. The essence behind the proposed method is that if each group of sequences can be represented by one feature sequence, composed of homologous sites, there should be less loss when the sequence is rebuilt, when a more relevant sequence is added to the group. On the basis of this consideration, the prediction becomes whether a query sequence belonging to a group of sequences can be transferred to calculate the probability that the new feature sequence evolves from the original one. The proposed work focuses on the hierarchical classification of G-protein Coupled Receptors (GPCRs), which begins by extracting the feature sequences from the multiple sequence alignment results of the GPCRs sub-subfamilies. The N-gram model is then applied to construct the input vectors. Finally, these vectors are imported into a convolutional neural network to make a prediction. The experimental results elucidate that the proposed method provides significant performance improvements. The classification error rate of the proposed method is reduced by at least 4.67% (family level I) and 5.75% (family Level II), in comparison with the current state-of-the-art methods. The implementation program of the proposed work is freely available at: https://github.com/alanFchina/CNN .	['Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China.', 'Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China. s0897918@gmail.com.', 'Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China.', 'Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China.']	['10.1007/s00726-017-2512-4 [doi]', '10.1007/s00726-017-2512-4 [pii]']	['Li M', 'Ling C', 'Xu Q', 'Gao J']	['ORCID: 0000-0003-3827-849X']						['2017/11/20 06:00']	20181226	20171118	2018 Feb	2017/11/21 06:00		['Li, Man', 'Ling, Cheng', 'Xu, Qi', 'Gao, Jingyang']		['61602026/National Natural Science Foundation of China/International']	2		1438-2199 (Electronic) 0939-4451 (Linking)	9200312	Amino acids	['eng']	10.1007/s00726-017-2512-4 [doi]	20181226	['*Algorithms', 'Amino Acid Sequence/genetics', 'Databases, Protein', 'Machine Learning', '*Models, Theoretical', '*Neural Networks (Computer)', 'Receptors, G-Protein-Coupled/chemistry/*classification', 'Reproducibility of Results', '*Sequence Alignment', '*Sequence Analysis, Protein']	2018/12/27 06:00		['*Convolutional neural network', '*Machine learning', '*Multiple sequence alignment', '*Sequence classification']	['NOTNLM']	NLM	255-266	['2017/06/24 00:00 [received]', '2017/11/14 00:00 [accepted]', '2017/11/21 06:00 [pubmed]', '2018/12/27 06:00 [medline]', '2017/11/20 06:00 [entrez]']	Austria			29151135	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Receptors, G-Protein-Coupled)']	IM		Amino Acids. 2018 Feb;50(2):255-266. doi: 10.1007/s00726-017-2512-4. Epub 2017 Nov 18.	MEDLINE	Amino Acids	Classification of G-protein coupled receptors based on a rich generation of convolutional neural network, N-gram transformation and multiple sequence alignments.		50	Classification of G-protein coupled receptors based on a rich generation of convolutional neural network, N-gram transformation and multiple sequence alignments.
Objective: To present research models based on artificial intelligence and discuss the concept of cognitive computing and eScience as disruptive factors in health and life science research methodologies. Methods: The paper identifies big data as a catalyst to innovation and the development of artificial intelligence, presents a framework for computer-supported human problem solving and describes a transformation of research support models. This framework includes traditional computer support; federated cognition using machine learning and cognitive agents to augment human intelligence; and a semi-autonomous/autonomous cognitive model, based on deep machine learning, which supports eScience. Results: The paper provides a forward view of the impact of artificial intelligence on our human-computer support and research methods in health and life science research. Conclusions: By augmenting or amplifying human task performance with artificial intelligence, cognitive computing and eScience research models are discussed as novel and innovative systems for developing more effective adaptive obesity intervention programs.	['Auburn University, Auburn, AL USA.0000 0001 2297 8753grid.252546.2', 'School of Biomedical Informatics, Houston, TX USA.', 'University of Texas, Austin, TX USA.0000000121548364grid.55460.32', 'The University of Texas Health Science Center at Houston, School of Public Health, Austin, TX USA.grid.468222.8']	['10.1007/s13755-017-0030-0 [doi]', '30 [pii]']	['Marshall T', 'Champagne-Langabeer T', 'Castelli D', 'Hoelscher D']	['ORCID: 0000-0002-7586-8870']						['2017/11/18 06:00']		20171101	2017 Dec	2017/11/18 06:00		['Marshall, Thomas', 'Champagne-Langabeer, Tiffiany', 'Castelli, Darla', 'Hoelscher, Deanna']			1		2047-2501 (Print) 2047-2501 (Linking)	101638060	Health information science and systems	['eng']	10.1007/s13755-017-0030-0 [doi]	20191120		2017/11/18 06:01		['Artificial intelligence', 'Cognitive computing', 'Obesity intervention']	['NOTNLM']	NLM	13	['2017/07/25 00:00 [received]', '2017/10/16 00:00 [accepted]', '2017/11/18 06:00 [entrez]', '2017/11/18 06:00 [pubmed]', '2017/11/18 06:01 [medline]']	England	PMC5665754		29147562	epublish	['Journal Article', 'Review']					Health Inf Sci Syst. 2017 Nov 1;5(1):13. doi: 10.1007/s13755-017-0030-0. eCollection 2017 Dec.	PubMed-not-MEDLINE	Health Inf Sci Syst	Cognitive computing and eScience in health and life science research: artificial intelligence and obesity intervention programs.		5	Cognitive computing and eScience in health and life science research: artificial intelligence and obesity intervention programs.
Prostate cancer (PCa) is a major cause of death since ancient time documented in Egyptian Ptolemaic mummy imaging. PCa detection is critical to personalized medicine and varies considerably under an MRI scan. 172 patients with 2,602 morphologic images (axial 2D T2-weighted imaging) of the prostate were obtained. A deep learning with deep convolutional neural network (DCNN) and a non-deep learning with SIFT image feature and bag-of-word (BoW), a representative method for image recognition and analysis, were used to distinguish pathologically confirmed PCa patients from prostate benign conditions (BCs) patients with prostatitis or prostate benign hyperplasia (BPH). In fully automated detection of PCa patients, deep learning had a statistically higher area under the receiver operating characteristics curve (AUC) than non-deep learning (P = 0.0007 < 0.001). The AUCs were 0.84 (95% CI 0.78-0.89) for deep learning method and 0.70 (95% CI 0.63-0.77) for non-deep learning method, respectively. Our results suggest that deep learning with DCNN is superior to non-deep learning with SIFT image feature and BoW model for fully automated PCa patients differentiation from prostate BCs patients. Our deep learning method is extensible to image modalities such as MR imaging, CT and PET of other organs.	"['Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Jiefang Road 1095, 430030, Wuhan, China.', 'School of Electronics Information and Communications, Huazhong University of Science and Technology, Luoyu Road 1037, Wuhan, Hubei, 430074, China.', 'Department of Nutrition and Food Hygiene, MOE Key Lab of Environment, Hubei Key Laboratory of Food Nutrition and Safety, Health, School of Public Health, Tongji Medical College, Huazhong University of Science and Technology, Hangkong Road 13, 430030, Wuhan, China.', 'Department of Radiology and Biomedical Imaging, Yale University School of Medicine, New Haven, 208042, Connecticut, USA.', 'Department of Maternal and Child and Adolescent & Department of Epidemiology and Biostatistics, School of Public Health, Tongji Medical College, Huazhong University of Science and Technology, Hangkong Road 13, 430030, Wuhan, China.', ""Program in Cellular and Molecular Medicine, Boston Children's Hospital, Boston, MA, 02115, USA."", 'Department of Radiology, Union Hospital, Huazhong University of Science and Technology, Jiefang Road 1277, 430022, Wuhan, China.', 'School of Electronics Information and Communications, Huazhong University of Science and Technology, Luoyu Road 1037, Wuhan, Hubei, 430074, China.', 'Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Jiefang Road 1095, 430030, Wuhan, China.', 'School of mechanical science and engineering, Huazhong University of Science and Technology, Luoyu Road 1037, 430074, Wuhan, China.', 'School of mechanical science and engineering, Huazhong University of Science and Technology, Luoyu Road 1037, 430074, Wuhan, China.', 'Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Jiefang Road 1095, 430030, Wuhan, China. wang6@tjh.tjmu.edu.cn.', 'Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science &Technology, Jie-Fang-Da-Dao 1095, Wuhan, 430030, P.R. China. wang6@tjh.tjmu.edu.cn.']"	['10.1038/s41598-017-15720-y [doi]', '10.1038/s41598-017-15720-y [pii]']	['Wang X', 'Yang W', 'Weinreb J', 'Han J', 'Li Q', 'Kong X', 'Yan Y', 'Ke Z', 'Luo B', 'Liu T', 'Wang L']							['2017/11/15 06:00']	20190723	20171113	2017 Nov 13	2017/11/15 06:00		['Wang, Xinggang', 'Yang, Wei', 'Weinreb, Jeffrey', 'Han, Juan', 'Li, Qiubai', 'Kong, Xiangchuang', 'Yan, Yongluan', 'Ke, Zan', 'Luo, Bo', 'Liu, Tao', 'Wang, Liang']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-15720-y [doi]	20190723	['Aged', 'Aged, 80 and over', '*Deep Learning', 'Diagnosis, Differential', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', 'Prostate/diagnostic imaging/pathology', 'Prostatic Hyperplasia/diagnostic imaging/pathology', 'Prostatic Neoplasms/*diagnostic imaging/pathology', 'Prostatitis/diagnostic imaging/pathology', 'ROC Curve', 'Retrospective Studies']	2019/07/25 06:00				NLM	15415	['2016/10/20 00:00 [received]', '2017/10/31 00:00 [accepted]', '2017/11/15 06:00 [entrez]', '2017/11/15 06:00 [pubmed]', '2019/07/25 06:00 [medline]']	England	PMC5684419		29133818	epublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"					Sci Rep. 2017 Nov 13;7(1):15415. doi: 10.1038/s41598-017-15720-y.	MEDLINE	Sci Rep	Searching for prostate cancer by fully automated magnetic resonance imaging classification: deep learning versus non-deep learning.		7	Searching for prostate cancer by fully automated magnetic resonance imaging classification: deep learning versus non-deep learning.
Computer science advances and ultra-fast computing speeds find artificial intelligence (AI) broadly benefitting modern society-forecasting weather, recognizing faces, detecting fraud, and deciphering genomics. AI's future role in medical practice remains an unanswered question. Machines (computers) learn to detect patterns not decipherable using biostatistics by processing massive datasets (big data) through layered mathematical models (algorithms). Correcting algorithm mistakes (training) adds to AI predictive model confidence. AI is being successfully applied for image analysis in radiology, pathology, and dermatology, with diagnostic speed exceeding, and accuracy paralleling, medical experts. While diagnostic confidence never reaches 100%, combining machines plus physicians reliably enhances system performance. Cognitive programs are impacting medical practice by applying natural language processing to read the rapidly expanding scientific literature and collate years of diverse electronic medical records. In this and other ways, AI may optimize the care trajectory of chronic disease patients, suggest precision therapies for complex illnesses, reduce medical errors, and improve subject enrollment into clinical trials.	['New York Medical College, Valhalla. Electronic address: ddouglasmiller1@gmail.com.', 'Foundational Innovations, IBM Watson Health, Yorktown Heights, NY.']	['S0002-9343(17)31117-8 [pii]', '10.1016/j.amjmed.2017.10.035 [doi]']	['Miller DD', 'Brown EW']		['Copyright (c) 2018 Elsevier Inc. All rights reserved.']					['2017/11/12 06:00']	20190626	20171107	2018 Feb	2017/11/12 06:00		['Miller, D Douglas', 'Brown, Eric W']			2		1555-7162 (Electronic) 0002-9343 (Linking)	0267200	The American journal of medicine	['eng']	S0002-9343(17)31117-8 [pii] 10.1016/j.amjmed.2017.10.035 [doi]	20190626	['Algorithms', '*Artificial Intelligence', 'Biostatistics', 'Chronic Disease/*therapy', 'Clinical Trials as Topic', '*Diagnosis, Computer-Assisted', 'Electronic Health Records', 'Humans', 'Image Processing, Computer-Assisted', 'Machine Learning', 'Medical Errors/prevention & control', 'Natural Language Processing', 'Patient Selection', 'Precision Medicine']	2019/06/27 06:00		['*Analytics', '*Artificial intelligence', '*Big data', '*Chronic disease', '*Deep learning', '*Electronic medical record', '*Machine learning', '*Medical imaging', '*Natural language processing', '*Neural networks', '*Precision medicine']	['NOTNLM']	NLM	129-133	['2017/10/05 00:00 [received]', '2017/10/23 00:00 [revised]', '2017/10/24 00:00 [accepted]', '2017/11/12 06:00 [pubmed]', '2019/06/27 06:00 [medline]', '2017/11/12 06:00 [entrez]']	United States			29126825	ppublish	['Journal Article', 'Review']			AIM IM		Am J Med. 2018 Feb;131(2):129-133. doi: 10.1016/j.amjmed.2017.10.035. Epub 2017 Nov 7.	MEDLINE	Am J Med	Artificial Intelligence in Medical Practice: The Question to the Answer?		131	Artificial Intelligence in Medical Practice: The Question to the Answer?
Visualization from trained deep neural networks has drawn massive public attention in recent. One of the visualization approaches is to train images maximizing the activation of specific neurons. However, directly maximizing the activation would lead to unrecognizable images, which cannot provide any meaningful information. In this paper, we introduce a simple but effective technique to constrain the optimization route of the visualization. By adding two totally inverse transformations, image blurring and deblurring, to the optimization procedure, recognizable images can be created. Our algorithm is good at extracting the details in the images, which are usually filtered by previous methods in the visualizations. Extensive experiments on AlexNet, VGGNet and GoogLeNet illustrate that we can better understand the neural networks utilizing the knowledge obtained by the visualization.	['School of Electronic Engineering, University of Electronic Science and Technology of China, China.', 'School of Electronic Engineering, University of Electronic Science and Technology of China, China.', 'School of Electronic Engineering, University of Electronic Science and Technology of China, China. Electronic address: chengjian@uestc.edu.cn.']	['S0893-6080(17)30209-5 [pii]', '10.1016/j.neunet.2017.09.007 [doi]']	['Wang F', 'Liu H', 'Cheng J']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/11/11 06:00']	20180607	20171010	2018 Jan	2017/11/11 06:00		['Wang, Feng', 'Liu, Haijun', 'Cheng, Jian']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30209-5 [pii] 10.1016/j.neunet.2017.09.007 [doi]	20180607	['Algorithms', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', '*Neural Networks (Computer)', 'Neurons/physiology']	2018/06/08 06:00		['Deep neural network', 'Image blurring and deblurring', 'Visualization']	['NOTNLM']	NLM	162-172	['2016/12/13 00:00 [received]', '2017/06/08 00:00 [revised]', '2017/09/04 00:00 [accepted]', '2017/11/11 06:00 [pubmed]', '2018/06/08 06:00 [medline]', '2017/11/11 06:00 [entrez]']	United States			29126069	ppublish	['Journal Article']			IM		Neural Netw. 2018 Jan;97:162-172. doi: 10.1016/j.neunet.2017.09.007. Epub 2017 Oct 10.	MEDLINE	Neural Netw	Visualizing deep neural network by alternately image blurring and deblurring.		97	Visualizing deep neural network by alternately image blurring and deblurring.
Protein-protein interactions (PPIs) play crucial roles in almost all cellular processes. Although a large amount of PPIs have been verified by high-throughput techniques in the past decades, currently known PPIs pairs are still far from complete. Furthermore, the wet-lab experiments based techniques for detecting PPIs are time-consuming and expensive. Hence, it is urgent and essential to develop automatic computational methods to efficiently and accurately predict PPIs. In this paper, a sequence-based approach called DNN-LCTD is developed by combining deep neural networks (DNNs) and a novel local conjoint triad description (LCTD) feature representation. LCTD incorporates the advantage of local description and conjoint triad, thus, it is capable to account for the interactions between residues in both continuous and discontinuous regions of amino acid sequences. DNNs can not only learn suitable features from the data by themselves, but also learn and discover hierarchical representations of data. When performing on the PPIs data of Saccharomyces cerevisiae, DNN-LCTD achieves superior performance with accuracy as 93.12%, precision as 93.75%, sensitivity as 93.83%, area under the receiver operating characteristic curve (AUC) as 97.92%, and it only needs 718 s. These results indicate DNN-LCTD is very promising for predicting PPIs. DNN-LCTD can be a useful supplementary tool for future proteomics study.	['College of Computer and Information Science, Southwest University, Chongqing 400715, China. kingjun@swu.edu.cn.', 'College of Computer and Information Science, Southwest University, Chongqing 400715, China. 18234031968@163.com.', 'College of Information Engineering and Automation, Kunming University of Science and Technology, Kunming 650000, China. jlianyin@163.com.', 'SMILE (Statistical Machine Intelligence & Learning) Lab and Big Data Research Center, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 610000, China. yazhou.ren@uestc.edu.cn.', 'College of Computer and Information Science, Southwest University, Chongqing 400715, China. gxyu@swu.edu.cn.']	['ijms18112373 [pii]', '10.3390/ijms18112373 [doi]']	['Wang J', 'Zhang L', 'Jia L', 'Ren Y', 'Yu G']	['ORCID: 0000-0002-5890-0365', 'ORCID: 0000-0002-1667-6705']				['The authors declare no conflict of interest']		['2017/11/09 06:00']	20180709	20171108	2017 Nov 8	2017/11/09 06:00		['Wang, Jun', 'Zhang, Long', 'Jia, Lianyin', 'Ren, Yazhou', 'Yu, Guoxian']			11		1422-0067 (Electronic) 1422-0067 (Linking)	101092791	International journal of molecular sciences	['eng']	E2373 [pii] 10.3390/ijms18112373 [doi]	20181113	['Amino Acid Sequence', 'Animals', 'Base Sequence', 'Neural Networks (Computer)', 'Protein Interaction Mapping/*methods', '*Protein Interaction Maps', 'ROC Curve', 'Saccharomyces cerevisiae/metabolism', 'Saccharomyces cerevisiae Proteins/metabolism', 'Sequence Analysis, Protein/*methods', 'Support Vector Machine']	2018/07/10 06:00		['amino acid sequences', 'deep neural networks', 'local conjoint triad descriptor', 'protein-protein interactions']	['NOTNLM']	NLM		['2017/10/09 00:00 [received]', '2017/11/01 00:00 [revised]', '2017/11/04 00:00 [accepted]', '2017/11/09 06:00 [entrez]', '2017/11/09 06:00 [pubmed]', '2018/07/10 06:00 [medline]']	Switzerland	PMC5713342		29117139	epublish	['Evaluation Studies', 'Journal Article']		['0 (Saccharomyces cerevisiae Proteins)']	IM		Int J Mol Sci. 2017 Nov 8;18(11). pii: ijms18112373. doi: 10.3390/ijms18112373.	MEDLINE	Int J Mol Sci	Protein-Protein Interactions Prediction Using a Novel Local Conjoint Triad Descriptor of Amino Acid Sequences.		18	Protein-Protein Interactions Prediction Using a Novel Local Conjoint Triad Descriptor of Amino Acid Sequences.
Molecular imaging enables the visualization and quantitative analysis of the alterations of biological procedures at molecular and/or cellular level, which is of great significance for early detection of cancer. In recent years, deep leaning has been widely used in medical imaging analysis, as it overcomes the limitations of visual assessment and traditional machine learning techniques by extracting hierarchical features with powerful representation capability. Research on cancer molecular images using deep learning techniques is also increasing dynamically. Hence, in this paper, we review the applications of deep learning in molecular imaging in terms of tumor lesion segmentation, tumor classification, and survival prediction. We also outline some future directions in which researchers may develop more powerful deep learning models for better performance in the applications in cancer molecular imaging.	['Guangzhou Panyu Central Hospital, Guangzhou, China.', 'Medical Imaging Institute of Panyu, Guangzhou, China.', 'National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China.', 'School of Nursing, The Hong Kong Polytechnic University, Hung Hom, Hong Kong.', 'Intensive Care Unit, Southern Medical University Shenzhen Hospital, Shenzhen, China.', 'Medical Imaging Institute of Panyu, Guangzhou, China.', 'National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China.', 'Guangzhou Panyu Central Hospital, Guangzhou, China.', 'Medical Imaging Institute of Panyu, Guangzhou, China.']	['10.1155/2017/9512370 [doi]']	['Xue Y', 'Chen S', 'Qin J', 'Liu Y', 'Huang B', 'Chen H']	['ORCID: 0000-0002-2961-0860', 'ORCID: 0000-0002-1183-7506', 'ORCID: 0000-0002-9618-542X']						['2017/11/09 06:00']	20180709	20171015	2017	2017/11/09 06:00		['Xue, Yong', 'Chen, Shihui', 'Qin, Jing', 'Liu, Yong', 'Huang, Bingsheng', 'Chen, Hanwei']					1555-4317 (Electronic) 1555-4309 (Linking)	101286760	Contrast media & molecular imaging	['eng']	10.1155/2017/9512370 [doi]	20190116	['Animals', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', 'Molecular Imaging/*methods', 'Neoplasms/*diagnostic imaging/mortality']	2018/07/10 06:00				NLM	9512370	['2017/04/07 00:00 [received]', '2017/09/06 00:00 [accepted]', '2017/11/09 06:00 [entrez]', '2017/11/09 06:00 [pubmed]', '2018/07/10 06:00 [medline]']	England	PMC5661078		29114182	epublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't""]"			IM		Contrast Media Mol Imaging. 2017 Oct 15;2017:9512370. doi: 10.1155/2017/9512370. eCollection 2017.	MEDLINE	Contrast Media Mol Imaging	Application of Deep Learning in Automated Analysis of Molecular Images in Cancer: A Survey.		2017	Application of Deep Learning in Automated Analysis of Molecular Images in Cancer: A Survey.
Some microbes possess the ability to adaptively manipulate host behavior. To better understand how such microbial parasites control animal behavior, we examine the cell-level interactions between the species-specific fungal parasite Ophiocordyceps unilateralis sensu lato and its carpenter ant host (Camponotus castaneus) at a crucial moment in the parasite's lifecycle: when the manipulated host fixes itself permanently to a substrate by its mandibles. The fungus is known to secrete tissue-specific metabolites and cause changes in host gene expression as well as atrophy in the mandible muscles of its ant host, but it is unknown how the fungus coordinates these effects to manipulate its host's behavior. In this study, we combine techniques in serial block-face scanning-electron microscopy and deep-learning-based image segmentation algorithms to visualize the distribution, abundance, and interactions of this fungus inside the body of its manipulated host. Fungal cells were found throughout the host body but not in the brain, implying that behavioral control of the animal body by this microbe occurs peripherally. Additionally, fungal cells invaded host muscle fibers and joined together to form networks that encircled the muscles. These networks may represent a collective foraging behavior of this parasite, which may in turn facilitate host manipulation.	['Department of Entomology, Pennsylvania State University, University Park, PA 16802.', 'Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556.', 'Huck Institutes of the Life Sciences Microscopy and Cytometry Facility, Pennsylvania State University, University Park, PA 16802.', 'Department of Entomology, Pennsylvania State University, University Park, PA 16802.', 'Center for Infectious Disease Dynamics, Pennsylvania State University, University Park, PA 16802.', 'Center for Infectious Disease Dynamics, Pennsylvania State University, University Park, PA 16802.', 'Department of Biochemistry and Molecular Biology, Pennsylvania State University, University Park, PA 16802.', 'Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556.', 'Department of Entomology, Pennsylvania State University, University Park, PA 16802; dhughes@psu.edu.', 'Center for Infectious Disease Dynamics, Pennsylvania State University, University Park, PA 16802.', 'Department of Biology, Pennsylvania State University, University Park, PA 16802.']	['1711673114 [pii]', '10.1073/pnas.1711673114 [doi]']	['Fredericksen MA', 'Zhang Y', 'Hazen ML', 'Loreto RG', 'Mangold CA', 'Chen DZ', 'Hughes DP']		['Copyright (c) 2017 the Author(s). Published by PNAS.']			['The authors declare no conflict of interest.']		['2017/11/09 06:00']	20180626	20171107	2017 Nov 21	2017/11/09 06:00		['Fredericksen, Maridel A', 'Zhang, Yizhe', 'Hazen, Missy L', 'Loreto, Raquel G', 'Mangold, Colleen A', 'Chen, Danny Z', 'Hughes, David P']		['R01 GM116927/GM/NIGMS NIH HHS/United States']	47		1091-6490 (Electronic) 0027-8424 (Linking)	7505876	Proceedings of the National Academy of Sciences of the United States of America	['eng']	10.1073/pnas.1711673114 [doi]	20190508	['Animals', 'Ants/anatomy & histology/cytology/*microbiology', 'Behavior, Animal', '*Host-Pathogen Interactions', 'Hypocreales/pathogenicity/physiology/*ultrastructure', 'Image Processing, Computer-Assisted/statistics & numerical data', 'Imaging, Three-Dimensional', '*Machine Learning', 'Mandible/microbiology', 'Muscles/*microbiology/ultrastructure']	2018/06/27 06:00		['*ants', '*behavioral manipulation', '*deep learning', '*extended phenotype', '*fungal networks']	['NOTNLM']	NLM	12590-12595	['2017/11/09 06:00 [pubmed]', '2018/06/27 06:00 [medline]', '2017/11/09 06:00 [entrez]']	United States	PMC5703306		29114054	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Proc Natl Acad Sci U S A. 2017 Nov 21;114(47):12590-12595. doi: 10.1073/pnas.1711673114. Epub 2017 Nov 7.	MEDLINE	Proc Natl Acad Sci U S A	Three-dimensional visualization and a deep-learning model reveal complex fungal parasite networks in behaviorally manipulated ants.		114	Three-dimensional visualization and a deep-learning model reveal complex fungal parasite networks in behaviorally manipulated ants.
The key finding in the DNA double helix model is the specific pairing or binding between nucleotides A-T and C-G, and the pairing rules are the molecule basis of genetic code. Unfortunately, no such rules have been discovered for proteins. Here we show that intrinsic sequence patterns between intra-protein binding peptide fragments exist, they can be extracted using a deep learning algorithm, and they bear an interesting semblance to the DNA double helix model. The intra-protein binding peptide fragments have specific and intrinsic sequence patterns, distinct from non-binding peptide fragments, and multi-millions of binding and non-binding peptide fragments from currently available protein X-ray structures are classified with an accuracy of up to 93%. The specific binding between short peptide fragments may provide an important driving force for protein folding and protein-protein interaction, two open and fundamental problems in molecular biology, and it may have significant potential in design, discovery, and development of peptide, protein, and antibody drugs.	['Department of chemistry and Laser Chemistry Institute, Fudan University, Shanghai, 200433, P.R. China. lake.chao@gmail.com.', 'Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, 76019, USA.', 'School of life science, Jilin University, Changchun, 130012, P.R. China.', 'Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, 76019, USA.', 'Department of chemistry and Laser Chemistry Institute, Fudan University, Shanghai, 200433, P.R. China.']	['10.1038/s41598-017-14877-w [doi]', '10.1038/s41598-017-14877-w [pii]']	['Wang Y', 'Huang J', 'Li W', 'Wang S', 'Ding C']							['2017/11/04 06:00']	20190715	20171102	2017 Nov 2	2017/11/04 06:00		['Wang, Yuhong', 'Huang, Junzhou', 'Li, Wei', 'Wang, Sheng', 'Ding, Chuanfan']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-14877-w [doi]	20190715	['Algorithms', 'Amino Acid Sequence', 'Binding Sites', 'Databases, Protein', '*Deep Learning', 'Peptide Fragments/chemistry/*metabolism', 'Protein Binding', 'Protein Conformation', 'Proteins/chemistry/*metabolism']	2019/07/16 06:00				NLM	14916	['2017/04/20 00:00 [received]', '2017/10/19 00:00 [accepted]', '2017/11/04 06:00 [entrez]', '2017/11/04 06:00 [pubmed]', '2019/07/16 06:00 [medline]']	England	PMC5668431		29097708	epublish	['Journal Article']		['0 (Peptide Fragments)', '0 (Proteins)']	IM		Sci Rep. 2017 Nov 2;7(1):14916. doi: 10.1038/s41598-017-14877-w.	MEDLINE	Sci Rep	Specific and intrinsic sequence patterns extracted by deep learning from intra-protein binding and non-binding peptide fragments.		7	Specific and intrinsic sequence patterns extracted by deep learning from intra-protein binding and non-binding peptide fragments.
Our ability to predict protein expression from DNA sequence alone remains poor, reflecting our limited understanding of cis-regulatory grammar and hampering the design of engineered genes for synthetic biology applications. Here, we generate a model that predicts the protein expression of the 5' untranslated region (UTR) of mRNAs in the yeast Saccharomyces cerevisiae. We constructed a library of half a million 50-nucleotide-long random 5' UTRs and assayed their activity in a massively parallel growth selection experiment. The resulting data allow us to quantify the impact on protein expression of Kozak sequence composition, upstream open reading frames (uORFs), and secondary structure. We trained a convolutional neural network (CNN) on the random library and showed that it performs well at predicting the protein expression of both a held-out set of the random 5' UTRs as well as native S. cerevisiae 5' UTRs. The model additionally was used to computationally evolve highly active 5' UTRs. We confirmed experimentally that the great majority of the evolved sequences led to higher protein expression rates than the starting sequences, demonstrating the predictive power of this model.	['Department of Genome Sciences, University of Washington, Seattle, Washington 98195, USA.', 'Howard Hughes Medical Institute, University of Washington, Seattle, Washington 98195, USA.', 'Department of Electrical Engineering, University of Washington, Seattle, Washington 98195, USA.', 'Department of Electrical Engineering, University of Washington, Seattle, Washington 98195, USA.', 'Department of Electrical Engineering, University of Washington, Seattle, Washington 98195, USA.', 'Microsoft Research, Seattle, Washington 98195, USA.', 'Department of Genome Sciences, University of Washington, Seattle, Washington 98195, USA.', 'Howard Hughes Medical Institute, University of Washington, Seattle, Washington 98195, USA.', 'Department of Medicine, University of Washington, Seattle, Washington 98195, USA.', 'Department of Electrical Engineering, University of Washington, Seattle, Washington 98195, USA.', 'Department of Computer Science & Engineering, University of Washington, Seattle, Washington 98195, USA.']	['gr.224964.117 [pii]', '10.1101/gr.224964.117 [doi]']	['Cuperus JT', 'Groves B', 'Kuchina A', 'Rosenberg AB', 'Jojic N', 'Fields S', 'Seelig G']	['ORCID: 0000-0002-8019-7733']	['(c) 2017 Cuperus et al.; Published by Cold Spring Harbor Laboratory Press.']					['2017/11/04 06:00']	20180703	20171102	2017 Dec	2017/11/04 06:00		['Cuperus, Josh T', 'Groves, Benjamin', 'Kuchina, Anna', 'Rosenberg, Alexander B', 'Jojic, Nebojsa', 'Fields, Stanley', 'Seelig, Georg']		['P41 GM103533/GM/NIGMS NIH HHS/United States', 'HHMI/Howard Hughes Medical Institute/United States']	12		1549-5469 (Electronic) 1088-9051 (Linking)	9518021	Genome research	['eng']	10.1101/gr.224964.117 [doi]	20181113	"[""5' Untranslated Regions"", 'Alternative Splicing', 'Computer Simulation', 'Gene Library', 'Machine Learning', '*Models, Genetic', 'Neural Networks (Computer)', 'RNA, Fungal', 'RNA, Messenger', 'Saccharomyces cerevisiae/*genetics']"	2018/07/04 06:00				NLM	2015-2024	['2017/05/12 00:00 [received]', '2017/10/18 00:00 [accepted]', '2017/11/04 06:00 [pubmed]', '2018/07/04 06:00 [medline]', '2017/11/04 06:00 [entrez]']	United States	PMC5741052		29097404	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S."", ""Research Support, Non-U.S. Gov't""]"		"[""0 (5' Untranslated Regions)"", '0 (RNA, Fungal)', '0 (RNA, Messenger)']"	IM		Genome Res. 2017 Dec;27(12):2015-2024. doi: 10.1101/gr.224964.117. Epub 2017 Nov 2.	MEDLINE	Genome Res	Deep learning of the regulatory grammar of yeast 5' untranslated regions from 500,000 random sequences.		27	Deep learning of the regulatory grammar of yeast 5' untranslated regions from 500,000 random sequences.
Machine learning methods have been applied to many data sets in pharmaceutical research for several decades. The relative ease and availability of fingerprint type molecular descriptors paired with Bayesian methods resulted in the widespread use of this approach for a diverse array of end points relevant to drug discovery. Deep learning is the latest machine learning algorithm attracting attention for many of pharmaceutical applications from docking to virtual screening. Deep learning is based on an artificial neural network with multiple hidden layers and has found considerable traction for many artificial intelligence applications. We have previously suggested the need for a comparison of different machine learning methods with deep learning across an array of varying data sets that is applicable to pharmaceutical research. End points relevant to pharmaceutical research include absorption, distribution, metabolism, excretion, and toxicity (ADME/Tox) properties, as well as activity against pathogens and drug discovery data sets. In this study, we have used data sets for solubility, probe-likeness, hERG, KCNQ1, bubonic plague, Chagas, tuberculosis, and malaria to compare different machine learning methods using FCFP6 fingerprints. These data sets represent whole cell screens, individual proteins, physicochemical properties as well as a data set with a complex end point. Our aim was to assess whether deep learning offered any improvement in testing when assessed using an array of metrics including AUC, F1 score, Cohen's kappa, Matthews correlation coefficient and others. Based on ranked normalized scores for the metrics or data sets Deep Neural Networks (DNN) ranked higher than SVM, which in turn was ranked higher than all the other machine learning methods. Visualizing these properties for training and test sets using radar type plots indicates when models are inferior or perhaps over trained. These results also suggest the need for assessing deep learning further using multiple metrics with much larger scale comparisons, prospective testing as well as assessment of different fingerprints and DNN architectures beyond those used.	['Science Data Software, LLC , 14914 Bradwill Court, Rockville, Maryland 20850, United States.', 'Science Data Software, LLC , 14914 Bradwill Court, Rockville, Maryland 20850, United States.', 'Collaborations Pharmaceuticals, Inc. , 840 Main Campus Drive, Lab 3510, Raleigh, North Carolina 27606, United States.', 'The Rutgers Center for Computational and Integrative Biology , Camden, New Jersey 08102, United States.', 'Collaborations Pharmaceuticals, Inc. , 840 Main Campus Drive, Lab 3510, Raleigh, North Carolina 27606, United States.']	['10.1021/acs.molpharmaceut.7b00578 [doi]']	['Korotcov A', 'Tkachenko V', 'Russo DP', 'Ekins S']	['ORCID: 0000-0002-5691-5790']						['2017/11/04 06:00']	20180727	20171113	2017 Dec 4	2017/11/04 06:00		['Korotcov, Alexandru', 'Tkachenko, Valery', 'Russo, Daniel P', 'Ekins, Sean']		['R21 TR001718/TR/NCATS NIH HHS/United States', 'R43 GM122196/GM/NIGMS NIH HHS/United States']	12		1543-8392 (Electronic) 1543-8384 (Linking)	101197791	Molecular pharmaceutics	['eng']	10.1021/acs.molpharmaceut.7b00578 [doi]	20190118	['Bayes Theorem', 'Datasets as Topic', 'Drug Discovery/*methods', '*Machine Learning', '*Neural Networks (Computer)']	2018/07/28 06:00	['NIHMS927142']	['*deep learning', '*drug discovery', '*machine learning', '*pharmaceutics', '*support vector machine']	['NOTNLM']	NLM	4462-4475	['2017/11/04 06:00 [pubmed]', '2018/07/28 06:00 [medline]', '2017/11/04 06:00 [entrez]']	United States	PMC5741413		29096442	ppublish	['Comparative Study', 'Journal Article', 'Research Support, N.I.H., Extramural']			IM		Mol Pharm. 2017 Dec 4;14(12):4462-4475. doi: 10.1021/acs.molpharmaceut.7b00578. Epub 2017 Nov 13.	MEDLINE	Mol Pharm	Comparison of Deep Learning With Multiple Machine Learning Methods and Metrics Using Diverse Drug Discovery Data Sets.		14	Comparison of Deep Learning With Multiple Machine Learning Methods and Metrics Using Diverse Drug Discovery Data Sets.
Purpose To compare the performance of a deep-learning bone age assessment model based on hand radiographs with that of expert radiologists and that of existing automated models. Materials and Methods The institutional review board approved the study. A total of 14 036 clinical hand radiographs and corresponding reports were obtained from two children's hospitals to train and validate the model. For the first test set, composed of 200 examinations, the mean of bone age estimates from the clinical report and three additional human reviewers was used as the reference standard. Overall model performance was assessed by comparing the root mean square (RMS) and mean absolute difference (MAD) between the model estimates and the reference standard bone ages. Ninety-five percent limits of agreement were calculated in a pairwise fashion for all reviewers and the model. The RMS of a second test set composed of 913 examinations from the publicly available Digital Hand Atlas was compared with published reports of an existing automated model. Results The mean difference between bone age estimates of the model and of the reviewers was 0 years, with a mean RMS and MAD of 0.63 and 0.50 years, respectively. The estimates of the model, the clinical report, and the three reviewers were within the 95% limits of agreement. RMS for the Digital Hand Atlas data set was 0.73 years, compared with 0.61 years of a previously reported model. Conclusion A deep-learning convolutional neural network model can estimate skeletal maturity with accuracy similar to that of an expert radiologist and to that of existing automated models. ((c)) RSNA, 2017 An earlier incorrect version of this article appeared online. This article was corrected on January 19, 2018.	"[""From the Departments of Radiology (D.B.L., M.P.L., S.S.H., C.P.L.), Computer Science (M.C.C.), and Biomedical Informatics (C.P.L.), Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305-5105; and Department of Radiology, Children's Hospital Colorado, Aurora, Colo (N.V.S.)."", ""From the Departments of Radiology (D.B.L., M.P.L., S.S.H., C.P.L.), Computer Science (M.C.C.), and Biomedical Informatics (C.P.L.), Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305-5105; and Department of Radiology, Children's Hospital Colorado, Aurora, Colo (N.V.S.)."", ""From the Departments of Radiology (D.B.L., M.P.L., S.S.H., C.P.L.), Computer Science (M.C.C.), and Biomedical Informatics (C.P.L.), Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305-5105; and Department of Radiology, Children's Hospital Colorado, Aurora, Colo (N.V.S.)."", ""From the Departments of Radiology (D.B.L., M.P.L., S.S.H., C.P.L.), Computer Science (M.C.C.), and Biomedical Informatics (C.P.L.), Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305-5105; and Department of Radiology, Children's Hospital Colorado, Aurora, Colo (N.V.S.)."", ""From the Departments of Radiology (D.B.L., M.P.L., S.S.H., C.P.L.), Computer Science (M.C.C.), and Biomedical Informatics (C.P.L.), Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305-5105; and Department of Radiology, Children's Hospital Colorado, Aurora, Colo (N.V.S.)."", ""From the Departments of Radiology (D.B.L., M.P.L., S.S.H., C.P.L.), Computer Science (M.C.C.), and Biomedical Informatics (C.P.L.), Stanford University School of Medicine, 300 Pasteur Dr, Stanford, CA 94305-5105; and Department of Radiology, Children's Hospital Colorado, Aurora, Colo (N.V.S.).""]"	['10.1148/radiol.2017170236 [doi]']	['Larson DB', 'Chen MC', 'Lungren MP', 'Halabi SS', 'Stence NV', 'Langlotz CP']			['Radiology. 2018 Apr;287(1):323-325. PMID: 29558310']				['2017/11/03 06:00']	20180509	20171102	2018 Apr	2017/11/03 06:00		['Larson, David B', 'Chen, Matthew C', 'Lungren, Matthew P', 'Halabi, Safwan S', 'Stence, Nicholas V', 'Langlotz, Curtis P']			1		1527-1315 (Electronic) 0033-8419 (Linking)	0401260	Radiology	['eng']	10.1148/radiol.2017170236 [doi]	20180509	['Adolescent', 'Adult', 'Age Determination by Skeleton/*methods', 'Child', 'Child, Preschool', 'Female', 'Hand/*anatomy & histology/diagnostic imaging', 'Humans', 'Infant', '*Machine Learning', 'Male', '*Neural Networks (Computer)', 'Radiography/*methods', 'Young Adult']	2018/05/10 06:00				NLM	313-322	['2017/11/03 06:00 [pubmed]', '2018/05/10 06:00 [medline]', '2017/11/03 06:00 [entrez]']	United States			29095675	ppublish	['Journal Article']			AIM IM		Radiology. 2018 Apr;287(1):313-322. doi: 10.1148/radiol.2017170236. Epub 2017 Nov 2.	MEDLINE	Radiology	Performance of a Deep-Learning Neural Network Model in Assessing Skeletal Maturity on Pediatric Hand Radiographs.		287	Performance of a Deep-Learning Neural Network Model in Assessing Skeletal Maturity on Pediatric Hand Radiographs.
Generative artificial intelligence models present a fresh approach to chemogenomics and de novo drug design, as they provide researchers with the ability to narrow down their search of the chemical space and focus on regions of interest. We present a method for molecular de novo design that utilizes generative recurrent neural networks (RNN) containing long short-term memory (LSTM) cells. This computational model captured the syntax of molecular representation in terms of SMILES strings with close to perfect accuracy. The learned pattern probabilities can be used for de novo SMILES generation. This molecular design concept eliminates the need for virtual compound library enumeration. By employing transfer learning, we fine-tuned the RNN's predictions for specific molecular targets. This approach enables virtual compound design without requiring secondary or external activity prediction, which could introduce error or unwanted bias. The results obtained advocate this generative RNN-LSTM system for high-impact use cases, such as low-data drug discovery, fragment based molecular design, and hit-to-lead optimization for diverse drug targets.	['Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093, Zurich, Switzerland.', 'Stanford University, Department of Computer Science, 450 Sierra Mall, Stanford, CA, 94305, USA.', 'Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093, Zurich, Switzerland.', 'Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093, Zurich, Switzerland.', 'Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093, Zurich, Switzerland.', 'Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093, Zurich, Switzerland.', 'inSili.com GmbH, 8049, Zurich, Switzerland.', 'Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, 8093, Zurich, Switzerland.']	['10.1002/minf.201700111 [doi]']	['Gupta A', 'Muller AT', 'Huisman BJH', 'Fuchs JA', 'Schneider P', 'Schneider G']	['ORCID: 0000-0001-6706-1084']	['(c) 2017 The Authors. Published by Wiley-VCH Verlag GmbH & Co. KGaA.']					['2017/11/03 06:00']	20181218	20171102	2018 Jan	2017/11/03 06:00	['Mol Inform. 2018 Jan;37(1-2):. PMID: 29442444']	['Gupta, Anvita', 'Muller, Alex T', 'Huisman, Berend J H', 'Fuchs, Jens A', 'Schneider, Petra', 'Schneider, Gisbert']			1-2		1868-1751 (Electronic) 1868-1743 (Linking)	101529315	Molecular informatics	['eng']	10.1002/minf.201700111 [doi]	20181218	['*Drug Design', 'Drug Discovery/methods', 'Models, Chemical', '*Neural Networks (Computer)', 'Quantitative Structure-Activity Relationship']	2018/12/19 06:00		['*Chemogenomics', '*deep learning', '*drug discovery', '*machine learning', '*medicinal chemistry']	['NOTNLM']	NLM		['2017/08/29 00:00 [received]', '2017/10/16 00:00 [accepted]', '2017/11/03 06:00 [pubmed]', '2018/12/19 06:00 [medline]', '2017/11/03 06:00 [entrez]']	Germany	PMC5836943		29095571	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Mol Inform. 2018 Jan;37(1-2). doi: 10.1002/minf.201700111. Epub 2017 Nov 2.	MEDLINE	Mol Inform	Generative Recurrent Networks for De Novo Drug Design.		37	Generative Recurrent Networks for De Novo Drug Design.
Traditional dysphagia prescreening diagnostic methods require doctors specialists to give patients a total score based on a water swallow test scale. This method is limited by the high dimensionality of the diagnostic elements in the water swallow test scale with heavy workload (Towards each patient, the scale requires the doctors give score for 18 diagnostic elements respectively) as well as the difficulties of extracting and using the diagnostic scale data's non-linear features and hidden expertise information (Even with the scale scores, specific diagnostic conclusions are still given by expert doctors under the expertise). In this paper, a hybrid classifier model based on Nonlinear-Principal Component Analysis (NPCA) and Deep Belief Networks (DBN) is proposed in order to effectively extract the diagnostic scale data's nonlinear features and hidden information and to provide the key scale elements' locating methods towards the diagnostic results (The key scale elements that affect different diagnostic conclusions are given to improve the efficiency and pertinence of diagnosis and reduce the workload of diagnosis). We demonstrate the effectiveness of the proposed method using the frame of 'information entropy theory'. Real dysphagia diagnosis examples from the China-Japanese Friendship Hospital are used to demonstrate applications of the proposed methods. The examples show satisfactory results compared to the traditional classifier.	['a School of Information Science and Technology , Beijing University of Chemical Technology , Beijing , China.', 'a School of Information Science and Technology , Beijing University of Chemical Technology , Beijing , China.', 'b Department of Rehabilitation , China-Japanese Friendship Hospital , Beijing , China.', 'b Department of Rehabilitation , China-Japanese Friendship Hospital , Beijing , China.', 'b Department of Rehabilitation , China-Japanese Friendship Hospital , Beijing , China.', 'a School of Information Science and Technology , Beijing University of Chemical Technology , Beijing , China.']	['10.1080/24699322.2017.1389391 [doi]']	['Su C', 'Gao Y', 'Xie Y', 'Xue Y', 'Ge L', 'Li H']							['2017/11/03 06:00']	20190621	20171102	2017 Dec	2017/11/03 06:00		['Su, Chong', 'Gao, Yue', 'Xie, Yuxiao', 'Xue, Yong', 'Ge, Lijun', 'Li, Hongguang']			sup1		2469-9322 (Electronic) 2469-9322 (Linking)	101681550	Computer assisted surgery (Abingdon, England)	['eng']	10.1080/24699322.2017.1389391 [doi]	20190621	['Cohort Studies', 'Deglutition/*physiology', 'Deglutition Disorders/*classification/*diagnosis', 'Diagnostic Techniques, Digestive System', 'Humans', 'Machine Learning', '*Neural Networks (Computer)', 'Principal Component Analysis', 'Water/*administration & dosage']	2019/06/22 06:00		['*Dysphagia diagnosis', '*deep belief networks (DBN)', '*entropy', '*non-linear PCA (NPCA)']	['NOTNLM']	NLM	135-147	['2017/11/03 06:00 [pubmed]', '2019/06/22 06:00 [medline]', '2017/11/03 06:00 [entrez]']	England			29095063	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['059QF0KO0R (Water)']	IM		Comput Assist Surg (Abingdon). 2017 Dec;22(sup1):135-147. doi: 10.1080/24699322.2017.1389391. Epub 2017 Nov 2.	MEDLINE	Comput Assist Surg (Abingdon)	A hybrid classifier based on nonlinear-PCA and deep belief networks with applications in dysphagia diagnosis.		22	A hybrid classifier based on nonlinear-PCA and deep belief networks with applications in dysphagia diagnosis.
New architectures of multilayer artificial neural networks and new methods for training them are rapidly revolutionizing the application of machine learning in diverse fields, including business, social science, physical sciences, and biology. Interpreting deep neural networks, however, currently remains elusive, and a critical challenge lies in understanding which meaningful features a network is actually learning. We present a general method for interpreting deep neural networks and extracting network-learned features from input data. We describe our algorithm in the context of biological sequence analysis. Our approach, based on ideas from statistical physics, samples from the maximum entropy distribution over possible sequences, anchored at an input sequence and subject to constraints implied by the empirical function learned by a network. Using our framework, we demonstrate that local transcription factor binding motifs can be identified from a network trained on ChIP-seq data and that nucleosome positioning signals are indeed learned by a network trained on chemical cleavage nucleosome maps. Imposing a further constraint on the maximum entropy distribution also allows us to probe whether a network is learning global sequence features, such as the high GC content in nucleosome-rich regions. This work thus provides valuable mathematical tools for interpreting and extracting learned features from feed-forward neural networks.	['Department of Physics, University of Illinois, Urbana-Champaign, Urbana, Illinois, United States of America.', 'Carl R. Woese Institute for Genomic Biology, University of Illinois, Urbana-Champaign, Urbana, Illinois, United States of America.', 'Department of Physics, University of Illinois, Urbana-Champaign, Urbana, Illinois, United States of America.', 'Carl R. Woese Institute for Genomic Biology, University of Illinois, Urbana-Champaign, Urbana, Illinois, United States of America.']	['10.1371/journal.pcbi.1005836 [doi]', 'PCOMPBIOL-D-17-00614 [pii]']	['Finnegan A', 'Song JS']	['ORCID: http://orcid.org/0000-0002-0422-2175']						['2017/10/31 06:00']	20171117	20171030	2017 Oct	2017/10/31 06:00		['Finnegan, Alex', 'Song, Jun S']		['R01 CA163336/CA/NCI NIH HHS/United States']	10		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1005836 [doi]	20181113	['*Algorithms', 'Computer Simulation', 'Entropy', '*Machine Learning', '*Models, Statistical', '*Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', 'Sequence Analysis, DNA/*methods']	2017/11/29 06:00				NLM	e1005836	['2017/04/18 00:00 [received]', '2017/10/23 00:00 [accepted]', '2017/11/09 00:00 [revised]', '2017/10/31 06:00 [pubmed]', '2017/11/29 06:00 [medline]', '2017/10/31 06:00 [entrez]']	United States	PMC5679649		29084280	epublish	['Journal Article']			IM		PLoS Comput Biol. 2017 Oct 30;13(10):e1005836. doi: 10.1371/journal.pcbi.1005836. eCollection 2017 Oct.	MEDLINE	PLoS Comput Biol	Maximum entropy methods for extracting the learned features of deep neural networks.		13	Maximum entropy methods for extracting the learned features of deep neural networks.
Motivation: Annotation of enzyme function has a broad range of applications, such as metagenomics, industrial biotechnology, and diagnosis of enzyme deficiency-caused diseases. However, the time and resource required make it prohibitively expensive to experimentally determine the function of every enzyme. Therefore, computational enzyme function prediction has become increasingly important. In this paper, we develop such an approach, determining the enzyme function by predicting the Enzyme Commission number. Results: We propose an end-to-end feature selection and classification model training approach, as well as an automatic and robust feature dimensionality uniformization method, DEEPre, in the field of enzyme function prediction. Instead of extracting manually crafted features from enzyme sequences, our model takes the raw sequence encoding as inputs, extracting convolutional and sequential features from the raw encoding based on the classification result to directly improve the prediction performance. The thorough cross-fold validation experiments conducted on two large-scale datasets show that DEEPre improves the prediction performance over the previous state-of-the-art methods. In addition, our server outperforms five other servers in determining the main class of enzymes on a separate low-homology dataset. Two case studies demonstrate DEEPre's ability to capture the functional difference of enzyme isoforms. Availability and implementation: The server could be accessed freely at http://www.cbrc.kaust.edu.sa/DEEPre. Contact: xin.gao@kaust.edu.sa. Supplementary information: Supplementary data are available at Bioinformatics online.	['Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC), Computer, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia.', 'Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC), Computer, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia.', 'Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC), Computer, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia.', 'Computer Science Department, Illinois Institute of Technology, Chicago, IL 60616, USA.', 'Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou 310018, China.', 'Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou 310018, China.', 'Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC), Computer, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia.']	['4562505 [pii]', '10.1093/bioinformatics/btx680 [doi]']	['Li Y', 'Wang S', 'Umarov R', 'Xie B', 'Fan M', 'Li L', 'Gao X']		['(c) The Author(s) 2017. Published by Oxford University Press.']					['2017/10/26 06:00']	20181023		2018 Mar 1	2017/10/27 06:00		['Li, Yu', 'Wang, Sheng', 'Umarov, Ramzan', 'Xie, Bingqing', 'Fan, Ming', 'Li, Lihua', 'Gao, Xin']			5		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx680 [doi]	20181113	['Computational Biology/*methods', 'Enzymes/*metabolism', 'Humans', '*Machine Learning', 'Molecular Sequence Annotation/*methods', 'Software']	2018/10/24 06:00				NLM	760-769	['2017/07/13 00:00 [received]', '2017/10/20 00:00 [accepted]', '2017/10/27 06:00 [pubmed]', '2018/10/24 06:00 [medline]', '2017/10/26 06:00 [entrez]']	England	PMC6030869		29069344	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Enzymes)']	IM		Bioinformatics. 2018 Mar 1;34(5):760-769. doi: 10.1093/bioinformatics/btx680.	MEDLINE	Bioinformatics	DEEPre: sequence-based enzyme EC number prediction by deep learning.		34	DEEPre: sequence-based enzyme EC number prediction by deep learning.
Lung cancer is the most common cancer that cannot be ignored and cause death with late health care. Currently, CT can be used to help doctors detect the lung cancer in the early stages. In many cases, the diagnosis of identifying the lung cancer depends on the experience of doctors, which may ignore some patients and cause some problems. Deep learning has been proved as a popular and powerful method in many medical imaging diagnosis areas. In this paper, three types of deep neural networks (e.g., CNN, DNN, and SAE) are designed for lung cancer calcification. Those networks are applied to the CT image classification task with some modification for the benign and malignant lung nodules. Those networks were evaluated on the LIDC-IDRI database. The experimental results show that the CNN network archived the best performance with an accuracy of 84.15%, sensitivity of 83.96%, and specificity of 84.32%, which has the best result among the three networks.	['School of Computer Science & Software Engineering, Tianjin Polytechnics University, Tianjin, China.', 'School of Computer Science & Software Engineering, Tianjin Polytechnics University, Tianjin, China.', 'School of Computer Science & Software Engineering, Tianjin Polytechnics University, Tianjin, China.', 'School of Computer Science & Software Engineering, Tianjin Polytechnics University, Tianjin, China.']	['10.1155/2017/8314740 [doi]']	['Song Q', 'Zhao L', 'Luo X', 'Dou X']	['ORCID: 0000-0002-8884-6638']						['2017/10/26 06:00']	20190730	20170809	2017	2017/10/27 06:00		['Song, QingZeng', 'Zhao, Lei', 'Luo, XingKe', 'Dou, XueChen']					2040-2295 (Print) 2040-2295 (Linking)	101528166	Journal of healthcare engineering	['eng']	10.1155/2017/8314740 [doi]	20190730	['Algorithms', '*Deep Learning', 'Diagnosis, Computer-Assisted/*methods', 'Humans', 'Image Processing, Computer-Assisted', 'Lung Neoplasms/*diagnostic imaging', 'Neural Networks (Computer)', 'ROC Curve', 'Radiography, Thoracic', 'Reproducibility of Results', 'Sensitivity and Specificity', 'Software', 'Solitary Pulmonary Nodule/*diagnostic imaging', '*Tomography, X-Ray Computed']	2019/07/31 06:00				NLM	8314740	['2017/03/10 00:00 [received]', '2017/05/14 00:00 [accepted]', '2017/10/26 06:00 [entrez]', '2017/10/27 06:00 [pubmed]', '2019/07/31 06:00 [medline]']	England	PMC5569872		29065651	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"					J Healthc Eng. 2017;2017:8314740. doi: 10.1155/2017/8314740. Epub 2017 Aug 9.	MEDLINE	J Healthc Eng	Using Deep Learning for Classification of Lung Nodules on Computed Tomography Images.		2017	Using Deep Learning for Classification of Lung Nodules on Computed Tomography Images.
Medical images play an important role in medical diagnosis and research. In this paper, a transfer learning- and deep learning-based super resolution reconstruction method is introduced. The proposed method contains one bicubic interpolation template layer and two convolutional layers. The bicubic interpolation template layer is prefixed by mathematics deduction, and two convolutional layers learn from training samples. For saving training medical images, a SIFT feature-based transfer learning method is proposed. Not only can medical images be used to train the proposed method, but also other types of images can be added into training dataset selectively. In empirical experiments, results of eight distinctive medical images show improvement of image quality and time reduction. Further, the proposed method also produces slightly sharper edges than other deep learning approaches in less time and it is projected that the hybrid architecture of prefixed template layer and unfixed hidden layers has potentials in other applications.	['School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China.', 'College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin 300222, China.', 'College of Science, Tianjin University of Science and Technology, Tianjin 300222, China.']	['10.1155/2017/5859727 [doi]']	['Zhang Y', 'An M']	['ORCID: 0000-0001-5970-7308']						['2017/10/26 06:00']	20190710	20170706	2017	2017/10/27 06:00		['Zhang, YiNan', 'An, MingQiang']					2040-2295 (Print) 2040-2295 (Linking)	101528166	Journal of healthcare engineering	['eng']	10.1155/2017/5859727 [doi]	20190710	['Algorithms', '*Deep Learning', '*Diagnostic Imaging', 'Image Processing, Computer-Assisted/*methods']	2019/07/11 06:00				NLM	5859727	['2017/01/23 00:00 [received]', '2017/04/05 00:00 [revised]', '2017/05/10 00:00 [accepted]', '2017/10/26 06:00 [entrez]', '2017/10/27 06:00 [pubmed]', '2019/07/11 06:00 [medline]']	England	PMC5518500		29065625	ppublish	['Journal Article']			IM		J Healthc Eng. 2017;2017:5859727. doi: 10.1155/2017/5859727. Epub 2017 Jul 6.	MEDLINE	J Healthc Eng	Deep Learning- and Transfer Learning-Based Super Resolution Reconstruction from Single Medical Image.		2017	Deep Learning- and Transfer Learning-Based Super Resolution Reconstruction from Single Medical Image.
In this study, we report the evaluation of the residue-residue contacts predicted by our three different methods in the CASP12 experiment, focusing on studying the impact of multiple sequence alignment, residue coevolution, and machine learning on contact prediction. The first method (MULTICOM-NOVEL) uses only traditional features (sequence profile, secondary structure, and solvent accessibility) with deep learning to predict contacts and serves as a baseline. The second method (MULTICOM-CONSTRUCT) uses our new alignment algorithm to generate deep multiple sequence alignment to derive coevolution-based features, which are integrated by a neural network method to predict contacts. The third method (MULTICOM-CLUSTER) is a consensus combination of the predictions of the first two methods. We evaluated our methods on 94 CASP12 domains. On a subset of 38 free-modeling domains, our methods achieved an average precision of up to 41.7% for top L/5 long-range contact predictions. The comparison of the three methods shows that the quality and effective depth of multiple sequence alignments, coevolution-based features, and machine learning integration of coevolution-based features and traditional features drive the quality of predicted protein contacts. On the full CASP12 dataset, the coevolution-based features alone can improve the average precision from 28.4% to 41.6%, and the machine learning integration of all the features further raises the precision to 56.3%, when top L/5 predicted long-range contacts are evaluated. And the correlation between the precision of contact prediction and the logarithm of the number of effective sequences in alignments is 0.66.	['Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, Missouri.', 'Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, Missouri.', 'Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, Missouri.']	['10.1002/prot.25405 [doi]']	['Adhikari B', 'Hou J', 'Cheng J']	['ORCID: 0000-0003-0305-2853']	['(c) 2017 Wiley Periodicals, Inc.']					['2017/10/20 06:00']	20190118	20171031	2018 Mar	2017/10/20 06:00		['Adhikari, Badri', 'Hou, Jie', 'Cheng, Jianlin']		['R01 GM093123/GM/NIGMS NIH HHS/United States']			1097-0134 (Electronic) 0887-3585 (Linking)	8700181	Proteins	['eng']	10.1002/prot.25405 [doi]	20190301	['Algorithms', 'Computational Biology/*methods', 'Crystallography, X-Ray', 'Databases, Protein', 'Datasets as Topic', 'Humans', '*Machine Learning', '*Models, Molecular', '*Protein Conformation', 'Protein Folding', 'Proteins/*chemistry', 'Sequence Alignment', 'Sequence Analysis, Protein']	2019/01/19 06:00	['NIHMS928808']	['*CASP', '*coevolution', '*deep learning', '*machine learning', '*multiple sequence alignment', '*protein contact prediction']	['NOTNLM']	NLM	84-96	['2017/06/23 00:00 [received]', '2017/09/08 00:00 [revised]', '2017/10/16 00:00 [accepted]', '2017/10/20 06:00 [pubmed]', '2019/01/19 06:00 [medline]', '2017/10/20 06:00 [entrez]']	United States	PMC5820155		29047157	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']		['0 (Proteins)']	IM		Proteins. 2018 Mar;86 Suppl 1:84-96. doi: 10.1002/prot.25405. Epub 2017 Oct 31.	MEDLINE	Proteins	Protein contact prediction by integrating deep multiple sequence alignments, coevolution and machine learning.		86 Suppl 1	Protein contact prediction by integrating deep multiple sequence alignments, coevolution and machine learning.
Malignant melanoma is one of the most deadly forms of skin cancer, which is one of the world's fastest-growing cancers. Early diagnosis and treatment is critical. In this study, a neural network structure is utilized to construct a broad and accurate basis for the diagnosis of skin cancer, thereby reducing screening errors. The technique is able to improve the efficacy for identification of normally indistinguishable lesions (such as pigment spots) versus clinically unknown lesions, and to ultimately improve the diagnostic accuracy. In the field of medical imaging, in general, using neural networks for image segmentation is relatively rare. The existing traditional machine-learning neural network algorithms still cannot completely solve the problem of information loss, nor detect the precise division of the boundary area. We use an improved neural network framework, described herein, to achieve efficacious feature learning, and satisfactory segmentation of melanoma images. The architecture of the network includes multiple convolution layers, dropout layers, softmax layers, multiple filters, and activation functions. The number of data sets can be increased via rotation of the training set. A non-linear activation function (such as ReLU and ELU) is employed to alleviate the problem of gradient disappearance, and RMSprop/Adam are incorporated to optimize the loss algorithm. A batch normalization layer is added between the convolution layer and the activation layer to solve the problem of gradient disappearance and explosion. Experiments, described herein, show that our improved neural network architecture achieves higher accuracy for segmentation of melanoma images as compared with existing processes.	['a College of Information Science and Technology , Donghua University , Shanghai , China.']	['10.1080/24699322.2017.1389405 [doi]']	['Zhang X']							['2017/10/19 06:00']	20190621	20171018	2017 Dec	2017/10/19 06:00		['Zhang, Xiaoqing']			sup1		2469-9322 (Electronic) 2469-9322 (Linking)	101681550	Computer assisted surgery (Abingdon, England)	['eng']	10.1080/24699322.2017.1389405 [doi]	20190621	['Algorithms', '*Deep Learning', 'Early Detection of Cancer/methods', 'Humans', '*Image Processing, Computer-Assisted', 'Melanoma/diagnosis/*pathology', 'Neural Networks (Computer)', 'Reproducibility of Results', 'Skin Neoplasms/diagnosis/*pathology']	2019/06/22 06:00		['*Melanoma', '*convolutional neural networks', '*deep learning', '*image segmentation']	['NOTNLM']	NLM	267-277	['2017/10/19 06:00 [pubmed]', '2019/06/22 06:00 [medline]', '2017/10/19 06:00 [entrez]']	England			29043858	ppublish	['Journal Article']		['Melanoma, Cutaneous Malignant']	IM		Comput Assist Surg (Abingdon). 2017 Dec;22(sup1):267-277. doi: 10.1080/24699322.2017.1389405. Epub 2017 Oct 18.	MEDLINE	Comput Assist Surg (Abingdon)	Melanoma segmentation based on deep learning.		22	Melanoma segmentation based on deep learning.
This study aimed to compare shallow and deep learning of classifying the patterns of interstitial lung diseases (ILDs). Using high-resolution computed tomography images, two experienced radiologists marked 1200 regions of interest (ROIs), in which 600 ROIs were each acquired using a GE or Siemens scanner and each group of 600 ROIs consisted of 100 ROIs for subregions that included normal and five regional pulmonary disease patterns (ground-glass opacity, consolidation, reticular opacity, emphysema, and honeycombing). We employed the convolution neural network (CNN) with six learnable layers that consisted of four convolution layers and two fully connected layers. The classification results were compared with the results classified by a shallow learning of a support vector machine (SVM). The CNN classifier showed significantly better performance for accuracy compared with that of the SVM classifier by 6-9%. As the convolution layer increases, the classification accuracy of the CNN showed better performance from 81.27 to 95.12%. Especially in the cases showing pathological ambiguity such as between normal and emphysema cases or between honeycombing and reticular opacity cases, the increment of the convolution layer greatly drops the misclassification rate between each case. Conclusively, the CNN classifier showed significantly greater accuracy than the SVM classifier, and the results implied structural characteristics that are inherent to the specific ILD patterns.	['Biomedical Engineering Research Center, Asan Institute of Life Science, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, Republic of Korea.', 'VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, Republic of Korea.', 'VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, Republic of Korea.', 'VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, Republic of Korea.', 'Department of Convergence Medicine, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, Republic of Korea. namkugkim@gmail.com.', 'Department of Convergence Medicine, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, Republic of Korea.', 'Department of Radiology, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, Republic of Korea. joonbeom.seo@gmail.com.', 'Department of Radiology, National Jewish Medical and Research Center, Denver, CO, USA.']	['10.1007/s10278-017-0028-9 [doi]', '10.1007/s10278-017-0028-9 [pii]']	['Kim GB', 'Jung KH', 'Lee Y', 'Kim HJ', 'Kim N', 'Jun S', 'Seo JB', 'Lynch DA']	['ORCID: 0000-0002-3438-2217']						['2017/10/19 06:00']	20191031		2018 Aug	2017/10/19 06:00		['Kim, Guk Bae', 'Jung, Kyu-Hwan', 'Lee, Yeha', 'Kim, Hyun-Jun', 'Kim, Namkug', 'Jun, Sanghoon', 'Seo, Joon Beom', 'Lynch, David A']			4		1618-727X (Electronic) 0897-1889 (Linking)	9100529	Journal of digital imaging	['eng']	10.1007/s10278-017-0028-9 [doi]	20191031	['Algorithms', 'Cohort Studies', '*Deep Learning', 'Female', 'Humans', 'Lung Diseases, Interstitial/*classification/*diagnostic imaging/pathology', 'Male', 'Neural Networks (Computer)', 'Pattern Recognition, Automated/*methods', 'Retrospective Studies', 'Tomography, X-Ray Computed/*methods']	2019/11/02 06:00		['*Convolution neural network', '*Deep architecture', '*Interscanner variation', '*Interstitial lung disease', '*Support vector machine']	['NOTNLM']	NLM	415-424	['2017/10/19 06:00 [pubmed]', '2019/11/02 06:00 [medline]', '2017/10/19 06:00 [entrez]']	United States	PMC6113148		29043528	ppublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Digit Imaging. 2018 Aug;31(4):415-424. doi: 10.1007/s10278-017-0028-9.	MEDLINE	J Digit Imaging	Comparison of Shallow and Deep Learning Methods on Classifying the Regional Pattern of Diffuse Lung Disease.		31	Comparison of Shallow and Deep Learning Methods on Classifying the Regional Pattern of Diffuse Lung Disease.
BACKGROUND & AIMS: Narrow-band imaging is an image-enhanced form of endoscopy used to observed microstructures and capillaries of the mucosal epithelium which allows for real-time prediction of histologic features of colorectal polyps. However, narrow-band imaging expertise is required to differentiate hyperplastic from neoplastic polyps with high levels of accuracy. We developed and tested a system of computer-aided diagnosis with a deep neural network (DNN-CAD) to analyze narrow-band images of diminutive colorectal polyps. METHODS: We collected 1476 images of neoplastic polyps and 681 images of hyperplastic polyps, obtained from the picture archiving and communications system database in a tertiary hospital in Taiwan. Histologic findings from the polyps were also collected and used as the reference standard. The images and data were used to train the DNN. A test set of images (96 hyperplastic and 188 neoplastic polyps, smaller than 5 mm), obtained from patients who underwent colonoscopies from March 2017 through August 2017, was then used to test the diagnostic ability of the DNN-CAD vs endoscopists (2 expert and 4 novice), who were asked to classify the images of the test set as neoplastic or hyperplastic. Their classifications were compared with findings from histologic analysis. The primary outcome measures were diagnostic accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic time. The accuracy, sensitivity, specificity, PPV, NPV, and diagnostic time were compared among DNN-CAD, the novice endoscopists, and the expert endoscopists. The study was designed to detect a difference of 10% in accuracy by a 2-sided McNemar test. RESULTS: In the test set, the DNN-CAD identified neoplastic or hyperplastic polyps with 96.3% sensitivity, 78.1% specificity, a PPV of 89.6%, and a NPV of 91.5%. Fewer than half of the novice endoscopists classified polyps with a NPV of 90% (their NPVs ranged from 73.9% to 84.0%). DNN-CAD classified polyps as neoplastic or hyperplastic in 0.45 +/- 0.07 seconds-shorter than the time required by experts (1.54 +/- 1.30 seconds) and nonexperts (1.77 +/- 1.37 seconds) (both P < .001). DNN-CAD classified polyps with perfect intra-observer agreement (kappa score of 1). There was a low level of intra-observer and inter-observer agreement in classification among endoscopists. CONCLUSIONS: We developed a system called DNN-CAD to identify neoplastic or hyperplastic colorectal polyps less than 5 mm. The system classified polyps with a PPV of 89.6%, and a NPV of 91.5%, and in a shorter time than endoscopists. This deep-learning model has potential for not only endoscopic image recognition but for other forms of medical image analysis, including sonography, computed tomography, and magnetic resonance images.	['Division of Gastroenterology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan. Electronic address: endoscopy@mail.ndmctsgh.edu.tw.', 'Department of Biological Science and Technology, National Chiao Tung University, Hsinchu, Taiwan; Division of Gastroenterology, Taichung Armed Forces General Hospital, Taichung, Taiwan.', 'Department of Pathology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan.', 'Division of Gastroenterology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan.', 'Big Data Research Center and Institute of Statistics, National Chiao Tung University, Hsinchu, Taiwan.', 'Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan. Electronic address: vtseng@cs.nctu.edu.tw.']	['S0016-5085(17)36251-0 [pii]', '10.1053/j.gastro.2017.10.010 [doi]']	['Chen PJ', 'Lin MC', 'Lai MJ', 'Lin JC', 'Lu HH', 'Tseng VS']		['Copyright (c) 2018 AGA Institute. Published by Elsevier Inc. All rights reserved.']					['2017/10/19 06:00']	20180503	20171016	2018 Feb	2017/10/19 06:00		['Chen, Peng-Jen', 'Lin, Meng-Chiung', 'Lai, Mei-Ju', 'Lin, Jung-Chun', 'Lu, Henry Horng-Shing', 'Tseng, Vincent S']			3		1528-0012 (Electronic) 0016-5085 (Linking)	0374630	Gastroenterology	['eng']	S0016-5085(17)36251-0 [pii] 10.1053/j.gastro.2017.10.010 [doi]	20180503	['Automation', 'Colonic Polyps/classification/*pathology', 'Colonoscopy/*methods', 'Colorectal Neoplasms/classification/*pathology', 'Databases, Factual', '*Decision Support Techniques', '*Diagnosis, Computer-Assisted', 'Humans', 'Hyperplasia', '*Image Interpretation, Computer-Assisted', '*Narrow Band Imaging', 'Neural Networks (Computer)', 'Observer Variation', 'Predictive Value of Tests', 'Reproducibility of Results', 'Retrospective Studies', 'Taiwan', 'Tumor Burden']	2018/05/04 06:00		['*Colon Cancer Detection', '*Cost-effectiveness', '*Machine Learning', '*Magnifying']	['NOTNLM']	NLM	568-575	['2017/07/25 00:00 [received]', '2017/10/04 00:00 [revised]', '2017/10/09 00:00 [accepted]', '2017/10/19 06:00 [pubmed]', '2018/05/04 06:00 [medline]', '2017/10/19 06:00 [entrez]']	United States			29042219	ppublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			AIM IM		Gastroenterology. 2018 Feb;154(3):568-575. doi: 10.1053/j.gastro.2017.10.010. Epub 2017 Oct 16.	MEDLINE	Gastroenterology	Accurate Classification of Diminutive Colorectal Polyps Using Computer-Aided Analysis.		154	Accurate Classification of Diminutive Colorectal Polyps Using Computer-Aided Analysis.
The malignancy risk differentiation of pulmonary nodule is one of the most challenge tasks of computer-aided diagnosis (CADx). Most recently reported CADx methods or schemes based on texture and shape estimation have shown relatively satisfactory on differentiating the risk level of malignancy among the nodules detected in lung cancer screening. However, the existing CADx schemes tend to detect and analyze characteristics of pulmonary nodules from a statistical perspective according to local features only. Enlightened by the currently prevailing learning ability of convolutional neural network (CNN), which simulates human neural network for target recognition and our previously research on texture features, we present a hybrid model that takes into consideration of both global and local features for pulmonary nodule differentiation using the largest public database founded by the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI). By comparing three types of CNN models in which two of them were newly proposed by us, we observed that the multi-channel CNN model yielded the best discrimination in capacity of differentiating malignancy risk of the nodules based on the projection of distributions of extracted features. Moreover, CADx scheme using the new multi-channel CNN model outperformed our previously developed CADx scheme using the 3D texture feature analysis method, which increased the computed area under a receiver operating characteristic curve (AUC) from 0.9441 to 0.9702.	['North China University of Technology, School of Electrical Information, Beijing, China.', 'School of Software Engineering, Beihang University, Beijing, China.', 'School of Software Engineering, Beihang University, Beijing, China.', 'Department of Engineering Science and Physics, City University of New York at CSI, Staten Island, NY, USA.', 'School of Software Engineering, Beihang University, Beijing, China.', 'North China University of Technology, School of Electrical Information, Beijing, China.', 'School of Software Engineering, Beihang University, Beijing, China.', 'Department of Biomedical, Northeast University, Shenyan, China.', 'North China University of Technology, School of Electrical Information, Beijing, China.', 'School of Software Engineering, Beihang University, Beijing, China.', 'Department of Radiology, State University of New York at Stony Brook, NY, USA.']	['XST17302 [pii]', '10.3233/XST-17302 [doi]']	['Wang H', 'Zhao T', 'Li LC', 'Pan H', 'Liu W', 'Gao H', 'Han F', 'Wang Y', 'Qi Y', 'Liang Z']							['2017/10/18 06:00']	20181002		2018	2017/10/19 06:00		['Wang, Huafeng', 'Zhao, Tingting', 'Li, Lihong Connie', 'Pan, Haixia', 'Liu, Wanquan', 'Gao, Haoqi', 'Han, Fangfang', 'Wang, Yuehai', 'Qi, Yifan', 'Liang, Zhengrong']			2		1095-9114 (Electronic) 0895-3996 (Linking)	9000080	Journal of X-ray science and technology	['eng']	10.3233/XST-17302 [doi]	20181004	['Algorithms', 'Diagnosis, Computer-Assisted/*methods', 'Early Detection of Cancer', 'Humans', 'Lung/*diagnostic imaging', 'Lung Neoplasms/*diagnostic imaging', 'Machine Learning', '*Neural Networks (Computer)', 'Risk']	2018/10/03 06:00		['*Convolutional neural network (CNN)', '*computer-aided diagnosis (CADx)', '*deep learning', '*multi-channel CNN', '*pulmonary nodule differentiation', '*texture']	['NOTNLM']	NLM	171-187	['2017/10/19 06:00 [pubmed]', '2018/10/03 06:00 [medline]', '2017/10/18 06:00 [entrez]']	Netherlands			29036877	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		J Xray Sci Technol. 2018;26(2):171-187. doi: 10.3233/XST-17302.	MEDLINE	J Xray Sci Technol	A hybrid CNN feature model for pulmonary nodule malignancy risk differentiation.		26	A hybrid CNN feature model for pulmonary nodule malignancy risk differentiation.
Alternative splicing (AS) is a genetically and epigenetically regulated pre-mRNA processing to increase transcriptome and proteome diversity. Comprehensively decoding these regulatory mechanisms holds promise in getting deeper insights into a variety of biological contexts involving in AS, such as development and diseases. We assembled splicing (epi)genetic code, DeepCode, for human embryonic stem cell (hESC) differentiation by integrating heterogeneous features of genomic sequences, 16 histone modifications with a multi-label deep neural network. With the advantages of epigenetic features, DeepCode significantly improves the performance in predicting the splicing patterns and their changes during hESC differentiation. Meanwhile, DeepCode reveals the superiority of epigenomic features and their dominant roles in decoding AS patterns, highlighting the necessity of including the epigenetic properties when assembling a more comprehensive splicing code. Moreover, DeepCode allows the robust predictions across cell lineages and datasets. Especially, we identified a putative H3K36me3-regulated AS event leading to a nonsense-mediated mRNA decay of BARD1. Reduced BARD1 expression results in the attenuation of ATM/ATR signalling activities and further the hESC differentiation. These results suggest a novel candidate mechanism linking histone modifications to hESC fate decision. In addition, when trained in different contexts, DeepCode can be expanded to a variety of biological and biomedical fields.	['Center for Systems Medicine, School of Biomedical Bioinformatics, University of Texas Health Science Center at Houston, TX 77030, USA.', 'Center for Bioinformatics and Systems Biology, Wake Forest School of Medicine, Winston-Salem, NC 27157, USA.', 'Key Laboratory of Adaptation and Evolution of Plateau Biota, Northwest Institute of Plateau Biology, Chinese Academy of Sciences, Xining, Qinghai 810008, China.', 'Center for Systems Medicine, School of Biomedical Bioinformatics, University of Texas Health Science Center at Houston, TX 77030, USA.', 'Center for Systems Medicine, School of Biomedical Bioinformatics, University of Texas Health Science Center at Houston, TX 77030, USA.', 'Center for Systems Medicine, School of Biomedical Bioinformatics, University of Texas Health Science Center at Houston, TX 77030, USA.', 'Center for Bioinformatics and Systems Biology, Wake Forest School of Medicine, Winston-Salem, NC 27157, USA.']	['4259771 [pii]', '10.1093/nar/gkx870 [doi]']	['Xu Y', 'Wang Y', 'Luo J', 'Zhao W', 'Zhou X']		['(c) The Author(s) 2017. Published by Oxford University Press on behalf of Nucleic', 'Acids Research.']					['2017/10/17 06:00']	20171226		2017 Dec 1	2017/10/17 06:00		['Xu, Yungang', 'Wang, Yongcui', 'Luo, Jiesi', 'Zhao, Weiling', 'Zhou, Xiaobo']			21		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gkx870 [doi]	20181113	['*Alternative Splicing', 'Cell Differentiation/genetics', 'Cell Line', 'Cell Lineage', 'Embryonic Stem Cells/*metabolism', '*Epigenesis, Genetic', 'High-Throughput Nucleotide Sequencing', '*Histone Code', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', 'Sequence Analysis, RNA', 'Tumor Suppressor Proteins/genetics/metabolism', 'Ubiquitin-Protein Ligases/genetics/metabolism']	2017/12/27 06:00				NLM	12100-12112	['2017/03/29 00:00 [received]', '2017/09/15 00:00 [accepted]', '2017/10/17 06:00 [pubmed]', '2017/12/27 06:00 [medline]', '2017/10/17 06:00 [entrez]']	England	PMC5716079		29036709	ppublish	['Evaluation Studies', 'Journal Article']		['0 (Tumor Suppressor Proteins)', 'EC 2.3.2.27 (BARD1 protein, human)', 'EC 2.3.2.27 (Ubiquitin-Protein Ligases)']	IM		Nucleic Acids Res. 2017 Dec 1;45(21):12100-12112. doi: 10.1093/nar/gkx870.	MEDLINE	Nucleic Acids Res	Deep learning of the splicing (epi)genetic code reveals a novel candidate mechanism linking histone modifications to ESC fate decision.		45	Deep learning of the splicing (epi)genetic code reveals a novel candidate mechanism linking histone modifications to ESC fate decision.
Motivation: Computational methods for phosphorylation site prediction play important roles in protein function studies and experimental design. Most existing methods are based on feature extraction, which may result in incomplete or biased features. Deep learning as the cutting-edge machine learning method has the ability to automatically discover complex representations of phosphorylation patterns from the raw sequences, and hence it provides a powerful tool for improvement of phosphorylation site prediction. Results: We present MusiteDeep, the first deep-learning framework for predicting general and kinase-specific phosphorylation sites. MusiteDeep takes raw sequence data as input and uses convolutional neural networks with a novel two-dimensional attention mechanism. It achieves over a 50% relative improvement in the area under the precision-recall curve in general phosphorylation site prediction and obtains competitive results in kinase-specific prediction compared to other well-known tools on the benchmark data. Availability and implementation: MusiteDeep is provided as an open-source tool available at https://github.com/duolinwang/MusiteDeep. Contact: xudong@missouri.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun 130012, China.', 'Department of Electrical Engineering and Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA.', 'Department of Electrical Engineering and Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA.', 'Department of Electrical Engineering and Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA.', 'Department of Electrical Engineering and Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA.', 'Computer Department, Jingdezhen Ceramic Institute, Jingdezhen 333403, China.', 'Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun 130012, China.', 'Department of Computer Science and Technology, Zhuhai College of Jilin University, Zhuhai 519041, China.', 'Department of Electrical Engineering and Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA.', 'Department of Health Management and Informatics, School of Medicine, University of Missouri, Columbia, MO 65211, USA.', 'Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun 130012, China.', 'Department of Electrical Engineering and Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA.']	['4061279 [pii]', '10.1093/bioinformatics/btx496 [doi]']	['Wang D', 'Zeng S', 'Xu C', 'Qiu W', 'Liang Y', 'Joshi T', 'Xu D']		['(c) The Author 2017. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com']					['2017/10/17 06:00']	20180806		2017 Dec 15	2017/10/17 06:00		['Wang, Duolin', 'Zeng, Shuai', 'Xu, Chunhui', 'Qiu, Wangren', 'Liang, Yanchun', 'Joshi, Trupti', 'Xu, Dong']		['R01 GM100701/GM/NIGMS NIH HHS/United States']	24		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx496 [doi]	20190610	['*Machine Learning', 'Neural Networks (Computer)', 'Phosphoproteins/*chemistry', 'Phosphorylation', 'Protein Kinases/metabolism', 'Proteins/metabolism', 'Sequence Analysis, Protein/*methods', '*Software']	2018/08/07 06:00				NLM	3909-3916	['2017/05/09 00:00 [received]', '2017/08/01 00:00 [accepted]', '2017/10/17 06:00 [pubmed]', '2018/08/07 06:00 [medline]', '2017/10/17 06:00 [entrez]']	England	PMC5860086		29036382	ppublish	['Journal Article']		['0 (Phosphoproteins)', '0 (Proteins)', 'EC 2.7.- (Protein Kinases)']	IM		Bioinformatics. 2017 Dec 15;33(24):3909-3916. doi: 10.1093/bioinformatics/btx496.	MEDLINE	Bioinformatics	MusiteDeep: a deep-learning framework for general and kinase-specific phosphorylation site prediction.		33	MusiteDeep: a deep-learning framework for general and kinase-specific phosphorylation site prediction.
The goal of the present study was to apply deep learning algorithms to identify autism spectrum disorder (ASD) patients from large brain imaging dataset, based solely on the patients brain activation patterns. We investigated ASD patients brain imaging data from a world-wide multi-site database known as ABIDE (Autism Brain Imaging Data Exchange). ASD is a brain-based disorder characterized by social deficits and repetitive behaviors. According to recent Centers for Disease Control data, ASD affects one in 68 children in the United States. We investigated patterns of functional connectivity that objectively identify ASD participants from functional brain imaging data, and attempted to unveil the neural patterns that emerged from the classification. The results improved the state-of-the-art by achieving 70% accuracy in identification of ASD versus control patients in the dataset. The patterns that emerged from the classification show an anticorrelation of brain function between anterior and posterior areas of the brain; the anticorrelation corroborates current empirical evidence of anterior-posterior disruption in brain connectivity in ASD. We present the results and identify the areas of the brain that contributed most to differentiating ASD from typically developing controls as per our deep learning model.	['PUCRS, School of Computer Science, Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, School of Engineering, Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, School of Medicine, Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'Center for the Developing Brain, Child Mind Institute, New York, New York 10022, USA.', 'Nathan Kline Institute for Psychiatric Research, Orangeburg, New York 10962, USA.', 'PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, School of Medicine, Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, School of Humanities, Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, School of Computer Science, Porto Alegre 90619, Rio Grande do Sul, Brazil.', 'PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre 90619, Rio Grande do Sul, Brazil.']	['10.1016/j.nicl.2017.08.017 [doi]', 'S2213-1582(17)30207-3 [pii]']	['Heinsfeld AS', 'Franco AR', 'Craddock RC', 'Buchweitz A', 'Meneguzzi F']							['2017/10/17 06:00']	20180612	20170830	2018	2017/10/17 06:00		['Heinsfeld, Anibal Solon', 'Franco, Alexandre Rosa', 'Craddock, R Cameron', 'Buchweitz, Augusto', 'Meneguzzi, Felipe']					2213-1582 (Electronic) 2213-1582 (Linking)	101597070	NeuroImage. Clinical	['eng']	10.1016/j.nicl.2017.08.017 [doi]	20181113	['Adolescent', 'Adult', 'Autism Spectrum Disorder/*diagnostic imaging', 'Brain/*diagnostic imaging', 'Brain Mapping', 'Case-Control Studies', 'Child', 'Datasets as Topic', 'Female', 'Functional Neuroimaging', 'Humans', 'Image Processing, Computer-Assisted', '*Machine Learning/classification', 'Male', '*Neural Networks (Computer)', 'Neural Pathways/*diagnostic imaging', 'Rest', 'Young Adult']	2018/06/13 06:00		['ABIDE', 'Autism', 'Deep learning', 'Resting state', 'fMRI']	['NOTNLM']	NLM	16-23	['2016/11/01 00:00 [received]', '2017/06/30 00:00 [revised]', '2017/08/22 00:00 [accepted]', '2017/10/17 06:00 [entrez]', '2017/10/17 06:00 [pubmed]', '2018/06/13 06:00 [medline]']	Netherlands	PMC5635344		29034163	epublish	['Journal Article']			IM		Neuroimage Clin. 2017 Aug 30;17:16-23. doi: 10.1016/j.nicl.2017.08.017. eCollection 2018.	MEDLINE	Neuroimage Clin	Identification of autism spectrum disorder using deep learning and the ABIDE dataset.		17	Identification of autism spectrum disorder using deep learning and the ABIDE dataset.
In this study, to advance smart health applications which have increasing security/privacy requirements, we propose a novel highly wearable ECG-based user identification system, empowered by both non-standard convenient ECG lead configurations and deep learning techniques. Specifically, to achieve a super wearability, we suggest situating all the ECG electrodes on the left upper-arm, or behind the ears, and successfully obtain weak but distinguishable ECG waveforms. Afterwards, to identify individuals from weak ECG, we further present a two-stage framework, including ECG imaging and deep feature learning/identification. In the former stage, the ECG heartbeats are projected to a 2D state space, to reveal heartbeats' trajectory behaviors and produce 2D images by a split-then-hit method. In the second stage, a convolutional neural network is introduced to automatically learn the intricate patterns directly from the ECG image representations without heavy feature engineering, and then perform user identification. Experimental results on two acquired datasets using our wearable prototype, show a promising identification rate of 98.4% (single-arm-ECG) and 91.1% (ear-ECG), respectively. To the best of our knowledge, it is the first study on the feasibility of using single-arm-ECG/ear-ECG for user identification purpose, which is expected to contribute to pervasive ECG-based user identification in smart health applications.	['Department of Electrical Engineering, University of Texas at Dallas, 800 W Campbell Rd, Richardson, TX, 75080, USA. qingxue.zhg@gmail.com.', 'Harvard Medical School, A-111, 25 Shattuck St, Boston, MA, 02115, USA. qingxue.zhg@gmail.com.', 'Massachusetts General Hospital, 55 Fruit St, Boston, MA, 02114, USA. qingxue.zhg@gmail.com.', 'Department of Electrical Engineering, University of Texas at Dallas, 800 W Campbell Rd, Richardson, TX, 75080, USA.', 'Department of Microelectronics, Fudan University, 220 Handan Rd, Shanghai, 200433, China.']	['10.1007/s10439-017-1944-z [doi]', '10.1007/s10439-017-1944-z [pii]']	['Zhang Q', 'Zhou D']	['ORCID: http://orcid.org/0000-0001-7125-7928']						['2017/10/15 06:00']	20190206	20171013	2018 Jan	2017/10/17 06:00		['Zhang, Qingxue', 'Zhou, Dian']		['Thousand Talents Plan/Recruitment of Global Experts', '61574044/National Natural Science Foundation of China (CN)']	1		1573-9686 (Electronic) 0090-6964 (Linking)	0361512	Annals of biomedical engineering	['eng']	10.1007/s10439-017-1944-z [doi]	20190215	['Arm', 'Biometric Identification/instrumentation/*methods', 'Ear', 'Electrocardiography/*instrumentation', 'Humans', 'Image Processing, Computer-Assisted', 'Machine Learning', '*Wearable Electronic Devices']	2019/02/07 06:00		['Biometric', 'Convolutional neural network', 'Deep learning', 'ECG', 'Machine learning', 'Representation learning', 'Smart health', 'User identification', 'Wearable computers']	['NOTNLM']	NLM	122-134	['2017/06/10 00:00 [received]', '2017/10/10 00:00 [accepted]', '2017/10/17 06:00 [pubmed]', '2019/02/07 06:00 [medline]', '2017/10/15 06:00 [entrez]']	United States			29030801	ppublish	['Journal Article']			IM		Ann Biomed Eng. 2018 Jan;46(1):122-134. doi: 10.1007/s10439-017-1944-z. Epub 2017 Oct 13.	MEDLINE	Ann Biomed Eng	Deep Arm/Ear-ECG Image Learning for Highly Wearable Biometric Human Identification.		46	Deep Arm/Ear-ECG Image Learning for Highly Wearable Biometric Human Identification.
Motivation: A large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. Experimental functional characterization of these proteins is time-consuming and expensive, and is often only done rigorously for few selected model organisms. Computational function prediction approaches have been suggested to fill this gap. The functions of proteins are classified using the Gene Ontology (GO), which contains over 40 000 classes. Additionally, proteins have multiple functions, making function prediction a large-scale, multi-class, multi-label problem. Results: We have developed a novel method to predict protein function from sequence. We use deep learning to learn features from protein sequences as well as a cross-species protein-protein interaction network. Our approach specifically outputs information in the structure of the GO and utilizes the dependencies between GO classes as background information to construct a deep learning model. We evaluate our method using the standards established by the Computational Assessment of Function Annotation (CAFA) and demonstrate a significant improvement over baseline methods such as BLAST, in particular for predicting cellular locations. Availability and implementation: Web server: http://deepgo.bio2vec.net, Source code: https://github.com/bio-ontology-research-group/deepgo. Contact: robert.hoehndorf@kaust.edu.sa. Supplementary information: Supplementary data are available at Bioinformatics online.	['Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal 23955-6900, Kingdom of Saudi Arabia.', 'Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal 23955-6900, Kingdom of Saudi Arabia.', 'Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal 23955-6900, Kingdom of Saudi Arabia.']	['4265461 [pii]', '10.1093/bioinformatics/btx624 [doi]']	['Kulmanov M', 'Khan MA', 'Hoehndorf R', 'Wren J']		['(c) The Author(s) 2017. Published by Oxford University Press.']					['2017/10/14 06:00']	20181114		2018 Feb 15	2017/10/14 06:00		['Kulmanov, Maxat', 'Khan, Mohammed Asif', 'Hoehndorf, Robert', 'Wren, Jonathan']			4		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx624 [doi]	20181114	['Animals', 'Bacteria/metabolism', 'Computational Biology/methods', 'Eukaryota/metabolism', '*Gene Ontology', 'Humans', '*Protein Interaction Maps', 'Proteins/*metabolism/physiology', 'Sequence Analysis, Protein/*methods', '*Software', '*Supervised Machine Learning']	2018/11/15 06:00				NLM	660-668	['2017/05/10 00:00 [received]', '2017/09/27 00:00 [accepted]', '2017/10/14 06:00 [pubmed]', '2018/11/15 06:00 [medline]', '2017/10/14 06:00 [entrez]']	England	PMC5860606		29028931	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		Bioinformatics. 2018 Feb 15;34(4):660-668. doi: 10.1093/bioinformatics/btx624.	MEDLINE	Bioinformatics	DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier.		34	DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier.
The synthesis of glycans and the sorting of proteins are critical functions of the Golgi apparatus and depend on its highly complex and compartmentalized architecture. High-content image analysis coupled to RNA interference screening offers opportunities to explore this organelle organization and the gene network underlying it. To date, image-based Golgi screens have based on a single parameter or supervised analysis with predefined Golgi structural classes. Here, we report the use of multiparametric data extracted from a single marker and a computational unsupervised analysis framework to explore Golgi phenotypic diversity more extensively. In contrast with the three visually definable phenotypes, our framework reproducibly identified 10 Golgi phenotypes. They were used to quantify and stratify phenotypic similarities among genetic perturbations. The derived phenotypic network partially overlaps previously reported protein-protein interactions as well as suggesting novel functional interactions. Our workflow suggests the existence of multiple stable Golgi organizational states and provides a proof of concept for the classification of drugs and genes using fine-grained phenotypic information.	['Institute of High Performance Computing, Singapore 138673.', 'Institute of Molecular and Cell Biology, Singapore 138673.', 'Institute of High Performance Computing, Singapore 138673.', 'Institute of High Performance Computing, Singapore 138673.', 'Institute of Molecular and Cell Biology, Singapore 138673.', 'School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.', 'Institute of High Performance Computing, Singapore 138673.', 'Institute of Molecular and Cell Biology, Singapore 138673 fbard@imcb.a-star.edu.sg.']	['mbc.E17-06-0379 [pii]', '10.1091/mbc.E17-06-0379 [doi]']	['Hussain S', 'Le Guezennec X', 'Yi W', 'Dong H', 'Chia J', 'Yiping K', 'Khoon LK', 'Bard F']		['(c) 2017 Hussain, Le Guezennec, et al. This article is distributed by The', 'American Society for Cell Biology under license from the author(s). Two months', 'after publication it is available to the public under an', 'Attribution-Noncommercial-Share Alike 3.0 Unported Creative Commons License', '(http://creativecommons.org/licenses/by-nc-sa/3.0).']					['2017/10/13 06:00']	20180720	20171011	2017 Dec 1	2017/10/13 06:00		['Hussain, Shaista', 'Le Guezennec, Xavier', 'Yi, Wang', 'Dong, Huang', 'Chia, Joanne', 'Yiping, Ke', 'Khoon, Lee Kee', 'Bard, Frederic']			25		1939-4586 (Electronic) 1059-1524 (Linking)	9201390	Molecular biology of the cell	['eng']	10.1091/mbc.E17-06-0379 [doi]	20181113	['Golgi Apparatus/genetics/metabolism/*physiology', 'HeLa Cells', 'High-Throughput Screening Assays/methods', 'Humans', 'Phenotype', 'Polysaccharides/metabolism', 'RNA Interference', 'RNA, Small Interfering/genetics/metabolism', 'Reproducibility of Results', '*Unsupervised Machine Learning']	2018/07/22 06:00				NLM	3686-3698	['2017/06/14 00:00 [received]', '2017/09/08 00:00 [revised]', '2017/10/04 00:00 [accepted]', '2017/10/13 06:00 [pubmed]', '2018/07/22 06:00 [medline]', '2017/10/13 06:00 [entrez]']	United States	PMC5706995		29021342	ppublish	['Journal Article']		['0 (Polysaccharides)', '0 (RNA, Small Interfering)']	IM		Mol Biol Cell. 2017 Dec 1;28(25):3686-3698. doi: 10.1091/mbc.E17-06-0379. Epub 2017 Oct 11.	MEDLINE	Mol Biol Cell	Digging deep into Golgi phenotypic diversity with unsupervised machine learning.		28	Digging deep into Golgi phenotypic diversity with unsupervised machine learning.
In plant phenotyping, it has become important to be able to measure many features on large image sets in order to aid genetic discovery. The size of the datasets, now often captured robotically, often precludes manual inspection, hence the motivation for finding a fully automated approach. Deep learning is an emerging field that promises unparalleled results on many data analysis problems. Building on artificial neural networks, deep approaches have many more hidden layers in the network, and hence have greater discriminative and predictive power. We demonstrate the use of such approaches as part of a plant phenotyping pipeline. We show the success offered by such techniques when applied to the challenging problem of image-based plant phenotyping and demonstrate state-of-the-art results (>97% accuracy) for root and shoot feature identification and localization. We use fully automated trait identification using deep learning to identify quantitative trait loci in root architecture datasets. The majority (12 out of 14) of manually identified quantitative trait loci were also discovered using our automated approach based on deep learning detection to locate plant features. We have shown deep learning-based phenotyping to have very good detection and localization accuracy in validation and testing image sets. We have shown that such features can be used to derive meaningful biological traits, which in turn can be used in quantitative trait loci discovery pipelines. This process can be completely automated. We predict a paradigm shift in image-based phenotyping bought about by such deep learning approaches, given sufficient training sets.	['School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, UK.', 'School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, UK.', 'School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, UK.', 'Centre for Plant Sciences, Faculty of Biological Sciences, University of Leeds, Leeds, LS2 9JT, UK.', 'School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, UK.', 'School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, UK.', 'School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, UK.', 'School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, UK.', 'School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, UK.', 'School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, UK.', 'School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, UK.', 'School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, UK.', 'School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, UK.']	['4091592 [pii]', '10.1093/gigascience/gix083 [doi]']	['Pound MP', 'Atkinson JA', 'Townsend AJ', 'Wilson MH', 'Griffiths M', 'Jackson AS', 'Bulat A', 'Tzimiropoulos G', 'Wells DM', 'Murchie EH', 'Pridmore TP', 'French AP']		['(c) The Authors 2017. Published by Oxford University Press.']					['2017/10/13 06:00']	20180604		2017 Oct 1	2017/10/13 06:00	['Gigascience. 2018 Jul 1;7(7):. PMID: 30053289']	['Pound, Michael P', 'Atkinson, Jonathan A', 'Townsend, Alexandra J', 'Wilson, Michael H', 'Griffiths, Marcus', 'Jackson, Aaron S', 'Bulat, Adrian', 'Tzimiropoulos, Georgios', 'Wells, Darren M', 'Murchie, Erik H', 'Pridmore, Tony P', 'French, Andrew P']		['294729/European Research Council/International', 'BB/N018575/1/Biotechnology and Biological Sciences Research Council/United', 'Kingdom']	10		2047-217X (Electronic) 2047-217X (Linking)	101596872	GigaScience	['eng']	10.1093/gigascience/gix083 [doi]	20190116	['*Machine Learning', 'Phenotype', 'Plant Roots/*classification/genetics', 'Plant Shoots/*classification/genetics', 'Plants', 'Quantitative Trait Loci', 'Triticum/classification/genetics']	2018/06/05 06:00		['*Phenotyping', '*QTL', '*deep learning', '*image analysis', '*root', '*shoot']	['NOTNLM']	NLM	1-10	['2017/05/26 00:00 [received]', '2017/08/16 00:00 [accepted]', '2017/10/13 06:00 [entrez]', '2017/10/13 06:00 [pubmed]', '2018/06/05 06:00 [medline]']	United States	PMC5632296		29020747	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Gigascience. 2017 Oct 1;6(10):1-10. doi: 10.1093/gigascience/gix083.	MEDLINE	Gigascience	Deep machine learning provides state-of-the-art performance in image-based plant phenotyping.		6	Deep machine learning provides state-of-the-art performance in image-based plant phenotyping.
Lifelong learning is fundamental in autonomous robotics for the acquisition and fine-tuning of knowledge through experience. However, conventional deep neural models for action recognition from videos do not account for lifelong learning but rather learn a batch of training data with a predefined number of action classes and samples. Thus, there is the need to develop learning systems with the ability to incrementally process available perceptual cues and to adapt their responses over time. We propose a self-organizing neural architecture for incrementally learning to classify human actions from video sequences. The architecture comprises growing self-organizing networks equipped with recurrent neurons for processing time-varying patterns. We use a set of hierarchically arranged recurrent networks for the unsupervised learning of action representations with increasingly large spatiotemporal receptive fields. Lifelong learning is achieved in terms of prediction-driven neural dynamics in which the growth and the adaptation of the recurrent networks are driven by their capability to reconstruct temporally ordered input sequences. Experimental results on a classification task using two action benchmark datasets show that our model is competitive with state-of-the-art methods for batch learning also when a significant number of sample labels are missing or corrupted during training sessions. Additional experiments show the ability of our model to adapt to non-stationary input avoiding catastrophic interference.	['Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany. Electronic address: parisi@informatik.uni-hamburg.de.', 'Cognitive Neurorobotics Research Unit, Okinawa Institute of Science and Technology (OIST), Japan.', 'Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany.', 'Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany.']	['S0893-6080(17)30203-4 [pii]', '10.1016/j.neunet.2017.09.001 [doi]']	['Parisi GI', 'Tani J', 'Weber C', 'Wermter S']		['Copyright (c) 2017 The Author(s). Published by Elsevier Ltd.. All rights', 'reserved.']					['2017/10/11 06:00']	20180509	20170920	2017 Dec	2017/10/11 06:00		['Parisi, German I', 'Tani, Jun', 'Weber, Cornelius', 'Wermter, Stefan']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30203-4 [pii] 10.1016/j.neunet.2017.09.001 [doi]	20181202	['Humans', 'Machine Learning/*trends', '*Neural Networks (Computer)', 'Neurons/physiology', '*Pattern Recognition, Visual/physiology', 'Robotics/methods/trends']	2018/05/10 06:00		['Action recognition', 'Lifelong learning', 'Self-organizing neural networks', 'Unsupervised deep learning']	['NOTNLM']	NLM	137-149	['2017/03/01 00:00 [received]', '2017/08/23 00:00 [revised]', '2017/09/01 00:00 [accepted]', '2017/10/11 06:00 [pubmed]', '2018/05/10 06:00 [medline]', '2017/10/11 06:00 [entrez]']	United States			29017140	ppublish	['Journal Article']			IM		Neural Netw. 2017 Dec;96:137-149. doi: 10.1016/j.neunet.2017.09.001. Epub 2017 Sep 20.	MEDLINE	Neural Netw	Lifelong learning of human actions with deep neural network self-organization.		96	Lifelong learning of human actions with deep neural network self-organization.
Epilepsy being one of the most prevalent neurological disorders, affecting approximately 50 million people worldwide, and with almost 30-40% of patients experiencing partial epilepsy being nonresponsive to medication, epilepsy surgery is widely accepted as an effective therapeutic option. Presurgical evaluation has advanced significantly using noninvasive techniques based on video monitoring, neuroimaging, and electrophysiological and neuropsychological tests; however, certain clinical settings call for invasive intracranial recordings such as stereoelectroencephalography (SEEG), aiming to accurately map the eloquent brain networks involved during a seizure. Most of the current presurgical evaluation procedures focus on semiautomatic techniques, where surgery diagnosis relies immensely on neurologists' experience and their time-consuming subjective interpretation of semiology or the manifestations of epilepsy and their correlation with the brain's electrical activity. Because surgery misdiagnosis reaches a rate of 30%, and more than one-third of all epilepsies are poorly understood, there is an evident keen interest in improving diagnostic precision using computer-based methodologies that in the past few years have shown near-human performance. Among them, deep learning has excelled in many biological and medical applications, but has advanced insufficiently in epilepsy evaluation and automated understanding of neural bases of semiology. In this paper, we systematically review the automatic applications in epilepsy for human motion analysis, brain electrical activity, and the anatomoelectroclinical correlation to attribute anatomical localization of the epileptogenic network to distinctive epilepsy patterns. Notably, recent advances in deep learning techniques will be investigated in the contexts of epilepsy to address the challenges exhibited by traditional machine learning techniques. Finally, we discuss and propose future research on epilepsy surgery assessment that can jointly learn across visually observed semiologic patterns and recorded brain electrical activity.	['The Speech, Audio, Image and Video Technologies (SAIVT) and Science and Engineering Faculty, Queensland University of Technology, Brisbane, Queensland, Australia.', 'The Speech, Audio, Image and Video Technologies (SAIVT) and Science and Engineering Faculty, Queensland University of Technology, Brisbane, Queensland, Australia.', 'Mater Centre for Neurosciences, Brisbane, Queensland, Australia.', 'The Speech, Audio, Image and Video Technologies (SAIVT) and Science and Engineering Faculty, Queensland University of Technology, Brisbane, Queensland, Australia.', 'The Institute of Systems and Computer Engineering, Technology and Science, and Faculty of Engineering, University of Porto, Porto, Portugal.', 'The Speech, Audio, Image and Video Technologies (SAIVT) and Science and Engineering Faculty, Queensland University of Technology, Brisbane, Queensland, Australia.']	['10.1111/epi.13907 [doi]']	['Ahmedt-Aristizabal D', 'Fookes C', 'Dionisio S', 'Nguyen K', 'Cunha JPS', 'Sridharan S']	['ORCID: 0000-0003-1598-4930']	['Wiley Periodicals, Inc. (c) 2017 International League Against Epilepsy.']					['2017/10/10 06:00']	20171109	20171009	2017 Nov	2017/10/11 06:00		['Ahmedt-Aristizabal, David', 'Fookes, Clinton', 'Dionisio, Sasha', 'Nguyen, Kien', 'Cunha, Joao Paulo S', 'Sridharan, Sridha']			11		1528-1167 (Electronic) 0013-9580 (Linking)	2983306R	Epilepsia	['eng']	10.1111/epi.13907 [doi]	20180108	['Brain/*physiopathology', 'Brain Mapping/*methods', 'Electrodes, Implanted', 'Electroencephalography/*methods', 'Epilepsy/diagnosis/physiopathology', 'Humans', 'Machine Learning', 'Preoperative Care/*methods', 'Seizures/diagnosis/*physiopathology', 'Surveys and Questionnaires']	2017/11/10 06:00		['*Deep learning', '*Epileptogenic network', '*Facial expression', '*Human motion', '*Machine learning']	['NOTNLM']	NLM	1817-1831	['2017/08/28 00:00 [accepted]', '2017/10/11 06:00 [pubmed]', '2017/11/10 06:00 [medline]', '2017/10/10 06:00 [entrez]']	United States			28990168	ppublish	['Journal Article', 'Review']			IM		Epilepsia. 2017 Nov;58(11):1817-1831. doi: 10.1111/epi.13907. Epub 2017 Oct 9.	MEDLINE	Epilepsia	Automated analysis of seizure semiology and brain electrical activity in presurgery evaluation of epilepsy: A focused survey.		58	Automated analysis of seizure semiology and brain electrical activity in presurgery evaluation of epilepsy: A focused survey.
INTRODUCTION: The ability to predict epitopes plays an enormous role in vaccine development in terms of our ability to zero in on where to do a more thorough in-vivo analysis of the protein in question. Though for the past decade there have been numerous advancements and improvements in epitope prediction, on average the best benchmark prediction accuracies are still only around 60%. New machine learning algorithms have arisen within the domain of deep learning, text mining, and convolutional networks. This paper presents a novel analytically trained and string kernel using deep neural network, which is tailored for continuous epitope prediction, called: Deep Ridge Regressed Epitope Predictor (DRREP). RESULTS: DRREP was tested on long protein sequences from the following datasets: SARS, Pellequer, HIV, AntiJen, and SEQ194. DRREP was compared to numerous state of the art epitope predictors, including the most recently published predictors called LBtope and DMNLBE. Using area under ROC curve (AUC), DRREP achieved a performance improvement over the best performing predictors on SARS (13.7%), HIV (8.9%), Pellequer (1.5%), and SEQ194 (3.1%), with its performance being matched only on the AntiJen dataset, by the LBtope predictor, where both DRREP and LBtope achieved an AUC of 0.702. CONCLUSION: DRREP is an analytically trained deep neural network, thus capable of learning in a single step through regression. By combining the features of deep learning, string kernels, and convolutional networks, the system is able to perform residue-by-residue prediction of continues epitopes with higher accuracy than the current state of the art predictors.	['Department of Computer Science, University of Central Florida, Orlando, FL, USA. gsher@knights.ucf.edu.', 'School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, USA.', 'Department of Computer Science, University of Central Florida, Orlando, FL, USA.']	['10.1186/s12864-017-4024-8 [doi]', '10.1186/s12864-017-4024-8 [pii]']	['Sher G', 'Zhi D', 'Zhang S']							['2017/10/07 06:00']	20180521	20171003	2017 Oct 3	2017/10/07 06:00		['Sher, Gene', 'Zhi, Degui', 'Zhang, Shaojie']			Suppl 6		1471-2164 (Electronic) 1471-2164 (Linking)	100965258	BMC genomics	['eng']	10.1186/s12864-017-4024-8 [doi]	20181113	['Amino Acid Sequence', 'Computational Biology/*methods', 'Epitopes, B-Lymphocyte/*chemistry/*immunology', '*Neural Networks (Computer)']	2018/05/22 06:00		['Analytical learning', 'Continuous epitope', 'Convolutional network', 'Deep network', 'Epitope prediction', 'Linear epitope', 'Neural network', 'String kernel']	['NOTNLM']	NLM	676	['2017/10/07 06:00 [entrez]', '2017/10/07 06:00 [pubmed]', '2018/05/22 06:00 [medline]']	England	PMC5629616		28984193	epublish	['Journal Article']		['0 (Epitopes, B-Lymphocyte)']	IM		BMC Genomics. 2017 Oct 3;18(Suppl 6):676. doi: 10.1186/s12864-017-4024-8.	MEDLINE	BMC Genomics	DRREP: deep ridge regressed epitope predictor.		18	DRREP: deep ridge regressed epitope predictor.
An encephalogram (EEG) is a commonly used ancillary test to aide in the diagnosis of epilepsy. The EEG signal contains information about the electrical activity of the brain. Traditionally, neurologists employ direct visual inspection to identify epileptiform abnormalities. This technique can be time-consuming, limited by technical artifact, provides variable results secondary to reader expertise level, and is limited in identifying abnormalities. Therefore, it is essential to develop a computer-aided diagnosis (CAD) system to automatically distinguish the class of these EEG signals using machine learning techniques. This is the first study to employ the convolutional neural network (CNN) for analysis of EEG signals. In this work, a 13-layer deep convolutional neural network (CNN) algorithm is implemented to detect normal, preictal, and seizure classes. The proposed technique achieved an accuracy, specificity, and sensitivity of 88.67%, 90.00% and 95.00%, respectively.	['Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, SUSS University, Singapore; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia. Electronic address: aru@np.edu.sg.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore.', 'Departments of Neuroscience, Neurology, Biomedical Engineering, Biomedical Informatics, and Civil, Environmental, and Geodetic Engineering, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, 43210, United States.']	['S0010-4825(17)30315-3 [pii]', '10.1016/j.compbiomed.2017.09.017 [doi]']	['Acharya UR', 'Oh SL', 'Hagiwara Y', 'Tan JH', 'Adeli H']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/10/05 06:00']	20190806	20170927	2018 Sep 1	2017/10/05 06:00		['Acharya, U Rajendra', 'Oh, Shu Lih', 'Hagiwara, Yuki', 'Tan, Jen Hong', 'Adeli, Hojjat']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(17)30315-3 [pii] 10.1016/j.compbiomed.2017.09.017 [doi]	20190806	['*Diagnosis, Computer-Assisted', '*Electroencephalography', 'Epilepsy/*physiopathology', 'Female', 'Humans', '*Machine Learning', 'Male', '*Neural Networks (Computer)', 'Seizures/*physiopathology', '*Signal Processing, Computer-Assisted']	2019/08/07 06:00		['*Convolutional neural network', '*Deep learning', '*Encephalogram signals', '*Epilepsy', '*Seizure']	['NOTNLM']	NLM	270-278	['2017/07/27 00:00 [received]', '2017/08/29 00:00 [revised]', '2017/09/22 00:00 [accepted]', '2017/10/05 06:00 [pubmed]', '2019/08/07 06:00 [medline]', '2017/10/05 06:00 [entrez]']	United States			28974302	ppublish	['Journal Article']					Comput Biol Med. 2018 Sep 1;100:270-278. doi: 10.1016/j.compbiomed.2017.09.017. Epub 2017 Sep 27.	MEDLINE	Comput Biol Med	Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals.		100	Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals.
Dopaminergic degeneration is a pathologic hallmark of Parkinson's disease (PD), which can be assessed by dopamine transporter imaging such as FP-CIT SPECT. Until now, imaging has been routinely interpreted by human though it can show interobserver variability and result in inconsistent diagnosis. In this study, we developed a deep learning-based FP-CIT SPECT interpretation system to refine the imaging diagnosis of Parkinson's disease. This system trained by SPECT images of PD patients and normal controls shows high classification accuracy comparable with the experts' evaluation referring quantification results. Its high accuracy was validated in an independent cohort composed of patients with PD and nonparkinsonian tremor. In addition, we showed that some patients clinically diagnosed as PD who have scans without evidence of dopaminergic deficit (SWEDD), an atypical subgroup of PD, could be reclassified by our automated system. Our results suggested that the deep learning-based model could accurately interpret FP-CIT SPECT and overcome variability of human evaluation. It could help imaging diagnosis of patients with uncertain Parkinsonism and provide objective patient group classification, particularly for SWEDD, in further clinical studies.	['Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Transdisciplinary Studies, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Republic of Korea.', 'Department of Neurosurgery, Seoul National University Hospital, Seoul, Republic of Korea.', 'Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, Republic of Korea.', 'Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Republic of Korea.', 'Korea Brain Research Institute, Daegu, Republic of Korea.']	['10.1016/j.nicl.2017.09.010 [doi]', 'S2213-1582(17)30224-3 [pii]']	['Choi H', 'Ha S', 'Im HJ', 'Paek SH', 'Lee DS']							['2017/10/04 06:00']	20180608	20170910	2017	2017/10/04 06:00		['Choi, Hongyoon', 'Ha, Seunggyun', 'Im, Hyung Jun', 'Paek, Sun Ha', 'Lee, Dong Soo']					2213-1582 (Electronic) 2213-1582 (Linking)	101597070	NeuroImage. Clinical	['eng']	10.1016/j.nicl.2017.09.010 [doi]	20181113	['Aged', 'Algorithms', 'Dopamine Plasma Membrane Transport Proteins/*analysis', 'Female', 'Humans', '*Machine Learning', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'Neuroimaging/*methods', 'Parkinson Disease/*diagnostic imaging', 'Radionuclide Imaging/methods', 'Tomography, Emission-Computed, Single-Photon', 'Tropanes']	2018/06/09 06:00		"['Deep learning', 'Deep neural network', 'FP-CIT', ""Parkinson's disease"", 'SWEDD']"	['NOTNLM']	NLM	586-594	['2017/07/08 00:00 [received]', '2017/09/09 00:00 [accepted]', '2017/10/04 06:00 [entrez]', '2017/10/04 06:00 [pubmed]', '2018/06/09 06:00 [medline]']	Netherlands	PMC5610036		28971009	epublish	['Journal Article']		['0 (Dopamine Plasma Membrane Transport Proteins)', '0 (Tropanes)', '155797-99-2 (2-carbomethoxy-8-(3-fluoropropyl)-3-(4-iodophenyl)tropane)']	IM		Neuroimage Clin. 2017 Sep 10;16:586-594. doi: 10.1016/j.nicl.2017.09.010. eCollection 2017.	MEDLINE	Neuroimage Clin	Refining diagnosis of Parkinson's disease with deep learning-based interpretation of dopamine transporter imaging.		16	Refining diagnosis of Parkinson's disease with deep learning-based interpretation of dopamine transporter imaging.
"BACKGROUND: Computer vision may aid in melanoma detection. OBJECTIVE: We sought to compare melanoma diagnostic accuracy of computer algorithms to dermatologists using dermoscopic images. METHODS: We conducted a cross-sectional study using 100 randomly selected dermoscopic images (50 melanomas, 44 nevi, and 6 lentigines) from an international computer vision melanoma challenge dataset (n = 379), along with individual algorithm results from 25 teams. We used 5 methods (nonlearned and machine learning) to combine individual automated predictions into ""fusion"" algorithms. In a companion study, 8 dermatologists classified the lesions in the 100 images as either benign or malignant. RESULTS: The average sensitivity and specificity of dermatologists in classification was 82% and 59%. At 82% sensitivity, dermatologist specificity was similar to the top challenge algorithm (59% vs. 62%, P = .68) but lower than the best-performing fusion algorithm (59% vs. 76%, P = .02). Receiver operating characteristic area of the top fusion algorithm was greater than the mean receiver operating characteristic area of dermatologists (0.86 vs. 0.71, P = .001). LIMITATIONS: The dataset lacked the full spectrum of skin lesions encountered in clinical practice, particularly banal lesions. Readers and algorithms were not provided clinical data (eg, age or lesion history/symptoms). Results obtained using our study design cannot be extrapolated to clinical practice. CONCLUSION: Deep learning computer vision systems classified melanoma dermoscopy images with accuracy that exceeded some but not all dermatologists."	"['Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, New York.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'Departments of Neurology, Psychiatry, and Biomedical Informatics, Emory University School of Medicine, Atlanta, Georgia.', 'Kitware Inc, Clifton Park, New York.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'Stoecker & Associates, Rolla, Missouri.', ""Melanoma Unit, Department of Dermatology, Hospital Clinic, Institut d'Investigacions Biomediques August Pi i Sunyer, CIBER de Enfermedades Raras, Instituto de Salud Carlos III, University of Barcelona, Barcelona, Spain."", 'Department of Computer Science, University of Central Arkansas, Conway, Arkansas.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'Dermatology Service, Aurora Centro Especializado en Cancer de Piel, Medellin, Colombia; Department of Dermatology and Cutaneous Surgery, University of Miami Miller School of Medicine, Miami, Florida.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York; Department of Dermatology, Sheba Medical Center, Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York.', 'Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, New York. Electronic address: halperna@mskcc.org.']"	['S0190-9622(17)32202-8 [pii]', '10.1016/j.jaad.2017.08.016 [doi]']	['Marchetti MA', 'Codella NCF', 'Dusza SW', 'Gutman DA', 'Helba B', 'Kalloo A', 'Mishra N', 'Carrera C', 'Celebi ME', 'DeFazio JL', 'Jaimes N', 'Marghoob AA', 'Quigley E', 'Scope A', 'Yelamos O', 'Halpern AC']		['Copyright (c) 2017 American Academy of Dermatology, Inc. Published by Elsevier', 'Inc. All rights reserved.']		['International Skin Imaging Collaboration']			['2017/10/04 06:00']	20180723	20170929	2018 Feb	2017/10/04 06:00		['Marchetti, Michael A', 'Codella, Noel C F', 'Dusza, Stephen W', 'Gutman, David A', 'Helba, Brian', 'Kalloo, Aadi', 'Mishra, Nabin', 'Carrera, Cristina', 'Celebi, M Emre', 'DeFazio, Jennifer L', 'Jaimes, Natalia', 'Marghoob, Ashfaq A', 'Quigley, Elizabeth', 'Scope, Alon', 'Yelamos, Oriol', 'Halpern, Allan C']		['P30 CA008748/CA/NCI NIH HHS/United States']	2		1097-6787 (Electronic) 0190-9622 (Linking)	7907132	Journal of the American Academy of Dermatology	['eng']	S0190-9622(17)32202-8 [pii] 10.1016/j.jaad.2017.08.016 [doi]	20190201	['*Algorithms', 'Congresses as Topic', 'Cross-Sectional Studies', '*Dermatologists', '*Dermoscopy', 'Diagnosis, Computer-Assisted', 'Humans', 'Lentigo/*diagnostic imaging', 'Machine Learning', 'Melanoma/*diagnosis/pathology', 'Nevus/*diagnostic imaging', 'ROC Curve', 'Skin Neoplasms/*diagnostic imaging/pathology']	2018/07/24 06:00	['NIHMS899256']	['*International Skin Imaging Collaboration', '*International Symposium on Biomedical Imaging', '*computer algorithm', '*computer vision', '*dermatologist', '*machine learning', '*melanoma', '*reader study', '*skin cancer']	['NOTNLM']	NLM	270-277.e1	['2017/03/23 00:00 [received]', '2017/08/04 00:00 [revised]', '2017/08/07 00:00 [accepted]', '2017/10/04 06:00 [pubmed]', '2018/07/24 06:00 [medline]', '2017/10/04 06:00 [entrez]']	United States	PMC5768444		28969863	ppublish	['Comparative Study', 'Journal Article', 'Research Support, N.I.H., Extramural']			IM		J Am Acad Dermatol. 2018 Feb;78(2):270-277.e1. doi: 10.1016/j.jaad.2017.08.016. Epub 2017 Sep 29.	MEDLINE	J Am Acad Dermatol	Results of the 2016 International Skin Imaging Collaboration International Symposium on Biomedical Imaging challenge: Comparison of the accuracy of computer algorithms to dermatologists for the diagnosis of melanoma from dermoscopic images.		78	Results of the 2016 International Skin Imaging Collaboration International Symposium on Biomedical Imaging challenge: Comparison of the accuracy of computer algorithms to dermatologists for the diagnosis of melanoma from dermoscopic images.
Motivation: Deep neural network architectures such as convolutional and long short-term memory networks have become increasingly popular as machine learning tools during the recent years. The availability of greater computational resources, more data, new algorithms for training deep models and easy to use libraries for implementation and training of neural networks are the drivers of this development. The use of deep learning has been especially successful in image recognition; and the development of tools, applications and code examples are in most cases centered within this field rather than within biology. Results: Here, we aim to further the development of deep learning methods within biology by providing application examples and ready to apply and adapt code templates. Given such examples, we illustrate how architectures consisting of convolutional and long short-term memory neural networks can relatively easily be designed and trained to state-of-the-art performance on three biological sequence problems: prediction of subcellular localization, protein secondary structure and the binding of peptides to MHC Class II molecules. Availability and implementation: All implementations and datasets are available online to the scientific community at https://github.com/vanessajurtz/lasagne4bio. Contact: skaaesonderby@gmail.com. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Bio and Health Informatics.', 'Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark.', 'Department of Bio and Health Informatics.', 'Instituto de Investigaciones Biotecnologicas, Universidad Nacional de San Martin, Buenos Aires, Argentina.', 'Department of Bio and Health Informatics.', 'Department of Bio and Health Informatics.', 'Department of Biology, University of Copenhagen, Copenhagen, Denmark.', 'Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark.', 'Department of Biology, University of Copenhagen, Copenhagen, Denmark.', 'Department of Biology, University of Copenhagen, Copenhagen, Denmark.']	['4092933 [pii]', '10.1093/bioinformatics/btx531 [doi]']	['Jurtz VI', 'Johansen AR', 'Nielsen M', 'Almagro Armenteros JJ', 'Nielsen H', 'Sonderby CK', 'Winther O', 'Sonderby SK']		['(c) The Author (2017). Published by Oxford University Press. All rights reserved.', 'For Permissions, please email: journals.permissions@oup.com']					['2017/09/30 06:00']	20180810		2017 Nov 15	2017/09/30 06:00		['Jurtz, Vanessa Isabell', 'Johansen, Alexander Rosenberg', 'Nielsen, Morten', 'Almagro Armenteros, Jose Juan', 'Nielsen, Henrik', 'Sonderby, Casper Kaae', 'Winther, Ole', 'Sonderby, Soren Kaae']			22		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx531 [doi]	20181202	['Computational Biology/methods', '*Machine Learning', 'Neural Networks (Computer)', 'Peptides/metabolism', 'Protein Binding', '*Protein Structure, Secondary', '*Protein Transport', 'Sequence Analysis, Protein/*methods']	2018/08/11 06:00				NLM	3685-3690	['2017/03/13 00:00 [received]', '2017/08/22 00:00 [accepted]', '2017/09/30 06:00 [pubmed]', '2018/08/11 06:00 [medline]', '2017/09/30 06:00 [entrez]']	England	PMC5870575		28961695	ppublish	['Journal Article']		['0 (Peptides)']	IM		Bioinformatics. 2017 Nov 15;33(22):3685-3690. doi: 10.1093/bioinformatics/btx531.	MEDLINE	Bioinformatics	An introduction to deep learning on biological sequence data: examples and solutions.		33	An introduction to deep learning on biological sequence data: examples and solutions.
Motivation: An accurate characterization of transcription factor (TF)-DNA affinity landscape is crucial to a quantitative understanding of the molecular mechanisms underpinning endogenous gene regulation. While recent advances in biotechnology have brought the opportunity for building binding affinity prediction methods, the accurate characterization of TF-DNA binding affinity landscape still remains a challenging problem. Results: Here we propose a novel sequence embedding approach for modeling the transcription factor binding affinity landscape. Our method represents DNA binding sequences as a hidden Markov model which captures both position specific information and long-range dependency in the sequence. A cornerstone of our method is a novel message passing-like embedding algorithm, called Sequence2Vec, which maps these hidden Markov models into a common nonlinear feature space and uses these embedded features to build a predictive model. Our method is a novel combination of the strength of probabilistic graphical models, feature space embedding and deep learning. We conducted comprehensive experiments on over 90 large-scale TF-DNA datasets which were measured by different high-throughput experimental technologies. Sequence2Vec outperforms alternative machine learning methods as well as the state-of-the-art binding affinity prediction methods. Availability and implementation: Our program is freely available at https://github.com/ramzan1990/sequence2vec. Contact: xin.gao@kaust.edu.sa or lsong@cc.gatech.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, USA.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal 23955-6900, Saudi Arabia.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal 23955-6900, Saudi Arabia.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal 23955-6900, Saudi Arabia.', 'College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, USA.', 'King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal 23955-6900, Saudi Arabia.']	['4042128 [pii]', '10.1093/bioinformatics/btx480 [doi]']	['Dai H', 'Umarov R', 'Kuwahara H', 'Li Y', 'Song L', 'Gao X']		['(c) The Author(s) 2017. Published by Oxford University Press.']					['2017/09/30 06:00']	20180807		2017 Nov 15	2017/09/30 06:00		['Dai, Hanjun', 'Umarov, Ramzan', 'Kuwahara, Hiroyuki', 'Li, Yu', 'Song, Le', 'Gao, Xin']			22		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx480 [doi]	20181202	['*Algorithms', 'Binding Sites', 'DNA/chemistry/*metabolism', 'Machine Learning', 'Models, Statistical', 'Protein Binding', 'Sequence Analysis, DNA/*methods', 'Transcription Factors/*metabolism']	2018/08/08 06:00				NLM	3575-3583	['2017/03/20 00:00 [received]', '2017/07/26 00:00 [accepted]', '2017/09/30 06:00 [pubmed]', '2018/08/08 06:00 [medline]', '2017/09/30 06:00 [entrez]']	England	PMC5870668		28961686	ppublish	['Journal Article']		['0 (Transcription Factors)', '9007-49-2 (DNA)']	IM		Bioinformatics. 2017 Nov 15;33(22):3575-3583. doi: 10.1093/bioinformatics/btx480.	MEDLINE	Bioinformatics	Sequence2Vec: a novel embedding approach for modeling transcription factor binding affinity landscape.		33	Sequence2Vec: a novel embedding approach for modeling transcription factor binding affinity landscape.
During routine ultrasound assessment of the fetal brain for biometry estimation and detection of fetal abnormalities, accurate imaging planes must be found by sonologists following a well-defined imaging protocol or clinical standard, which can be difficult for non-experts to do well. This assessment helps provide accurate biometry estimation and the detection of possible brain abnormalities. We describe a machine-learning method to assess automatically that transventricular ultrasound images of the fetal brain have been correctly acquired and meet the required clinical standard. We propose a deep learning solution, which breaks the problem down into three stages: (i) accurate localization of the fetal brain, (ii) detection of regions that contain structures of interest and (iii) learning the acoustic patterns in the regions that enable plane verification. We evaluate the developed methodology on a large real-world clinical data set of 2-D mid-gestation fetal images. We show that the automatic verification method approaches human expert assessment.	['Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, UK. Electronic address: mohammad.yaqub@eng.ox.ac.uk.', 'Nuffield Department of Obstetrics & Gynaecology, University of Oxford, Oxford, UK.', 'Nuffield Department of Obstetrics & Gynaecology, University of Oxford, Oxford, UK.', 'Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, UK.']	['S0301-5629(17)30332-0 [pii]', '10.1016/j.ultrasmedbio.2017.07.013 [doi]']	['Yaqub M', 'Kelly B', 'Papageorghiou AT', 'Noble JA']		['Copyright (c) 2017 World Federation for Ultrasound in Medicine and Biology.', 'Published by Elsevier Inc. All rights reserved.']					['2017/09/30 06:00']	20180716	20170928	2017 Dec	2017/09/30 06:00		['Yaqub, Mohammad', 'Kelly, Brenda', 'Papageorghiou, Aris T', 'Noble, J Alison']			12		1879-291X (Electronic) 0301-5629 (Linking)	0410553	Ultrasound in medicine & biology	['eng']	S0301-5629(17)30332-0 [pii] 10.1016/j.ultrasmedbio.2017.07.013 [doi]	20180720	['Brain/*diagnostic imaging/*embryology', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', '*Neural Networks (Computer)', 'Pregnancy', 'Ultrasonography, Prenatal/*methods']	2018/07/17 06:00		['*Convolutional neural networks', '*Fetal ultrasound', '*Knowledge-based image analysis', '*Neurosonography', '*Pregnancy', '*Trans-ventricular plane']	['NOTNLM']	NLM	2925-2933	['2016/12/21 00:00 [received]', '2017/06/19 00:00 [revised]', '2017/07/17 00:00 [accepted]', '2017/09/30 06:00 [pubmed]', '2018/07/17 06:00 [medline]', '2017/09/30 06:00 [entrez]']	England			28958729	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Ultrasound Med Biol. 2017 Dec;43(12):2925-2933. doi: 10.1016/j.ultrasmedbio.2017.07.013. Epub 2017 Sep 28.	MEDLINE	Ultrasound Med Biol	A Deep Learning Solution for Automatic Fetal Neurosonographic Diagnostic Plane Verification Using Clinical Standard Constraints.		43	A Deep Learning Solution for Automatic Fetal Neurosonographic Diagnostic Plane Verification Using Clinical Standard Constraints.
Ribosome stalling is manifested by the local accumulation of ribosomes at specific codon positions of mRNAs. Here, we present ROSE, a deep learning framework to analyze high-throughput ribosome profiling data and estimate the probability of a ribosome stalling event occurring at each genomic location. Extensive validation tests on independent data demonstrated that ROSE possessed higher prediction accuracy than conventional prediction models, with an increase in the area under the receiver operating characteristic curve by up to 18.4%. In addition, genome-wide statistical analyses showed that ROSE predictions can be well correlated with diverse putative regulatory factors of ribosome stalling. Moreover, the genome-wide ribosome stalling landscapes of both human and yeast computed by ROSE recovered the functional interplays between ribosome stalling and cotranslational events in protein biogenesis, including protein targeting by the signal recognition particles and protein secondary structure formation. Overall, our study provides a novel method to complement the ribosome profiling techniques and further decipher the complex regulatory mechanisms underlying translation elongation dynamics encoded in the mRNA sequence.	['Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China.', 'School of Medicine, Tsinghua University, Beijing, China.', 'School of Medicine, Tsinghua University, Beijing, China.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China.', 'Department of Computer Science and Engineering, University of California, Riverside, CA, USA; MOE Key Lab of Bioinformatics and Bioinformatics Division, TNLIST/Department of Computer Science and Technology, Tsinghua University, Beijing, China; Institute of Integrative Genome Biology, University of California, Riverside, CA, USA.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China. Electronic address: zengjy321@tsinghua.edu.cn.']	['S2405-4712(17)30337-X [pii]', '10.1016/j.cels.2017.08.004 [doi]']	['Zhang S', 'Hu H', 'Zhou J', 'He X', 'Jiang T', 'Zeng J']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/09/29 06:00']	20190701		2017 Sep 27	2017/09/29 06:00		['Zhang, Sai', 'Hu, Hailin', 'Zhou, Jingtian', 'He, Xuan', 'Jiang, Tao', 'Zeng, Jianyang']			3		2405-4712 (Print) 2405-4712 (Linking)	101656080	Cell systems	['eng']	S2405-4712(17)30337-X [pii] 10.1016/j.cels.2017.08.004 [doi]	20190701	['Algorithms', 'Amino Acid Sequence', 'Codon/*analysis', 'Computational Biology/*methods', 'Deep Learning', 'Genomics', 'High-Throughput Nucleotide Sequencing/methods', 'Humans', 'Peptide Chain Elongation, Translational/*genetics/physiology', 'Protein Biosynthesis/physiology', 'RNA, Messenger/analysis', 'Ribosomes/chemistry', 'Saccharomyces cerevisiae/genetics']	2019/07/02 06:00		['*deep learning', '*protein biogenesis', '*ribosome profiling', '*ribosome stalling', '*translation elongation dynamics', '*translational regulation']	['NOTNLM']	NLM	212-220.e6	['2017/03/07 00:00 [received]', '2017/06/27 00:00 [revised]', '2017/08/04 00:00 [accepted]', '2017/09/29 06:00 [entrez]', '2017/09/29 06:00 [pubmed]', '2019/07/02 06:00 [medline]']	United States			28957655	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Codon)', '0 (RNA, Messenger)']	IM		Cell Syst. 2017 Sep 27;5(3):212-220.e6. doi: 10.1016/j.cels.2017.08.004.	MEDLINE	Cell Syst	Analysis of Ribosome Stalling and Translation Elongation Dynamics by Deep Learning.		5	Analysis of Ribosome Stalling and Translation Elongation Dynamics by Deep Learning.
Computational elucidation of membrane protein (MP) structures is challenging partially due to lack of sufficient solved structures for homology modeling. Here, we describe a high-throughput deep transfer learning method that first predicts MP contacts by learning from non-MPs and then predicts 3D structure models using the predicted contacts as distance restraints. Tested on 510 non-redundant MPs, our method has contact prediction accuracy at least 0.18 better than existing methods, predicts correct folds for 218 MPs, and generates 3D models with root-mean-square deviation (RMSD) less than 4 and 5 A for 57 and 108 MPs, respectively. A rigorous blind test in the continuous automated model evaluation project shows that our method predicted high-resolution 3D models for two recent test MPs of 210 residues with RMSD approximately 2 A. We estimated that our method could predict correct folds for 1,345-1,871 reviewed human multi-pass MPs including a few hundred new folds, which shall facilitate the discovery of drugs targeting at MPs.	['Toyota Technological Institute at Chicago, Chicago, IL 60637, USA; Department of Human Genetics, University of Chicago, Chicago, IL 60637, USA; Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia.', 'Toyota Technological Institute at Chicago, Chicago, IL 60637, USA; Department of Computer Science, University of Hong Kong, Hong Kong.', 'Department of Computer Science, University of Hong Kong, Hong Kong.', 'Toyota Technological Institute at Chicago, Chicago, IL 60637, USA. Electronic address: jinboxu@gmail.com.']	['S2405-4712(17)30389-7 [pii]', '10.1016/j.cels.2017.09.001 [doi]']	['Wang S', 'Li Z', 'Yu Y', 'Xu J']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/09/29 06:00']	20190701		2017 Sep 27	2017/09/29 06:00		['Wang, Sheng', 'Li, Zhen', 'Yu, Yizhou', 'Xu, Jinbo']		['R01 GM089753/GM/NIGMS NIH HHS/United States']	3		2405-4712 (Print) 2405-4712 (Linking)	101656080	Cell systems	['eng']	S2405-4712(17)30389-7 [pii] 10.1016/j.cels.2017.09.001 [doi]	20190701	['Algorithms', 'Computational Biology/*methods', 'Computer Simulation', 'Databases, Protein', 'Deep Learning', 'Forecasting', 'Humans', 'Membrane Proteins/*chemistry/metabolism/*physiology', 'Molecular Dynamics Simulation', 'Protein Conformation', 'Protein Folding', 'Protein Structure, Tertiary/*physiology', 'Sequence Analysis, Protein/methods']	2019/07/02 06:00	['NIHMS908517']	['*co-evolution analysis', '*deep learning', '*deep transfer learning', '*homology modeling', '*membrane protein contact prediction', '*membrane protein folding', '*multiple sequence alignment']	['NOTNLM']	NLM	202-211.e3	['2017/02/22 00:00 [received]', '2017/06/01 00:00 [revised]', '2017/08/29 00:00 [accepted]', '2017/09/29 06:00 [entrez]', '2017/09/29 06:00 [pubmed]', '2019/07/02 06:00 [medline]']	United States	PMC5637520		28957654	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Membrane Proteins)']	IM		Cell Syst. 2017 Sep 27;5(3):202-211.e3. doi: 10.1016/j.cels.2017.09.001.	MEDLINE	Cell Syst	Folding Membrane Proteins by Deep Transfer Learning.		5	Folding Membrane Proteins by Deep Transfer Learning.
Cardiovascular imaging technologies continue to increase in their capacity to capture and store large quantities of data. Modern computational methods, developed in the field of machine learning, offer new approaches to leveraging the growing volume of imaging data available for analyses. Machine learning methods can now address data-related problems ranging from simple analytic queries of existing measurement data to the more complex challenges involved in analyzing raw images. To date, machine learning has been used in 2 broad and highly interconnected areas: automation of tasks that might otherwise be performed by a human and generation of clinically important new knowledge. Most cardiovascular imaging studies have focused on task-oriented problems, but more studies involving algorithms aimed at generating new clinical insights are emerging. Continued expansion in the size and dimensionality of cardiovascular imaging databases is driving strong interest in applying powerful deep learning methods, in particular, to analyze these data. Overall, the most effective approaches will require an investment in the resources needed to appropriately prepare such large data sets for analyses. Notwithstanding current technical and logistical challenges, machine learning and especially deep learning methods have much to offer and will substantially impact the future practice and science of cardiovascular imaging.	"[""From the Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (M.H., G.S., P.V.H., S.C.); Google Brain, Google Inc, Cambridge, MA (J.S., A.W.); and Framingham Heart Study, MA (S.C.). scheng@rics.bwh.harvard.edu."", ""From the Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (M.H., G.S., P.V.H., S.C.); Google Brain, Google Inc, Cambridge, MA (J.S., A.W.); and Framingham Heart Study, MA (S.C.)."", ""From the Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (M.H., G.S., P.V.H., S.C.); Google Brain, Google Inc, Cambridge, MA (J.S., A.W.); and Framingham Heart Study, MA (S.C.)."", ""From the Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (M.H., G.S., P.V.H., S.C.); Google Brain, Google Inc, Cambridge, MA (J.S., A.W.); and Framingham Heart Study, MA (S.C.)."", ""From the Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (M.H., G.S., P.V.H., S.C.); Google Brain, Google Inc, Cambridge, MA (J.S., A.W.); and Framingham Heart Study, MA (S.C.)."", ""From the Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, Boston, MA (M.H., G.S., P.V.H., S.C.); Google Brain, Google Inc, Cambridge, MA (J.S., A.W.); and Framingham Heart Study, MA (S.C.).""]"	['CIRCIMAGING.117.005614 [pii]', '10.1161/CIRCIMAGING.117.005614 [doi]']	['Henglin M', 'Stein G', 'Hushcha PV', 'Snoek J', 'Wiltschko AB', 'Cheng S']		['(c) 2017 American Heart Association, Inc.']					['2017/09/29 06:00']	20171010		2017 Oct	2017/09/29 06:00		['Henglin, Mir', 'Stein, Gillian', 'Hushcha, Pavel V', 'Snoek, Jasper', 'Wiltschko, Alexander B', 'Cheng, Susan']		['R01 HL131532/HL/NHLBI NIH HHS/United States', 'R01 HL134168/HL/NHLBI NIH HHS/United States']	10		1942-0080 (Electronic) 1941-9651 (Linking)	101479935	Circulation. Cardiovascular imaging	['eng']	e005614 [pii] 10.1161/CIRCIMAGING.117.005614 [doi]	20181113	['Algorithms', 'Automation', 'Cardiovascular Diseases/*diagnostic imaging/therapy', 'Diagnostic Imaging/*methods', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Predictive Value of Tests', 'Prognosis', 'Reproducibility of Results', 'Severity of Illness Index', 'Workflow']	2017/10/11 06:00	['NIHMS903257']	['*algorithms', '*artificial intelligence', '*automation', '*workflow']	['NOTNLM']	NLM		['2017/09/29 06:00 [entrez]', '2017/09/29 06:00 [pubmed]', '2017/10/11 06:00 [medline]']	United States	PMC5718356		28956772	ppublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't"", 'Research Support, N.I.H., Extramural']"			IM		Circ Cardiovasc Imaging. 2017 Oct;10(10). pii: CIRCIMAGING.117.005614. doi: 10.1161/CIRCIMAGING.117.005614.	MEDLINE	Circ Cardiovasc Imaging	Machine Learning Approaches in Cardiovascular Imaging.		10	Machine Learning Approaches in Cardiovascular Imaging.
In this paper the classic momentum algorithm for stochastic optimization is considered. A method is introduced that adjusts coefficients for this algorithm during its operation. The method does not depend on any preliminary knowledge of the optimization problem. In the experimental study, the method is applied to on-line learning in feed-forward neural networks, including deep auto-encoders, and outperforms any fixed coefficients. The method eliminates coefficients that are difficult to determine, with profound influence on performance. While the method itself has some coefficients, they are ease to determine and sensitivity of performance to them is low. Consequently, the method makes on-line learning a practically parameter-free process and broadens the area of potential application of this technology.	['Warsaw University of Technology, Institute of Computer Science, Nowowiejska 15/19, 00-665 Warsaw, Poland. Electronic address: p.wawrzynski@elka.pw.edu.pl.']	['S0893-6080(17)30159-4 [pii]', '10.1016/j.neunet.2017.07.007 [doi]']	['Wawrzynski P']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/09/27 06:00']	20180509	20170907	2017 Dec	2017/09/28 06:00		['Wawrzynski, Pawel']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30159-4 [pii] 10.1016/j.neunet.2017.07.007 [doi]	20181202	['*Algorithms', 'Learning', '*Machine Learning/trends', '*Neural Networks (Computer)', 'Stochastic Processes']	2018/05/10 06:00		['Classic momentum', 'Deep learning', 'Learning rate', 'On-line learning', 'Step-size', 'Stochastic gradient descent']	['NOTNLM']	NLM	1-10	['2016/08/02 00:00 [received]', '2017/04/21 00:00 [revised]', '2017/07/07 00:00 [accepted]', '2017/09/28 06:00 [pubmed]', '2018/05/10 06:00 [medline]', '2017/09/27 06:00 [entrez]']	United States			28950104	ppublish	['Journal Article']			IM		Neural Netw. 2017 Dec;96:1-10. doi: 10.1016/j.neunet.2017.07.007. Epub 2017 Sep 7.	MEDLINE	Neural Netw	ASD+M: Automatic parameter tuning in stochastic optimization and on-line learning.		96	ASD+M: Automatic parameter tuning in stochastic optimization and on-line learning.
The advent of 'Big Data' and 'Deep Learning' offers both, a great challenge and a huge opportunity for personalised health-care. In machine learning-based biomedical data analysis, feature extraction is a key step for 'feeding' the subsequent classifiers. With increasing numbers of biomedical data, extracting features from these 'big' data is an intensive and time-consuming task. In this case study, we employ a Graphics Processing Unit (GPU) via Python to extract features from a large corpus of snore sound data. Those features can subsequently be imported into many well-known deep learning training frameworks without any format processing. The snore sound data were collected from several hospitals (20 subjects, with 770-990 MB per subject - in total 17.20 GB). Experimental results show that our GPU-based processing significantly speeds up the feature extraction phase, by up to seven times, as compared to the previous CPU system.	['School of Computer Science and Engineering, Nanjing University of Science Technology, Nanjing, China.', 'Department of Electrical and Computer Engineering, MISP group, MMK Technische University Munchen, Munich, Germany.', 'School of Computer Science and Engineering, Nanjing University of Science Technology, Nanjing, China. gongxuan@njust.edu.cn.', 'Department of Otolaryngology, Beijing Hospital, Beijing, China.', 'Bjorn Schuller Department of Computing, Machine Learning Group Imperial College London, London, UK.']	['10.1007/s12539-017-0232-9 [doi]', '10.1007/s12539-017-0232-9 [pii]']	['Guo J', 'Qian K', 'Zhang G', 'Xu H', 'Schuller B']							['2017/09/27 06:00']	20180709	20170925	2017 Dec	2017/09/28 06:00		['Guo, Jian', 'Qian, Kun', 'Zhang, Gongxuan', 'Xu, Huijie', 'Schuller, Bjorn']		"['61472189/National Natural Science Foundation of China', '61272420/National Natural Science Foundation of China', ""338164/European Union's Seventh Framework and Horizon 2020 Programmes"", ""645378/European Union's Seventh Framework and Horizon 2020 Programmes""]"	4		1867-1462 (Electronic) 1867-1462 (Linking)	101515919	Interdisciplinary sciences, computational life sciences	['eng']	10.1007/s12539-017-0232-9 [doi]	20180710	['*Algorithms', 'Humans', 'Machine Learning', 'Snoring', '*Sound']	2018/07/10 06:00		['Biomedical', 'Feature extraction', 'GPU', 'Python', 'Signal processing']	['NOTNLM']	NLM	550-555	['2016/09/27 00:00 [received]', '2017/04/17 00:00 [accepted]', '2017/04/05 00:00 [revised]', '2017/09/28 06:00 [pubmed]', '2018/07/10 06:00 [medline]', '2017/09/27 06:00 [entrez]']	Germany			28948531	ppublish	['Journal Article']			IM		Interdiscip Sci. 2017 Dec;9(4):550-555. doi: 10.1007/s12539-017-0232-9. Epub 2017 Sep 25.	MEDLINE	Interdiscip Sci	Accelerating Biomedical Signal Processing Using GPU: A Case Study of Snore Sound Feature Extraction.		9	Accelerating Biomedical Signal Processing Using GPU: A Case Study of Snore Sound Feature Extraction.
We introduce a deep learning architecture for structure-based virtual screening that generates fixed-sized fingerprints of proteins and small molecules by applying learnable atom convolution and softmax operations to each molecule separately. These fingerprints are further non-linearly transformed, their inner product is calculated and used to predict the binding potential. Moreover, we show that widely used benchmark datasets may be insufficient for testing structure-based virtual screening methods that utilize machine learning. Therefore, we introduce a new benchmark dataset, which we constructed based on DUD-E, MUV and PDBBind databases.	['Department of Computer Science, Wroclaw University of Science and Technology, Poland; Alphamoon, Wroclaw, Poland. Electronic address: adam.gonczarek@pwr.edu.pl.', 'Department of Computer Science, Wroclaw University of Science and Technology, Poland.', 'Department of Computer Science, Wroclaw University of Science and Technology, Poland; Alphamoon, Wroclaw, Poland.', 'Department of Computer Science, Wroclaw University of Science and Technology, Poland.', 'Department of Computer Science, Wroclaw University of Science and Technology, Poland; Indata SA, Wroclaw, Poland.', 'Alphamoon, Wroclaw, Poland.']	['S0010-4825(17)30297-4 [pii]', '10.1016/j.compbiomed.2017.09.007 [doi]']	['Gonczarek A', 'Tomczak JM', 'Zareba S', 'Kaczmar J', 'Dabrowski P', 'Walczak MJ']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/09/25 06:00']	20190806	20170914	2018 Sep 1	2017/09/25 06:00		['Gonczarek, Adam', 'Tomczak, Jakub M', 'Zareba, Szymon', 'Kaczmar, Joanna', 'Dabrowski, Piotr', 'Walczak, Michal J']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(17)30297-4 [pii] 10.1016/j.compbiomed.2017.09.007 [doi]	20190806	['*Databases, Protein', '*Deep Learning', 'Protein Conformation', 'Proteins/*chemistry']	2019/08/07 06:00		['*DUD-E', '*Deep learning', '*Graph convolution', '*MUV', '*Neural fingerprint', '*PDBBind', '*Virtual screening']	['NOTNLM']	NLM	253-258	['2017/01/31 00:00 [received]', '2017/08/22 00:00 [revised]', '2017/09/08 00:00 [accepted]', '2017/09/25 06:00 [pubmed]', '2019/08/07 06:00 [medline]', '2017/09/25 06:00 [entrez]']	United States			28941550	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']			Comput Biol Med. 2018 Sep 1;100:253-258. doi: 10.1016/j.compbiomed.2017.09.007. Epub 2017 Sep 14.	MEDLINE	Comput Biol Med	Interaction prediction in structure-based virtual screening using deep learning.		100	Interaction prediction in structure-based virtual screening using deep learning.
In a physical neural system, learning rules must be local both in space and time. In order for learning to occur, non-local information must be communicated to the deep synapses through a communication channel, the deep learning channel. We identify several possible architectures for this learning channel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges: (1) symmetry of architectures; (2) symmetry of weights; (3) symmetry of neurons; (4) symmetry of derivatives; (5) symmetry of processing; and (6) symmetry of learning rules. Random backpropagation (RBP) addresses the second and third symmetry, and some of its variations, such as skipped RBP (SRBP) address the first and the fourth symmetry. Here we address the last two desirable symmetries showing through simulations that they can be achieved and that the learning channel is particularly robust to symmetry variations. Specifically, random backpropagation and its variations can be performed with the same non-linear neurons used in the main input-output forward channel, and the connections in the learning channel can be adapted using the same algorithm used in the forward channel, removing the need for any specialized hardware in the learning channel. Finally, we provide mathematical results in simple cases showing that the learning equations in the forward and backward channels converge to fixed points, for almost any initial conditions. In symmetric architectures, if the weights in both channels are small at initialization, adaptation in both channels leads to weights that are essentially symmetric during and after learning. Biological connections are discussed.	['Department of Computer Science, University of California, Irvine, Irvine, CA 92617, United States. Electronic address: pfbaldi@uci.edu.', 'Department of Computer Science, University of California, Irvine, Irvine, CA 92617, United States.', 'Department of Mathematics, University of California, Irvine, Irvine, CA 92617, United States.']	['S0893-6080(17)30198-3 [pii]', '10.1016/j.neunet.2017.08.008 [doi]']	['Baldi P', 'Sadowski P', 'Lu Z']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/09/23 06:00']	20180423	20170905	2017 Nov	2017/09/25 06:00		['Baldi, Pierre', 'Sadowski, Peter', 'Lu, Zhiqin']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30198-3 [pii] 10.1016/j.neunet.2017.08.008 [doi]	20181202	['*Machine Learning', '*Neural Networks (Computer)']	2018/04/24 06:00		['Backpropagation', 'Deep learning', 'Learning channel', 'Learning dynamics', 'Local learning', 'Neural networks']	['NOTNLM']	NLM	110-133	['2017/02/05 00:00 [received]', '2017/07/30 00:00 [revised]', '2017/08/22 00:00 [accepted]', '2017/09/25 06:00 [pubmed]', '2018/04/24 06:00 [medline]', '2017/09/23 06:00 [entrez]']	United States			28938130	ppublish	['Journal Article']			IM		Neural Netw. 2017 Nov;95:110-133. doi: 10.1016/j.neunet.2017.08.008. Epub 2017 Sep 5.	MEDLINE	Neural Netw	Learning in the machine: The symmetries of the deep learning channel.		95	Learning in the machine: The symmetries of the deep learning channel.
BACKGROUND: Worldwide propagation of minimally invasive surgeries (MIS) is hindered by their drawback of indirect observation and manipulation, while monitoring of surgical instruments moving in the operated body required by surgeons is a challenging problem. Tracking of surgical instruments by vision-based methods is quite lucrative, due to its flexible implementation via software-based control with no need to modify instruments or surgical workflow. METHODS: A MIS instrument is conventionally split into a shaft and end-effector portions, while a 2D/3D tracking-by-detection framework is proposed, which performs the shaft tracking followed by the end-effector one. The former portion is described by line features via the RANSAC scheme, while the latter is depicted by special image features based on deep learning through a well-trained convolutional neural network. RESULTS: The method verification in 2D and 3D formulation is performed through the experiments on ex-vivo video sequences, while qualitative validation on in-vivo video sequences is obtained. CONCLUSION: The proposed method provides robust and accurate tracking, which is confirmed by the experimental results: its 3D performance in ex-vivo video sequences exceeds those of the available state-of -the-art methods. Moreover, the experiments on in-vivo sequences demonstrate that the proposed method can tackle the difficult condition of tracking with unknown camera parameters. Further refinements of the method will refer to the occlusion and multi-instrumental MIS applications.	['a School of Control Science and Engineering , Shandong University , Jinan , China.', 'b CNRS, INSERM, TIMC-IMAG , University Grenoble-Alpes , Grenoble , France.', 'c School of Computer Science , Bangor University , Bangor , UK.', 'a School of Control Science and Engineering , Shandong University , Jinan , China.', 'd Department of cardiology, Qilu Hospital of Shandong University , Jinan , China.']	['10.1080/24699322.2017.1378777 [doi]']	['Zhao Z', 'Voros S', 'Weng Y', 'Chang F', 'Li R']							['2017/09/23 06:00']	20190621	20170922	2017 Dec	2017/09/25 06:00		['Zhao, Zijian', 'Voros, Sandrine', 'Weng, Ying', 'Chang, Faliang', 'Li, Ruijian']			sup1		2469-9322 (Electronic) 2469-9322 (Linking)	101681550	Computer assisted surgery (Abingdon, England)	['eng']	10.1080/24699322.2017.1378777 [doi]	20190621	['Algorithms', '*Deep Learning', 'Endoscopes', 'Humans', '*Imaging, Three-Dimensional', 'Laparoscopes', 'Minimally Invasive Surgical Procedures/*instrumentation/methods', '*Neural Networks (Computer)', '*Surgical Instruments']	2019/06/22 06:00		['*Tracking by detection', '*convolutional neural network', '*minimally invasive surgery', '*surgical vision']	['NOTNLM']	NLM	26-35	['2017/09/25 06:00 [pubmed]', '2019/06/22 06:00 [medline]', '2017/09/23 06:00 [entrez]']	England			28937281	ppublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Assist Surg (Abingdon). 2017 Dec;22(sup1):26-35. doi: 10.1080/24699322.2017.1378777. Epub 2017 Sep 22.	MEDLINE	Comput Assist Surg (Abingdon)	Tracking-by-detection of surgical instruments in minimally invasive surgery via the convolutional neural network deep learning-based method.		22	Tracking-by-detection of surgical instruments in minimally invasive surgery via the convolutional neural network deep learning-based method.
Oral Squamous Cell Carcinoma (OSCC) is a common type of cancer of the oral epithelium. Despite their high impact on mortality, sufficient screening methods for early diagnosis of OSCC often lack accuracy and thus OSCCs are mostly diagnosed at a late stage. Early detection and accurate outline estimation of OSCCs would lead to a better curative outcome and a reduction in recurrence rates after surgical treatment. Confocal Laser Endomicroscopy (CLE) records sub-surface micro-anatomical images for in vivo cell structure analysis. Recent CLE studies showed great prospects for a reliable, real-time ultrastructural imaging of OSCC in situ. We present and evaluate a novel automatic approach for OSCC diagnosis using deep learning technologies on CLE images. The method is compared against textural feature-based machine learning approaches that represent the current state of the art. For this work, CLE image sequences (7894 images) from patients diagnosed with OSCC were obtained from 4 specific locations in the oral cavity, including the OSCC lesion. The present approach is found to outperform the state of the art in CLE image recognition with an area under the curve (AUC) of 0.96 and a mean accuracy of 88.3% (sensitivity 86.6%, specificity 90%).	['Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany. marc.aubreville@fau.de.', 'Department of Oral and Maxillofacial Surgery, University Medical Center Hamburg-Eppendorf, Hamburg, Germany.', 'Erlangen Graduate School in Advanced Optical Technologies (SAOT), Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Erlangen Graduate School in Advanced Optical Technologies (SAOT), Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Department of Oral and Maxillofacial Surgery, University Hospital Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Computer Vision Group, Friedrich-Schiller-Universitat Jena, Jena, Germany.', 'Computer Vision Group, Friedrich-Schiller-Universitat Jena, Jena, Germany.', 'Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Erlangen Graduate School in Advanced Optical Technologies (SAOT), Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'First Department of Internal Medicine, University Hospital Mainz, Johannes Gutenberg-Universitat Mainz, Mainz, Germany.', 'Erlangen Graduate School in Advanced Optical Technologies (SAOT), Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Department of Oral and Maxillofacial Surgery, University Hospital Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Pattern Recognition Lab, Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Erlangen Graduate School in Advanced Optical Technologies (SAOT), Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.']	['10.1038/s41598-017-12320-8 [doi]', '10.1038/s41598-017-12320-8 [pii]']	['Aubreville M', 'Knipfer C', 'Oetter N', 'Jaremenko C', 'Rodner E', 'Denzler J', 'Bohr C', 'Neumann H', 'Stelzle F', 'Maier A']	['ORCID: 0000-0002-5294-5247']						['2017/09/22 06:00']	20190701	20170920	2017 Sep 20	2017/09/22 06:00		['Aubreville, Marc', 'Knipfer, Christian', 'Oetter, Nicolai', 'Jaremenko, Christian', 'Rodner, Erik', 'Denzler, Joachim', 'Bohr, Christopher', 'Neumann, Helmut', 'Stelzle, Florian', 'Maier, Andreas']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-12320-8 [doi]	20190701	['Automation, Laboratory/*methods', 'Carcinoma, Squamous Cell/*diagnosis', '*Deep Learning', 'Endoscopy/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Microscopy/*methods', 'Mouth/pathology', 'Mouth Neoplasms/*diagnosis', 'Sensitivity and Specificity']	2019/07/02 06:00				NLM	11979	['2017/03/14 00:00 [received]', '2017/09/07 00:00 [accepted]', '2017/09/22 06:00 [entrez]', '2017/09/22 06:00 [pubmed]', '2019/07/02 06:00 [medline]']	England	PMC5607286		28931888	epublish	['Evaluation Studies', 'Journal Article']			IM		Sci Rep. 2017 Sep 20;7(1):11979. doi: 10.1038/s41598-017-12320-8.	MEDLINE	Sci Rep	Automatic Classification of Cancerous Tissue in Laserendomicroscopy Images of the Oral Cavity using Deep Learning.		7	Automatic Classification of Cancerous Tissue in Laserendomicroscopy Images of the Oral Cavity using Deep Learning.
BACKGROUND: Deep learning is one of the most powerful machine learning methods that has achieved the state-of-the-art performance in many domains. Since deep learning was introduced to the field of bioinformatics in 2012, it has achieved success in a number of areas such as protein residue-residue contact prediction, secondary structure prediction, and fold recognition. In this work, we developed deep learning methods to improve the prediction of torsion (dihedral) angles of proteins. RESULTS: We design four different deep learning architectures to predict protein torsion angles. The architectures including deep neural network (DNN) and deep restricted Boltzmann machine (DRBN), deep recurrent neural network (DRNN) and deep recurrent restricted Boltzmann machine (DReRBM) since the protein torsion angle prediction is a sequence related problem. In addition to existing protein features, two new features (predicted residue contact number and the error distribution of torsion angles extracted from sequence fragments) are used as input to each of the four deep learning architectures to predict phi and psi angles of protein backbone. The mean absolute error (MAE) of phi and psi angles predicted by DRNN, DReRBM, DRBM and DNN is about 20-21 degrees and 29-30 degrees on an independent dataset. The MAE of phi angle is comparable to the existing methods, but the MAE of psi angle is 29 degrees , 2 degrees lower than the existing methods. On the latest CASP12 targets, our methods also achieved the performance better than or comparable to a state-of-the art method. CONCLUSIONS: Our experiment demonstrates that deep learning is a valuable method for predicting protein torsion angles. The deep recurrent network architecture performs slightly better than deep feed-forward architecture, and the predicted residue contact number and the error distribution of torsion angles extracted from sequence fragments are useful features for improving prediction accuracy.	['Department of Computer Science and Technology, Soochow University, Suzhou, Jiangsu, 215006, China.', 'Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, 65211, USA.', 'Department of Mathematics and Computer Science, University of Missouri-St. Louis, 1 University Blvd. 311 Express Scripts Hall, St. Louis, MO, 63121, USA.', 'Department of Computer Science and Technology, Soochow University, Suzhou, Jiangsu, 215006, China.', 'Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, 65211, USA. chengji@missouri.edu.']	['10.1186/s12859-017-1834-2 [doi]', '10.1186/s12859-017-1834-2 [pii]']	['Li H', 'Hou J', 'Adhikari B', 'Lyu Q', 'Cheng J']							['2017/09/20 06:00']	20171218	20170918	2017 Sep 18	2017/09/20 06:00		['Li, Haiou', 'Hou, Jie', 'Adhikari, Badri', 'Lyu, Qiang', 'Cheng, Jianlin']		['R01 GM093123/GM/NIGMS NIH HHS/United States']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']	10.1186/s12859-017-1834-2 [doi]	20181202	['*Machine Learning', 'Molecular Structure', 'Neural Networks (Computer)', 'Protein Structure, Secondary', 'Proteins/*chemistry']	2017/12/19 06:00		['Deep learning', 'Deep recurrent neural network', 'Protein torsion angle prediction', 'Restricted Boltzmann machine']	['NOTNLM']	NLM	417	['2017/04/14 00:00 [received]', '2017/09/11 00:00 [accepted]', '2017/09/20 06:00 [entrez]', '2017/09/20 06:00 [pubmed]', '2017/12/19 06:00 [medline]']	England	PMC5604354		28923002	epublish	['Journal Article']		['0 (Proteins)']	IM		BMC Bioinformatics. 2017 Sep 18;18(1):417. doi: 10.1186/s12859-017-1834-2.	MEDLINE	BMC Bioinformatics	Deep learning methods for protein torsion angle prediction.		18	Deep learning methods for protein torsion angle prediction.
Translating the vast data generated by genomic platforms into accurate predictions of clinical outcomes is a fundamental challenge in genomic medicine. Many prediction methods face limitations in learning from the high-dimensional profiles generated by these platforms, and rely on experts to hand-select a small number of features for training prediction models. In this paper, we demonstrate how deep learning and Bayesian optimization methods that have been remarkably successful in general high-dimensional prediction tasks can be adapted to the problem of predicting cancer outcomes. We perform an extensive comparison of Bayesian optimized deep survival models and other state of the art machine learning methods for survival analysis, and describe a framework for interpreting deep survival models using a risk backpropagation technique. Finally, we illustrate that deep survival models can successfully transfer information across diseases to improve prognostic accuracy. We provide an open-source software implementation of this framework called SurvivalNet that enables automatic training, evaluation and interpretation of deep survival models.	['Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Department of Biostatistics, Mailman School of Public Health, Columbia University, New York, NY, 10032, USA.', 'Department of Biomedical Engineering, Georgia Institute of Technology/Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Department of Computer Science, Cornell University, Ithaca, NY, 14850, USA.', 'Department of Neurology, Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Department of Pathology and Laboratory Medicine, Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Department of Pathology and Laboratory Medicine, Emory University School of Medicine, Atlanta, GA, 30322, USA.', 'Winship Cancer Institute, Emory University, Atlanta, GA, 30322, USA.', 'Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, GA, 30322, USA. lee.cooper@emory.edu.', 'Department of Biomedical Engineering, Georgia Institute of Technology/Emory University School of Medicine, Atlanta, GA, 30322, USA. lee.cooper@emory.edu.', 'Winship Cancer Institute, Emory University, Atlanta, GA, 30322, USA. lee.cooper@emory.edu.']	['10.1038/s41598-017-11817-6 [doi]', '10.1038/s41598-017-11817-6 [pii]']	['Yousefi S', 'Amrollahi F', 'Amgad M', 'Dong C', 'Lewis JE', 'Song C', 'Gutman DA', 'Halani SH', 'Velazquez Vega JE', 'Brat DJ', 'Cooper LAD']	['ORCID: 0000-0002-3504-4965']						['2017/09/17 06:00']	20190715	20170915	2017 Sep 15	2017/09/17 06:00		['Yousefi, Safoora', 'Amrollahi, Fatemeh', 'Amgad, Mohamed', 'Dong, Chengliang', 'Lewis, Joshua E', 'Song, Congzheng', 'Gutman, David A', 'Halani, Sameer H', 'Velazquez Vega, Jose Enrique', 'Brat, Daniel J', 'Cooper, Lee A D']		['K22 LM011576/LM/NLM NIH HHS/United States', 'TL1 TR000456/TR/NCATS NIH HHS/United States', 'U24 CA194362/CA/NCI NIH HHS/United States', 'UL1 TR000454/TR/NCATS NIH HHS/United States']	1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-11817-6 [doi]	20190715	['Bayes Theorem', 'Datasets as Topic', '*Deep Learning', 'Genomics/*methods', 'Humans', 'Neoplasms/genetics/mortality', 'Neural Networks (Computer)', '*Prognosis', '*Software', '*Survival', 'Treatment Outcome']	2019/07/16 06:00				NLM	11707	['2017/05/23 00:00 [received]', '2017/08/30 00:00 [accepted]', '2017/09/17 06:00 [entrez]', '2017/09/17 06:00 [pubmed]', '2019/07/16 06:00 [medline]']	England	PMC5601479		28916782	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2017 Sep 15;7(1):11707. doi: 10.1038/s41598-017-11817-6.	MEDLINE	Sci Rep	Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models.		7	Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models.
In microbiology it is diagnostically useful to recognize various genera and species of bacteria. It can be achieved using computer-aided methods, which make the recognition processes more automatic and thus significantly reduce the time necessary for the classification. Moreover, in case of diagnostic uncertainty (the misleading similarity in shape or structure of bacterial cells), such methods can minimize the risk of incorrect recognition. In this article, we apply the state of the art method for texture analysis to classify genera and species of bacteria. This method uses deep Convolutional Neural Networks to obtain image descriptors, which are then encoded and classified with Support Vector Machine or Random Forest. To evaluate this approach and to make it comparable with other approaches, we provide a new dataset of images. DIBaS dataset (Digital Image of Bacterial Species) contains 660 images with 33 different genera and species of bacteria.	['Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Lojasiewicza Street, 30-348 Krakow, Poland.', 'Department of Computer Science, Cracow University of Technology, 24 Warszawska Street, 31-422 Krakow, Poland.', 'Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Lojasiewicza Street, 30-348 Krakow, Poland.', 'Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Lojasiewicza Street, 30-348 Krakow, Poland.', 'Department of Bacteriology, Microbial Ecology and Parasitology, Chair of Microbiology, Jagiellonian University Medical College, 18 Czysta Street, 31-121 Krakow, Poland.', 'Department of Infection Epidemiology, Chair of Microbiology, Faculty of Medicine, Jagiellonian University Medical College, 18 Czysta Street, 31-121 Krakow, Poland.']	['10.1371/journal.pone.0184554 [doi]', 'PONE-D-17-20371 [pii]']	['Zielinski B', 'Plichta A', 'Misztal K', 'Spurek P', 'Brzychczy-Wloch M', 'Ochonska D']	['ORCID: http://orcid.org/0000-0002-3063-3621']						['2017/09/15 06:00']	20171013	20170914	2017	2017/09/15 06:00		['Zielinski, Bartosz', 'Plichta, Anna', 'Misztal, Krzysztof', 'Spurek, Przemyslaw', 'Brzychczy-Wloch, Monika', 'Ochonska, Dorota']			9		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0184554 [doi]	20181113	['Bacteria/*classification', 'Databases, Factual', 'Machine Learning', '*Neural Networks (Computer)', 'Support Vector Machine']	2017/10/14 06:00				NLM	e0184554	['2017/05/27 00:00 [received]', '2017/08/25 00:00 [accepted]', '2017/09/15 06:00 [entrez]', '2017/09/15 06:00 [pubmed]', '2017/10/14 06:00 [medline]']	United States	PMC5599001		28910352	epublish	['Journal Article']			IM		PLoS One. 2017 Sep 14;12(9):e0184554. doi: 10.1371/journal.pone.0184554. eCollection 2017.	MEDLINE	PLoS One	Deep learning approach to bacterial colony classification.		12	Deep learning approach to bacterial colony classification.
In addition to routine clinical examination, unobtrusive and physical monitoring of Rheumatoid Arthritis (RA) patients provides an important source of information to enable understanding the impact of the disease on quality of life. Besides an increase in sedentary behaviour, pain in RA can negatively impact simple physical activities such as getting out of bed and standing up from a chair. The objective of this work is to develop a method that can generate fine-grained actigraphies to capture the impact of the disease on the daily activities of patients. A processing methodology is presented to automatically tag activity accelerometer data from a cohort of moderate-to-severe RA patients. A study of procesing methods based on machine learning and deep learning is provided. Thirty subjects, 10 RA patients and 20 healthy control subjects, were recruited in the study. A single tri-axial accelerometer was attached to the position of the fifth lumbar vertebra (L5) of each subject with a tag prediction granularity of 3 s. The proposed method is capable of handling unbalanced datasets from tagged data while accounting for long-duration activities such as sitting and lying, as well as short transitions such as sit-to-stand or lying-to-sit. The methodology also includes a novel mechanism for automatically applying a threshold to predictions by their confidence levels, in addition to a logical filter to correct for infeasible sequences of activities. Performance tests showed that the method was able to achieve around 95% accuracy and 81% F-score. The produced actigraphies can be helpful to generate objective RA disease-specific markers of patient mobility in-between clinical site visits.	"['The Hamlyn Centre, Imperial College London, London SW7 2AZ, UK. javier.andreu@imperial.ac.uk.', 'School of Computer Science and Electronic Engineering, University of Essex, Colchester CO4 3SQ, UK. javier.andreu@imperial.ac.uk.', 'Clinical Innovation & Digital Platforms; Projects, Clinical Platforms & Sciences, GSK, Stevenage SG1 2NY, UK. luis.x.garcia-gancedo@gsk.com.', 'Emerging Platforms, Platform Technology & Science, GSK, Stevenage SG1 2NY, UK. jonathanmckinnell@hotmail.com.', ""Tessella, Altran's World Class Center for Analytics, Stevenage SG1 3QP, UK. anniek.vanderdrift@tessella.com."", ""Tessella, Altran's World Class Center for Analytics, Stevenage SG1 3QP, UK. adam.powell@tessella.com."", 'Clinical Innovation & Digital Platforms; Projects, Clinical Platforms & Sciences, GSK, Stevenage SG1 2NY, UK. valentin.x.hamy@gsk.com.', 'Emerging Platforms, Platform Technology & Science, GSK, Stevenage SG1 2NY, UK. Thomas.h.keller@gsk.com.', 'The Hamlyn Centre, Imperial College London, London SW7 2AZ, UK. g.z.yang@imperial.ac.uk.']"	['s17092113 [pii]', '10.3390/s17092113 [doi]']	['Andreu-Perez J', 'Garcia-Gancedo L', 'McKinnell J', 'Van der Drift A', 'Powell A', 'Hamy V', 'Keller T', 'Yang GZ']	['ORCID: 0000-0002-7421-4808', 'ORCID: 0000-0002-6593-829X']				['The authors declare no conflict of interest.']		['2017/09/15 06:00']	20180522	20170914	2017 Sep 14	2017/09/15 06:00		['Andreu-Perez, Javier', 'Garcia-Gancedo, Luis', 'McKinnell, Jonathan', 'Van der Drift, Anniek', 'Powell, Adam', 'Hamy, Valentin', 'Keller, Thomas', 'Yang, Guang-Zhong']			9		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E2113 [pii] 10.3390/s17092113 [doi]	20181202	['Accelerometry', '*Arthritis, Rheumatoid', 'Humans', 'Machine Learning', 'Posture', 'Quality of Life']	2018/05/23 06:00		['actigraphy', 'continuous monitoring', 'machine learning', 'rheumatoid arthritis']	['NOTNLM']	NLM		['2017/07/20 00:00 [received]', '2017/08/24 00:00 [revised]', '2017/08/24 00:00 [accepted]', '2017/09/15 06:00 [entrez]', '2017/09/15 06:00 [pubmed]', '2018/05/23 06:00 [medline]']	Switzerland	PMC5620953		28906437	epublish	['Journal Article']			IM		Sensors (Basel). 2017 Sep 14;17(9). pii: s17092113. doi: 10.3390/s17092113.	MEDLINE	Sensors (Basel)	Developing Fine-Grained Actigraphies for Rheumatoid Arthritis Patients from a Single Accelerometer Using Machine Learning.		17	Developing Fine-Grained Actigraphies for Rheumatoid Arthritis Patients from a Single Accelerometer Using Machine Learning.
The automatic detection and recognition of sound events by computers is a requirement for a number of emerging sensing and human computer interaction technologies. Recent advances in this field have been achieved by machine learning classifiers working in conjunction with time-frequency feature representations. This combination has achieved excellent accuracy for classification of discrete sounds. The ability to recognise sounds under real-world noisy conditions, called robust sound event classification, is an especially challenging task that has attracted recent research attention. Another aspect of real-word conditions is the classification of continuous, occluded or overlapping sounds, rather than classification of short isolated sound recordings. This paper addresses the classification of noise-corrupted, occluded, overlapped, continuous sound recordings. It first proposes a standard evaluation task for such sounds based upon a common existing method for evaluating isolated sound classification. It then benchmarks several high performing isolated sound classifiers to operate with continuous sound data by incorporating an energy-based event detection front end. Results are reported for each tested system using the new task, to provide the first analysis of their performance for continuous sound event detection. In addition it proposes and evaluates a novel Bayesian-inspired front end for the segmentation and detection of continuous sound recordings prior to classification.	['School of Computing, The University of Kent, Medway, Kent, United Kingdom.', 'National Engineering Laboratory of Speech and Language Information Processing, The University of Science and Technology of China, Hefei, PR China.', 'National Engineering Laboratory of Speech and Language Information Processing, The University of Science and Technology of China, Hefei, PR China.', 'National Engineering Laboratory of Speech and Language Information Processing, The University of Science and Technology of China, Hefei, PR China.', 'National Engineering Laboratory of Speech and Language Information Processing, The University of Science and Technology of China, Hefei, PR China.', 'European Research Center, Huawei Technologies Duesseldorf GmbH, Munich, Germany.', 'The Institute for Signal Processing, University of Lubeck, Lubeck, Germany.']	['10.1371/journal.pone.0182309 [doi]', 'PONE-D-15-50800 [pii]']	['McLoughlin I', 'Zhang H', 'Xie Z', 'Song Y', 'Xiao W', 'Phan H']	['ORCID: http://orcid.org/0000-0001-7111-2008']						['2017/09/12 06:00']	20171018	20170911	2017	2017/09/12 06:00		['McLoughlin, Ian', 'Zhang, Haomin', 'Xie, Zhipeng', 'Song, Yan', 'Xiao, Wei', 'Phan, Huy']			9		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0182309 [doi]	20190116	['Algorithms', 'Humans', '*Machine Learning', 'Models, Theoretical', '*Sound']	2017/10/19 06:00				NLM	e0182309	['2015/11/21 00:00 [received]', '2017/07/17 00:00 [accepted]', '2017/09/12 06:00 [entrez]', '2017/09/12 06:00 [pubmed]', '2017/10/19 06:00 [medline]']	United States	PMC5593179		28892478	epublish	['Journal Article']			IM		PLoS One. 2017 Sep 11;12(9):e0182309. doi: 10.1371/journal.pone.0182309. eCollection 2017.	MEDLINE	PLoS One	Continuous robust sound event classification using time-frequency features and deep learning.		12	Continuous robust sound event classification using time-frequency features and deep learning.
Identifying the interaction between drugs and target proteins is an important area of drug research, which provides a broad prospect for low-risk and faster drug development. However, due to the limitations of traditional experiments when revealing drug-protein interactions (DTIs), the screening of targets not only takes a lot of time and money but also has high false-positive and false-negative rates. Therefore, it is imperative to develop effective automatic computational methods to accurately predict DTIs in the postgenome era. In this article, we propose a new computational method for predicting DTIs from drug molecular structure and protein sequence by using the stacked autoencoder of deep learning, which can adequately extract the raw data information. The proposed method has the advantage that it can automatically mine the hidden information from protein sequences and generate highly representative features through iterations of multiple layers. The feature descriptors are then constructed by combining the molecular substructure fingerprint information, and fed into the rotation forest for accurate prediction. The experimental results of fivefold cross-validation indicate that the proposed method achieves superior performance on gold standard data sets (enzymes, ion channels, GPCRs [G-protein-coupled receptors], and nuclear receptors) with accuracy of 0.9414, 0.9116, 0.8669, and 0.8056, respectively. We further comprehensively explore the performance of the proposed method by comparing it with other feature extraction algorithms, state-of-the-art classifiers, and other excellent methods on the same data set. The excellent comparison results demonstrate that the proposed method is highly competitive when predicting drug-target interactions.	['1 School of Computer Science and Technology, China University of Mining and Technology , Xuzhou, China .', '2 College of Information Science and Engineering, Zaozhuang University , Zaozhuang, China .', '3 Xinjiang Technical Institutes of Physics and Chemistry , Chinese Academy of Science, Urumqi, China .', '4 School of Information and Control Engineering, China University of Mining and Technology , Xuzhou, China .', '1 School of Computer Science and Technology, China University of Mining and Technology , Xuzhou, China .', '5 China National Coal Association , Beijing, China .', '6 School of Foreign Languages, Zaozhuang University , Zaozhuang, China .', '1 School of Computer Science and Technology, China University of Mining and Technology , Xuzhou, China .', '7 School of Information Engineering, JiangXi University of Science and Technology , Ganzhou, China .']	['10.1089/cmb.2017.0135 [doi]']	['Wang L', 'You ZH', 'Chen X', 'Xia SX', 'Liu F', 'Yan X', 'Zhou Y', 'Song KJ']							['2017/09/12 06:00']	20190618	20170911	2018 Mar	2017/09/12 06:00		['Wang, Lei', 'You, Zhu-Hong', 'Chen, Xing', 'Xia, Shi-Xiong', 'Liu, Feng', 'Yan, Xin', 'Zhou, Yong', 'Song, Ke-Jian']			3		1557-8666 (Electronic) 1066-5277 (Linking)	9433358	Journal of computational biology : a journal of computational molecular cell biology	['eng']	10.1089/cmb.2017.0135 [doi]	20190618	['Databases, Chemical', '*Deep Learning', 'Molecular Docking Simulation/*methods/standards', 'Protein Binding', 'Reproducibility of Results', 'Sequence Analysis, Protein/*methods/standards']	2019/06/19 06:00		['*deep learning', '*drug-target interactions', '*position-specific scoring matrix', '*stacked autoencoder.']	['NOTNLM']	NLM	361-373	['2017/09/12 06:00 [pubmed]', '2019/06/19 06:00 [medline]', '2017/09/12 06:00 [entrez]']	United States			28891684	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Comput Biol. 2018 Mar;25(3):361-373. doi: 10.1089/cmb.2017.0135. Epub 2017 Sep 11.	MEDLINE	J Comput Biol	A Computational-Based Method for Predicting Drug-Target Interactions by Using Stacked Autoencoder Deep Neural Network.		25	A Computational-Based Method for Predicting Drug-Target Interactions by Using Stacked Autoencoder Deep Neural Network.
The purpose of this work is to evaluate methods from deep learning for application to Magnetic Resonance Fingerprinting (MRF). MRF is a recently proposed measurement technique for generating quantitative parameter maps. In MRF a non-steady state signal is generated by a pseudo-random excitation pattern. A comparison of the measured signal in each voxel with the physical model yields quantitative parameter maps. Currently, the comparison is done by matching a dictionary of simulated signals to the acquired signals. To accelerate the computation of quantitative maps we train a Convolutional Neural Network (CNN) on simulated dictionary data. As a proof of principle we show that the neural network implicitly encodes the dictionary and can replace the matching process.	['MR Application Development, Siemens Healthcare, Erlangen, Germany.', 'MR Application Development, Siemens Healthcare, Erlangen, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.', 'MR Application Development, Siemens Healthcare, Erlangen, Germany.', 'Pattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, Erlangen, Germany.']		['Hoppe E', 'Korzdorfer G', 'Wurfl T', 'Wetzl J', 'Lugauer F', 'Pfeuffer J', 'Maier A']							['2017/09/09 06:00']	20180423		2017	2017/09/09 06:00		['Hoppe, Elisabeth', 'Korzdorfer, Gregor', 'Wurfl, Tobias', 'Wetzl, Jens', 'Lugauer, Felix', 'Pfeuffer, Josef', 'Maier, Andreas']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']		20181202	['Algorithms', 'Brain', '*Machine Learning', 'Magnetic Resonance Imaging', '*Magnetic Resonance Spectroscopy', 'Models, Theoretical', '*Neural Networks (Computer)', 'Pattern Recognition, Automated', 'Signal Processing, Computer-Assisted']	2018/04/24 06:00		['Convolutional Neural Networks', 'Deep Learning', 'Machine Learning', 'Magnetic Resonance Fingerprinting', 'Supervised Machine Learning']	['NOTNLM']	NLM	202-206	['2017/09/09 06:00 [entrez]', '2017/09/09 06:00 [pubmed]', '2018/04/24 06:00 [medline]']	Netherlands			28883201	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2017;243:202-206.	MEDLINE	Stud Health Technol Inform	Deep Learning for Magnetic Resonance Fingerprinting: A New Approach for Predicting Quantitative Parameter Values from Time Series.		243	Deep Learning for Magnetic Resonance Fingerprinting: A New Approach for Predicting Quantitative Parameter Values from Time Series.
Motivation: Translation initiation is a key step in the regulation of gene expression. In addition to the annotated translation initiation sites (TISs), the translation process may also start at multiple alternative TISs (including both AUG and non-AUG codons), which makes it challenging to predict TISs and study the underlying regulatory mechanisms. Meanwhile, the advent of several high-throughput sequencing techniques for profiling initiating ribosomes at single-nucleotide resolution, e.g. GTI-seq and QTI-seq, provides abundant data for systematically studying the general principles of translation initiation and the development of computational method for TIS identification. Methods: We have developed a deep learning-based framework, named TITER, for accurately predicting TISs on a genome-wide scale based on QTI-seq data. TITER extracts the sequence features of translation initiation from the surrounding sequence contexts of TISs using a hybrid neural network and further integrates the prior preference of TIS codon composition into a unified prediction framework. Results: Extensive tests demonstrated that TITER can greatly outperform the state-of-the-art prediction methods in identifying TISs. In addition, TITER was able to identify important sequence signatures for individual types of TIS codons, including a Kozak-sequence-like motif for AUG start codon. Furthermore, the TITER prediction score can be related to the strength of translation initiation in various biological scenarios, including the repressive effect of the upstream open reading frames on gene expression and the mutational effects influencing translation initiation efficiency. Availability and Implementation: TITER is available as an open-source software and can be downloaded from https://github.com/zhangsaithu/titer . Contact: lzhang20@mail.tsinghua.edu.cn or zengjy321@tsinghua.edu.cn. Supplementary information: Supplementary data are available at Bioinformatics online.	['Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China.', 'School of Medicine, Tsinghua University, Beijing, China.', 'Department of Computer Science and Engineering, University of California, Riverside, CA, USA.', 'MOE Key Lab of Bioinformatics and Bioinformatics Division, TNLIST/Department of Computer Science and Technology, Tsinghua University, Beijing, China.', 'Institute of Integrative Genome Biology, University of California, Riverside, CA, USA.', 'School of Medicine, Tsinghua University, Beijing, China.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China.']	['3953962 [pii]', '10.1093/bioinformatics/btx247 [doi]']	['Zhang S', 'Hu H', 'Jiang T', 'Zhang L', 'Zeng J']		['(c) The Author 2017. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com']					['2017/09/09 06:00']	20180503		2017 Jul 15	2017/09/09 06:00		['Zhang, Sai', 'Hu, Hailin', 'Jiang, Tao', 'Zhang, Lei', 'Zeng, Jianyang']			14		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx247 [doi]	20181202	['Animals', '*Codon, Initiator', 'Computational Biology/*methods', 'Humans', '*Machine Learning', 'Mice', 'Models, Genetic', 'Neural Networks (Computer)', 'Open Reading Frames', '*Peptide Chain Initiation, Translational', '*Software']	2018/05/04 06:00				NLM	i234-i242	['2017/09/09 06:00 [entrez]', '2017/09/09 06:00 [pubmed]', '2018/05/04 06:00 [medline]']	England	PMC5870772		28881981	ppublish	['Journal Article']		['0 (Codon, Initiator)']	IM		Bioinformatics. 2017 Jul 15;33(14):i234-i242. doi: 10.1093/bioinformatics/btx247.	MEDLINE	Bioinformatics	TITER: predicting translation initiation sites by deep learning.		33	TITER: predicting translation initiation sites by deep learning.
Motivation: Moonlighting proteins (MPs) are an important class of proteins that perform more than one independent cellular function. MPs are gaining more attention in recent years as they are found to play important roles in various systems including disease developments. MPs also have a significant impact in computational function prediction and annotation in databases. Currently MPs are not labeled as such in biological databases even in cases where multiple distinct functions are known for the proteins. In this work, we propose a novel method named DextMP, which predicts whether a protein is a MP or not based on its textual features extracted from scientific literature and the UniProt database. Results: DextMP extracts three categories of textual information for a protein: titles, abstracts from literature, and function description in UniProt. Three language models were applied and compared: a state-of-the-art deep unsupervised learning algorithm along with two other language models of different types, Term Frequency-Inverse Document Frequency in the bag-of-words and Latent Dirichlet Allocation in the topic modeling category. Cross-validation results on a dataset of known MPs and non-MPs showed that DextMP successfully predicted MPs with over 91% accuracy with significant improvement over existing MP prediction methods. Lastly, we ran DextMP with the best performing language models and text-based feature combinations on three genomes, human, yeast and Xenopus laevis , and found that about 2.5-35% of the proteomes are potential MPs. Availability and Implementation: Code available at http://kiharalab.org/DextMP . Contact: dkihara@purdue.edu.	['Department of Computer Science, Purdue University, West Lafayette, IN, USA.', 'Department of Computer Science, Indiana University-Purdue University Indianapolis (IUPUI), Indianapolis, IN, USA.', 'Department of Computer Science, Purdue University, West Lafayette, IN, USA.', 'Department of Biological Science, Purdue University, West Lafayette, IN, USA.']	['3953945 [pii]', '10.1093/bioinformatics/btx231 [doi]']	['Khan IK', 'Bhuiyan M', 'Kihara D']		['(c) The Author 2017. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com']					['2017/09/09 06:00']	20180406		2017 Jul 15	2017/09/09 06:00		['Khan, Ishita K', 'Bhuiyan, Mansurul', 'Kihara, Daisuke']		['R01 GM097528/GM/NIGMS NIH HHS/United States']	14		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx231 [doi]	20181202	['Animals', 'Data Mining/*methods', 'Databases, Factual', 'Humans', 'Models, Biological', 'Molecular Sequence Annotation', 'Proteomics/*methods', 'Saccharomyces cerevisiae/genetics/metabolism', '*Software', '*Unsupervised Machine Learning', 'Xenopus laevis/genetics/metabolism']	2018/04/07 06:00				NLM	i83-i91	['2017/09/09 06:00 [entrez]', '2017/09/09 06:00 [pubmed]', '2018/04/07 06:00 [medline]']	England	PMC5870774		28881966	ppublish	['Journal Article']			IM		Bioinformatics. 2017 Jul 15;33(14):i83-i91. doi: 10.1093/bioinformatics/btx231.	MEDLINE	Bioinformatics	DextMP: deep dive into text for predicting moonlighting proteins.		33	DextMP: deep dive into text for predicting moonlighting proteins.
Motivation: Cellular Electron CryoTomography (CECT) enables 3D visualization of cellular organization at near-native state and in sub-molecular resolution, making it a powerful tool for analyzing structures of macromolecular complexes and their spatial organizations inside single cells. However, high degree of structural complexity together with practical imaging limitations makes the systematic de novo discovery of structures within cells challenging. It would likely require averaging and classifying millions of subtomograms potentially containing hundreds of highly heterogeneous structural classes. Although it is no longer difficult to acquire CECT data containing such amount of subtomograms due to advances in data acquisition automation, existing computational approaches have very limited scalability or discrimination ability, making them incapable of processing such amount of data. Results: To complement existing approaches, in this article we propose a new approach for subdividing subtomograms into smaller but relatively homogeneous subsets. The structures in these subsets can then be separately recovered using existing computation intensive methods. Our approach is based on supervised structural feature extraction using deep learning, in combination with unsupervised clustering and reference-free classification. Our experiments show that, compared with existing unsupervised rotation invariant feature and pose-normalization based approaches, our new approach achieves significant improvements in both discrimination ability and scalability. More importantly, our new approach is able to discover new structural classes and recover structures that do not exist in training data. Availability and Implementation: Source code freely available at http://www.cs.cmu.edu/ approximately mxu1/software . Contact: mxu1@cs.cmu.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['Computational Biology Department, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Biomedical Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Biomedical Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA.', 'Division of Structural Biology, Wellcome Trust Centre for Human Genetics, University of Oxford, Oxford, UK.', 'Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA.']	['3953944 [pii]', '10.1093/bioinformatics/btx230 [doi]']	['Xu M', 'Chai X', 'Muthakana H', 'Liang X', 'Yang G', 'Zeev-Ben-Mordehai T', 'Xing EP']		['(c) The Author 2017. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com']					['2017/09/09 06:00']	20180406		2017 Jul 15	2017/09/09 06:00		['Xu, Min', 'Chai, Xiaoqi', 'Muthakana, Hariank', 'Liang, Xiaodan', 'Yang, Ge', 'Zeev-Ben-Mordehai, Tzviya', 'Xing, Eric P']		['Wellcome Trust/United Kingdom', 'P30 DA035778/DA/NIDA NIH HHS/United States', 'P41 GM103712/GM/NIGMS NIH HHS/United States', 'R01 GM114311/GM/NIGMS NIH HHS/United States']	14		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx230 [doi]	20181202	['Cluster Analysis', 'Electron Microscope Tomography/*methods', 'Image Processing, Computer-Assisted/methods', '*Machine Learning', '*Molecular Structure']	2018/04/07 06:00				NLM	i13-i22	['2017/09/09 06:00 [entrez]', '2017/09/09 06:00 [pubmed]', '2018/04/07 06:00 [medline]']	England	PMC5946875		28881965	ppublish	['Journal Article']			IM		Bioinformatics. 2017 Jul 15;33(14):i13-i22. doi: 10.1093/bioinformatics/btx230.	MEDLINE	Bioinformatics	Deep learning-based subdivision approach for large scale macromolecules structure recovery from electron cryo tomograms.		33	Deep learning-based subdivision approach for large scale macromolecules structure recovery from electron cryo tomograms.
Motivation: Text mining has become an important tool for biomedical research. The most fundamental text-mining task is the recognition of biomedical named entities (NER), such as genes, chemicals and diseases. Current NER methods rely on pre-defined features which try to capture the specific surface properties of entity types, properties of the typical local context, background knowledge, and linguistic information. State-of-the-art tools are entity-specific, as dictionaries and empirically optimal feature sets differ between entity types, which makes their development costly. Furthermore, features are often optimized for a specific gold standard corpus, which makes extrapolation of quality measures difficult. Results: We show that a completely generic method based on deep learning and statistical word embeddings [called long short-term memory network-conditional random field (LSTM-CRF)] outperforms state-of-the-art entity-specific NER tools, and often by a large margin. To this end, we compared the performance of LSTM-CRF on 33 data sets covering five different entity classes with that of best-of-class NER tools and an entity-agnostic CRF implementation. On average, F1-score of LSTM-CRF is 5% above that of the baselines, mostly due to a sharp increase in recall. Availability and implementation: The source code for LSTM-CRF is available at https://github.com/glample/tagger and the links to the corpora are available at https://corposaurus.github.io/corpora/ . Contact: habibima@informatik.hu-berlin.de.	['Computer Science Department, Humboldt-Universitat zu Berlin, Berlin, Germany.', 'Computer Science Department, Humboldt-Universitat zu Berlin, Berlin, Germany.', 'Enterprise Platform and Integration Concepts, Hasso-Plattner-Institute, Potsdam, Germany.', 'Computer Science Department, Humboldt-Universitat zu Berlin, Berlin, Germany.', 'Computer Science Department, Humboldt-Universitat zu Berlin, Berlin, Germany.']	['3953940 [pii]', '10.1093/bioinformatics/btx228 [doi]']	['Habibi M', 'Weber L', 'Neves M', 'Wiegandt DL', 'Leser U']		['(c) The Author 2017. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com']					['2017/09/09 06:00']	20180406		2017 Jul 15	2017/09/09 06:00		['Habibi, Maryam', 'Weber, Leon', 'Neves, Mariana', 'Wiegandt, David Luis', 'Leser, Ulf']			14		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx228 [doi]	20181202	['Animals', 'Data Mining/*methods', 'Humans', '*Machine Learning', 'Mice', 'Software']	2018/04/07 06:00				NLM	i37-i48	['2017/09/09 06:00 [entrez]', '2017/09/09 06:00 [pubmed]', '2018/04/07 06:00 [medline]']	England	PMC5870729		28881963	ppublish	['Journal Article']			IM		Bioinformatics. 2017 Jul 15;33(14):i37-i48. doi: 10.1093/bioinformatics/btx228.	MEDLINE	Bioinformatics	Deep learning with word embeddings improves biomedical named entity recognition.		33	Deep learning with word embeddings improves biomedical named entity recognition.
PURPOSE: Cell nuclei classification in breast cancer histopathology images plays an important role in effective diagnose since breast cancer can often be characterized by its expression in cell nuclei. However, due to the small and variant sizes of cell nuclei, and heavy noise in histopathology images, traditional machine learning methods cannot achieve desirable recognition accuracy. To address this challenge, this paper aims to present a novel deep neural network which performs representation learning and cell nuclei recognition in an end-to-end manner. METHODS: The proposed model hierarchically maps raw medical images into a latent space in which robustness is achieved by employing a stacked denoising autoencoder. A supervised classifier is further developed to improve the discrimination of the model by maximizing inter-subject separability in the latent space. The proposed method involves a cascade model which jointly learns a set of nonlinear mappings and a classifier from the given raw medical images. Such an on-the-shelf learning strategy makes obtaining discriminative features possible, thus leading to better recognition performance. RESULTS: Extensive experiments with benign and malignant breast cancer datasets are conducted to verify the effectiveness of the proposed method. Better performance was obtained when compared with other feature extraction methods, and higher recognition rate was achieved when compared with other seven classification methods. CONCLUSIONS: We propose an end-to-end DNN model for cell nuclei and non-nuclei classification of histopathology images. It demonstrates that the proposed method can achieve promising performance in cell nuclei classification, and the proposed method is suitable for the cell nuclei classification task.	['Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China.', 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China. leizhang@scu.edu.cn.', 'Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, 610065, China.']	['10.1007/s11548-017-1663-9 [doi]', '10.1007/s11548-017-1663-9 [pii]']	['Feng Y', 'Zhang L', 'Yi Z']							['2017/09/02 06:00']	20180709	20170831	2018 Feb	2017/09/02 06:00		['Feng, Yangqin', 'Zhang, Lei', 'Yi, Zhang']		['151068/Fok Ying Tung Education Foundation', '61332002/National Natural Science Foundation of China', '2016TD0018/Foundation for Youth Science and Technology Innovation Research Team', 'of Sichuan Province']	2		1861-6429 (Electronic) 1861-6410 (Linking)	101499225	International journal of computer assisted radiology and surgery	['eng']	10.1007/s11548-017-1663-9 [doi]	20181202	['Algorithms', 'Breast Neoplasms/*diagnosis/pathology', 'Cell Nucleus/classification/*pathology', 'Diagnosis, Computer-Assisted', 'Female', 'Humans', 'Image Processing, Computer-Assisted', '*Machine Learning', '*Neural Networks (Computer)', 'Reproducibility of Results', 'Software']	2018/07/10 06:00		['Cell nuclei classification', 'Deep neural network', 'Denoising autoencoder', 'Medical image processing', 'Representation learning']	['NOTNLM']	NLM	179-191	['2017/04/27 00:00 [received]', '2017/08/18 00:00 [accepted]', '2017/09/02 06:00 [pubmed]', '2018/07/10 06:00 [medline]', '2017/09/02 06:00 [entrez]']	Germany			28861708	ppublish	['Journal Article', 'Review']			IM		Int J Comput Assist Radiol Surg. 2018 Feb;13(2):179-191. doi: 10.1007/s11548-017-1663-9. Epub 2017 Aug 31.	MEDLINE	Int J Comput Assist Radiol Surg	Breast cancer cell nuclei classification in histopathology images using deep neural networks.		13	Breast cancer cell nuclei classification in histopathology images using deep neural networks.
Recently, microRNAs (miRNAs) are confirmed to be important molecules within many crucial biological processes and therefore related to various complex human diseases. However, previous methods of predicting miRNA-disease associations have their own deficiencies. Under this circumstance, we developed a prediction method called deep representations-based miRNA-disease association (DRMDA) prediction. The original miRNA-disease association data were extracted from HDMM database. Meanwhile, stacked auto-encoder, greedy layer-wise unsupervised pre-training algorithm and support vector machine were implemented to predict potential associations. We compared DRMDA with five previous classical prediction models (HGIMDA, RLSMDA, HDMP, WBSMDA and RWRMDA) in global leave-one-out cross-validation (LOOCV), local LOOCV and fivefold cross-validation, respectively. The AUCs achieved by DRMDA were 0.9177, 08339 and 0.9156 +/- 0.0006 in the three tests above, respectively. In further case studies, we predicted the top 50 potential miRNAs for colon neoplasms, lymphoma and prostate neoplasms, and 88%, 90% and 86% of the predicted miRNA can be verified by experimental evidence, respectively. In conclusion, DRMDA is a promising prediction method which could identify potential and novel miRNA-disease associations.	['School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China.', 'School of Life Science, Peking University, Beijing, China.', 'School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China.', 'Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, China.', 'School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China.']	['10.1111/jcmm.13336 [doi]']	['Chen X', 'Gong Y', 'Zhang DH', 'You ZH', 'Li ZW']	['ORCID: 0000-0001-9028-5342']	['(c) 2017 The Authors. Journal of Cellular and Molecular Medicine published by', 'John Wiley & Sons Ltd and Foundation for Cellular and Molecular Medicine.']					['2017/09/01 06:00']	20190211	20170831	2018 Jan	2017/09/01 06:00		['Chen, Xing', 'Gong, Yao', 'Zhang, De-Hong', 'You, Zhu-Hong', 'Li, Zheng-Wei']			1		1582-4934 (Electronic) 1582-1838 (Linking)	101083777	Journal of cellular and molecular medicine	['eng']	10.1111/jcmm.13336 [doi]	20190215	['*Algorithms', 'Computational Biology/*methods', '*Deep Learning', '*Genetic Association Studies', 'Humans', 'MicroRNAs/*genetics/metabolism', 'Neoplasms/genetics']	2019/02/12 06:00		['*auto-encoder', '*deep representation', '*disease', '*miRNA', '*miRNA-disease association']	['NOTNLM']	NLM	472-485	['2017/03/06 00:00 [received]', '2017/07/01 00:00 [accepted]', '2017/09/01 06:00 [pubmed]', '2019/02/12 06:00 [medline]', '2017/09/01 06:00 [entrez]']	England	PMC5742725		28857494	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (MicroRNAs)']	IM		J Cell Mol Med. 2018 Jan;22(1):472-485. doi: 10.1111/jcmm.13336. Epub 2017 Aug 31.	MEDLINE	J Cell Mol Med	DRMDA: deep representations-based miRNA-disease association prediction.		22	DRMDA: deep representations-based miRNA-disease association prediction.
	['Division of Gynecologic Oncology, Department of Obstetrics and Gynecology, University of Southern California, Los Angeles, CA; Norris Comprehensive Cancer Center, University of Southern California, Los Angeles, CA. Electronic address: koji.matsuo@med.usc.edu.', 'Department of Computer Science, University of Southern California, Los Angeles, CA.', 'Division of Gynecologic Oncology, Department of Obstetrics and Gynecology, University of Southern California, Los Angeles, CA.', 'Department of Computer Science, University of Southern California, Los Angeles, CA.', 'Division of Gynecologic Oncology, Department of Obstetrics and Gynecology, University of Southern California, Los Angeles, CA.', 'Department of Computer Science, University of Southern California, Los Angeles, CA.', 'Division of Gynecologic Oncology, Department of Obstetrics and Gynecology, University of Southern California, Los Angeles, CA; Norris Comprehensive Cancer Center, University of Southern California, Los Angeles, CA.']	['S0002-9378(17)30947-X [pii]', '10.1016/j.ajog.2017.08.012 [doi]']	['Matsuo K', 'Purushotham S', 'Moeini A', 'Li G', 'Machida H', 'Liu Y', 'Roman LD']							['2017/08/28 06:00']	20180126	20170824	2017 Dec	2017/08/28 06:00		['Matsuo, Koji', 'Purushotham, Sanjay', 'Moeini, Aida', 'Li, Guangyu', 'Machida, Hiroko', 'Liu, Yan', 'Roman, Lynda D']			6		1097-6868 (Electronic) 0002-9378 (Linking)	0370476	American journal of obstetrics and gynecology	['eng']	S0002-9378(17)30947-X [pii] 10.1016/j.ajog.2017.08.012 [doi]	20180126	['Clinical Decision-Making', '*Decision Support Techniques', 'Female', 'Humans', '*Life Expectancy', 'Linear Models', '*Machine Learning', 'Neoplasm Recurrence, Local/*mortality', '*Neural Networks (Computer)', 'Pilot Projects', 'Prognosis', 'Retrospective Studies', 'Uterine Cervical Neoplasms/*mortality']	2018/01/27 06:00				NLM	703-705	['2017/06/23 00:00 [received]', '2017/08/10 00:00 [revised]', '2017/08/16 00:00 [accepted]', '2017/08/28 06:00 [pubmed]', '2018/01/27 06:00 [medline]', '2017/08/28 06:00 [entrez]']	United States			28843741	ppublish	"['Letter', ""Research Support, Non-U.S. Gov't""]"			AIM IM		Am J Obstet Gynecol. 2017 Dec;217(6):703-705. doi: 10.1016/j.ajog.2017.08.012. Epub 2017 Aug 24.	MEDLINE	Am J Obstet Gynecol	A pilot study in using deep learning to predict limited life expectancy in women with recurrent cervical cancer.		217	A pilot study in using deep learning to predict limited life expectancy in women with recurrent cervical cancer.
This paper presents an open, multi-vendor, multi-field strength magnetic resonance (MR) T1-weighted volumetric brain imaging dataset, named Calgary-Campinas-359 (CC-359). The dataset is composed of images of older healthy adults (29-80 years) acquired on scanners from three vendors (Siemens, Philips and General Electric) at both 1.5 T and 3 T. CC-359 is comprised of 359 datasets, approximately 60 subjects per vendor and magnetic field strength. The dataset is approximately age and gender balanced, subject to the constraints of the available images. It provides consensus brain extraction masks for all volumes generated using supervised classification. Manual segmentation results for twelve randomly selected subjects performed by an expert are also provided. The CC-359 dataset allows investigation of 1) the influences of both vendor and magnetic field strength on quantitative analysis of brain MR; 2) parameter optimization for automatic segmentation methods; and potentially 3) machine learning classifiers with big data, specifically those based on deep learning methods, as these approaches require a large amount of data. To illustrate the utility of this dataset, we compared to the results of a supervised classifier, the results of eight publicly available skull stripping methods and one publicly available consensus algorithm. A linear mixed effects model analysis indicated that vendor (p-value<0.001) and magnetic field strength (p-value<0.001) have statistically significant impacts on skull stripping results.	['Medical Imaging and Computing Laboratory, Department of Computer Engineering and Industrial Automation, University of Campinas, Campinas, Sao Paulo, Brazil; Departments of Radiology and Clinical Neurosciences, Hotchkiss Brain Institute, University of Calgary, Calgary, Alberta, Canada; Calgary Image Processing and Analysis Centre, Foothills Medical Centre, Alberta Health Services, Calgary, Alberta, Canada; Seaman Family Magnetic Resonance Research Centre, Foothills Medical Centre, Alberta Health Services, Calgary, Alberta, Canada. Electronic address: roberto.medeirosdeso@ucalgary.ca.', 'Medical Imaging and Computing Laboratory, Department of Computer Engineering and Industrial Automation, University of Campinas, Campinas, Sao Paulo, Brazil.', 'Division of Rheumatology, Faculty of Medical Science, University of Campinas, Campinas, Sao Paulo, Brazil.', 'Departments of Radiology and Clinical Neurosciences, Hotchkiss Brain Institute, University of Calgary, Calgary, Alberta, Canada; Calgary Image Processing and Analysis Centre, Foothills Medical Centre, Alberta Health Services, Calgary, Alberta, Canada.', 'Departments of Radiology and Clinical Neurosciences, Hotchkiss Brain Institute, University of Calgary, Calgary, Alberta, Canada; Calgary Image Processing and Analysis Centre, Foothills Medical Centre, Alberta Health Services, Calgary, Alberta, Canada.', 'Division of Rheumatology, Faculty of Medical Science, University of Campinas, Campinas, Sao Paulo, Brazil.', 'Medical Imaging and Computing Laboratory, Department of Computer Engineering and Industrial Automation, University of Campinas, Campinas, Sao Paulo, Brazil.', 'Departments of Radiology and Clinical Neurosciences, Hotchkiss Brain Institute, University of Calgary, Calgary, Alberta, Canada; Calgary Image Processing and Analysis Centre, Foothills Medical Centre, Alberta Health Services, Calgary, Alberta, Canada; Seaman Family Magnetic Resonance Research Centre, Foothills Medical Centre, Alberta Health Services, Calgary, Alberta, Canada.', 'Medical Imaging and Computing Laboratory, Department of Computer Engineering and Industrial Automation, University of Campinas, Campinas, Sao Paulo, Brazil.']	['S1053-8119(17)30668-7 [pii]', '10.1016/j.neuroimage.2017.08.021 [doi]']	['Souza R', 'Lucena O', 'Garrafa J', 'Gobbi D', 'Saluzzi M', 'Appenzeller S', 'Rittner L', 'Frayne R', 'Lotufo R']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/08/16 06:00']	20181211	20170812	2018 Apr 15	2017/08/16 06:00		['Souza, Roberto', 'Lucena, Oeslle', 'Garrafa, Julia', 'Gobbi, David', 'Saluzzi, Marina', 'Appenzeller, Simone', 'Rittner, Leticia', 'Frayne, Richard', 'Lotufo, Roberto']		['MOP-333931/CIHR/Canada']			1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(17)30668-7 [pii] 10.1016/j.neuroimage.2017.08.021 [doi]	20181211	['Adult', 'Aged', 'Aged, 80 and over', 'Brain/*diagnostic imaging', '*Consensus', '*Datasets as Topic', 'Female', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', 'Magnetic Fields', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', 'Neuroimaging/*methods', 'Skull/diagnostic imaging', 'Software']	2018/12/12 06:00		['*Brain MR image analysis', '*Brain extraction', '*Brain segmentation', '*MP-RAGE', '*Public database', '*Skull stripping']	['NOTNLM']	NLM	482-494	['2016/11/01 00:00 [received]', '2017/08/04 00:00 [revised]', '2017/08/05 00:00 [accepted]', '2017/08/16 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2017/08/16 06:00 [entrez]']	United States			28807870	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Neuroimage. 2018 Apr 15;170:482-494. doi: 10.1016/j.neuroimage.2017.08.021. Epub 2017 Aug 12.	MEDLINE	Neuroimage	An open, multi-vendor, multi-field-strength brain MR dataset and analysis of publicly available skull stripping methods agreement.		170	An open, multi-vendor, multi-field-strength brain MR dataset and analysis of publicly available skull stripping methods agreement.
"Establishing early warning systems for anthrax attacks is crucial in biodefense. Despite numerous studies for decades, the limited sensitivity of conventional biochemical methods essentially requires preprocessing steps and thus has limitations to be used in realistic settings of biological warfare. We present an optical method for rapid and label-free screening of Bacillus anthracis spores through the synergistic application of holographic microscopy and deep learning. A deep convolutional neural network is designed to classify holographic images of unlabeled living cells. After training, the network outperforms previous techniques in all accuracy measures, achieving single-spore sensitivity and subgenus specificity. The unique ""representation learning"" capability of deep learning enables direct training from raw images instead of manually extracted features. The method automatically recognizes key biological traits encoded in the images and exploits them as fingerprints. This remarkable learning ability makes the proposed method readily applicable to classifying various single cells in addition to B. anthracis, as demonstrated for the diagnosis of Listeria monocytogenes, without any modification. We believe that our strategy will make holographic microscopy more accessible to medical doctors and biomedical scientists for easy, rapid, and accurate point-of-care diagnosis of pathogens."	['Department of Physics, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.', 'Department of Chemical and Biomolecular Engineering (BK21 Plus Program), KAIST, Daejeon 34141, Republic of Korea.', 'Agency for Defense Development (ADD), Daejeon 34186, Republic of Korea.', 'Department of Physics, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.', 'Department of Physics, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.', 'School of Electrical Engineering, KAIST, Daejeon 34141, Republic of Korea.', 'Department of Biological Sciences, KAIST, Daejeon 34141, Republic of Korea.', 'Department of Biological Sciences, KAIST, Daejeon 34141, Republic of Korea.', 'Department of Bio and Brain Engineering, KAIST, Daejeon 34141, Republic of Korea.', 'Department of Chemical and Biomolecular Engineering (BK21 Plus Program), KAIST, Daejeon 34141, Republic of Korea.', 'Department of Physics, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.', 'Tomocube Inc., Daejeon 34051, Republic of Korea.']	['10.1126/sciadv.1700606 [doi]', '1700606 [pii]']	['Jo Y', 'Park S', 'Jung J', 'Yoon J', 'Joo H', 'Kim MH', 'Kang SJ', 'Choi MC', 'Lee SY', 'Park Y']	['ORCID: 0000-0001-8826-6177', 'ORCID: 0000-0003-0599-3091']						['2017/08/12 06:00']	20190628	20170804	2017 Aug	2017/08/12 06:00		['Jo, YoungJu', 'Park, Sangjin', 'Jung, JaeHwang', 'Yoon, Jonghee', 'Joo, Hosung', 'Kim, Min-Hyeok', 'Kang, Suk-Jo', 'Choi, Myung Chul', 'Lee, Sang Yup', 'Park, YongKeun']			8		2375-2548 (Electronic) 2375-2548 (Linking)	101653440	Science advances	['eng']	10.1126/sciadv.1700606 [doi]	20190628	['Algorithms', 'Anthrax/*diagnosis/*microbiology', 'Bacillus anthracis/*cytology', 'Data Analysis', '*Deep Learning', '*Holography/instrumentation/methods', 'Humans', 'Image Processing, Computer-Assisted', 'Machine Learning', '*Microscopy/instrumentation/methods', 'Spores, Bacterial']	2019/06/30 06:00				NLM	e1700606	['2017/02/27 00:00 [received]', '2017/06/29 00:00 [accepted]', '2017/08/12 06:00 [entrez]', '2017/08/12 06:00 [pubmed]', '2019/06/30 06:00 [medline]']	United States	PMC5544395		28798957	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Adv. 2017 Aug 4;3(8):e1700606. doi: 10.1126/sciadv.1700606. eCollection 2017 Aug.	MEDLINE	Sci Adv	Holographic deep learning for rapid optical screening of anthrax spores.		3	Holographic deep learning for rapid optical screening of anthrax spores.
Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end-to-end learning, that is, learning from the raw data. There is increasing interest in using deep ConvNets for end-to-end EEG analysis, but a better understanding of how to design and train ConvNets for end-to-end EEG decoding and how to visualize the informative EEG features the ConvNets learn is still needed. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed tasks from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching at least as good performance as the widely used filter bank common spatial patterns (FBCSP) algorithm (mean decoding accuracies 82.1% FBCSP, 84.0% deep ConvNets). While FBCSP is designed to use spectral power modulations, the features used by ConvNets are not fixed a priori. Our novel methods for visualizing the learned features demonstrated that ConvNets indeed learned to use spectral power modulations in the alpha, beta, and high gamma frequencies, and proved useful for spatially mapping the learned features by revealing the topography of the causal contributions of features in different frequency bands to the decoding decision. Our study thus shows how to design and train ConvNets to decode task-related information from the raw EEG without handcrafted features and highlights the potential of deep ConvNets combined with advanced visualization techniques for EEG-based brain mapping. Hum Brain Mapp 38:5391-5420, 2017. (c) 2017 Wiley Periodicals, Inc.	['Translational Neurotechnology Lab, Epilepsy Center, Medical Center - University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Machine Learning Lab, Computer Science Dept, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Translational Neurotechnology Lab, Epilepsy Center, Medical Center - University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Neurobiology and Biophysics, Faculty of Biology, University of Freiburg, Hansastr. 9a, Freiburg, 79104, Germany.', 'Translational Neurotechnology Lab, Epilepsy Center, Medical Center - University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Machine Learning for Automated Algorithm Design Lab, Computer Science Dept, University of Freiburg, Georges-Kohler-Allee 52, Freiburg im Breisgau, 79110, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Brain State Decoding Lab, Computer Science Dept, University of Freiburg, Albertstr. 23, Freiburg, 79104, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Machine Learning for Automated Algorithm Design Lab, Computer Science Dept, University of Freiburg, Georges-Kohler-Allee 52, Freiburg im Breisgau, 79110, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Autonomous Intelligent Systems Lab, Computer Science Dept, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.', 'Translational Neurotechnology Lab, Epilepsy Center, Medical Center - University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany.', 'BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Kohler-Allee 79, Freiburg, 79110, Germany.']	['10.1002/hbm.23730 [doi]']	['Schirrmeister RT', 'Springenberg JT', 'Fiederer LDJ', 'Glasstetter M', 'Eggensperger K', 'Tangermann M', 'Hutter F', 'Burgard W', 'Ball T']	['ORCID: 0000-0002-5518-7445', 'ORCID: 0000-0003-1803-9694', 'ORCID: 0000-0002-4993-466X']	['(c) 2017 The Authors Human Brain Mapping Published by Wiley Periodicals, Inc.']					['2017/08/08 06:00']	20180529	20170807	2017 Nov	2017/08/08 06:00		['Schirrmeister, Robin Tibor', 'Springenberg, Jost Tobias', 'Fiederer, Lukas Dominique Josef', 'Glasstetter, Martin', 'Eggensperger, Katharina', 'Tangermann, Michael', 'Hutter, Frank', 'Burgard, Wolfram', 'Ball, Tonio']			11		1097-0193 (Electronic) 1065-9471 (Linking)	9419065	Human brain mapping	['eng']	10.1002/hbm.23730 [doi]	20181113	['Brain/*physiology', 'Brain Mapping/methods', 'Brain-Computer Interfaces', 'Electroencephalography/*methods', 'Humans', 'Imagination/physiology', 'Language', '*Machine Learning', 'Motor Activity/physiology', 'Neural Pathways/physiology', 'Space Perception/physiology']	2018/05/31 06:00		['*EEG analysis', '*brain mapping', '*brain-computer interface', '*brain-machine interface', '*electroencephalography', '*end-to-end learning', '*machine learning', '*model interpretability']	['NOTNLM']	NLM	5391-5420	['2017/02/22 00:00 [received]', '2017/05/31 00:00 [revised]', '2017/07/05 00:00 [accepted]', '2017/08/08 06:00 [pubmed]', '2018/05/31 06:00 [medline]', '2017/08/08 06:00 [entrez]']	United States	PMC5655781		28782865	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Hum Brain Mapp. 2017 Nov;38(11):5391-5420. doi: 10.1002/hbm.23730. Epub 2017 Aug 7.	MEDLINE	Hum Brain Mapp	Deep learning with convolutional neural networks for EEG decoding and visualization.		38	Deep learning with convolutional neural networks for EEG decoding and visualization.
Automatic and accurate estimation of disease severity is essential for food security, disease management, and yield loss prediction. Deep learning, the latest breakthrough in computer vision, is promising for fine-grained disease severity classification, as the method avoids the labor-intensive feature engineering and threshold-based segmentation. Using the apple black rot images in the PlantVillage dataset, which are further annotated by botanists with four severity stages as ground truth, a series of deep convolutional neural networks are trained to diagnose the severity of the disease. The performances of shallow networks trained from scratch and deep models fine-tuned by transfer learning are evaluated systemically in this paper. The best model is the deep VGG16 model trained with transfer learning, which yields an overall accuracy of 90.4% on the hold-out test set. The proposed deep learning model may have great potential in disease control for modern agriculture.	['School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.', 'School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.', 'School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.']	['10.1155/2017/2917536 [doi]']	['Wang G', 'Sun Y', 'Wang J']	['ORCID: 0000-0002-3568-2908', 'ORCID: 0000-0003-3206-9515', 'ORCID: 0000-0003-1320-3969']						['2017/08/01 06:00']	20180411	20170705	2017	2017/08/02 06:00		['Wang, Guan', 'Sun, Yu', 'Wang, Jianxin']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2017/2917536 [doi]	20181202	['*Machine Learning', 'Malus/microbiology', 'Neural Networks (Computer)', 'Plant Diseases/*classification/microbiology']	2018/04/12 06:00				NLM	2917536	['2017/03/08 00:00 [received]', '2017/05/09 00:00 [revised]', '2017/06/04 00:00 [accepted]', '2017/08/01 06:00 [entrez]', '2017/08/02 06:00 [pubmed]', '2018/04/12 06:00 [medline]']	United States	PMC5516765		28757863	ppublish	['Journal Article']			IM		Comput Intell Neurosci. 2017;2017:2917536. doi: 10.1155/2017/2917536. Epub 2017 Jul 5.	MEDLINE	Comput Intell Neurosci	Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning.		2017	Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning.
Accurately annotating biological functions of proteins is one of the key tasks in the postgenome era. Many machine learning based methods have been applied to predict functional annotations of proteins, but this task is rarely solved by deep learning techniques. Deep learning techniques recently have been successfully applied to a wide range of problems, such as video, images, and nature language processing. Inspired by these successful applications, we investigate deep restricted Boltzmann machines (DRBM), a representative deep learning technique, to predict the missing functional annotations of partially annotated proteins. Experimental results on Homo sapiens, Saccharomyces cerevisiae, Mus musculus, and Drosophila show that DRBM achieves better performance than other related methods across different evaluation metrics, and it also runs faster than these comparing methods.	['College of Computer and Information Science, Southwest University, Chongqing, China.', 'College of Computer and Information Science, Southwest University, Chongqing, China.', 'College of Computer and Information Science, Southwest University, Chongqing, China.']	['10.1155/2017/1729301 [doi]']	['Zou X', 'Wang G', 'Yu G']	['ORCID: 0000-0002-1667-6705']						['2017/07/27 06:00']	20180416	20170628	2017	2017/07/27 06:00		['Zou, Xianchun', 'Wang, Guijun', 'Yu, Guoxian']					2314-6141 (Electronic)	101600173	BioMed research international	['eng']	10.1155/2017/1729301 [doi]	20181113	['*Algorithms', 'Animals', 'Computational Biology/*methods', 'Databases, Protein', 'Drosophila/metabolism', 'Gene Ontology', 'Humans', 'Mice', 'Molecular Sequence Annotation', 'Proteins/*metabolism', 'Saccharomyces cerevisiae/metabolism', 'Statistics as Topic']	2018/04/17 06:00				NLM	1729301	['2017/03/30 00:00 [received]', '2017/05/30 00:00 [accepted]', '2017/07/27 06:00 [entrez]', '2017/07/27 06:00 [pubmed]', '2018/04/17 06:00 [medline]']	United States	PMC5506480		28744460	ppublish	['Journal Article']		['0 (Proteins)']	IM		Biomed Res Int. 2017;2017:1729301. doi: 10.1155/2017/1729301. Epub 2017 Jun 28.	MEDLINE	Biomed Res Int	Protein Function Prediction Using Deep Restricted Boltzmann Machines.		2017	Protein Function Prediction Using Deep Restricted Boltzmann Machines.
"PURPOSE: We propose a single network trained by pixel-to-label deep learning to address the general issue of automatic multiple organ segmentation in three-dimensional (3D) computed tomography (CT) images. Our method can be described as a voxel-wise multiple-class classification scheme for automatically assigning labels to each pixel/voxel in a 2D/3D CT image. METHODS: We simplify the segmentation algorithms of anatomical structures (including multiple organs) in a CT image (generally in 3D) to a majority voting scheme over the semantic segmentation of multiple 2D slices drawn from different viewpoints with redundancy. The proposed method inherits the spirit of fully convolutional networks (FCNs) that consist of ""convolution"" and ""deconvolution"" layers for 2D semantic image segmentation, and expands the core structure with 3D-2D-3D transformations to adapt to 3D CT image segmentation. All parameters in the proposed network are trained pixel-to-label from a small number of CT cases with human annotations as the ground truth. The proposed network naturally fulfills the requirements of multiple organ segmentations in CT cases of different sizes that cover arbitrary scan regions without any adjustment. RESULTS: The proposed network was trained and validated using the simultaneous segmentation of 19 anatomical structures in the human torso, including 17 major organs and two special regions (lumen and content inside of stomach). Some of these structures have never been reported in previous research on CT segmentation. A database consisting of 240 (95% for training and 5% for testing) 3D CT scans, together with their manually annotated ground-truth segmentations, was used in our experiments. The results show that the 19 structures of interest were segmented with acceptable accuracy (88.1% and 87.9% voxels in the training and testing datasets, respectively, were labeled correctly) against the ground truth. CONCLUSIONS: We propose a single network based on pixel-to-label deep learning to address the challenging issue of anatomical structure segmentation in 3D CT cases. The novelty of this work is the policy of deep learning of the different 2D sectional appearances of 3D anatomical structures for CT cases and the majority voting of the 3D segmentation results from multiple crossed 2D sections to achieve availability and reliability with better efficiency, generality, and flexibility than conventional segmentation methods, which must be guided by human expertise."	['Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan.', 'Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan.', 'Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, 29208, USA.', 'Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan.', 'Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan.']	['10.1002/mp.12480 [doi]']	['Zhou X', 'Takayama R', 'Wang S', 'Hara T', 'Fujita H']		['(c) 2017 The Authors. Medical Physics published by Wiley Periodicals, Inc. on', 'behalf of American Association of Physicists in Medicine.']					['2017/07/22 06:00']	20180523	20170831	2017 Oct	2017/07/22 06:00		['Zhou, Xiangrong', 'Takayama, Ryosuke', 'Wang, Song', 'Hara, Takeshi', 'Fujita, Hiroshi']			10		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.12480 [doi]	20180523	['Humans', 'Imaging, Three-Dimensional/*methods', 'Lung/diagnostic imaging', '*Machine Learning', '*Tomography, X-Ray Computed']	2018/05/24 06:00		['2D semantic segmentation', 'CT images', 'anatomical structure segmentation', 'deep learning', 'fully convolutional network (FCN)']	['NOTNLM']	NLM	5221-5233	['2016/10/31 00:00 [received]', '2017/07/03 00:00 [revised]', '2017/07/10 00:00 [accepted]', '2017/07/22 06:00 [pubmed]', '2018/05/24 06:00 [medline]', '2017/07/22 06:00 [entrez]']	United States			28730602	ppublish	['Journal Article']			IM		Med Phys. 2017 Oct;44(10):5221-5233. doi: 10.1002/mp.12480. Epub 2017 Aug 31.	MEDLINE	Med Phys	Deep learning of the sectional appearances of 3D CT images for anatomical structure segmentation based on an FCN voting method.		44	Deep learning of the sectional appearances of 3D CT images for anatomical structure segmentation based on an FCN voting method.
This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multi-modal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.	['University of North Carolina at Chapel Hill, Chapel Hill, USA. Electronic address: xy@cs.unc.edu.', 'Department of Computer Science, University of Salzburg, Austria.', 'University of North Carolina at Chapel Hill, Chapel Hill, USA; Department of Psychiatry, UNC, Chapel Hill, USA.', 'University of North Carolina at Chapel Hill, Chapel Hill, USA; Biomedical Research Imaging Center (BRIC), Chapel Hill, USA.']	['S1053-8119(17)30576-1 [pii]', '10.1016/j.neuroimage.2017.07.008 [doi]']	['Yang X', 'Kwitt R', 'Styner M', 'Niethammer M']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/07/15 06:00']	20180601	20170711	2017 Sep	2017/07/15 06:00		['Yang, Xiao', 'Kwitt, Roland', 'Styner, Martin', 'Niethammer, Marc']		['R01 HD055741/HD/NICHD NIH HHS/United States', 'R44 NS081792/NS/NINDS NIH HHS/United States']			1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(17)30576-1 [pii] 10.1016/j.neuroimage.2017.07.008 [doi]	20181113	['Algorithms', 'Brain/*anatomy & histology/*physiology', 'Brain Mapping/*methods', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Imaging, Three-Dimensional/*methods', 'Machine Learning', 'Pattern Recognition, Automated/methods']	2018/06/02 06:00	['NIHMS894138']	['*Brain imaging', '*Deep learning', '*Image registration']	['NOTNLM']	NLM	378-396	['2017/03/31 00:00 [received]', '2017/07/05 00:00 [revised]', '2017/07/07 00:00 [accepted]', '2017/07/15 06:00 [pubmed]', '2018/06/02 06:00 [medline]', '2017/07/15 06:00 [entrez]']	United States	PMC6036629		28705497	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Neuroimage. 2017 Sep;158:378-396. doi: 10.1016/j.neuroimage.2017.07.008. Epub 2017 Jul 11.	MEDLINE	Neuroimage	Quicksilver: Fast predictive image registration - A deep learning approach.		158	Quicksilver: Fast predictive image registration - A deep learning approach.
BACKGROUND: Entity recognition is one of the most primary steps for text analysis and has long attracted considerable attention from researchers. In the clinical domain, various types of entities, such as clinical entities and protected health information (PHI), widely exist in clinical texts. Recognizing these entities has become a hot topic in clinical natural language processing (NLP), and a large number of traditional machine learning methods, such as support vector machine and conditional random field, have been deployed to recognize entities from clinical texts in the past few years. In recent years, recurrent neural network (RNN), one of deep learning methods that has shown great potential on many problems including named entity recognition, also has been gradually used for entity recognition from clinical texts. METHODS: In this paper, we comprehensively investigate the performance of LSTM (long-short term memory), a representative variant of RNN, on clinical entity recognition and protected health information recognition. The LSTM model consists of three layers: input layer - generates representation of each word of a sentence; LSTM layer - outputs another word representation sequence that captures the context information of each word in this sentence; Inference layer - makes tagging decisions according to the output of LSTM layer, that is, outputting a label sequence. RESULTS: Experiments conducted on corpora of the 2010, 2012 and 2014 i2b2 NLP challenges show that LSTM achieves highest micro-average F1-scores of 85.81% on the 2010 i2b2 medical concept extraction, 92.29% on the 2012 i2b2 clinical event detection, and 94.37% on the 2014 i2b2 de-identification, which is considerably competitive with other state-of-the-art systems. CONCLUSIONS: LSTM that requires no hand-crafted feature has great potential on entity recognition from clinical texts. It outperforms traditional machine learning methods that suffer from fussy feature engineering. A possible future direction is how to integrate knowledge bases widely existing in the clinical domain into LSTM, which is a case of our future work. Moreover, how to use LSTM to recognize entities in specific formats is also another possible future direction.	"['Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China.', ""Pharmacy Department, Shenzhen Second People's Hospital, First Affiliated Hospital of Shenzhen University, Shenzhen, 518035, China."", 'Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China.', 'Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China.', 'Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China. tangbuzhou@gmail.com.', 'Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China. tangbuzhou@gmail.com.', 'Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.']"	['10.1186/s12911-017-0468-7 [doi]', '10.1186/s12911-017-0468-7 [pii]']	['Liu Z', 'Yang M', 'Wang X', 'Chen Q', 'Tang B', 'Wang Z', 'Xu H']							['2017/07/13 06:00']	20180412	20170705	2017 Jul 5	2017/07/13 06:00		['Liu, Zengjian', 'Yang, Ming', 'Wang, Xiaolong', 'Chen, Qingcai', 'Tang, Buzhou', 'Wang, Zhe', 'Xu, Hua']			Suppl 2		1472-6947 (Electronic) 1472-6947 (Linking)	101088682	BMC medical informatics and decision making	['eng']	10.1186/s12911-017-0468-7 [doi]	20181202	['*Electronic Health Records', 'Humans', '*Machine Learning', '*Medical Informatics', '*Natural Language Processing', '*Neural Networks (Computer)']	2018/04/13 06:00		['Clinical notes', 'Deep learning', 'Entity recognition', 'Recurrent neural network', 'Sequence labeling']	['NOTNLM']	NLM	67	['2017/07/13 06:00 [entrez]', '2017/07/13 06:00 [pubmed]', '2018/04/13 06:00 [medline]']	England	PMC5506598		28699566	epublish	['Journal Article']			IM		BMC Med Inform Decis Mak. 2017 Jul 5;17(Suppl 2):67. doi: 10.1186/s12911-017-0468-7.	MEDLINE	BMC Med Inform Decis Mak	Entity recognition from clinical texts via recurrent neural network.		17	Entity recognition from clinical texts via recurrent neural network.
"With many thyroid nodules being incidentally detected, it is important to identify as many malignant nodules as possible while excluding those that are highly likely to be benign from fine needle aspiration (FNA) biopsies or surgeries. This paper presents a computer-aided diagnosis (CAD) system for classifying thyroid nodules in ultrasound images. We use deep learning approach to extract features from thyroid ultrasound images. Ultrasound images are pre-processed to calibrate their scale and remove the artifacts. A pre-trained GoogLeNet model is then fine-tuned using the pre-processed image samples which leads to superior feature extraction. The extracted features of the thyroid ultrasound images are sent to a Cost-sensitive Random Forest classifier to classify the images into ""malignant"" and ""benign"" cases. The experimental results show the proposed fine-tuned GoogLeNet model achieves excellent classification performance, attaining 98.29% classification accuracy, 99.10% sensitivity and 93.90% specificity for the images in an open access database (Pedraza et al. 16), while 96.34% classification accuracy, 86% sensitivity and 99% specificity for the images in our local health region database."	['Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, SK, S7N 5C9, Canada. chi.jianning@gmail.com.', 'Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, SK, S7N 5C9, Canada.', 'Department of Medical Imaging, University of Saskatchewan, 103 Hospital Dr, Saskatoon, SK, S7N 0W8, Canada.', 'Department of Medical Imaging, University of Saskatchewan, 103 Hospital Dr, Saskatoon, SK, S7N 0W8, Canada.', 'Department of Surgery, Royal University Hospital, 103 Hospital Drive, Suite 2646, Saskatoon, SK, S7N 0W8, Canada.', 'Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, SK, S7N 5C9, Canada.']	['10.1007/s10278-017-9997-y [doi]', '10.1007/s10278-017-9997-y [pii]']	['Chi J', 'Walia E', 'Babyn P', 'Wang J', 'Groot G', 'Eramian M']							['2017/07/12 06:00']	20180404		2017 Aug	2017/07/12 06:00		['Chi, Jianning', 'Walia, Ekta', 'Babyn, Paul', 'Wang, Jimmy', 'Groot, Gary', 'Eramian, Mark']			4		1618-727X (Electronic) 0897-1889 (Linking)	9100529	Journal of digital imaging	['eng']	10.1007/s10278-017-9997-y [doi]	20181202	['Biopsy, Fine-Needle', 'Diagnosis, Computer-Assisted/*methods', 'Humans', '*Neural Networks (Computer)', 'Sensitivity and Specificity', 'Thyroid Gland/diagnostic imaging/pathology', 'Thyroid Nodule/*classification/*diagnostic imaging/pathology', 'Ultrasonography/methods']	2018/04/05 06:00		['Computer vision', 'Convolutional neural network', 'Deep learning', 'Fine-tuning', 'Machine learning', 'Thyroid nodules', 'Ultrasonography']	['NOTNLM']	NLM	477-486	['2017/07/12 06:00 [pubmed]', '2018/04/05 06:00 [medline]', '2017/07/12 06:00 [entrez]']	United States	PMC5537102		28695342	ppublish	['Journal Article']			IM		J Digit Imaging. 2017 Aug;30(4):477-486. doi: 10.1007/s10278-017-9997-y.	MEDLINE	J Digit Imaging	Thyroid Nodule Classification in Ultrasound Images by Fine-Tuning Deep Convolutional Neural Network.		30	Thyroid Nodule Classification in Ultrasound Images by Fine-Tuning Deep Convolutional Neural Network.
Multitask deep learning has emerged as a powerful tool for computational drug discovery. However, despite a number of preliminary studies, multitask deep networks have yet to be widely deployed in the pharmaceutical and biotech industries. This lack of acceptance stems from both software difficulties and lack of understanding of the robustness of multitask deep networks. Our work aims to resolve both of these barriers to adoption. We introduce a high-quality open-source implementation of multitask deep networks as part of the DeepChem open-source platform. Our implementation enables simple python scripts to construct, fit, and evaluate sophisticated deep models. We use our implementation to analyze the performance of multitask deep networks and related deep models on four collections of pharmaceutical data (three of which have not previously been analyzed in the literature). We split these data sets into train/valid/test using time and neighbor splits to test multitask deep learning performance under challenging conditions. Our results demonstrate that multitask deep networks are surprisingly robust and can offer strong improvement over random forests. Our analysis and open-source implementation in DeepChem provide an argument that multitask deep networks are ready for widespread use in commercial drug discovery.	['Department of Computer Science, Stanford University , Stanford, California 94305, United States.', 'Department of Chemistry, Stanford University , Stanford, California 94305, United States.', 'Department of Chemistry, Stanford University , Stanford, California 94305, United States.', 'Chemistry Capabilities and Screening, Merck & Co., Inc. , 2000 Galloping Hill Road, Kenilworth, New Jersey 07033, United States.', 'Chemistry Capabilities and Screening, Merck & Co., Inc. , 770 Sumneytown Pike, West Point, Pennsylvania 19846, United States.', 'Chemistry Capabilities and Screening, Merck & Co., Inc. , 2000 Galloping Hill Road, Kenilworth, New Jersey 07033, United States.', 'Department of Chemistry, Stanford University , Stanford, California 94305, United States.']	['10.1021/acs.jcim.7b00146 [doi]']	['Ramsundar B', 'Liu B', 'Wu Z', 'Verras A', 'Tudor M', 'Sheridan RP', 'Pande V']	['ORCID: 0000-0001-8450-4262', 'ORCID: 0000-0003-0609-3087', 'ORCID: 0000-0002-6549-1635']						['2017/07/11 06:00']	20171002	20170801	2017 Aug 28	2017/07/12 06:00		['Ramsundar, Bharath', 'Liu, Bowen', 'Wu, Zhenqin', 'Verras, Andreas', 'Tudor, Matthew', 'Sheridan, Robert P', 'Pande, Vijay']		['R01 GM062868/GM/NIGMS NIH HHS/United States', 'U19 AI109662/AI/NIAID NIH HHS/United States']	8		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.7b00146 [doi]	20180227	['Absorption, Radiation', 'Drug Discovery/*methods', 'Inhibitory Concentration 50', '*Machine Learning', 'Protein Kinase Inhibitors/chemistry/pharmacology', 'Serine Proteinase Inhibitors/chemistry/pharmacology', 'Software', 'Ultraviolet Rays']	2017/10/03 06:00				NLM	2068-2076	['2017/07/12 06:00 [pubmed]', '2017/10/03 06:00 [medline]', '2017/07/11 06:00 [entrez]']	United States			28692267	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Research Support, N.I.H., Extramural']"		['0 (Protein Kinase Inhibitors)', '0 (Serine Proteinase Inhibitors)']	IM		J Chem Inf Model. 2017 Aug 28;57(8):2068-2076. doi: 10.1021/acs.jcim.7b00146. Epub 2017 Aug 1.	MEDLINE	J Chem Inf Model	Is Multitask Deep Learning Practical for Pharma?		57	Is Multitask Deep Learning Practical for Pharma?
BACKGROUND: Visual inspection of cardiotocography traces by obstetricians and midwives is the gold standard for monitoring the wellbeing of the foetus during antenatal care. However, inter- and intra-observer variability is high with only a 30% positive predictive value for the classification of pathological outcomes. This has a significant negative impact on the perinatal foetus and often results in cardio-pulmonary arrest, brain and vital organ damage, cerebral palsy, hearing, visual and cognitive defects and in severe cases, death. This paper shows that using machine learning and foetal heart rate signals provides direct information about the foetal state and helps to filter the subjective opinions of medical practitioners when used as a decision support tool. The primary aim is to provide a proof-of-concept that demonstrates how machine learning can be used to objectively determine when medical intervention, such as caesarean section, is required and help avoid preventable perinatal deaths. METHODS: This is evidenced using an open dataset that comprises 506 controls (normal virginal deliveries) and 46 cases (caesarean due to pH </= 7.20-acidosis, n = 18; pH > 7.20 and pH < 7.25-foetal deterioration, n = 4; or clinical decision without evidence of pathological outcome measures, n = 24). Several machine-learning algorithms are trained, and validated, using binary classifier performance measures. RESULTS: The findings show that deep learning classification achieves sensitivity = 94%, specificity = 91%, Area under the curve = 99%, F-score = 100%, and mean square error = 1%. CONCLUSIONS: The results demonstrate that machine learning significantly improves the efficiency for the detection of caesarean section and normal vaginal deliveries using foetal heart rate signals compared with obstetrician and midwife predictions and systems reported in previous studies.	['Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Liverpool John Moors University, Byron Street, Liverpool, L3 3AF, UK. p.fergus@ljmu.ac.uk.', 'Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Liverpool John Moors University, Byron Street, Liverpool, L3 3AF, UK.', 'Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Liverpool John Moors University, Byron Street, Liverpool, L3 3AF, UK.', 'Institute of Machine Learning and Systems Biology, Tongji University, No. 4800 Caoan Road, Shanghai, 201804, China.', 'Concordia Institute for Information Systems Engineering, Concorida University, 1455 de Maisonneuve Blvd West, EV7.632, Montreal, QC, HJ3G 2W1, Canada.']	['10.1186/s12938-017-0378-z [doi]', '10.1186/s12938-017-0378-z [pii]']	['Fergus P', 'Hussain A', 'Al-Jumeily D', 'Huang DS', 'Bouguila N']	['ORCID: http://orcid.org/0000-0002-7070-4447']						['2017/07/07 06:00']	20180320	20170706	2017 Jul 6	2017/07/07 06:00		['Fergus, Paul', 'Hussain, Abir', 'Al-Jumeily, Dhiya', 'Huang, De-Shuang', 'Bouguila, Nizar']			1		1475-925X (Electronic) 1475-925X (Linking)	101147518	Biomedical engineering online	['eng']	10.1186/s12938-017-0378-z [doi]	20181113	['Adult', '*Cardiotocography', 'Cesarean Section/*classification', 'Contraceptive Devices, Female/*classification', 'Discriminant Analysis', 'Female', '*Heart Rate, Fetal', 'Humans', '*Machine Learning', 'Nonlinear Dynamics', 'Pregnancy', '*Signal Processing, Computer-Assisted', 'Young Adult']	2018/03/21 06:00		['Classification', 'Deep learning', 'Feature extraction and selection', 'Intrapartum cardiotocography', 'Machine learning', 'Random forest']	['NOTNLM']	NLM	89	['2017/02/11 00:00 [received]', '2017/06/26 00:00 [accepted]', '2017/07/07 06:00 [entrez]', '2017/07/07 06:00 [pubmed]', '2018/03/21 06:00 [medline]']	England	PMC5498914		28679415	epublish	['Journal Article']			IM		Biomed Eng Online. 2017 Jul 6;16(1):89. doi: 10.1186/s12938-017-0378-z.	MEDLINE	Biomed Eng Online	Classification of caesarean section and normal vaginal deliveries using foetal heart rate signals and advanced machine learning algorithms.		16	Classification of caesarean section and normal vaginal deliveries using foetal heart rate signals and advanced machine learning algorithms.
Speech separation can be formulated as learning to estimate a time-frequency mask from acoustic features extracted from noisy speech. For supervised speech separation, generalization to unseen noises and unseen speakers is a critical issue. Although deep neural networks (DNNs) have been successful in noise-independent speech separation, DNNs are limited in modeling a large number of speakers. To improve speaker generalization, a separation model based on long short-term memory (LSTM) is proposed, which naturally accounts for temporal dynamics of speech. Systematic evaluation shows that the proposed model substantially outperforms a DNN-based model on unseen speakers and unseen noises in terms of objective speech intelligibility. Analyzing LSTM internal representations reveals that LSTM captures long-term speech contexts. It is also found that the LSTM model is more advantageous for low-latency speech separation and it, without future frames, performs better than the DNN model with future frames. The proposed model represents an effective approach for speaker- and noise-independent speech separation.	['Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio 43210, USA.']	['10.1121/1.4986931 [doi]']	['Chen J', 'Wang D']							['2017/07/07 06:00']	20190709		2017 Jun	2017/07/07 06:00		['Chen, Jitong', 'Wang, DeLiang']		['R01 DC012048/DC/NIDCD NIH HHS/United States']	6		1520-8524 (Electronic) 0001-4966 (Linking)	7503051	The Journal of the Acoustical Society of America	['eng']	10.1121/1.4986931 [doi]	20190709	['*Acoustics', 'Deep Learning', 'Female', 'Humans', 'Male', '*Memory, Short-Term', 'Noise/*adverse effects', '*Perceptual Masking', 'Signal Processing, Computer-Assisted', 'Sound Spectrography', '*Speech Acoustics', 'Speech Intelligibility', '*Speech Perception', 'Speech Production Measurement/*methods', 'Time Factors', '*Voice Quality']	2019/07/10 06:00				NLM	4705	['2017/07/07 06:00 [entrez]', '2017/07/07 06:00 [pubmed]', '2019/07/10 06:00 [medline]']	United States	PMC5482750		28679261	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		J Acoust Soc Am. 2017 Jun;141(6):4705. doi: 10.1121/1.4986931.	MEDLINE	J Acoust Soc Am	Long short-term memory for speaker generalization in supervised speech separation.		141	Long short-term memory for speaker generalization in supervised speech separation.
Northern leaf blight (NLB) can cause severe yield loss in maize; however, scouting large areas to accurately diagnose the disease is time consuming and difficult. We demonstrate a system capable of automatically identifying NLB lesions in field-acquired images of maize plants with high reliability. This approach uses a computational pipeline of convolutional neural networks (CNNs) that addresses the challenges of limited data and the myriad irregularities that appear in images of field-grown plants. Several CNNs were trained to classify small regions of images as containing NLB lesions or not; their predictions were combined into separate heat maps, then fed into a final CNN trained to classify the entire image as containing diseased plants or not. The system achieved 96.7% accuracy on test set images not used in training. We suggest that such systems mounted on aerial- or ground-based vehicles can help in automated high-throughput plant phenotyping, precision breeding for disease resistance, and reduced pesticide use through targeted application across a variety of plant and disease categories.	['First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.', 'First author: Department of Computer Science, Columbia University in the City of New York, 10027; second, fourth, and sixth authors: Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, NY 14853; third author: Department of Mechanical Engineering, Columbia University; fifth author: Uber AI Labs, San Francisco 94103; seventh author: Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University; and eighth author: Department of Mechanical Engineering and Institute of Data Science, Columbia University.']	['10.1094/PHYTO-11-16-0417-R [doi]']	['DeChant C', 'Wiesner-Hanks T', 'Chen S', 'Stewart EL', 'Yosinski J', 'Gore MA', 'Nelson RJ', 'Lipson H']							['2017/06/28 06:00']	20171221	20170824	2017 Nov	2017/06/28 06:00		['DeChant, Chad', 'Wiesner-Hanks, Tyr', 'Chen, Siyuan', 'Stewart, Ethan L', 'Yosinski, Jason', 'Gore, Michael A', 'Nelson, Rebecca J', 'Lipson, Hod']			11		0031-949X (Print) 0031-949X (Linking)	9427222	Phytopathology	['eng']	10.1094/PHYTO-11-16-0417-R [doi]	20171221	['Ascomycota/classification/physiology', '*Automation', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', 'Plant Diseases/*microbiology', 'Plant Leaves/microbiology', 'Zea mays/*microbiology']	2017/12/22 06:00				NLM	1426-1432	['2017/06/28 06:00 [pubmed]', '2017/12/22 06:00 [medline]', '2017/06/28 06:00 [entrez]']	United States			28653579	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Phytopathology. 2017 Nov;107(11):1426-1432. doi: 10.1094/PHYTO-11-16-0417-R. Epub 2017 Aug 24.	MEDLINE	Phytopathology	Automated Identification of Northern Leaf Blight-Infected Maize Plants from Field Imagery Using Deep Learning.		107	Automated Identification of Northern Leaf Blight-Infected Maize Plants from Field Imagery Using Deep Learning.
The choice of kernel has an important effect on the performance of a support vector machine (SVM). The effect could be reduced by NEUROSVM, an architecture using multilayer perceptron for feature extraction and SVM for classification. In binary classification, a general linear kernel NEUROSVM can be theoretically simplified as an input layer, many hidden layers, and an SVM output layer. As a feature extractor, the sub-network composed of the input and hidden layers is first trained together with a virtual ordinary output layer by backpropagation, then with the output of its last hidden layer taken as input of the SVM classifier for further training separately. By taking the sub-network as a kernel mapping from the original input space into a feature space, we present a novel model, called deep neural mapping support vector machine (DNMSVM), from the viewpoint of deep learning. This model is also a new and general kernel learning method, where the kernel mapping is indeed an explicit function expressed as a sub-network, different from an implicit function induced by a kernel function traditionally. Moreover, we exploit a two-stage procedure of contrastive divergence learning and gradient descent for DNMSVM to jointly training an adaptive kernel mapping instead of a kernel function, without requirement of kernel tricks. As a whole of the sub-network and the SVM classifier, the joint training of DNMSVM is done by using gradient descent to optimize the objective function with the sub-network layer-wise pre-trained via contrastive divergence learning of restricted Boltzmann machines. Compared to the separate training of NEUROSVM, the joint training is a new algorithm for DNMSVM to have advantages over NEUROSVM. Experimental results show that DNMSVM can outperform NEUROSVM and RBFSVM (i.e., SVM with the kernel of radial basis function), demonstrating its effectiveness.	['College of Computer Science, Beijing University of Technology, Beijing 100124, China. Electronic address: liyujian@bjut.edu.cn.', 'College of Computer Science, Beijing University of Technology, Beijing 100124, China. Electronic address: zhangting08@emails.bjut.edu.cn.']	['S0893-6080(17)30122-3 [pii]', '10.1016/j.neunet.2017.05.010 [doi]']	['Li Y', 'Zhang T']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/06/25 06:00']	20180326	20170621	2017 Sep	2017/06/25 06:00		['Li, Yujian', 'Zhang, Ting']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30122-3 [pii] 10.1016/j.neunet.2017.05.010 [doi]	20181202	['Humans', '*Neural Networks (Computer)', '*Support Vector Machine']	2018/03/27 06:00		['Deep learning', 'Kernel choice', 'Kernel function', 'Kernel mapping', 'Neural network', 'Support vector machine']	['NOTNLM']	NLM	185-194	['2016/10/01 00:00 [received]', '2017/02/26 00:00 [revised]', '2017/05/24 00:00 [accepted]', '2017/06/25 06:00 [pubmed]', '2018/03/27 06:00 [medline]', '2017/06/25 06:00 [entrez]']	United States			28646763	ppublish	['Journal Article']			IM		Neural Netw. 2017 Sep;93:185-194. doi: 10.1016/j.neunet.2017.05.010. Epub 2017 Jun 21.	MEDLINE	Neural Netw	Deep neural mapping support vector machines.		93	Deep neural mapping support vector machines.
Automated breast cancer multi-classification from histopathological images plays a key role in computer-aided breast cancer diagnosis or prognosis. Breast cancer multi-classification is to identify subordinate classes of breast cancer (Ductal carcinoma, Fibroadenoma, Lobular carcinoma, etc.). However, breast cancer multi-classification from histopathological images faces two main challenges from: (1) the great difficulties in breast cancer multi-classification methods contrasting with the classification of binary classes (benign and malignant), and (2) the subtle differences in multiple classes due to the broad variability of high-resolution image appearances, high coherency of cancerous cells, and extensive inhomogeneity of color distribution. Therefore, automated breast cancer multi-classification from histopathological images is of great clinical significance yet has never been explored. Existing works in literature only focus on the binary classification but do not support further breast cancer quantitative assessment. In this study, we propose a breast cancer multi-classification method using a newly proposed deep learning model. The structured deep learning model has achieved remarkable performance (average 93.2% accuracy) on a large-scale dataset, which demonstrates the strength of our method in providing an efficient tool for breast cancer multi-classification in clinical settings.	['College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China.', 'College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China. wbz99@sina.com.', 'Institute of evidence based Traditional Chinese Medicine, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China. wbz99@sina.com.', 'School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China.', 'School of Computer Science and Technology, Shandong University, Jinan, 250100, China.', 'Institute of evidence based Traditional Chinese Medicine, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China.', 'Department of Medical Imaging, Western University, London, N6A 4V2, Canada.']	['10.1038/s41598-017-04075-z [doi]', '10.1038/s41598-017-04075-z [pii]']	['Han Z', 'Wei B', 'Zheng Y', 'Yin Y', 'Li K', 'Li S']							['2017/06/25 06:00']	20190107	20170623	2017 Jun 23	2017/06/25 06:00		['Han, Zhongyi', 'Wei, Benzheng', 'Zheng, Yuanjie', 'Yin, Yilong', 'Li, Kejian', 'Li, Shuo']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-04075-z [doi]	20190107	['Breast Neoplasms/*classification/*pathology', 'Databases as Topic', '*Deep Learning', 'Female', 'Humans', '*Models, Theoretical', 'Neural Networks (Computer)']	2019/01/08 06:00				NLM	4172	['2017/02/01 00:00 [received]', '2017/05/09 00:00 [accepted]', '2017/06/25 06:00 [entrez]', '2017/06/25 06:00 [pubmed]', '2019/01/08 06:00 [medline]']	England	PMC5482871		28646155	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2017 Jun 23;7(1):4172. doi: 10.1038/s41598-017-04075-z.	MEDLINE	Sci Rep	Breast Cancer Multi-classification from Histopathological Images with Structured Deep Learning Model.		7	Breast Cancer Multi-classification from Histopathological Images with Structured Deep Learning Model.
Individuals with hearing impairment have particular difficulty perceptually segregating concurrent voices and understanding a talker in the presence of a competing voice. In contrast, individuals with normal hearing perform this task quite well. This listening situation represents a very different problem for both the human and machine listener, when compared to perceiving speech in other types of background noise. A machine learning algorithm is introduced here to address this listening situation. A deep neural network was trained to estimate the ideal ratio mask for a male target talker in the presence of a female competing talker. The monaural algorithm was found to produce sentence-intelligibility increases for hearing-impaired (HI) and normal-hearing (NH) listeners at various signal-to-noise ratios (SNRs). This benefit was largest for the HI listeners and averaged 59%-points at the least-favorable SNR, with a maximum of 87%-points. The mean intelligibility achieved by the HI listeners using the algorithm was equivalent to that of young NH listeners without processing, under conditions of identical interference. Possible reasons for the limited ability of HI listeners to perceptually segregate concurrent voices are reviewed as are possible implementation considerations for algorithms like the current one.	['Department of Speech and Hearing Science, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Speech and Hearing Science, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Speech and Hearing Science, The Ohio State University, Columbus, Ohio 43210, USA.', 'Department of Computer Science and Engineering, The Ohio State University, Columbus, Ohio 43210, USA.']	['10.1121/1.4984271 [doi]']	['Healy EW', 'Delfarah M', 'Vasko JL', 'Carter BL', 'Wang D']							['2017/06/17 06:00']	20190709		2017 Jun	2017/06/18 06:00		['Healy, Eric W', 'Delfarah, Masood', 'Vasko, Jordan L', 'Carter, Brittney L', 'Wang, DeLiang']		['R01 DC012048/DC/NIDCD NIH HHS/United States', 'R01 DC015521/DC/NIDCD NIH HHS/United States']	6		1520-8524 (Electronic) 0001-4966 (Linking)	7503051	The Journal of the Acoustical Society of America	['eng']	10.1121/1.4984271 [doi]	20190709	['Acoustic Stimulation', 'Aged', 'Audiometry, Speech', 'Auditory Threshold', 'Comprehension', 'Correction of Hearing Impairment/*instrumentation', '*Deep Learning', 'Female', 'Hearing', '*Hearing Aids', 'Hearing Loss, Sensorineural/diagnosis/physiopathology/psychology/*rehabilitation', 'Humans', 'Male', 'Middle Aged', '*Perceptual Masking', 'Persons With Hearing Impairments/psychology/*rehabilitation', '*Signal Processing, Computer-Assisted', 'Signal-To-Noise Ratio', '*Speech Intelligibility', '*Speech Perception', 'Young Adult']	2019/07/10 06:00				NLM	4230	['2017/06/17 06:00 [entrez]', '2017/06/18 06:00 [pubmed]', '2019/07/10 06:00 [medline]']	United States	PMC5464956		28618817	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		J Acoust Soc Am. 2017 Jun;141(6):4230. doi: 10.1121/1.4984271.	MEDLINE	J Acoust Soc Am	An algorithm to increase intelligibility for hearing-impaired listeners in the presence of a competing talker.		141	An algorithm to increase intelligibility for hearing-impaired listeners in the presence of a competing talker.
Plant image identification has become an interdisciplinary focus in both botanical taxonomy and computer vision. The first plant image dataset collected by mobile phone in natural scene is presented, which contains 10,000 images of 100 ornamental plant species in Beijing Forestry University campus. A 26-layer deep learning model consisting of 8 residual building blocks is designed for large-scale plant classification in natural environment. The proposed model achieves a recognition rate of 91.78% on the BJFU100 dataset, demonstrating that deep learning is a promising technology for smart forestry.	['School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.', 'School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.', 'School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.', 'School of Information Science and Technology, Beijing Forestry University, Beijing 100083, China.']	['10.1155/2017/7361042 [doi]']	['Sun Y', 'Liu Y', 'Wang G', 'Zhang H']	['ORCID: 0000-0003-3206-9515', 'ORCID: 0000-0002-8629-2838']						['2017/06/15 06:00']	20180319	20170522	2017	2017/06/15 06:00		['Sun, Yu', 'Liu, Yuan', 'Wang, Guan', 'Zhang, Haiyan']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2017/7361042 [doi]	20181202	['Cell Phone', 'China', 'Classification/*methods', 'Datasets as Topic', '*Environment', 'Forestry/methods', '*Machine Learning', 'Photography', 'Plants/*classification', 'Universities']	2018/03/20 06:00				NLM	7361042	['2017/03/02 00:00 [received]', '2017/04/18 00:00 [accepted]', '2017/06/15 06:00 [entrez]', '2017/06/15 06:00 [pubmed]', '2018/03/20 06:00 [medline]']	United States	PMC5458433		28611840	ppublish	['Journal Article']			IM		Comput Intell Neurosci. 2017;2017:7361042. doi: 10.1155/2017/7361042. Epub 2017 May 22.	MEDLINE	Comput Intell Neurosci	Deep Learning for Plant Identification in Natural Environment.		2017	Deep Learning for Plant Identification in Natural Environment.
Recently, online health expert question-answering (HQA) services (systems) have attracted more and more health consumers to ask health-related questions everywhere at any time due to the convenience and effectiveness. However, the quality of answers in existing HQA systems varies in different situations. It is significant to provide effective tools to automatically determine the quality of the answers. Two main characteristics in HQA systems raise the difficulties of classification: (1) physicians' answers in an HQA system are usually written in short text, which yields the data sparsity issue; (2) HQA systems apply the quality control mechanism, which refrains the wisdom of crowd. The important information, such as the best answer and the number of users' votes, is missing. To tackle these issues, we prepare the first HQA research data set labeled by three medical experts in 90days and formulate the problem of predicting the quality of answers in the system as a classification task. We not only incorporate the standard textual feature of answers, but also introduce a set of unique non-textual features, i.e., the popular used surface linguistic features and the novel social features, from other modalities. A multimodal deep belief network (DBN)-based learning framework is then proposed to learn the high-level hidden semantic representations of answers from both textual features and non-textual features while the learned joint representation is fed into popular classifiers to determine the quality of answers. Finally, we conduct extensive experiments to demonstrate the effectiveness of including the non-textual features and the proposed multimodal deep learning framework.	['School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China.', 'Department of Computing, Hang Seng Management College, Hong Kong.', 'Research Center on Satellite Technology, Harbin Institute of Technology, Harbin 150001, China.', 'School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China. Electronic address: zuodc_hit@163.com.']	['S1532-0464(17)30135-1 [pii]', '10.1016/j.jbi.2017.06.012 [doi]']	['Hu Z', 'Zhang Z', 'Yang H', 'Chen Q', 'Zuo D']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/06/14 06:00']	20180116	20170609	2017 Jul	2017/06/14 06:00		['Hu, Ze', 'Zhang, Zhan', 'Yang, Haiqin', 'Chen, Qing', 'Zuo, Decheng']					1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(17)30135-1 [pii] 10.1016/j.jbi.2017.06.012 [doi]	20181202	['*Consumer Health Information', 'Delivery of Health Care', 'Humans', '*Machine Learning', 'Quality Control', '*Semantics']	2018/01/18 06:00		['*Deep belief network', '*Deep learning', '*Multimodal learning', '*Online health expert question-answering services', '*Social features', '*Surface linguistic features']	['NOTNLM']	NLM	241-253	['2016/12/10 00:00 [received]', '2017/05/10 00:00 [revised]', '2017/06/07 00:00 [accepted]', '2017/06/14 06:00 [pubmed]', '2018/01/18 06:00 [medline]', '2017/06/14 06:00 [entrez]']	United States			28606870	ppublish	['Journal Article']			IM		J Biomed Inform. 2017 Jul;71:241-253. doi: 10.1016/j.jbi.2017.06.012. Epub 2017 Jun 9.	MEDLINE	J Biomed Inform	A deep learning approach for predicting the quality of online health expert question-answering services.		71	A deep learning approach for predicting the quality of online health expert question-answering services.
BACKGROUND: Applications of natural language processing to mental health notes are not common given the sensitive nature of the associated narratives. The CEGS N-GRID 2016 Shared Task in Clinical Natural Language Processing (NLP) changed this scenario by providing the first set of neuropsychiatric notes to participants. This study summarizes our efforts and results in proposing a novel data use case for this dataset as part of the third track in this shared task. OBJECTIVE: We explore the feasibility and effectiveness of predicting a set of common mental conditions a patient has based on the short textual description of patient's history of present illness typically occurring in the beginning of a psychiatric initial evaluation note. MATERIALS AND METHODS: We clean and process the 1000 records made available through the N-GRID clinical NLP task into a key-value dictionary and build a dataset of 986 examples for which there is a narrative for history of present illness as well as Yes/No responses with regards to presence of specific mental conditions. We propose two independent deep neural network models: one based on convolutional neural networks (CNN) and another based on recurrent neural networks with hierarchical attention (ReHAN), the latter of which allows for interpretation of model decisions. We conduct experiments to compare these methods to each other and to baselines based on linear models and named entity recognition (NER). RESULTS: Our CNN model with optimized thresholding of output probability estimates achieves best overall mean micro-F score of 63.144% for 11 common mental conditions with statistically significant gains (p<0.05) over all other models. The ReHAN model with interpretable attention mechanism scored 61.904% mean micro-F1 score. Both models' improvements over baseline models (support vector machines and NER) are statistically significant. The ReHAN model additionally aids in interpretation of the results by surfacing important words and sentences that lead to a particular prediction for each instance. CONCLUSIONS: Although the history of present illness is a short text segment averaging 300 words, it is a good predictor for a few conditions such as anxiety, depression, panic disorder, and attention deficit hyperactivity disorder. Proposed CNN and RNN models outperform baseline approaches and complement each other when evaluating on a per-label basis.	['Department of Computer Science, University of Kentucky, 329 Rose Street, Lexington, KY 40506, USA. Electronic address: tung.tran@uky.edu.', 'Department of Computer Science, University of Kentucky, 329 Rose Street, Lexington, KY 40506, USA; Division of Biomedical Informatics, Department of Internal Medicine, University Kentucky, 725 Rose Street, Lexington, KY 40536, USA. Electronic address: ramakanth.kavuluru@uky.edu.']	['S1532-0464(17)30133-8 [pii]', '10.1016/j.jbi.2017.06.010 [doi]']	['Tran T', 'Kavuluru R']		['Copyright (c) 2017. Published by Elsevier Inc.']					['2017/06/14 06:00']	20180720	20170610	2017 Nov	2017/06/14 06:00		['Tran, Tung', 'Kavuluru, Ramakanth']		['P50 MH106933/MH/NIMH NIH HHS/United States', 'R13 LM011411/LM/NLM NIH HHS/United States', 'R21 LM012274/LM/NLM NIH HHS/United States', 'UL1 TR001998/TR/NCATS NIH HHS/United States']			1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	S1532-0464(17)30133-8 [pii] 10.1016/j.jbi.2017.06.010 [doi]	20181113	['Humans', 'Machine Learning', 'Mental Disorders/*diagnosis', 'Natural Language Processing', '*Neural Networks (Computer)']	2018/07/22 06:00	['NIHMS891480']	['Convolutional and recurrent neural networks', 'Hierarchical attention networks', 'Multi-label text classification', 'Psychiatric condition prediction']	['NOTNLM']	NLM	S138-S148	['2017/02/01 00:00 [received]', '2017/06/05 00:00 [revised]', '2017/06/06 00:00 [accepted]', '2017/06/14 06:00 [pubmed]', '2018/07/22 06:00 [medline]', '2017/06/14 06:00 [entrez]']	United States	PMC5705423		28606869	ppublish	['Journal Article']			IM		J Biomed Inform. 2017 Nov;75S:S138-S148. doi: 10.1016/j.jbi.2017.06.010. Epub 2017 Jun 10.	MEDLINE	J Biomed Inform	"Predicting mental conditions based on ""history of present illness"" in psychiatric notes with deep neural networks."		75S	"Predicting mental conditions based on ""history of present illness"" in psychiatric notes with deep neural networks."
Drug-drug interaction (DDI), which is a specific type of adverse drug reaction, occurs when a drug influences the level or activity of another drug. Natural language processing techniques can provide health-care professionals with a novel way of reducing the time spent reviewing the literature for potential DDIs. The current state-of-the-art for the extraction of DDIs is based on feature-engineering algorithms (such as support vector machines), which usually require considerable time and effort. One possible alternative to these approaches includes deep learning. This technique aims to automatically learn the best feature representation from the input data for a given task. The purpose of this paper is to examine whether a convolutional neural network (CNN), which only uses word embeddings as input features, can be applied successfully to classify DDIs from biomedical texts. Proposed herein, is a CNN architecture with only one hidden layer, thus making the model more computationally efficient, and we perform detailed experiments in order to determine the best settings of the model. The goal is to determine the best parameter of this basic CNN that should be considered for future research. The experimental results show that the proposed approach is promising because it attained the second position in the 2013 rankings of the DDI extraction challenge. However, it obtained worse results than previous works using neural networks with more complex architectures.	['Department of Computer Science, University Carlos III of Madrid Leganes 28911, Madrid, Spain.', 'Department of Computer Science, University Carlos III of Madrid Leganes 28911, Madrid, Spain.', 'Department of Computer Science, University Carlos III of Madrid Leganes 28911, Madrid, Spain.']	['3854772 [pii]', '10.1093/database/bax019 [doi]']	['Suarez-Paniagua V', 'Segura-Bedmar I', 'Martinez P']		['(c) The Author(s) 2017. Published by Oxford University Press.']					['2017/06/13 06:00']	20171120		2017 Jan 1	2017/06/13 06:00		['Suarez-Paniagua, Victor', 'Segura-Bedmar, Isabel', 'Martinez, Paloma']					1758-0463 (Electronic) 1758-0463 (Linking)	101517697	Database : the journal of biological databases and curation	['eng']	10.1093/database/bax019 [doi]	20181202	['Data Mining/*methods', '*Drug Interactions', 'Electronic Data Processing/*methods', '*Models, Theoretical', '*Natural Language Processing', '*Neural Networks (Computer)', '*Support Vector Machine']	2017/11/29 06:00				NLM		['2016/11/02 00:00 [received]', '2017/02/16 00:00 [accepted]', '2017/06/13 06:00 [entrez]', '2017/06/13 06:00 [pubmed]', '2017/11/29 06:00 [medline]']	England	PMC5467573		28605776	ppublish	['Journal Article']			IM		Database (Oxford). 2017 Jan 1;2017. pii: 3854772. doi: 10.1093/database/bax019.	MEDLINE	Database (Oxford)	Exploring convolutional neural networks for drug-drug interaction extraction.		2017	Exploring convolutional neural networks for drug-drug interaction extraction.
Automated methods for prostate cancer (PCa) diagnosis in multi-parametric magnetic resonance imaging (MP-MRIs) are critical for alleviating requirements for interpretation of radiographs while helping to improve diagnostic accuracy (Artan et al 2010 IEEE Trans. Image Process. 19 2444-55, Litjens et al 2014 IEEE Trans. Med. Imaging 33 1083-92, Liu et al 2013 SPIE Medical Imaging (International Society for Optics and Photonics) p 86701G, Moradi et al 2012 J. Magn. Reson. Imaging 35 1403-13, Niaf et al 2014 IEEE Trans. Image Process. 23 979-91, Niaf et al 2012 Phys. Med. Biol. 57 3833, Peng et al 2013a SPIE Medical Imaging (International Society for Optics and Photonics) p 86701H, Peng et al 2013b Radiology 267 787-96, Wang et al 2014 BioMed. Res. Int. 2014). This paper presents an automated method based on multimodal convolutional neural networks (CNNs) for two PCa diagnostic tasks: (1) distinguishing between cancerous and noncancerous tissues and (2) distinguishing between clinically significant (CS) and indolent PCa. Specifically, our multimodal CNNs effectively fuse apparent diffusion coefficients (ADCs) and T2-weighted MP-MRI images (T2WIs). To effectively fuse ADCs and T2WIs we design a new similarity loss function to enforce consistent features being extracted from both ADCs and T2WIs. The similarity loss is combined with the conventional classification loss functions and integrated into the back-propagation procedure of CNN training. The similarity loss enables better fusion results than existing methods as the feature learning processes of both modalities are mutually guided, jointly facilitating CNN to 'see' the true visual patterns of PCa. The classification results of multimodal CNNs are further combined with the results based on handcrafted features using a support vector machine classifier. To achieve a satisfactory accuracy for clinical use, we comprehensively investigate three critical factors which could greatly affect the performance of our multimodal CNNs but have not been carefully studied previously. (1) Given limited training data, how can these be augmented in sufficient numbers and variety for fine-tuning deep CNN networks for PCa diagnosis? (2) How can multimodal MP-MRI information be effectively combined in CNNs? (3) What is the impact of different CNN architectures on the accuracy of PCa diagnosis? Experimental results on extensive clinical data from 364 patients with a total of 463 PCa lesions and 450 identified noncancerous image patches demonstrate that our system can achieve a sensitivity of 89.85% and a specificity of 95.83% for distinguishing cancer from noncancerous tissues and a sensitivity of 100% and a specificity of 76.92% for distinguishing indolent PCa from CS PCa. This result is significantly superior to the state-of-the-art method relying on handcrafted features.	"[""School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, People's Republic of China.""]"	['10.1088/1361-6560/aa7731 [doi]']	['Le MH', 'Chen J', 'Wang L', 'Wang Z', 'Liu W', 'Cheng KT', 'Yang X']							['2017/06/06 06:00']	20180220	20170724	2017 Jul 24	2017/06/06 06:00		['Le, Minh Hung', 'Chen, Jingyu', 'Wang, Liang', 'Wang, Zhiwei', 'Liu, Wenyu', 'Cheng, Kwang-Ting Tim', 'Yang, Xin']			16		1361-6560 (Electronic) 0031-9155 (Linking)	0401220	Physics in medicine and biology	['eng']	10.1088/1361-6560/aa7731 [doi]	20181202	['Aged', 'Aged, 80 and over', 'Algorithms', 'Automation', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Magnetic Resonance Imaging/*methods', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'Prostatic Hyperplasia/*diagnosis/diagnostic imaging', 'Prostatic Neoplasms/*diagnosis/diagnostic imaging', 'Support Vector Machine']	2018/02/21 06:00				NLM	6497-6514	['2017/06/06 06:00 [pubmed]', '2018/02/21 06:00 [medline]', '2017/06/06 06:00 [entrez]']	England			28582269	epublish	['Journal Article']			IM		Phys Med Biol. 2017 Jul 24;62(16):6497-6514. doi: 10.1088/1361-6560/aa7731.	MEDLINE	Phys Med Biol	Automated diagnosis of prostate cancer in multi-parametric MRI based on multimodal convolutional neural networks.		62	Automated diagnosis of prostate cancer in multi-parametric MRI based on multimodal convolutional neural networks.
Characterizing the binding behaviors of RNA-binding proteins (RBPs) is important for understanding their functional roles in gene expression regulation. However, current high-throughput experimental methods for identifying RBP targets, such as CLIP-seq and RNAcompete, usually suffer from the false negative issue. Here, we develop a deep boosting based machine learning approach, called DeBooster, to accurately model the binding sequence preferences and identify the corresponding binding targets of RBPs from CLIP-seq data. Comprehensive validation tests have shown that DeBooster can outperform other state-of-the-art approaches in RBP target prediction. In addition, we have demonstrated that DeBooster may provide new insights into understanding the regulatory functions of RBPs, including the binding effects of the RNA helicase MOV10 on mRNA degradation, the potentially different ADAR1 binding behaviors related to its editing activity, as well as the antagonizing effect of RBP binding on miRNA repression. Moreover, DeBooster may provide an effective index to investigate the effect of pathogenic mutations in RBP binding sites, especially those related to splicing events. We expect that DeBooster will be widely applied to analyze large-scale CLIP-seq experimental data and can provide a practically useful tool for novel biological discoveries in understanding the regulatory mechanisms of RBPs. The source code of DeBooster can be downloaded from http://github.com/dongfanghong/deepboost.	['School of Life Sciences, Tsinghua University, Beijing 100084, China.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing 100084, China.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing 100084, China.', 'Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA 15232, USA.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing 100084, China.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing 100084, China.', 'School of Life Sciences, Tsinghua University, Beijing 100084, China.', 'Department of Computer Science and Engineering, University of California, Riverside, CA 92521, USA.', 'MOE Key Lab of Bioinformatics and Bioinformatics Division, TNLIST/Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China.', 'Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing 100084, China.']	['3858203 [pii]', '10.1093/nar/gkx492 [doi]']	['Li S', 'Dong F', 'Wu Y', 'Zhang S', 'Zhang C', 'Liu X', 'Jiang T', 'Zeng J']		['(c) The Author(s) 2017. Published by Oxford University Press on behalf of Nucleic', 'Acids Research.']					['2017/06/03 06:00']	20171023		2017 Aug 21	2017/06/03 06:00		['Li, Shuya', 'Dong, Fanghong', 'Wu, Yuexin', 'Zhang, Sai', 'Zhang, Chen', 'Liu, Xiao', 'Jiang, Tao', 'Zeng, Jianyang']			14		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gkx492 [doi]	20181113	"[""3' Untranslated Regions/genetics"", 'Algorithms', 'Base Sequence', 'Binding Sites/genetics', 'Binding, Competitive', 'Computational Biology/*methods', 'Gene Expression Regulation', 'High-Throughput Nucleotide Sequencing/*methods/statistics & numerical data', 'Humans', 'Internet', '*Machine Learning', 'Mutation', 'Nucleotide Motifs/genetics', 'Protein Binding', 'RNA-Binding Proteins/*genetics/metabolism', 'Reproducibility of Results']"	2017/10/24 06:00				NLM	e129	['2016/12/19 00:00 [received]', '2017/05/23 00:00 [accepted]', '2017/06/03 06:00 [pubmed]', '2017/10/24 06:00 [medline]', '2017/06/03 06:00 [entrez]']	England	PMC5737578		28575488	ppublish	['Journal Article']		"[""0 (3' Untranslated Regions)"", '0 (RNA-Binding Proteins)']"	IM		Nucleic Acids Res. 2017 Aug 21;45(14):e129. doi: 10.1093/nar/gkx492.	MEDLINE	Nucleic Acids Res	A deep boosting based approach for capturing the sequence binding preferences of RNA-binding proteins from high-throughput CLIP-seq data.		45	A deep boosting based approach for capturing the sequence binding preferences of RNA-binding proteins from high-throughput CLIP-seq data.
Artificial intelligence (AI) is a field of computer science that aims to mimic human thought processes, learning capacity, and knowledge storage. AI techniques have been applied in cardiovascular medicine to explore novel genotypes and phenotypes in existing diseases, improve the quality of patient care, enable cost-effectiveness, and reduce readmission and mortality rates. Over the past decade, several machine-learning techniques have been used for cardiovascular disease diagnosis and prediction. Each problem requires some degree of understanding of the problem, in terms of cardiovascular medicine and statistics, to apply the optimal machine-learning algorithm. In the near future, AI will result in a paradigm shift toward precision cardiovascular medicine. The potential of AI in cardiovascular medicine is tremendous; however, ignorance of the challenges may overshadow its potential clinical impact. This paper gives a glimpse of AI's application in cardiovascular clinical care and discusses its potential role in facilitating precision cardiovascular medicine.	"[""Department of Internal Medicine, Icahn School of Medicine at Mount Sinai St. Luke's and Mount Sinai West, New York, New York; Department of Cardiovascular Medicine, Heart and Vascular Institute, Cleveland Clinic, Cleveland, Ohio. Electronic address: Chayakrit.Krittanawong@Mountsinai.org."", 'Division of Cardiovascular Disease, Department of Medicine, Mayo Clinic, Rochester, Minnesota.', 'Robert D. and Patricia E. Kern Center for the Science of Health Care Delivery, Mayo Clinic, Rochester, Minnesota; Division of Health Care Policy and Research, Department of Health Sciences Research, Mayo Clinic, Rochester, Minnesota.', 'Department of Cardiovascular Medicine, Heart and Vascular Institute, Cleveland Clinic, Cleveland, Ohio; Department of Computer Science at Kent State University, Kent, Ohio.', 'Department of Cardiovascular Medicine, Heart and Vascular Institute, Cleveland Clinic, Cleveland, Ohio; Department of Cardiovascular Medicine, Kobe City Medical Center General Hospital, Kobe, Japan.']"	['S0735-1097(17)36845-6 [pii]', '10.1016/j.jacc.2017.03.571 [doi]']	['Krittanawong C', 'Zhang H', 'Wang Z', 'Aydar M', 'Kitai T']		['Copyright (c) 2017 American College of Cardiology Foundation. Published by', 'Elsevier Inc. All rights reserved.']					['2017/05/27 06:00']	20170809		2017 May 30	2017/05/27 06:00		['Krittanawong, Chayakrit', 'Zhang, HongJu', 'Wang, Zhen', 'Aydar, Mehmet', 'Kitai, Takeshi']			21		1558-3597 (Electronic) 0735-1097 (Linking)	8301365	Journal of the American College of Cardiology	['eng']	S0735-1097(17)36845-6 [pii] 10.1016/j.jacc.2017.03.571 [doi]	20170809	['Algorithms', '*Artificial Intelligence', 'Cardiology/*methods', 'Humans', 'Machine Learning', 'Precision Medicine/*methods']	2017/08/10 06:00		['big data', 'cognitive computing', 'deep learning', 'machine learning']	['NOTNLM']	NLM	2657-2664	['2017/03/12 00:00 [received]', '2017/03/22 00:00 [accepted]', '2017/05/27 06:00 [entrez]', '2017/05/27 06:00 [pubmed]', '2017/08/10 06:00 [medline]']	United States			28545640	ppublish	['Journal Article', 'Review']			AIM IM		J Am Coll Cardiol. 2017 May 30;69(21):2657-2664. doi: 10.1016/j.jacc.2017.03.571.	MEDLINE	J Am Coll Cardiol	Artificial Intelligence in Precision Cardiovascular Medicine.		69	Artificial Intelligence in Precision Cardiovascular Medicine.
In the past decade diabetes management has been transformed by the addition of continuous glucose monitoring and insulin pump data. More recently, a wide variety of functions and physiologic variables, such as heart rate, hours of sleep, number of steps walked and movement, have been available through wristbands or watches. New data, hydration, geolocation, and barometric pressure, among others, will be incorporated in the future. All these parameters, when analyzed, can be helpful for patients and doctors' decision support. Similar new scenarios have appeared in most medical fields, in such a way that in recent years, there has been an increased interest in the development and application of the methods of artificial intelligence (AI) to decision support and knowledge acquisition. Multidisciplinary research teams integrated by computer engineers and doctors are more and more frequent, mirroring the need of cooperation in this new topic. AI, as a science, can be defined as the ability to make computers do things that would require intelligence if done by humans. Increasingly, diabetes-related journals have been incorporating publications focused on AI tools applied to diabetes. In summary, diabetes management scenarios have suffered a deep transformation that forces diabetologists to incorporate skills from new areas. This recently needed knowledge includes AI tools, which have become part of the diabetes health care. The aim of this article is to explain in an easy and plane way the most used AI methodologies to promote the implication of health care providers-doctors and nurses-in this field.	['1 Endocrinology and Nutrition Department, Parc Tauli University Hospital, Sabadell, Spain.', '2 Bioengineering and Telemedicine Centre, Universidad Politecnica de Madrid, Spain.', '3 CIBER-BBN: Networking Research Centre for Bioengineering, Biomaterials and Nanomedicine, Madrid, Spain.', '1 Endocrinology and Nutrition Department, Parc Tauli University Hospital, Sabadell, Spain.', '2 Bioengineering and Telemedicine Centre, Universidad Politecnica de Madrid, Spain.', '3 CIBER-BBN: Networking Research Centre for Bioengineering, Biomaterials and Nanomedicine, Madrid, Spain.']	['10.1177/1932296817710475 [doi]']	['Rigla M', 'Garcia-Saez G', 'Pons B', 'Hernando ME']							['2017/05/26 06:00']	20190610	20170525	2018 Mar	2017/05/26 06:00		['Rigla, Mercedes', 'Garcia-Saez, Gema', 'Pons, Belen', 'Hernando, Maria Elena']			2		1932-2968 (Electronic) 1932-2968 (Linking)	101306166	Journal of diabetes science and technology	['eng']	10.1177/1932296817710475 [doi]	20190613	['*Artificial Intelligence', '*Decision Support Systems, Clinical', '*Diabetes Mellitus', 'Humans', '*Machine Learning']	2019/06/14 06:00		['*artificial intelligence', '*decision support', '*diabetes', '*machine learning']	['NOTNLM']	NLM	303-310	['2017/05/26 06:00 [pubmed]', '2019/06/14 06:00 [medline]', '2017/05/26 06:00 [entrez]']	United States	PMC5851211		28539087	ppublish	['Journal Article']			IM		J Diabetes Sci Technol. 2018 Mar;12(2):303-310. doi: 10.1177/1932296817710475. Epub 2017 May 25.	MEDLINE	J Diabetes Sci Technol	Artificial Intelligence Methodologies and Their Application to Diabetes.		12	Artificial Intelligence Methodologies and Their Application to Diabetes.
While deep convolutional neural networks (CNNs) have achieved remarkable success in 2D medical image segmentation, it is still a difficult task for CNNs to segment important organs or structures from 3D medical images owing to several mutually affected challenges, including the complicated anatomical environments in volumetric images, optimization difficulties of 3D networks and inadequacy of training samples. In this paper, we present a novel and efficient 3D fully convolutional network equipped with a 3D deep supervision mechanism to comprehensively address these challenges; we call it 3D DSN. Our proposed 3D DSN is capable of conducting volume-to-volume learning and inference, which can eliminate redundant computations and alleviate the risk of over-fitting on limited training data. More importantly, the 3D deep supervision mechanism can effectively cope with the optimization problem of gradients vanishing or exploding when training a 3D deep model, accelerating the convergence speed and simultaneously improving the discrimination capability. Such a mechanism is developed by deriving an objective function that directly guides the training of both lower and upper layers in the network, so that the adverse effects of unstable gradient changes can be counteracted during the training procedure. We also employ a fully connected conditional random field model as a post-processing step to refine the segmentation results. We have extensively validated the proposed 3D DSN on two typical yet challenging volumetric medical image segmentation tasks: (i) liver segmentation from 3D CT scans and (ii) whole heart and great vessels segmentation from 3D MR images, by participating two grand challenges held in conjunction with MICCAI. We have achieved competitive segmentation results to state-of-the-art approaches in both challenges with a much faster speed, corroborating the effectiveness of our proposed 3D DSN.	['Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong, China. Electronic address: harry.qin@polyu.edu.hk.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.']	['S1361-8415(17)30072-5 [pii]', '10.1016/j.media.2017.05.001 [doi]']	['Dou Q', 'Yu L', 'Chen H', 'Jin Y', 'Yang X', 'Qin J', 'Heng PA']		['Copyright (c) 2017 Elsevier B.V. All rights reserved.']					['2017/05/21 06:00']	20180501	20170508	2017 Oct	2017/05/21 06:00		['Dou, Qi', 'Yu, Lequan', 'Chen, Hao', 'Jin, Yueming', 'Yang, Xin', 'Qin, Jing', 'Heng, Pheng-Ann']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(17)30072-5 [pii] 10.1016/j.media.2017.05.001 [doi]	20181202	['Humans', 'Imaging, Three-Dimensional/*methods', '*Neural Networks (Computer)', 'Reproducibility of Results', 'Sensitivity and Specificity', 'Supervised Machine Learning']	2018/05/02 06:00		['3D deeply supervised networks', '3D fully convolutional networks', 'Deep learning', 'Volumetric medical image segmentation']	['NOTNLM']	NLM	40-54	['2017/01/26 00:00 [received]', '2017/04/14 00:00 [revised]', '2017/05/01 00:00 [accepted]', '2017/05/21 06:00 [pubmed]', '2018/05/02 06:00 [medline]', '2017/05/21 06:00 [entrez]']	Netherlands			28526212	ppublish	['Journal Article', 'Validation Studies']			IM		Med Image Anal. 2017 Oct;41:40-54. doi: 10.1016/j.media.2017.05.001. Epub 2017 May 8.	MEDLINE	Med Image Anal	3D deeply supervised network for automated segmentation of volumetric medical images.		41	3D deeply supervised network for automated segmentation of volumetric medical images.
Understanding epigenetic processes holds immense promise for medical applications. Advances in Machine Learning (ML) are critical to realize this promise. Previous studies used epigenetic data sets associated with the germline transmission of epigenetic transgenerational inheritance of disease and novel ML approaches to predict genome-wide locations of critical epimutations. A combination of Active Learning (ACL) and Imbalanced Class Learning (ICL) was used to address past problems with ML to develop a more efficient feature selection process and address the imbalance problem in all genomic data sets. The power of this novel ML approach and our ability to predict epigenetic phenomena and associated disease is suggested. The current approach requires extensive computation of features over the genome. A promising new approach is to introduce Deep Learning (DL) for the generation and simultaneous computation of novel genomic features tuned to the classification task. This approach can be used with any genomic or biological data set applied to medicine. The application of molecular epigenetic data in advanced machine learning analysis to medicine is the focus of this review.	['a School of Electrical Engineering and Computer Science , Washington State University , Pullman , WA , USA.', 'a School of Electrical Engineering and Computer Science , Washington State University , Pullman , WA , USA.', 'b Center for Reproductive Biology, School of Biological Sciences , Washington State University , Pullman , WA , USA.', 'b Center for Reproductive Biology, School of Biological Sciences , Washington State University , Pullman , WA , USA.']	['10.1080/15592294.2017.1329068 [doi]']	['Holder LB', 'Haque MM', 'Skinner MK']							['2017/05/20 06:00']	20171207	20170519	2017 Jul 3	2017/05/20 06:00		['Holder, Lawrence B', 'Haque, M Muksitul', 'Skinner, Michael K']		['R01 ES012974/ES/NIEHS NIH HHS/United States', 'ES012974-10/ES/NIEHS NIH HHS/United States']	7		1559-2308 (Electronic) 1559-2294 (Linking)	101265293	Epigenetics	['eng']	10.1080/15592294.2017.1329068 [doi]	20181113	['Animals', '*Epigenesis, Genetic', 'Epigenomics/*methods', 'Genetics, Medical/*methods', 'Humans', '*Machine Learning']	2017/12/08 06:00		['*Active learning', '*DNA methylation', '*deep learning', '*epigenetics', '*epigenome', '*imbalanced-class learning', '*machine learning', '*molecular diagnostics']	['NOTNLM']	NLM	505-514	['2017/05/20 06:00 [pubmed]', '2017/12/08 06:00 [medline]', '2017/05/20 06:00 [entrez]']	United States	PMC5687335		28524769	ppublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S."", 'Research Support, N.I.H., Extramural']"			IM		Epigenetics. 2017 Jul 3;12(7):505-514. doi: 10.1080/15592294.2017.1329068. Epub 2017 May 19.	MEDLINE	Epigenetics	Machine learning for epigenetics and future medical applications.		12	Machine learning for epigenetics and future medical applications.
Autosomal Dominant Polycystic Kidney Disease (ADPKD) is the most common inherited disorder of the kidneys. It is characterized by enlargement of the kidneys caused by progressive development of renal cysts, and thus assessment of total kidney volume (TKV) is crucial for studying disease progression in ADPKD. However, automatic segmentation of polycystic kidneys is a challenging task due to severe alteration in the morphology caused by non-uniform cyst formation and presence of adjacent liver cysts. In this study, an automated segmentation method based on deep learning has been proposed for TKV computation on computed tomography (CT) dataset of ADPKD patients exhibiting mild to moderate or severe renal insufficiency. The proposed method has been trained (n = 165) and tested (n = 79) on a wide range of TKV (321.2-14,670.7 mL) achieving an overall mean Dice Similarity Coefficient of 0.86 +/- 0.07 (mean +/- SD) between automated and manual segmentations from clinical experts and a mean correlation coefficient (rho) of 0.98 (p < 0.001) for segmented kidney volume measurements in the entire test set. Our method facilitates fast and reproducible measurements of kidney volumes in agreement with manual segmentations from clinical experts.	['Department of Biomedical Engineering, IRCCS-Istituto di Ricerche Farmacologiche Mario Negri, Ranica (BG), 24020, Italy. kanishkasharma10@gmail.com.', 'Computer Aided Medical Procedures, Technische Universitat Munchen, Garching bei Munchen, 85748, Germany. kanishkasharma10@gmail.com.', 'Computer Aided Medical Procedures, Technische Universitat Munchen, Garching bei Munchen, 85748, Germany.', 'Department of Computer Science, Johns Hopkins University, Baltimore, 21218, USA.', 'Department of Biomedical Engineering, IRCCS-Istituto di Ricerche Farmacologiche Mario Negri, Ranica (BG), 24020, Italy.', 'Department of Biomedical Engineering, IRCCS-Istituto di Ricerche Farmacologiche Mario Negri, Ranica (BG), 24020, Italy.', 'Department of Management, Information and Production Engineering, University of Bergamo, Dalmine (BG), 24044, Italy.', 'Computer Aided Medical Procedures, Technische Universitat Munchen, Garching bei Munchen, 85748, Germany.', 'Computer Aided Medical Procedures, Technische Universitat Munchen, Garching bei Munchen, 85748, Germany.', 'Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, 21218, USA.']	['10.1038/s41598-017-01779-0 [doi]', '10.1038/s41598-017-01779-0 [pii]']	['Sharma K', 'Rupprecht C', 'Caroli A', 'Aparicio MC', 'Remuzzi A', 'Baust M', 'Navab N']							['2017/05/19 06:00']	20181211	20170517	2017 May 17	2017/05/19 06:00		['Sharma, Kanishka', 'Rupprecht, Christian', 'Caroli, Anna', 'Aparicio, Maria Carolina', 'Remuzzi, Andrea', 'Baust, Maximilian', 'Navab, Nassir']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-01779-0 [doi]	20181211	['Adult', 'Aged', '*Deep Learning', 'Female', 'Glomerular Filtration Rate', 'Humans', 'Image Processing, Computer-Assisted', 'Kidney/*diagnostic imaging/*pathology/physiopathology', 'Male', 'Middle Aged', 'Organ Size', 'Polycystic Kidney, Autosomal Dominant/*diagnosis/physiopathology', 'Reproducibility of Results', 'Tomography, X-Ray Computed']	2018/12/12 06:00				NLM	2049	['2016/11/03 00:00 [received]', '2017/04/04 00:00 [accepted]', '2017/05/19 06:00 [entrez]', '2017/05/19 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	England	PMC5435691		28515418	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2017 May 17;7(1):2049. doi: 10.1038/s41598-017-01779-0.	MEDLINE	Sci Rep	Automatic Segmentation of Kidneys using Deep Learning for Total Kidney Volume Quantification in Autosomal Dominant Polycystic Kidney Disease.		7	Automatic Segmentation of Kidneys using Deep Learning for Total Kidney Volume Quantification in Autosomal Dominant Polycystic Kidney Disease.
The complex language of eukaryotic gene expression remains incompletely understood. Despite the importance suggested by many proteins variants statistically associated with human disease, nearly all such variants have unknown mechanisms, for example, protein-protein interactions (PPIs). In this study, we address this challenge using a recent machine learning advance-deep neural networks (DNNs). We aim at improving the performance of PPIs prediction and propose a method called DeepPPI (Deep neural networks for Protein-Protein Interactions prediction), which employs deep neural networks to learn effectively the representations of proteins from common protein descriptors. The experimental results indicate that DeepPPI achieves superior performance on the test data set with an Accuracy of 92.50%, Precision of 94.38%, Recall of 90.56%, Specificity of 94.49%, Matthews Correlation Coefficient of 85.08% and Area Under the Curve of 97.43%, respectively. Extensive experiments show that DeepPPI can learn useful features of proteins pairs by a layer-wise abstraction, and thus achieves better prediction performance than existing methods. The source code of our approach can be available via http://ailab.ahu.edu.cn:8087/DeepPPI/index.html .	['Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, double daggerSchool of Computer Science and Technology, and section signCenter of Information Support & Assurance Technology, Anhui University , Hefei, 230601 Anhui, China.', 'Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, double daggerSchool of Computer Science and Technology, and section signCenter of Information Support & Assurance Technology, Anhui University , Hefei, 230601 Anhui, China.', 'Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, double daggerSchool of Computer Science and Technology, and section signCenter of Information Support & Assurance Technology, Anhui University , Hefei, 230601 Anhui, China.', 'Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, double daggerSchool of Computer Science and Technology, and section signCenter of Information Support & Assurance Technology, Anhui University , Hefei, 230601 Anhui, China.', 'Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, double daggerSchool of Computer Science and Technology, and section signCenter of Information Support & Assurance Technology, Anhui University , Hefei, 230601 Anhui, China.', 'Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, double daggerSchool of Computer Science and Technology, and section signCenter of Information Support & Assurance Technology, Anhui University , Hefei, 230601 Anhui, China.']	['10.1021/acs.jcim.7b00028 [doi]']	['Du X', 'Sun S', 'Hu C', 'Yao Y', 'Yan Y', 'Zhang Y']	['ORCID: 0000-0001-7913-7605']						['2017/05/18 06:00']	20170921	20170526	2017 Jun 26	2017/05/18 06:00		['Du, Xiuquan', 'Sun, Shiwei', 'Hu, Changlin', 'Yao, Yu', 'Yan, Yuanting', 'Zhang, Yanping']			6		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.7b00028 [doi]	20180227	['*Neural Networks (Computer)', 'Protein Interaction Mapping/*methods', 'Saccharomyces cerevisiae/metabolism']	2017/09/22 06:00				NLM	1499-1510	['2017/05/18 06:00 [pubmed]', '2017/09/22 06:00 [medline]', '2017/05/18 06:00 [entrez]']	United States			28514151	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Chem Inf Model. 2017 Jun 26;57(6):1499-1510. doi: 10.1021/acs.jcim.7b00028. Epub 2017 May 26.	MEDLINE	J Chem Inf Model	DeepPPI: Boosting Prediction of Protein-Protein Interactions with Deep Neural Networks.		57	DeepPPI: Boosting Prediction of Protein-Protein Interactions with Deep Neural Networks.
Precision medicine approaches rely on obtaining precise knowledge of the true state of health of an individual patient, which results from a combination of their genetic risks and environmental exposures. This approach is currently limited by the lack of effective and efficient non-invasive medical tests to define the full range of phenotypic variation associated with individual health. Such knowledge is critical for improved early intervention, for better treatment decisions, and for ameliorating the steadily worsening epidemic of chronic disease. We present proof-of-concept experiments to demonstrate how routinely acquired cross-sectional CT imaging may be used to predict patient longevity as a proxy for overall individual health and disease status using computer image analysis techniques. Despite the limitations of a modest dataset and the use of off-the-shelf machine learning methods, our results are comparable to previous 'manual' clinical methods for longevity prediction. This work demonstrates that radiomics techniques can be used to extract biomarkers relevant to one of the most widely used outcomes in epidemiological and clinical research - mortality, and that deep learning with convolutional neural networks can be usefully applied to radiomics research. Computer image analysis applied to routinely collected medical images offers substantial potential to enhance precision medicine initiatives.	['Department of Radiology, Royal Adelaide Hospital, North Terrace, Adelaide, SA, 5000, Australia. lukeoakdenrayner@gmail.com.', 'School of Public Health, The University of Adelaide, North Terrace, Adelaide, SA, 5000, Australia. lukeoakdenrayner@gmail.com.', 'School of Computer Science, The University of Adelaide, North Terrace, Adelaide, SA, 5000, Australia.', 'Department of Radiology, Royal Adelaide Hospital, North Terrace, Adelaide, SA, 5000, Australia.', 'Instituto Superior Tecnico, Lisbon, Portugal.', 'School of Information Technology and Electrical Engineering, The University of Queensland, Building 78, St Lucia QLD 4067, Queensland, Australia.', 'School of Public Health, The University of Adelaide, North Terrace, Adelaide, SA, 5000, Australia.']	['10.1038/s41598-017-01931-w [doi]', '10.1038/s41598-017-01931-w [pii]']	['Oakden-Rayner L', 'Carneiro G', 'Bessen T', 'Nascimento JC', 'Bradley AP', 'Palmer LJ']							['2017/05/12 06:00']	20181211	20170510	2017 May 10	2017/05/12 06:00		['Oakden-Rayner, Luke', 'Carneiro, Gustavo', 'Bessen, Taryn', 'Nascimento, Jacinto C', 'Bradley, Andrew P', 'Palmer, Lyle J']			1		2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/s41598-017-01931-w [doi]	20181211	['Area Under Curve', '*Deep Learning', 'Diagnostic Imaging', 'Humans', 'Image Processing, Computer-Assisted', 'Kaplan-Meier Estimate', 'Longevity/*physiology', 'Mortality', 'Phenotype', '*Precision Medicine', 'ROC Curve', '*Radiology', 'Reproducibility of Results', 'Risk Factors', 'Task Performance and Analysis', 'Tomography, X-Ray Computed']	2018/12/12 06:00				NLM	1648	['2016/12/08 00:00 [received]', '2017/04/06 00:00 [accepted]', '2017/05/12 06:00 [entrez]', '2017/05/12 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	England	PMC5431941		28490744	epublish	['Journal Article']			IM		Sci Rep. 2017 May 10;7(1):1648. doi: 10.1038/s41598-017-01931-w.	MEDLINE	Sci Rep	Precision Radiology: Predicting longevity using feature engineering and deep learning methods in a radiomics framework.		7	Precision Radiology: Predicting longevity using feature engineering and deep learning methods in a radiomics framework.
Different types of breast cancer are affecting lives of women across the world. Common types include Ductal carcinoma in situ (DCIS), Invasive ductal carcinoma (IDC), Tubular carcinoma, Medullary carcinoma, and Invasive lobular carcinoma (ILC). While detecting cancer, one important factor is mitotic count - showing how rapidly the cells are dividing. But the class imbalance problem, due to the small number of mitotic nuclei in comparison to the overwhelming number of non-mitotic nuclei, affects the performance of classification models. This work presents a two-phase model to mitigate the class biasness issue while classifying mitotic and non-mitotic nuclei in breast cancer histopathology images through a deep convolutional neural network (CNN). First, nuclei are segmented out using blue ratio and global binary thresholding. In Phase-1 a CNN is then trained on the segmented out 80x80 pixel patches based on a standard dataset. Hard non-mitotic examples are identified and augmented; mitotic examples are oversampled by rotation and flipping; whereas non-mitotic examples are undersampled by blue ratio histogram based k-means clustering. Based on this information from Phase-1, the dataset is modified for Phase-2 in order to reduce the effects of class imbalance. The proposed CNN architecture and data balancing technique yielded an F-measure of 0.79, and outperformed all the methods relying on specific handcrafted features, as well as those using a combination of handcrafted and CNN-generated features.	['Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences Islamabad, Pakistan.', 'Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences Islamabad, Pakistan. Electronic address: asif@pieas.edu.pk.', 'Department of Biomedical Engineering, College of Medical Science, Catholic University of Daegu, Gyoungsangbuk-do Zip 38430, Republic of Korea.']	['S0010-4825(17)30098-7 [pii]', '10.1016/j.compbiomed.2017.04.012 [doi]']	['Wahab N', 'Khan A', 'Lee YS']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/05/07 06:00']	20180319	20170418	2017 Jun 1	2017/05/10 06:00		['Wahab, Noorul', 'Khan, Asifullah', 'Lee, Yeon Soo']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(17)30098-7 [pii] 10.1016/j.compbiomed.2017.04.012 [doi]	20180420	['Algorithms', 'Breast Neoplasms/*diagnostic imaging/pathology', 'Cell Nucleus', 'Female', 'Histocytochemistry', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Machine Learning', 'Mitosis', '*Neural Networks (Computer)', 'ROC Curve']	2018/03/20 06:00		['*Breast cancer', '*Class imbalance', '*Convolutional neural networks', '*Deep learning', '*Histopathology', '*Mitosis count']	['NOTNLM']	NLM	86-97	['2016/11/29 00:00 [received]', '2017/03/26 00:00 [revised]', '2017/04/15 00:00 [accepted]', '2017/05/10 06:00 [pubmed]', '2018/03/20 06:00 [medline]', '2017/05/07 06:00 [entrez]']	United States			28477446	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Biol Med. 2017 Jun 1;85:86-97. doi: 10.1016/j.compbiomed.2017.04.012. Epub 2017 Apr 18.	MEDLINE	Comput Biol Med	Two-phase deep convolutional neural network for reducing class skewness in histopathological images based breast cancer detection.		85	Two-phase deep convolutional neural network for reducing class skewness in histopathological images based breast cancer detection.
Segmentation of key brain tissues from 3D medical images is of great significance for brain disease diagnosis, progression assessment and monitoring of neurologic conditions. While manual segmentation is time-consuming, laborious, and subjective, automated segmentation is quite challenging due to the complicated anatomical environment of brain and the large variations of brain tissues. We propose a novel voxelwise residual network (VoxResNet) with a set of effective training schemes to cope with this challenging problem. The main merit of residual learning is that it can alleviate the degradation problem when training a deep network so that the performance gains achieved by increasing the network depth can be fully leveraged. With this technique, our VoxResNet is built with 25 layers, and hence can generate more representative features to deal with the large variations of brain tissues than its rivals using hand-crafted features or shallower networks. In order to effectively train such a deep network with limited training data for brain segmentation, we seamlessly integrate multi-modality and multi-level contextual information into our network, so that the complementary information of different modalities can be harnessed and features of different scales can be exploited. Furthermore, an auto-context version of the VoxResNet is proposed by combining the low-level image appearance features, implicit shape information, and high-level context together for further improving the segmentation performance. Extensive experiments on the well-known benchmark (i.e., MRBrainS) of brain segmentation from 3D magnetic resonance (MR) images corroborated the efficacy of the proposed VoxResNet. Our method achieved the first place in the challenge out of 37 competitors including several state-of-the-art brain segmentation methods. Our method is inherently general and can be readily applied as a powerful tool to many brain-related studies, where accurate segmentation of brain structures is critical.	['Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China. Electronic address: hchen@cse.cuhk.edu.hk.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China. Electronic address: qdou@cse.cuhk.edu.hk.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'School of Nursing, The Hong Kong Polytechnic University, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China.']	['S1053-8119(17)30334-8 [pii]', '10.1016/j.neuroimage.2017.04.041 [doi]']	['Chen H', 'Dou Q', 'Yu L', 'Qin J', 'Heng PA']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/04/27 06:00']	20181211	20170423	2018 Apr 15	2017/04/27 06:00		['Chen, Hao', 'Dou, Qi', 'Yu, Lequan', 'Qin, Jing', 'Heng, Pheng-Ann']					1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(17)30334-8 [pii] 10.1016/j.neuroimage.2017.04.041 [doi]	20181211	['Brain/*anatomy & histology/*diagnostic imaging/pathology', '*Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', 'Imaging, Three-Dimensional/*methods', 'Magnetic Resonance Imaging/*methods', 'Neuroimaging/*methods']	2018/12/12 06:00		['*3D deep learning', '*Auto-context', '*Brain segmentation', '*Convolutional neural network', '*Multi-level contextual information', '*Multi-modality', '*Residual learning']	['NOTNLM']	NLM	446-455	['2016/12/21 00:00 [received]', '2017/03/24 00:00 [revised]', '2017/04/18 00:00 [accepted]', '2017/04/27 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2017/04/27 06:00 [entrez]']	United States			28445774	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Neuroimage. 2018 Apr 15;170:446-455. doi: 10.1016/j.neuroimage.2017.04.041. Epub 2017 Apr 23.	MEDLINE	Neuroimage	VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images.		170	VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images.
Motivation: Many biological processes are governed by protein-ligand interactions. One such example is the recognition of self and non-self cells by the immune system. This immune response process is regulated by the major histocompatibility complex (MHC) protein which is encoded by the human leukocyte antigen (HLA) complex. Understanding the binding potential between MHC and peptides can lead to the design of more potent, peptide-based vaccines and immunotherapies for infectious autoimmune diseases. Results: We apply machine learning techniques from the natural language processing (NLP) domain to address the task of MHC-peptide binding prediction. More specifically, we introduce a new distributed representation of amino acids, name HLA-Vec, that can be used for a variety of downstream proteomic machine learning tasks. We then propose a deep convolutional neural network architecture, name HLA-CNN, for the task of HLA class I-peptide binding prediction. Experimental results show combining the new distributed representation with our HLA-CNN architecture achieves state-of-the-art results in the majority of the latest two Immune Epitope Database (IEDB) weekly automated benchmark datasets. We further apply our model to predict binding on the human genome and identify 15 genes with potential for self binding. Availability and Implementation: Codes to generate the HLA-Vec and HLA-CNN are publicly available at: https://github.com/uci-cbcl/HLA-bind . Contact: xhx@ics.uci.edu. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of California, Irvine, CA 92697, USA.', 'Department of Computer Science, University of California, Irvine, CA 92697, USA.', 'Institute for Genomics and Bioinformatics, University of California, Irvine, CA 92697, USA.']	['3746909 [pii]', '10.1093/bioinformatics/btx264 [doi]']	['Vang YS', 'Xie X']		['(c) The Author (2017). Published by Oxford University Press. All rights reserved.', 'For Permissions, please email: journals.permissions@oup.com']					['2017/04/27 06:00']	20180601		2017 Sep 1	2017/04/27 06:00		['Vang, Yeeleng S', 'Xie, Xiaohui']			17		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btx264 [doi]	20181202	['Epitopes', 'HLA Antigens/metabolism', 'Histocompatibility Antigens Class I/*metabolism', 'Humans', '*Machine Learning', '*Neural Networks (Computer)', 'Peptides/*metabolism', 'Protein Binding', 'Proteomics/*methods']	2018/06/02 06:00				NLM	2658-2665	['2016/12/21 00:00 [received]', '2017/04/18 00:00 [accepted]', '2017/04/27 06:00 [pubmed]', '2018/06/02 06:00 [medline]', '2017/04/27 06:00 [entrez]']	England			28444127	ppublish	['Journal Article']		['0 (Epitopes)', '0 (HLA Antigens)', '0 (Histocompatibility Antigens Class I)', '0 (Peptides)']	IM		Bioinformatics. 2017 Sep 1;33(17):2658-2665. doi: 10.1093/bioinformatics/btx264.	MEDLINE	Bioinformatics	HLA class I binding prediction via convolutional neural networks.		33	HLA class I binding prediction via convolutional neural networks.
Automated left ventricular (LV) segmentation is crucial for efficient quantification of cardiac function and morphology to aid subsequent management of cardiac pathologies. In this paper, we parameterize the complete (all short axis slices and phases) LV segmentation task in terms of the radial distances between the LV centerpoint and the endo- and epicardial contours in polar space. We then utilize convolutional neural network regression to infer these parameters. Utilizing parameter regression, as opposed to conventional pixel classification, allows the network to inherently reflect domain-specific physical constraints. We have benchmarked our approach primarily against the publicly-available left ventricle segmentation challenge (LVSC) dataset, which consists of 100 training and 100 validation cardiac MRI cases representing a heterogeneous mix of cardiac pathologies and imaging parameters across multiple centers. Our approach attained a .77 Jaccard index, which is the highest published overall result in comparison to other automated algorithms. To test general applicability, we also evaluated against the Kaggle Second Annual Data Science Bowl, where the evaluation metric was the indirect clinical measures of LV volume rather than direct myocardial contours. Our approach attained a Continuous Ranked Probability Score (CRPS) of .0124, which would have ranked tenth in the original challenge. With this we demonstrate the effectiveness of convolutional neural network regression paired with domain-specific features in clinical segmentation.	['Department of Biomedical Imaging, Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia; University Malaya Research Imaging Centre, University of Malaya, Kuala Lumpur, Malaysia.', 'Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Kuala Lumpur, Malaysia. Electronic address: liewym@um.edu.my.', 'Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Kuala Lumpur, Malaysia.', 'Australian Research Council Centre of Excellence for Nanoscale Biophotonics, School of Medicine, Faculty of Health and Medical Sciences, University of Adelaide, Adelaide, Australia.']	['S1361-8415(17)30054-3 [pii]', '10.1016/j.media.2017.04.002 [doi]']	['Tan LK', 'Liew YM', 'Lim E', 'McLaughlin RA']		['Copyright (c) 2017 Elsevier B.V. All rights reserved.']					['2017/04/25 06:00']	20180525	20170412	2017 Jul	2017/04/25 06:00		['Tan, Li Kuo', 'Liew, Yih Miin', 'Lim, Einly', 'McLaughlin, Robert A']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(17)30054-3 [pii] 10.1016/j.media.2017.04.002 [doi]	20181202	['Heart Ventricles/*diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Magnetic Resonance Imaging, Cine/*methods', '*Neural Networks (Computer)', '*Regression Analysis', 'Reproducibility of Results']	2018/05/26 06:00		['Cardiac MRI', 'Convolutional neural networks', 'Deep learning', 'LV segmentation']	['NOTNLM']	NLM	78-86	['2016/07/04 00:00 [received]', '2017/04/04 00:00 [revised]', '2017/04/11 00:00 [accepted]', '2017/04/25 06:00 [pubmed]', '2018/05/26 06:00 [medline]', '2017/04/25 06:00 [entrez]']	Netherlands			28437634	ppublish	['Journal Article']			IM		Med Image Anal. 2017 Jul;39:78-86. doi: 10.1016/j.media.2017.04.002. Epub 2017 Apr 12.	MEDLINE	Med Image Anal	Convolutional neural network regression for short-axis left ventricle segmentation in cardiac cine MR sequences.		39	Convolutional neural network regression for short-axis left ventricle segmentation in cardiac cine MR sequences.
Recent years have witnessed significant advancement in computer vision research based on deep learning. Success of these tasks largely depends on the availability of a large amount of training samples. Labeling the training samples is an expensive process. In this paper, we present a simulated deep convolutional neural network for yield estimation. Knowing the exact number of fruits, flowers, and trees helps farmers to make better decisions on cultivation practices, plant disease prevention, and the size of harvest labor force. The current practice of yield estimation based on the manual counting of fruits or flowers by workers is a very time consuming and expensive process and it is not practical for big fields. Automatic yield estimation based on robotic agriculture provides a viable solution in this regard. Our network is trained entirely on synthetic data and tested on real data. To capture features on multiple scales, we used a modified version of the Inception-ResNet architecture. Our algorithm counts efficiently even if fruits are under shadow, occluded by foliage, branches, or if there is some degree of overlap amongst fruits. Experimental results show a 91% average test accuracy on real images and 93% on synthetic images.	['Department of Computer Science, Texas A&M University-Corpus Christi, Corpus Christi, TX 78412, USA. maryam.rahnemoonfar@tamucc.edu.', 'Department of Computer Science, Texas A&M University-Corpus Christi, Corpus Christi, TX 78412, USA. csheppard1@islander.tamucc.edu.']	['s17040905 [pii]', '10.3390/s17040905 [doi]']	['Rahnemoonfar M', 'Sheppard C']							['2017/04/21 06:00']	20180517	20170420	2017 Apr 20	2017/04/21 06:00		['Rahnemoonfar, Maryam', 'Sheppard, Clay']			4		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E905 [pii] 10.3390/s17040905 [doi]	20181202	['Algorithms', '*Machine Learning', 'Neural Networks (Computer)']	2018/05/18 06:00		['agricultural sensors', 'deep learning', 'simulated learning', 'yield estimation']	['NOTNLM']	NLM		['2017/02/18 00:00 [received]', '2017/04/05 00:00 [revised]', '2017/04/07 00:00 [accepted]', '2017/04/21 06:00 [entrez]', '2017/04/21 06:00 [pubmed]', '2018/05/18 06:00 [medline]']	Switzerland	PMC5426829		28425947	epublish	['Journal Article']			IM		Sensors (Basel). 2017 Apr 20;17(4). pii: s17040905. doi: 10.3390/s17040905.	MEDLINE	Sensors (Basel)	Deep Count: Fruit Counting Based on Deep Simulated Learning.		17	Deep Count: Fruit Counting Based on Deep Simulated Learning.
We investigate the application of distributional semantics models for facilitating unsupervised extraction of biomedical terms from unannotated corpora. Term extraction is used as the first step of an ontology learning process that aims to (semi-)automatic annotation of biomedical concepts and relations from more than 300K PubMed titles and abstracts. We experimented with both traditional distributional semantics methods such as Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) as well as the neural language models CBOW and Skip-gram from Deep Learning. The evaluation conducted concentrates on sepsis, a major life-threatening condition, and shows that Deep Learning models outperform LSA and LDA with much higher precision.	['School of Computer Science, University of Manchester (UK).', 'Midcheshire Hospital Foundation Trust, NHS England (UK).', 'School of Computer Science, University of Manchester (UK).', 'School of Computer Science, University of Manchester (UK).', 'Salford Languages, University of Salford (UK).', 'Hospital do Salnes de Villagarcia, SERGAS (Spain).', 'School of Computer Science, University of Manchester (UK).', 'School of Computer Science, University of Manchester (UK).', 'School of Computer Science, University of Manchester (UK).']		['Arguello Casteleiro M', 'Maseda Fernandez D', 'Demetriou G', 'Read W', 'Fernandez Prieto MJ', 'Des Diz J', 'Nenadic G', 'Keane J', 'Stevens R']							['2017/04/21 06:00']	20180418		2017	2017/04/21 06:00		['Arguello Casteleiro, Mercedes', 'Maseda Fernandez, Diego', 'Demetriou, George', 'Read, Warren', 'Fernandez Prieto, Maria Jesus', 'Des Diz, Julio', 'Nenadic, Goran', 'Keane, John', 'Stevens, Robert']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']		20181202	['Humans', 'Information Storage and Retrieval', '*Machine Learning', 'Natural Language Processing', '*PubMed', '*Semantics', '*Sepsis']	2018/04/19 06:00		['Deep Learning', 'OWL', 'Ontology Learning', 'PubMed', 'SPARQL']	['NOTNLM']	NLM	516-520	['2017/04/21 06:00 [entrez]', '2017/04/21 06:00 [pubmed]', '2018/04/19 06:00 [medline]']	Netherlands			28423846	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2017;235:516-520.	MEDLINE	Stud Health Technol Inform	A Case Study on Sepsis Using PubMed and Deep Learning for Ontology Learning.		235	A Case Study on Sepsis Using PubMed and Deep Learning for Ontology Learning.
We present an approach to automatically classify clinical text at a sentence level. We are using deep convolutional neural networks to represent complex features. We train the network on a dataset providing a broad categorization of health information. Through a detailed evaluation, we demonstrate that our method outperforms several approaches widely used in natural language processing tasks by about 15%.	['IBM Research Lab, Ireland.', 'IBM Research Lab, Ireland.', 'IBM Research Lab, Ireland.', 'Japan Science and Technology Agency, Tokyo, Japan.']		['Hughes M', 'Li I', 'Kotoulas S', 'Suzumura T']							['2017/04/21 06:00']	20171020		2017	2017/04/21 06:00		['Hughes, Mark', 'Li, Irene', 'Kotoulas, Spyros', 'Suzumura, Toyotaro']					1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']		20171020	['*Machine Learning', '*Natural Language Processing', '*Neural Networks (Computer)', 'Semantics']	2017/10/21 06:00		['Clinical text', 'convolutional neural network', 'semantic clinical classification', 'sentence classification']	['NOTNLM']	NLM	246-250	['2017/04/21 06:00 [entrez]', '2017/04/21 06:00 [pubmed]', '2017/10/21 06:00 [medline]']	Netherlands			28423791	ppublish	['Journal Article']			T		Stud Health Technol Inform. 2017;235:246-250.	MEDLINE	Stud Health Technol Inform	Medical Text Classification Using Convolutional Neural Networks.		235	Medical Text Classification Using Convolutional Neural Networks.
BACKGROUND: Celiac disease is one of the most common diseases in the world. Capsule endoscopy is an alternative way to visualize the entire small intestine without invasiveness to the patient. It is useful to characterize celiac disease, but hours are need to manually analyze the retrospective data of a single patient. Computer-aided quantitative analysis by a deep learning method helps in alleviating the workload during analysis of the retrospective videos. METHOD: Capsule endoscopy clips from 6 celiac disease patients and 5 controls were preprocessed for training. The frames with a large field of opaque extraluminal fluid or air bubbles were removed automatically by using a pre-selection algorithm. Then the frames were cropped and the intensity was corrected prior to frame rotation in the proposed new method. The GoogLeNet is trained with these frames. Then, the clips of capsule endoscopy from 5 additional celiac disease patients and 5 additional control patients are used for testing. The trained GoogLeNet was able to distinguish the frames from capsule endoscopy clips of celiac disease patients vs controls. Quantitative measurement with evaluation of the confidence was developed to assess the severity level of pathology in the subjects. RESULTS: Relying on the evaluation confidence, the GoogLeNet achieved 100% sensitivity and specificity for the testing set. The t-test confirmed the evaluation confidence is significant to distinguish celiac disease patients from controls. Furthermore, it is found that the evaluation confidence may also relate to the severity level of small bowel mucosal lesions. CONCLUSIONS: A deep convolutional neural network was established for quantitative measurement of the existence and degree of pathology throughout the small intestine, which may improve computer-aided clinical techniques to assess mucosal atrophy and other etiologies in real-time with videocapsule endoscopy.	['School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.', 'Department of Biomedical Engineering, Hefei University of Technology, Hefei 230009, China. Electronic address: bingoon@ieee.org.', 'Affiliated Shantou Hospital of Sun Yat-sen University, Shantou Central Hospital, Shantou 515000, China.', 'Department of Medicine, Celiac Disease Center, Columbia University, New York, USA.', 'Department of Medicine, Celiac Disease Center, Columbia University, New York, USA.', 'Center for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong.']	['S0010-4825(17)30086-0 [pii]', '10.1016/j.compbiomed.2017.03.031 [doi]']	['Zhou T', 'Han G', 'Li BN', 'Lin Z', 'Ciaccio EJ', 'Green PH', 'Qin J']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/04/17 06:00']	20180319	20170408	2017 Jun 1	2017/04/17 06:00		['Zhou, Teng', 'Han, Guoqiang', 'Li, Bing Nan', 'Lin, Zhizhe', 'Ciaccio, Edward J', 'Green, Peter H', 'Qin, Jing']					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(17)30086-0 [pii] 10.1016/j.compbiomed.2017.03.031 [doi]	20180420	['Algorithms', 'Capsule Endoscopy/*methods', 'Celiac Disease/*diagnostic imaging', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Neural Networks (Computer)']	2018/03/20 06:00		['*Celiac disease', '*Deep learning', '*GoogLeNet', '*Quantitative analysis', '*Videocapsule endoscopy']	['NOTNLM']	NLM	1-6	['2016/11/11 00:00 [received]', '2017/03/18 00:00 [revised]', '2017/03/31 00:00 [accepted]', '2017/04/17 06:00 [pubmed]', '2018/03/20 06:00 [medline]', '2017/04/17 06:00 [entrez]']	United States			28412572	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Biol Med. 2017 Jun 1;85:1-6. doi: 10.1016/j.compbiomed.2017.03.031. Epub 2017 Apr 8.	MEDLINE	Comput Biol Med	Quantitative analysis of patients with celiac disease by video capsule endoscopy: A deep learning method.		85	Quantitative analysis of patients with celiac disease by video capsule endoscopy: A deep learning method.
Speech Emotion Recognition (SER) can be regarded as a static or dynamic classification problem, which makes SER an excellent test bed for investigating and comparing various deep learning architectures. We describe a frame-based formulation to SER that relies on minimal speech processing and end-to-end deep learning to model intra-utterance dynamics. We use the proposed SER system to empirically explore feed-forward and recurrent neural network architectures and their variants. Experiments conducted illuminate the advantages and limitations of these architectures in paralinguistic speech recognition and emotion recognition in particular. As a result of our exploration, we report state-of-the-art results on the IEMOCAP database for speaker-independent SER and present quantitative and qualitative assessments of the models' performances.	['School of Engineering, RMIT University, Melbourne VIC 3001, Australia. Electronic address: haytham.fayek@ieee.org.', 'School of Engineering, RMIT University, Melbourne VIC 3001, Australia. Electronic address: margaret.lech@rmit.edu.au.', 'School of Science, RMIT University, Melbourne VIC 3001, Australia. Electronic address: lawrence.cavedon@rmit.edu.au.']	['S0893-6080(17)30059-X [pii]', '10.1016/j.neunet.2017.02.013 [doi]']	['Fayek HM', 'Lech M', 'Cavedon L']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/04/12 06:00']	20180131	20170321	2017 Aug	2017/04/12 06:00		['Fayek, Haytham M', 'Lech, Margaret', 'Cavedon, Lawrence']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30059-X [pii] 10.1016/j.neunet.2017.02.013 [doi]	20181202	['*Emotions', '*Machine Learning', 'Neural Networks (Computer)', '*Speech Recognition Software']	2018/02/01 06:00		['Affective computing', 'Deep learning', 'Emotion recognition', 'Neural networks', 'Speech recognition']	['NOTNLM']	NLM	60-68	['2016/08/26 00:00 [received]', '2017/02/12 00:00 [revised]', '2017/02/13 00:00 [accepted]', '2017/04/12 06:00 [pubmed]', '2018/02/01 06:00 [medline]', '2017/04/12 06:00 [entrez]']	United States			28396068	ppublish	['Journal Article']			IM		Neural Netw. 2017 Aug;92:60-68. doi: 10.1016/j.neunet.2017.02.013. Epub 2017 Mar 21.	MEDLINE	Neural Netw	Evaluating deep learning architectures for Speech Emotion Recognition.		92	Evaluating deep learning architectures for Speech Emotion Recognition.
High-throughput microscopy of many single cells generates high-dimensional data that are far from straightforward to analyze. One important problem is automatically detecting the cellular compartment where a fluorescently-tagged protein resides, a task relatively simple for an experienced human, but difficult to automate on a computer. Here, we train an 11-layer neural network on data from mapping thousands of yeast proteins, achieving per cell localization classification accuracy of 91%, and per protein accuracy of 99% on held-out images. We confirm that low-level network features correspond to basic image characteristics, while deeper layers separate localization classes. Using this network as a feature calculator, we train standard classifiers that assign proteins to previously unseen compartments after observing only a small number of training examples. Our results are the most accurate subcellular localization classifications to date, and demonstrate the usefulness of deep learning for high-throughput microscopy.	['Institute of Computer Science, University of Tartu, 50409, Estonia.', 'Institute of Computer Science, University of Tartu, 50409, Estonia leopold.parts@sanger.ac.uk.', 'Wellcome Trust Sanger Institute, Hinxton, Cambridgeshire CB10 1SA, United Kingdom.']	['g3.116.033654 [pii]', '10.1534/g3.116.033654 [doi]']	['Parnamaa T', 'Parts L']		['Copyright (c) 2017 Parnamaa and Parts.']					['2017/04/10 06:00']	20180201	20170505	2017 May 5	2017/04/10 06:00		['Parnamaa, Tanel', 'Parts, Leopold']		['Wellcome Trust/United Kingdom']	5		2160-1836 (Electronic) 2160-1836 (Linking)	101566598	G3 (Bethesda, Md.)	['eng']	10.1534/g3.116.033654 [doi]	20181113	['Fungal Proteins/classification/*metabolism', 'High-Throughput Screening Assays/methods', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Microscopy, Fluorescence/methods', 'Protein Transport', 'Proteome/classification/*metabolism', 'Yeasts/metabolism/ultrastructure']	2018/02/02 06:00		['*deep learning', '*high-content screening', '*machine learning', '*microscopy', '*yeast']	['NOTNLM']	NLM	1385-1392	['2017/04/10 06:00 [pubmed]', '2018/02/02 06:00 [medline]', '2017/04/10 06:00 [entrez]']	United States	PMC5427497		28391243	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Fungal Proteins)', '0 (Proteome)']	IM		G3 (Bethesda). 2017 May 5;7(5):1385-1392. doi: 10.1534/g3.116.033654.	MEDLINE	G3 (Bethesda)	Accurate Classification of Protein Subcellular Localization from High-Throughput Microscopy Images Using Deep Learning.		7	Accurate Classification of Protein Subcellular Localization from High-Throughput Microscopy Images Using Deep Learning.
Tissue biomarker scoring by pathologists is central to defining the appropriate therapy for patients with cancer. Yet, inter-pathologist variability in the interpretation of ambiguous cases can affect diagnostic accuracy. Modern artificial intelligence methods such as deep learning have the potential to supplement pathologist expertise to ensure constant diagnostic accuracy. We developed a computational approach based on deep learning that automatically scores HER2, a biomarker that defines patient eligibility for anti-HER2 targeted therapies in breast cancer. In a cohort of 71 breast tumour resection samples, automated scoring showed a concordance of 83% with a pathologist. The twelve discordant cases were then independently reviewed, leading to a modification of diagnosis from initial pathologist assessment for eight cases. Diagnostic discordance was found to be largely caused by perceptual differences in assessing HER2 expression due to high HER2 staining heterogeneity. This study provides evidence that deep learning aided diagnosis can facilitate clinical decision making in breast cancer by identifying cases at high risk of misdiagnosis.	['Personalised Healthcare &Biomarkers, IMED Biotech Unit, AstraZeneca, HODGKIN, C/o B310 Cambridge Science Park, Milton Road, Cambridge, CB4 0WG, United Kingdom.', 'Personalised Healthcare &Biomarkers, IMED Biotech Unit, AstraZeneca, HODGKIN, C/o B310 Cambridge Science Park, Milton Road, Cambridge, CB4 0WG, United Kingdom.', 'Personalised Healthcare &Biomarkers, IMED Biotech Unit, AstraZeneca, HODGKIN, C/o B310 Cambridge Science Park, Milton Road, Cambridge, CB4 0WG, United Kingdom.', 'Pathology, Drug Safety &Metabolism, IMED Biotech Unit, AstraZeneca, Pepparedsleden 1, 431 50 Molndal, Sweden.', 'Personalised Healthcare &Biomarkers, IMED Biotech Unit, AstraZeneca, HODGKIN, C/o B310 Cambridge Science Park, Milton Road, Cambridge, CB4 0WG, United Kingdom.', 'Personalised Healthcare &Biomarkers, IMED Biotech Unit, AstraZeneca, HODGKIN, C/o B310 Cambridge Science Park, Milton Road, Cambridge, CB4 0WG, United Kingdom.']	['srep45938 [pii]', '10.1038/srep45938 [doi]']	['Vandenberghe ME', 'Scott ML', 'Scorer PW', 'Soderberg M', 'Balcerzak D', 'Barker C']							['2017/04/06 06:00']	20181211	20170405	2017 Apr 5	2017/04/06 06:00		['Vandenberghe, Michel E', 'Scott, Marietta L J', 'Scorer, Paul W', 'Soderberg, Magnus', 'Balcerzak, Denis', 'Barker, Craig']					2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/srep45938 [doi]	20181211	['Antineoplastic Agents, Immunological/therapeutic use', 'Biomarkers, Tumor/antagonists & inhibitors/*metabolism', 'Breast Neoplasms/diagnosis/drug therapy/*metabolism', 'Cohort Studies', 'Diagnosis, Computer-Assisted/methods', 'Female', 'Humans', 'Immunohistochemistry', '*Machine Learning', 'Receptor, ErbB-2/antagonists & inhibitors/*metabolism', 'Reproducibility of Results', 'Trastuzumab/therapeutic use']	2018/12/12 06:00				NLM	45938	['2017/01/10 00:00 [received]', '2017/03/06 00:00 [accepted]', '2017/04/06 06:00 [entrez]', '2017/04/06 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	England	PMC5380996		28378829	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Antineoplastic Agents, Immunological)', '0 (Biomarkers, Tumor)', 'EC 2.7.10.1 (Receptor, ErbB-2)', 'P188ANX8CK (Trastuzumab)']	IM		Sci Rep. 2017 Apr 5;7:45938. doi: 10.1038/srep45938.	MEDLINE	Sci Rep	Relevance of deep learning to facilitate the diagnosis of HER2 status in breast cancer.		7	Relevance of deep learning to facilitate the diagnosis of HER2 status in breast cancer.
Computational approaches to drug discovery can reduce the time and cost associated with experimental assays and enable the screening of novel chemotypes. Structure-based drug design methods rely on scoring functions to rank and predict binding affinities and poses. The ever-expanding amount of protein-ligand binding and structural data enables the use of deep machine learning techniques for protein-ligand scoring. We describe convolutional neural network (CNN) scoring functions that take as input a comprehensive three-dimensional (3D) representation of a protein-ligand interaction. A CNN scoring function automatically learns the key features of protein-ligand interactions that correlate with binding. We train and optimize our CNN scoring functions to discriminate between correct and incorrect binding poses and known binders and nonbinders. We find that our CNN scoring function outperforms the AutoDock Vina scoring function when ranking poses both for pose prediction and virtual screening.	['Department of Computer Science, The College of New Jersey , Ewing, New Jersey 08628, United States.']	['10.1021/acs.jcim.6b00740 [doi]']	['Ragoza M', 'Hochuli J', 'Idrobo E', 'Sunseri J', 'Koes DR']	['ORCID: 0000-0002-6892-6614']						['2017/04/04 06:00']	20170921	20170411	2017 Apr 24	2017/04/04 06:00		['Ragoza, Matthew', 'Hochuli, Joshua', 'Idrobo, Elisa', 'Sunseri, Jocelyn', 'Koes, David Ryan']		['R01 GM108340/GM/NIGMS NIH HHS/United States', 'T32 EB009403/EB/NIBIB NIH HHS/United States']	4		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/acs.jcim.6b00740 [doi]	20181113	['Computational Biology/*methods', 'Drug Evaluation, Preclinical', 'Ligands', 'Models, Molecular', '*Neural Networks (Computer)', 'Protein Conformation', 'Proteins/chemistry/*metabolism', 'User-Computer Interface']	2017/09/22 06:00	['NIHMS865537']			NLM	942-957	['2017/04/04 06:00 [pubmed]', '2017/09/22 06:00 [medline]', '2017/04/04 06:00 [entrez]']	United States	PMC5479431		28368587	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Ligands)', '0 (Proteins)']	IM		J Chem Inf Model. 2017 Apr 24;57(4):942-957. doi: 10.1021/acs.jcim.6b00740. Epub 2017 Apr 11.	MEDLINE	J Chem Inf Model	Protein-Ligand Scoring with Convolutional Neural Networks.		57	Protein-Ligand Scoring with Convolutional Neural Networks.
To develop an advanced human-robot interaction system, it is important to first understand how human beings learn to perceive, think, and act in an ever-changing world. In this paper, we propose an intention understanding system that uses an Object Augmented-Supervised Multiple Timescale Recurrent Neural Network (OA-SMTRNN) and demonstrate the effects of perception-action connected learning in an artificial agent, which is inspired by psychological and neurological phenomena in humans. We believe that action and perception are not isolated processes in human mental development, and argue that these psychological and neurological interactions can be replicated in a human-machine scenario. The proposed OA-SMTRNN consists of perception and action modules and their connection, which are constructed of supervised multiple timescale recurrent neural networks and the deep auto-encoder, respectively, and connects their perception and action for understanding human intention. Our experimental results show the effects of perception-action connected learning, and demonstrate that robots can understand human intention with OA-SMTRNN through perception-action connected learning.	['School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu 702-701, Republic of Korea.', 'College of Information Science and Engineering, Ocean University of China (OUC), 238 Songling Road Qingdao, China.', 'School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu 702-701, Republic of Korea. Electronic address: mholee@gmail.com.']	['S0893-6080(17)30009-6 [pii]', '10.1016/j.neunet.2017.01.009 [doi]']	['Kim S', 'Yu Z', 'Lee M']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/03/21 06:00']	20180131	20170211	2017 Aug	2017/03/21 06:00		['Kim, Sangwook', 'Yu, Zhibin', 'Lee, Minho']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(17)30009-6 [pii] 10.1016/j.neunet.2017.01.009 [doi]	20181202	['Biometric Identification/methods', 'Humans', '*Intention', 'Movement', 'Neural Networks (Computer)', '*Posture', '*Support Vector Machine']	2018/02/01 06:00		['Affordance', 'Cognitive agent', 'Human-robot interaction', 'Intention understanding', 'Object-Augmented Multiple Timescale Recurrent Neural Network', 'Perception-action connected learning']	['NOTNLM']	NLM	29-38	['2016/09/01 00:00 [received]', '2017/01/20 00:00 [revised]', '2017/01/20 00:00 [accepted]', '2017/03/21 06:00 [pubmed]', '2018/02/01 06:00 [medline]', '2017/03/21 06:00 [entrez]']	United States			28318903	ppublish	['Journal Article']			IM		Neural Netw. 2017 Aug;92:29-38. doi: 10.1016/j.neunet.2017.01.009. Epub 2017 Feb 11.	MEDLINE	Neural Netw	Understanding human intention by connecting perception and action learning in artificial agents.		92	Understanding human intention by connecting perception and action learning in artificial agents.
"The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry. Yet almost two decades later, we are now seeing a resurgence of interest in deep learning, a machine learning algorithm based on multilayer neural networks. Within the last few years, we have seen the transformative impact of deep learning in many domains, particularly in speech recognition and computer vision, to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models. In this review, we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics. By providing an overview of the variety of emerging applications of deep neural networks, we highlight its ubiquity and broad applicability to a wide range of challenges in the field, including quantitative structure activity relationship, virtual screening, protein structure prediction, quantum chemistry, materials design, and property prediction. In reviewing the performance of deep neural networks, we observed a consistent outperformance against non-neural networks state-of-the-art models across disparate research topics, and deep neural network-based models often exceeded the ""glass ceiling"" expectations of their respective tasks. Coupled with the maturity of GPU-accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on, we anticipate that deep learning algorithms will be a valuable tool for computational chemistry. (c) 2017 Wiley Periodicals, Inc."	['Advanced Computing, Mathematics, and Data Division, Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, Washington, 99354.', 'Advanced Computing, Mathematics, and Data Division, Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, Washington, 99354.', 'Advanced Computing, Mathematics, and Data Division, Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, Washington, 99354.']	['10.1002/jcc.24764 [doi]']	['Goh GB', 'Hodas NO', 'Vishnu A']	['ORCID: 0000-0002-8858-0868']	['(c) 2017 Wiley Periodicals, Inc.']					['2017/03/09 06:00']		20170308	2017 Jun 15	2017/03/09 06:00		['Goh, Garrett B', 'Hodas, Nathan O', 'Vishnu, Abhinav']			16		1096-987X (Electronic) 0192-8651 (Linking)	9878362	Journal of computational chemistry	['eng']	10.1002/jcc.24764 [doi]	20191120		2017/03/09 06:01		['*artificial intelligence', '*cheminformatics', '*deep learning', '*machine learning', '*materials genome', '*molecular modeling', '*protein structure prediction', '*quantitative structure activity relationship', '*quantum chemistry', '*toxicology']	['NOTNLM']	NLM	1291-1307	['2016/09/14 00:00 [received]', '2017/01/09 00:00 [revised]', '2017/01/18 00:00 [accepted]', '2017/03/09 06:00 [pubmed]', '2017/03/09 06:01 [medline]', '2017/03/09 06:00 [entrez]']	United States			28272810	ppublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't""]"					J Comput Chem. 2017 Jun 15;38(16):1291-1307. doi: 10.1002/jcc.24764. Epub 2017 Mar 8.	PubMed-not-MEDLINE	J Comput Chem	Deep learning for computational chemistry.		38	Deep learning for computational chemistry.
BACKGROUND AND OBJECTIVES: Highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. Traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. The same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. In this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning. METHODS: We first apply domain transferred deep convolutional neural network for building a deep model; and then develop an overall deep learning architecture based on the raw pixels of original biomedical images using supervised training. In our model, we do not need the manual design of the feature space, seek an effective feature vector classifier or segment specific detection object and image patches, which are the main technological difficulties in the adoption of traditional image classification methods. Moreover, we do not need to be concerned with whether there are large training sets of annotated biomedical images, affordable parallel computing resources featuring GPUs or long times to wait for training a perfect deep model, which are the main problems to train deep neural networks for biomedical image classification as observed in recent works. RESULTS: With the utilization of a simple data augmentation method and fast convergence speed, our algorithm can achieve the best accuracy rate and outstanding classification ability for biomedical images. We have evaluated our classifier on several well-known public biomedical datasets and compared it with several state-of-the-art approaches. CONCLUSIONS: We propose a robust automated end-to-end classifier for biomedical images based on a domain transferred deep convolutional neural network model that shows a highly reliable and accurate performance which has been confirmed on several public biomedical image datasets.	['College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, NSW 2109, Australia. Electronic address: pangshuchao1212@sina.com.', 'College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China. Electronic address: yuzz@jlu.edu.cn.', 'Department of Computing, Macquarie University, Sydney, NSW 2109, Australia; Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macau. Electronic address: mehmet.orgun@mq.edu.au.']	['S0169-2607(16)31306-2 [pii]', '10.1016/j.cmpb.2016.12.019 [doi]']	['Pang S', 'Yu Z', 'Orgun MA']		['Copyright (c) 2017 Elsevier Ireland Ltd. All rights reserved.']					['2017/03/04 06:00']	20170411	20170106	2017 Mar	2017/03/04 06:00		['Pang, Shuchao', 'Yu, Zhezhou', 'Orgun, Mehmet A']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(16)31306-2 [pii] 10.1016/j.cmpb.2016.12.019 [doi]	20170411	['*Diagnostic Imaging', 'Machine Learning', 'Models, Theoretical', '*Neural Networks (Computer)']	2017/04/12 06:00		['Biomedical image classification', 'Convolutional neural network', 'Data augmentation', 'Deep learning', 'Transfer learning']	['NOTNLM']	NLM	283-293	['2016/11/22 00:00 [received]', '2016/12/31 00:00 [accepted]', '2017/03/04 06:00 [entrez]', '2017/03/04 06:00 [pubmed]', '2017/04/12 06:00 [medline]']	Ireland			28254085	ppublish	['Journal Article']			IM		Comput Methods Programs Biomed. 2017 Mar;140:283-293. doi: 10.1016/j.cmpb.2016.12.019. Epub 2017 Jan 6.	MEDLINE	Comput Methods Programs Biomed	A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images.		140	A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images.
In many computerized methods for cell detection, segmentation, and classification in digital histopathology that have recently emerged, the task of cell segmentation remains a chief problem for image processing in designing computer-aided diagnosis (CAD) systems. In research and diagnostic studies on cancer, pathologists can use CAD systems as second readers to analyze high-resolution histopathological images. Since cell detection and segmentation are critical for cancer grade assessments, cellular and extracellular structures should primarily be extracted from histopathological images. In response, we sought to identify a useful cell segmentation approach with histopathological images that uses not only prominent deep learning algorithms (i.e., convolutional neural networks, stacked autoencoders, and deep belief networks), but also spatial relationships, information of which is critical for achieving better cell segmentation results. To that end, we collected cellular and extracellular samples from histopathological images by windowing in small patches with various sizes. In experiments, the segmentation accuracies of the methods used improved as the window sizes increased due to the addition of local spatial and contextual information. Once we compared the effects of training sample size and influence of window size, results revealed that the deep learning algorithms, especially convolutional neural networks and partly stacked autoencoders, performed better than conventional methods in cell segmentation.	['Signal and Image Processing Lab. (SIMPLAB), YTU, Istanbul, Turkey.', 'Graduate School of Natural and Applied Science, Yildiz Technical University, 34220, Istanbul, Turkey.', 'Department of Computer Engineering, Yildiz Technical University (YTU), 34220, Istanbul, Turkey. gbilgin@yildiz.edu.tr.', 'Signal and Image Processing Lab. (SIMPLAB), YTU, Istanbul, Turkey. gbilgin@yildiz.edu.tr.']	['10.1007/s11517-017-1630-1 [doi]', '10.1007/s11517-017-1630-1 [pii]']	['Hatipoglu N', 'Bilgin G']	['ORCID: http://orcid.org/0000-0002-5532-477X']						['2017/03/02 06:00']	20180711	20170228	2017 Oct	2017/03/02 06:00		['Hatipoglu, Nuh', 'Bilgin, Gokhan']		['2014-04-01-KAP01/Yildiz Technical University, Scientific Research Projects', 'Coordination Department']	10		1741-0444 (Electronic) 0140-0118 (Linking)	7704869	Medical & biological engineering & computing	['eng']	10.1007/s11517-017-1630-1 [doi]	20181113	['Algorithms', 'Cell Separation/*methods', 'Humans', 'Image Processing, Computer-Assisted/methods', 'Machine Learning', 'Neural Networks (Computer)']	2018/07/12 06:00		['Computer-aided diagnosis systems', 'Deep learning algorithms', 'Histopathological images', 'Segmentation', 'Spatial relationships']	['NOTNLM']	NLM	1829-1848	['2016/07/27 00:00 [received]', '2017/02/13 00:00 [accepted]', '2017/03/02 06:00 [pubmed]', '2018/07/12 06:00 [medline]', '2017/03/02 06:00 [entrez]']	United States			28247185	ppublish	['Journal Article']			IM		Med Biol Eng Comput. 2017 Oct;55(10):1829-1848. doi: 10.1007/s11517-017-1630-1. Epub 2017 Feb 28.	MEDLINE	Med Biol Eng Comput	Cell segmentation in histopathological images with deep learning algorithms by utilizing spatial relationships.		55	Cell segmentation in histopathological images with deep learning algorithms by utilizing spatial relationships.
Advances in optical microscopy, biosensors and cell culturing technologies have transformed live cell imaging. Thanks to these advances live cell imaging plays an increasingly important role in basic biology research as well as at all stages of drug development. Image analysis methods are needed to extract quantitative information from these vast and complex data sets. The aim of this review is to provide an overview of available image analysis methods for live cell imaging, in particular required preprocessing image segmentation, cell tracking and data visualisation methods. The potential opportunities recent advances in machine learning, especially deep learning, and computer vision provide are being discussed. This review includes overview of the different available software packages and toolkits.	['Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, United Kingdom.', 'Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, United Kingdom.', 'Department of Biomedical Engineering, University of Virginia, Charlottesville, VA 22908, United States.', 'Computer Science and Engineering, The Ohio State University, 2015 Neil Ave, Columbus, OH 43210, United States.', 'Institute of Biomedical Engineering, Department of Engineering Science, Old Road Campus Research Building, University of Oxford, Headington, Oxford OX3 7DQ, United Kingdom; Ludwig Institute for Cancer Research, University of Oxford, Nuffield Department of Medicine, Old Road Campus Research Building, Oxford OX3 7DQ, United Kingdom; Target Discovery Institute, NDM Research Building, University of Oxford, Old Road Campus, Headington OX3 7FZ, United Kingdom. Electronic address: jens.rittscher@eng.ox.ac.uk.']	['S1046-2023(17)30083-X [pii]', '10.1016/j.ymeth.2017.02.007 [doi]']	['Nketia TA', 'Sailem H', 'Rohde G', 'Machiraju R', 'Rittscher J']		['Copyright (c) 2017. Published by Elsevier Inc.']					['2017/03/01 06:00']	20180207	20170227	2017 Feb 15	2017/03/01 06:00		['Nketia, Thomas A', 'Sailem, Heba', 'Rohde, Gustavo', 'Machiraju, Raghu', 'Rittscher, Jens']					1095-9130 (Electronic) 1046-2023 (Linking)	9426302	Methods (San Diego, Calif.)	['eng']	S1046-2023(17)30083-X [pii] 10.1016/j.ymeth.2017.02.007 [doi]	20180522	['Animals', 'Biosensing Techniques/instrumentation/methods', 'Cell Culture Techniques', 'Cell Tracking/instrumentation/methods', 'Eukaryotic Cells/metabolism/ultrastructure', 'Humans', 'Image Processing, Computer-Assisted/*methods/statistics & numerical data', '*Machine Learning', 'Microscopy/instrumentation/*methods', 'Molecular Imaging/instrumentation/*methods', 'Signal-To-Noise Ratio', '*Software']	2018/02/08 06:00		['*Biological image analysis', '*Cell segmentation', '*Cell tracking', '*Live cell imaging', '*Machine learning', '*Quantitative biological imaging']	['NOTNLM']	NLM	65-79	['2016/10/04 00:00 [received]', '2017/02/20 00:00 [revised]', '2017/02/21 00:00 [accepted]', '2017/03/01 06:00 [pubmed]', '2018/02/08 06:00 [medline]', '2017/03/01 06:00 [entrez]']	United States			28242295	ppublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't""]"			IM		Methods. 2017 Feb 15;115:65-79. doi: 10.1016/j.ymeth.2017.02.007. Epub 2017 Feb 27.	MEDLINE	Methods	Analysis of live cell images: Methods, tools and opportunities.		115	Analysis of live cell images: Methods, tools and opportunities.
We introduce DeepNAT, a 3D Deep convolutional neural network for the automatic segmentation of NeuroAnaTomy in T1-weighted magnetic resonance images. DeepNAT is an end-to-end learning-based approach to brain segmentation that jointly learns an abstract feature representation and a multi-class classification. We propose a 3D patch-based approach, where we do not only predict the center voxel of the patch but also neighbors, which is formulated as multi-task learning. To address a class imbalance problem, we arrange two networks hierarchically, where the first one separates foreground from background, and the second one identifies 25 brain structures on the foreground. Since patches lack spatial context, we augment them with coordinates. To this end, we introduce a novel intrinsic parameterization of the brain volume, formed by eigenfunctions of the Laplace-Beltrami operator. As network architecture, we use three convolutional layers with pooling, batch normalization, and non-linearities, followed by fully connected layers with dropout. The final segmentation is inferred from the probabilistic output of the network with a 3D fully connected conditional random field, which ensures label agreement between close voxels. The roughly 2.7million parameters in the network are learned with stochastic gradient descent. Our results show that DeepNAT compares favorably to state-of-the-art methods. Finally, the purely learning-based method may have a high potential for the adaptation to young, old, or diseased brains by fine-tuning the pre-trained network with a small training sample on the target application, where the availability of larger datasets with manual annotations may boost the overall segmentation accuracy in the future.	['Department of Child and Adolescent Psychiatry, Psychosomatic and Psychotherapy, Ludwig-Maximilian-University, Waltherstr. 23, 81369 Munchen, Munich, Germany. Electronic address: christian.wachinger@med.uni-muenchen.de.', 'Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; German Centre for Neurodegenerative Diseases (DZNE), Department of Image Analysis, Bonn, Germany.', 'SAP SE, Berlin, Germany.']	['S1053-8119(17)30146-5 [pii]', '10.1016/j.neuroimage.2017.02.035 [doi]']	['Wachinger C', 'Reuter M', 'Klein T']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/02/23 06:00']	20181211	20170220	2018 Apr 15	2017/02/23 06:00		['Wachinger, Christian', 'Reuter, Martin', 'Klein, Tassilo']		['K25 CA181632/CA/NCI NIH HHS/United States', 'P50 AG005134/AG/NIA NIH HHS/United States']			1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(17)30146-5 [pii] 10.1016/j.neuroimage.2017.02.035 [doi]	20191008	['Brain/*anatomy & histology/*diagnostic imaging', 'Deep Learning', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Machine Learning', 'Magnetic Resonance Imaging/*methods', '*Neural Networks (Computer)', 'Neuroimaging/*methods']	2018/12/12 06:00	['NIHMS858477']	['*Brain segmentation', '*Conditional random field', '*Convolutional neural networks', '*Deep learning', '*Multi-task learning']	['NOTNLM']	NLM	434-445	['2016/10/25 00:00 [received]', '2017/02/13 00:00 [revised]', '2017/02/13 00:00 [accepted]', '2017/02/23 06:00 [pubmed]', '2018/12/12 06:00 [medline]', '2017/02/23 06:00 [entrez]']	United States	PMC5563492		28223187	ppublish	"['Evaluation Studies', 'Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			IM		Neuroimage. 2018 Apr 15;170:434-445. doi: 10.1016/j.neuroimage.2017.02.035. Epub 2017 Feb 20.	MEDLINE	Neuroimage	DeepNAT: Deep convolutional neural network for segmenting neuroanatomy.		170	DeepNAT: Deep convolutional neural network for segmenting neuroanatomy.
Differentiation alters molecular properties of stem and progenitor cells, leading to changes in their shape and movement characteristics. We present a deep neural network that prospectively predicts lineage choice in differentiating primary hematopoietic progenitors using image patches from brightfield microscopy and cellular movement. Surprisingly, lineage choice can be detected up to three generations before conventional molecular markers are observable. Our approach allows identification of cells with differentially expressed lineage-specifying genes without molecular labeling.	['Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, CB10 1SD Hinxton, Cambridge, UK.', 'Department of Biosystems Science and Engineering (D-BSSE), ETH Zurich, 4058 Basel, Switzerland.', 'Research Unit Stem Cell Dynamics, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Biosystems Science and Engineering (D-BSSE), ETH Zurich, 4058 Basel, Switzerland.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Mathematics, Technische Universitat Munchen, 85748 Garching, Germany.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Biosystems Science and Engineering (D-BSSE), ETH Zurich, 4058 Basel, Switzerland.', 'Research Unit Stem Cell Dynamics, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Biosystems Science and Engineering (D-BSSE), ETH Zurich, 4058 Basel, Switzerland.', 'Research Unit Stem Cell Dynamics, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Biosystems Science and Engineering (D-BSSE), ETH Zurich, 4058 Basel, Switzerland.', 'Research Unit Stem Cell Dynamics, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Biosystems Science and Engineering (D-BSSE), ETH Zurich, 4058 Basel, Switzerland.', 'Research Unit Stem Cell Dynamics, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.', 'Department of Mathematics, Technische Universitat Munchen, 85748 Garching, Germany.', 'Institute of Computational Biology, Helmholtz Zentrum Munchen - German Research Center for Environmental Health, 85764 Neuherberg, Germany.']	['10.1038/nmeth.4182 [doi]']	['Buggenthin F', 'Buettner F', 'Hoppe PS', 'Endele M', 'Kroiss M', 'Strasser M', 'Schwarzfischer M', 'Loeffler D', 'Kokkaliaris KD', 'Hilsenbeck O', 'Schroeder T', 'Theis FJ', 'Marr C']			['Cell Syst. 2017 Mar 22;4(3):260-261. PMID: 28334574']				['2017/02/21 06:00']	20170706	20170220	2017 Apr	2017/02/22 06:00		['Buggenthin, Felix', 'Buettner, Florian', 'Hoppe, Philipp S', 'Endele, Max', 'Kroiss, Manuel', 'Strasser, Michael', 'Schwarzfischer, Michael', 'Loeffler, Dirk', 'Kokkaliaris, Konstantinos D', 'Hilsenbeck, Oliver', 'Schroeder, Timm', 'Theis, Fabian J', 'Marr, Carsten']		['MR/M01536X/1/Medical Research Council/United Kingdom']	4		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/nmeth.4182 [doi]	20181113	['Animals', 'Area Under Curve', 'Biomarkers/metabolism', 'Cell Differentiation', 'Cell Lineage', 'Gene Knock-In Techniques', 'Hematopoietic Stem Cells/*cytology/*physiology', 'Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Male', 'Mice, Mutant Strains', '*Neural Networks (Computer)', 'Proto-Oncogene Proteins/genetics/metabolism', 'Time-Lapse Imaging/*methods', 'Trans-Activators/genetics/metabolism']	2017/07/07 06:00	['EMS71148']			NLM	403-406	['2015/10/21 00:00 [received]', '2017/01/17 00:00 [accepted]', '2017/02/22 06:00 [pubmed]', '2017/07/07 06:00 [medline]', '2017/02/21 06:00 [entrez]']	United States	PMC5376497		28218899	ppublish	['Journal Article']		['0 (Biomarkers)', '0 (Proto-Oncogene Proteins)', '0 (Trans-Activators)', '0 (proto-oncogene protein Spi-1)']	IM		Nat Methods. 2017 Apr;14(4):403-406. doi: 10.1038/nmeth.4182. Epub 2017 Feb 20.	MEDLINE	Nat Methods	Prospective identification of hematopoietic lineage choice by deep learning.		14	Prospective identification of hematopoietic lineage choice by deep learning.
BACKGROUND: The recent success of deep learning techniques in machine learning and artificial intelligence has stimulated a great deal of interest among bioinformaticians, who now wish to bring the power of deep learning to bare on a host of bioinformatical problems. Deep learning is ideally suited for biological problems that require automatic or hierarchical feature representation for biological data when prior knowledge is limited. In this work, we address the sequence-specific bias correction problem for RNA-seq data redusing Recurrent Neural Networks (RNNs) to model nucleotide sequences without pre-determining sequence structures. The sequence-specific bias of a read is then calculated based on the sequence probabilities estimated by RNNs, and used in the estimation of gene abundance. RESULT: We explore the application of two popular RNN recurrent units for this task and demonstrate that RNN-based approaches provide a flexible way to model nucleotide sequences without knowledge of predetermined sequence structures. Our experiments show that training a RNN-based nucleotide sequence model is efficient and RNN-based bias correction methods compare well with the-state-of-the-art sequence-specific bias correction method on the commonly used MAQC-III data set. CONCLUSTIONS: RNNs provides an alternative and flexible way to calculate sequence-specific bias without explicitly pre-determining sequence structures.	['The Institute of Medical Science, The University of Tokyo, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan.', 'The Institute of Medical Science, The University of Tokyo, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan.', 'The Institute of Medical Science, The University of Tokyo, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan.', 'The Institute of Medical Science, The University of Tokyo, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan. miyano@ims.u-tokyo.ac.jp.']	['10.1186/s12864-016-3262-5 [doi]', '10.1186/s12864-016-3262-5 [pii]']	['Zhang YZ', 'Yamaguchi R', 'Imoto S', 'Miyano S']							['2017/02/16 06:00']	20170911	20170125	2017 Jan 25	2017/02/16 06:00		['Zhang, Yao-Zhong', 'Yamaguchi, Rui', 'Imoto, Seiya', 'Miyano, Satoru']			Suppl 1		1471-2164 (Electronic) 1471-2164 (Linking)	100965258	BMC genomics	['eng']	10.1186/s12864-016-3262-5 [doi]	20190109	['Algorithms', 'Bias', 'Computational Biology/*methods/*standards', 'Gene Expression Profiling', 'Humans', 'Models, Statistical', '*Neural Networks (Computer)', 'Sequence Analysis, RNA/*methods/*standards']	2017/09/12 06:00		['*Gene expression analysis', '*RNA-seq', '*Recurrent neural network', '*Sequence-specific bias']	['NOTNLM']	NLM	1044	['2017/02/16 06:00 [entrez]', '2017/02/16 06:00 [pubmed]', '2017/09/12 06:00 [medline]']	England	PMC5310274		28198674	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		BMC Genomics. 2017 Jan 25;18(Suppl 1):1044. doi: 10.1186/s12864-016-3262-5.	MEDLINE	BMC Genomics	Sequence-specific bias correction for RNA-seq data using recurrent neural networks.		18	Sequence-specific bias correction for RNA-seq data using recurrent neural networks.
BACKGROUND: When left untreated, age-related macular degeneration (AMD) is the leading cause of vision loss in people over fifty in the US. Currently it is estimated that about eight million US individuals have the intermediate stage of AMD that is often asymptomatic with regard to visual deficit. These individuals are at high risk for progressing to the advanced stage where the often treatable choroidal neovascular form of AMD can occur. Careful monitoring to detect the onset and prompt treatment of the neovascular form as well as dietary supplementation can reduce the risk of vision loss from AMD, therefore, preferred practice patterns recommend identifying individuals with the intermediate stage in a timely manner. METHODS: Past automated retinal image analysis (ARIA) methods applied on fundus imagery have relied on engineered and hand-designed visual features. We instead detail the novel application of a machine learning approach using deep learning for the problem of ARIA and AMD analysis. We use transfer learning and universal features derived from deep convolutional neural networks (DCNN). We address clinically relevant 4-class, 3-class, and 2-class AMD severity classification problems. RESULTS: Using 5664 color fundus images from the NIH AREDS dataset and DCNN universal features, we obtain values for accuracy for the (4-, 3-, 2-) class classification problem of (79.4%, 81.5%, 93.4%) for machine vs. (75.8%, 85.0%, 95.2%) for physician grading. DISCUSSION: This study demonstrates the efficacy of machine grading based on deep universal features/transfer learning when applied to ARIA and is a promising step in providing a pre-screener to identify individuals with intermediate AMD and also as a tool that can facilitate identifying such individuals for clinical studies aimed at developing improved therapies. It also demonstrates comparable performance between computer and physician grading.	['Applied Physics Laboratory, The Johns Hopkins University, MD, USA; Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, USA; Department of Computer Science, The Johns Hopkins University, MD, USA.', 'Retina Division, Brazilian Center of Vision Eye Hospital, DF, Brazil.', 'Applied Physics Laboratory, The Johns Hopkins University, MD, USA.', 'Applied Physics Laboratory, The Johns Hopkins University, MD, USA. Electronic address: David.Freund@jhuapl.edu.', 'Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, USA.']	['S0010-4825(17)30024-0 [pii]', '10.1016/j.compbiomed.2017.01.018 [doi]']	['Burlina P', 'Pacheco KD', 'Joshi N', 'Freund DE', 'Bressler NM']		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/02/08 06:00']	20171204	20170127	2017 Mar 1	2017/02/09 06:00		['Burlina, Philippe', 'Pacheco, Katia D', 'Joshi, Neil', 'Freund, David E', 'Bressler, Neil M']		['R21 EY024310/EY/NEI NIH HHS/United States']			1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(17)30024-0 [pii] 10.1016/j.compbiomed.2017.01.018 [doi]	20181113	['*Algorithms', 'Early Diagnosis', 'Fluorescein Angiography/*methods', 'Humans', 'Image Interpretation, Computer-Assisted', '*Machine Learning', 'Macular Degeneration/classification/*diagnostic imaging/*pathology', 'Observer Variation', 'Pattern Recognition, Automated/*methods', 'Reproducibility of Results', 'Sensitivity and Specificity', 'Severity of Illness Index']	2017/12/05 06:00	['NIHMS849294']	['*Age-related macular degeneration, (AMD)', '*Deep Convolutional Neural Networks, (DCNNs)', '*Deep learning', '*Retinal image analysis', '*Transfer learning', '*Universal features']	['NOTNLM']	NLM	80-86	['2016/11/03 00:00 [received]', '2017/01/18 00:00 [revised]', '2017/01/26 00:00 [accepted]', '2017/02/09 06:00 [pubmed]', '2017/12/05 06:00 [medline]', '2017/02/08 06:00 [entrez]']	United States	PMC5373654		28167406	ppublish	['Comparative Study', 'Evaluation Studies', 'Journal Article']			IM		Comput Biol Med. 2017 Mar 1;82:80-86. doi: 10.1016/j.compbiomed.2017.01.018. Epub 2017 Jan 27.	MEDLINE	Comput Biol Med	Comparing humans and deep learning performance for grading AMD: A study in using universal deep features and transfer learning for automated AMD analysis.		82	Comparing humans and deep learning performance for grading AMD: A study in using universal deep features and transfer learning for automated AMD analysis.
BACKGROUND: Non-intrusive inspection systems based on X-ray radiography techniques are routinely used at transport hubs to ensure the conformity of cargo content with the supplied shipping manifest. As trade volumes increase and regulations become more stringent, manual inspection by trained operators is less and less viable due to low throughput. Machine vision techniques can assist operators in their task by automating parts of the inspection workflow. Since cars are routinely involved in trafficking, export fraud, and tax evasion schemes, they represent an attractive target for automated detection and flagging for subsequent inspection by operators. OBJECTIVE: Development and evaluation of a novel method for the automated detection of cars in complex X-ray cargo imagery. METHODS: X-ray cargo images from a stream-of-commerce dataset were classified using a window-based scheme. The limited number of car images was addressed by using an oversampling scheme. Different Convolutional Neural Network (CNN) architectures were compared with well-established bag of words approaches. In addition, robustness to concealment was evaluated by projection of objects into car images. RESULTS: CNN approaches outperformed all other methods evaluated, achieving 100% car image classification rate for a false positive rate of 1-in-454. Cars that were partially or completely obscured by other goods, a modus operandi frequently adopted by criminals, were correctly detected. CONCLUSIONS: We believe that this level of performance suggests that the method is suitable for deployment in the field. It is expected that the generic object detection workflow described can be extended to other object classes given the availability of suitable training data.	['Department of Computer Science, University College London, London, UK.', 'Department of Computer Science, University College London, London, UK.', 'Department of Security and Crime Sciences, University College London, London, UK.', 'Rapiscan Systems Ltd., Stoke-On-Trent, UK.', 'Department of Computer Science, University College London, London, UK.']	['XST16199 [pii]', '10.3233/XST-16199 [doi]']	['Jaccard N', 'Rogers TW', 'Morton EJ', 'Griffin LD']							['2017/02/04 06:00']	20180319		2017	2017/02/06 06:00		['Jaccard, Nicolas', 'Rogers, Thomas W', 'Morton, Edward J', 'Griffin, Lewis D']			3		1095-9114 (Electronic) 0895-3996 (Linking)	9000080	Journal of X-ray science and technology	['eng']	10.3233/XST-16199 [doi]	20180518	['*Automobiles', 'Humans', '*Machine Learning', 'Radiographic Image Enhancement/*methods', 'Radiography/*methods', '*Security Measures']	2018/03/20 06:00		['*Classification', '*Deep Learning', '*Security', '*X-ray cargo image']	['NOTNLM']	NLM	323-339	['2017/02/06 06:00 [pubmed]', '2018/03/20 06:00 [medline]', '2017/02/04 06:00 [entrez]']	Netherlands			28157116	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Xray Sci Technol. 2017;25(3):323-339. doi: 10.3233/XST-16199.	MEDLINE	J Xray Sci Technol	Detection of concealed cars in complex cargo X-ray imagery using Deep Learning.		25	Detection of concealed cars in complex cargo X-ray imagery using Deep Learning.
High-grade glioma is the most aggressive and severe brain tumor that leads to death of almost 50% patients in 1-2 years. Thus, accurate prognosis for glioma patients would provide essential guidelines for their treatment planning. Conventional survival prediction generally utilizes clinical information and limited handcrafted features from magnetic resonance images (MRI), which is often time consuming, laborious and subjective. In this paper, we propose using deep learning frameworks to automatically extract features from multi-modal preoperative brain images (i.e., T1 MRI, fMRI and DTI) of high-grade glioma patients. Specifically, we adopt 3D convolutional neural networks (CNNs) and also propose a new network architecture for using multi-channel data and learning supervised features. Along with the pivotal clinical features, we finally train a support vector machine to predict if the patient has a long or short overall survival (OS) time. Experimental results demonstrate that our methods can achieve an accuracy as high as 89.9% We also find that the learned features from fMRI and DTI play more important roles in accurately predicting the OS time, which provides valuable insights into functional neuro-oncological applications.	['Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, USA.', 'Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, USA.']	['10.1007/978-3-319-46723-8_25 [doi]']	['Nie D', 'Zhang H', 'Adeli E', 'Liu L', 'Shen D']							['2017/02/03 06:00']	20181211	20161002	2016 Oct	2017/02/06 06:00		['Nie, Dong', 'Zhang, Han', 'Adeli, Ehsan', 'Liu, Luyan', 'Shen, Dinggang']		['R01 EB008374/EB/NIBIB NIH HHS/United States']				101249582	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	['eng']	10.1007/978-3-319-46723-8_25 [doi]	20181211	['*Algorithms', 'Brain/diagnostic imaging', 'Brain Neoplasms/*diagnostic imaging/mortality/pathology', '*Deep Learning', 'Glioma/*diagnostic imaging/mortality/pathology', 'Humans', '*Life Expectancy', 'Magnetic Resonance Imaging/*methods', 'Multimodal Imaging/*methods', 'Neoplasm Grading', 'Neural Networks (Computer)', 'Prognosis', 'Reproducibility of Results', 'Sensitivity and Specificity']	2018/12/12 06:00	['NIHMS833625']			NLM	212-220	['2017/02/03 06:00 [entrez]', '2017/02/06 06:00 [pubmed]', '2018/12/12 06:00 [medline]']	Germany	PMC5278791		28149967	ppublish	['Journal Article']			IM		Med Image Comput Comput Assist Interv. 2016 Oct;9901:212-220. doi: 10.1007/978-3-319-46723-8_25. Epub 2016 Oct 2.	MEDLINE	Med Image Comput Comput Assist Interv	3D Deep Learning for Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients.		9901	3D Deep Learning for Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients.
We provide a comprehensive account of recent advances in biomedical image analysis and classification from two complementary imaging modalities: terahertz (THz) pulse imaging and dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI). The work aims to highlight underlining commonalities in both data structures so that a common multi-channel data fusion framework can be developed. Signal pre-processing in both datasets is discussed briefly taking into consideration advances in multi-resolution analysis and model based fractional order calculus system identification. Developments in statistical signal processing using principal component and independent component analysis are also considered. These algorithms have been developed independently by the THz-pulse imaging and DCE-MRI communities, and there is scope to place them in a common multi-channel framework to provide better software standardization at the pre-processing de-noising stage. A comprehensive discussion of feature selection strategies is also provided and the importance of preserving textural information is highlighted. Feature extraction and classification methods taking into consideration recent advances in support vector machine (SVM) and extreme learning machine (ELM) classifiers and their complex extensions are presented. An outlook on Clifford algebra classifiers and deep learning techniques suitable to both types of datasets is also provided. The work points toward the direction of developing a new unified multi-channel signal processing framework for biomedical image analysis that will explore synergies from both sensing modalities for inferring disease proliferation.	['Centre of Applied Informatics, College of Engineering and Science, Victoria University, Melbourne, VIC 8001, Australia. Electronic address: xiaoxia.yin@vu.edu.au.', 'Centre of Applied Informatics, College of Engineering and Science, Victoria University, Melbourne, VIC 8001, Australia; School of Computer Science, Fudan University, Shanghai, China. Electronic address: yanchun.zhang@vu.edu.au.', 'Nanjing University of Finance and Economics school of Computer Science, Nanjing, China.', 'Department of Radiology, Affiliated Zhongshan Hospital of Dalian University, Dalian, Liaoning, China. Electronic address: wujianlin@vip.163.com.', 'School of Biological Sciences and Department of Bioengineering, University of Reading, Reading RG6 6AY, UK. Electronic address: s.hadjiloucas@reading.ac.uk.']	['S0169-2607(15)30099-7 [pii]', '10.1016/j.cmpb.2016.08.026 [doi]']	['Yin XX', 'Zhang Y', 'Cao J', 'Wu JL', 'Hadjiloucas S']		['Copyright (c) 2016 Elsevier Ireland Ltd. All rights reserved.']					['2017/01/24 06:00']	20170411	20160913	2016 Dec	2017/01/24 06:00		['Yin, X-X', 'Zhang, Y', 'Cao, J', 'Wu, J-L', 'Hadjiloucas, S']					1872-7565 (Electronic) 0169-2607 (Linking)	8506513	Computer methods and programs in biomedicine	['eng']	S0169-2607(15)30099-7 [pii] 10.1016/j.cmpb.2016.08.026 [doi]	20170411	['Humans', '*Learning', 'Magnetic Resonance Imaging/*methods', 'Models, Theoretical', 'Support Vector Machine']	2017/04/12 06:00		['Complex extreme learning machine', 'Deep learning', 'MRI', 'THz imaging', 'Wavelet analysis']	['NOTNLM']	NLM	87-114	['2015/08/10 00:00 [received]', '2016/07/23 00:00 [revised]', '2016/08/31 00:00 [accepted]', '2017/01/24 06:00 [entrez]', '2017/01/24 06:00 [pubmed]', '2017/04/12 06:00 [medline]']	Ireland			28110743	ppublish	['Journal Article', 'Review']			IM		Comput Methods Programs Biomed. 2016 Dec;137:87-114. doi: 10.1016/j.cmpb.2016.08.026. Epub 2016 Sep 13.	MEDLINE	Comput Methods Programs Biomed	Exploring the complementarity of THz pulse imaging and DCE-MRIs: Toward a unified multi-channel classification and a deep learning framework.		137	Exploring the complementarity of THz pulse imaging and DCE-MRIs: Toward a unified multi-channel classification and a deep learning framework.
This paper proposes a computer-aided cirrhosis diagnosis system to diagnose cirrhosis based on ultrasound images. We first propose a method to extract a liver capsule on an ultrasound image, then, based on the extracted liver capsule, we fine-tune a deep convolutional neural network (CNN) model to extract features from the image patches cropped around the liver capsules. Finally, a trained support vector machine (SVM) classifier is applied to classify the sample into normal or abnormal cases. Experimental results show that the proposed method can effectively extract the liver capsules and accurately classify the ultrasound images.	['School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai 201203, China. xiangliu09@fudan.edu.cn.', 'School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai 201620, China. xiangliu09@fudan.edu.cn.', 'Department of ultrasound, Changzheng Hospital Affiliated to Second Military Medical University, Shanghai 200003, China. jialin19810818@126.com.', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai 201203, China. sh_wang@fudan.edu.cn.', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai 201203, China. jingwenzhao13@fudan.edu.cn.', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai 201203, China. chenyq@fudan.edu.cn.']	['s17010149 [pii]', '10.3390/s17010149 [doi]']	['Liu X', 'Song JL', 'Wang SH', 'Zhao JW', 'Chen YQ']					['The authors declare no conflict of interest.']		['2017/01/19 06:00']	20180517	20170113	2017 Jan 13	2017/01/19 06:00		['Liu, Xiang', 'Song, Jia Lin', 'Wang, Shuo Hong', 'Zhao, Jing Wen', 'Chen, Yan Qiu']			1		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E149 [pii] 10.3390/s17010149 [doi]	20190109	['Humans', '*Liver Cirrhosis', 'Neural Networks (Computer)', 'Support Vector Machine', 'Ultrasonography']	2018/05/18 06:00		['cirrhosis', 'computer-aided diagnosis', 'convolutional neural network', 'ultrasound imaging']	['NOTNLM']	NLM		['2016/11/20 00:00 [received]', '2016/12/27 00:00 [revised]', '2017/01/10 00:00 [accepted]', '2017/01/19 06:00 [entrez]', '2017/01/19 06:00 [pubmed]', '2018/05/18 06:00 [medline]']	Switzerland	PMC5298722		28098774	epublish	['Journal Article']			IM		Sensors (Basel). 2017 Jan 13;17(1). pii: s17010149. doi: 10.3390/s17010149.	MEDLINE	Sensors (Basel)	Learning to Diagnose Cirrhosis with Liver Capsule Guided Ultrasound Image Classification.		17	Learning to Diagnose Cirrhosis with Liver Capsule Guided Ultrasound Image Classification.
Early detection of prostate cancer increases chances of patients' survival. Our automated non-invasive system for computer-aided diagnosis (CAD) of prostate cancer segments the prostate on diffusion-weighted magnetic resonance images (DW-MRI) acquired at different b-values, estimates its apparent diffusion coefficients (ADC), and classifies their descriptors - empirical cumulative distribution functions (CDF) - with a trained deep learning network. To segment the prostate, an evolving geometric (level-set-based) deformable model is guided by a speed function depending on intensity attributes extracted from the DW-MRI with nonnegative matrix factorization (NMF). For a more robust evolution, the attributes are fused with a probabilistic shape prior and estimated spatial dependencies between prostate voxels. To preserve continuity, the ADCs of the segmented prostate volume at different b-values are normalized and refined using a generalized Gauss-Markov random field image model. The CDFs of the refined ADCs at different b-values are considered global water diffusion features and used to distinguish between benign and malignant prostates. A deep learning network of stacked non-negativity-constrained auto-encoders (SNCAE) is trained to classify the benign or malignant prostates on the basis of the constructed CDFs. Our experiments on 53 clinical DW-MRI data sets resulted in 92.3% accuracy, 83.3% sensitivity, and 100% specificity, indicating that the proposed CAD system could be used as a reliable non-invasive diagnostic tool.	['Faculty of Computers and Information, Mansoura University, Mansoura 35516, Egypt; Bioengineering Department, University of Louisville, Louisville KY 40292, USA.', 'Bioengineering Department, University of Louisville, Louisville KY 40292, USA.', 'Faculty of Computers and Information, Mansoura University, Mansoura 35516, Egypt; Bioengineering Department, University of Louisville, Louisville KY 40292, USA.', 'Faculty of Computers and Information, Mansoura University, Mansoura 35516, Egypt.', 'Bioengineering Department, University of Louisville, Louisville KY 40292, USA; Electronics and Communication Engineering Department, Mansoura University, Mansoura, Egypt.', 'Radiology Department, Urology and Nephrology Center, University of Mansoura, Egypt.', 'Electrical and Computer Engineering, University of Louisville, Louisville KY 40292, USA.', 'Department of Computer Science, University of Auckland, Auckland, New Zealand.', 'Khalifa University of Science Technology and Research, Abu Dhabi, UAE.', 'Bioengineering Department, University of Louisville, Louisville KY 40292, USA. Electronic address: aselba01@louisville.edu.']	['S0010-4825(16)30330-4 [pii]', '10.1016/j.compbiomed.2016.12.010 [doi]']	"['Reda I', 'Shalaby A', 'Elmogy M', 'Elfotouh AA', 'Khalifa F', 'El-Ghar MA', 'Hosseini-Asl E', ""Gimel'farb G"", 'Werghi N', 'El-Baz A']"		['Copyright (c) 2017 Elsevier Ltd. All rights reserved.']					['2017/01/08 06:00']	20171204	20161223	2017 Feb 1	2017/01/08 06:00		"['Reda, Islam', 'Shalaby, Ahmed', 'Elmogy, Mohammed', 'Elfotouh, Ahmed Abou', 'Khalifa, Fahmi', 'El-Ghar, Mohamed Abou', 'Hosseini-Asl, Ehsan', ""Gimel'farb, Georgy"", 'Werghi, Naoufel', 'El-Baz, Ayman']"					1879-0534 (Electronic) 0010-4825 (Linking)	1250250	Computers in biology and medicine	['eng']	S0010-4825(16)30330-4 [pii] 10.1016/j.compbiomed.2016.12.010 [doi]	20180420	['*Algorithms', 'Diffusion Magnetic Resonance Imaging/*methods', 'Early Detection of Cancer/*methods', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Machine Learning', 'Male', 'Pattern Recognition, Automated/*methods', 'Prostatic Neoplasms/*diagnosis/pathology', 'ROC Curve', 'Reproducibility of Results', 'Sensitivity and Specificity']	2017/12/05 06:00		['*CAD', '*DW-MRI', '*MGRF', '*NMF', '*Prostate cancer']	['NOTNLM']	NLM	148-158	['2016/09/21 00:00 [received]', '2016/12/16 00:00 [revised]', '2016/12/17 00:00 [accepted]', '2017/01/08 06:00 [pubmed]', '2017/12/05 06:00 [medline]', '2017/01/08 06:00 [entrez]']	United States			28063376	ppublish	['Evaluation Studies', 'Journal Article']			IM		Comput Biol Med. 2017 Feb 1;81:148-158. doi: 10.1016/j.compbiomed.2016.12.010. Epub 2016 Dec 23.	MEDLINE	Comput Biol Med	A comprehensive non-invasive framework for diagnosing prostate cancer.		81	A comprehensive non-invasive framework for diagnosing prostate cancer.
This review aims at providing a practical overview of the use of statistical features and associated data science methods in bioimage informatics. To achieve a quantitative link between images and biological concepts, one typically replaces an object coming from an image (a segmented cell or intracellular object, a pattern of expression or localisation, even a whole image) by a vector of numbers. They range from carefully crafted biologically relevant measurements to features learnt through deep neural networks. This replacement allows for the use of practical algorithms for visualisation, comparison and inference, such as the ones from machine learning or multivariate statistics. While originating mainly, for biology, in high content screening, those methods are integral to the use of data science for the quantitative analysis of microscopy images to gain biological insight, and they are sure to gather more interest as the need to make sense of the increasing amount of acquired imaging data grows more pressing.	['LOB, Ecole Polytechnique, CNRS, INSERM, Universite Paris-Saclay, 91128 Palaiseau cedex, France. Electronic address: anatole.chessel@polytechnique.edu.']	['S1046-2023(16)30508-4 [pii]', '10.1016/j.ymeth.2016.12.014 [doi]']	['Chessel A']		['Copyright (c) 2017 Elsevier Inc. All rights reserved.']					['2017/01/07 06:00']	20180207	20170103	2017 Feb 15	2017/01/07 06:00		['Chessel, Anatole']					1095-9130 (Electronic) 1046-2023 (Linking)	9426302	Methods (San Diego, Calif.)	['eng']	S1046-2023(16)30508-4 [pii] 10.1016/j.ymeth.2016.12.014 [doi]	20180522	['Analysis of Variance', 'Computational Biology/methods/*statistics & numerical data', 'Humans', 'Image Processing, Computer-Assisted/methods/*statistics & numerical data', 'Information Dissemination/methods', 'Information Storage and Retrieval/methods', '*Machine Learning', 'Microscopy, Fluorescence/*statistics & numerical data', 'Pattern Recognition, Automated/*statistics & numerical data']	2018/02/08 06:00		['*Bioimage informatics', '*Data science', '*High content screening', '*Image analysis']	['NOTNLM']	NLM	110-118	['2016/08/31 00:00 [received]', '2016/12/09 00:00 [revised]', '2016/12/30 00:00 [accepted]', '2017/01/07 06:00 [pubmed]', '2018/02/08 06:00 [medline]', '2017/01/07 06:00 [entrez]']	United States			28057585	ppublish	['Journal Article', 'Review']			IM		Methods. 2017 Feb 15;115:110-118. doi: 10.1016/j.ymeth.2016.12.014. Epub 2017 Jan 3.	MEDLINE	Methods	An Overview of data science uses in bioimage informatics.		115	An Overview of data science uses in bioimage informatics.
Summary: Protein quality assessment is a long-standing problem in bioinformatics. For more than a decade we have developed state-of-art predictors by carefully selecting and optimising inputs to a machine learning method. The correlation has increased from 0.60 in ProQ to 0.81 in ProQ2 and 0.85 in ProQ3 mainly by adding a large set of carefully tuned descriptions of a protein. Here, we show that a substantial improvement can be obtained using exactly the same inputs as in ProQ2 or ProQ3 but replacing the support vector machine by a deep neural network. This improves the Pearson correlation to 0.90 (0.85 using ProQ2 input features). Availability and Implementation: ProQ3D is freely available both as a webserver and a stand-alone program at http://proq3.bioinfo.se/. Contact: arne@bioinfo.se. Supplementary information: Supplementary data are available at Bioinformatics online.	['Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden.', 'Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden.', 'Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden.', 'Bioinformatics Short-term Support and Infrastructure (BILS), Science for Life Laboratory, Solna, Sweden.', 'Department of Physics, Chemistry and Biology (IFM)/Bioinformatics. Linkoping University, ?Linkoping, Sweden.', 'Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden.']	['2801464 [pii]', '10.1093/bioinformatics/btw819 [doi]']	['Uziela K', 'Menendez Hurtado D', 'Shu N', 'Wallner B', 'Elofsson A']		['(c) The Author 2017. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com']					['2017/01/06 06:00']	20180222		2017 May 15	2017/01/06 06:00		['Uziela, Karolis', 'Menendez Hurtado, David', 'Shu, Nanjiang', 'Wallner, Bjorn', 'Elofsson, Arne']			10		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btw819 [doi]	20181202	['Computational Biology/*methods', 'Models, Molecular', '*Neural Networks (Computer)', '*Protein Conformation', '*Software', '*Support Vector Machine']	2018/02/23 06:00				NLM	1578-1580	['2016/10/12 00:00 [received]', '2016/12/20 00:00 [accepted]', '2017/01/06 06:00 [pubmed]', '2018/02/23 06:00 [medline]', '2017/01/06 06:00 [entrez]']	England			28052925	ppublish	['Journal Article']			IM		Bioinformatics. 2017 May 15;33(10):1578-1580. doi: 10.1093/bioinformatics/btw819.	MEDLINE	Bioinformatics	ProQ3D: improved model quality assessments using deep learning.		33	ProQ3D: improved model quality assessments using deep learning.
"Physical activity is widely known to be one of the key elements of a healthy life. The many benefits of physical activity described in the medical literature include weight loss and reductions in the risk factors for chronic diseases. With the recent advances in wearable devices, such as smartwatches or physical activity wristbands, motion tracking sensors are becoming pervasive, which has led to an impressive growth in the amount of physical activity data available and an increasing interest in recognizing which specific activity a user is performing. Moreover, big data and machine learning are now cross-fertilizing each other in an approach called ""deep learning"", which consists of massive artificial neural networks able to detect complicated patterns from enormous amounts of input data to learn classification models. This work compares various state-of-the-art classification techniques for automatic cross-person activity recognition under different scenarios that vary widely in how much information is available for analysis. We have incorporated deep learning by using Google's TensorFlow framework. The data used in this study were acquired from PAMAP2 (Physical Activity Monitoring in the Ageing Population), a publicly available dataset containing physical activity data. To perform cross-person prediction, we used the leave-one-subject-out (LOSO) cross-validation technique. When working with large training sets, the best classifiers obtain very high average accuracies (e.g., 96% using extra randomized trees). However, when the data volume is drastically reduced (where available data are only 0.001% of the continuous data), deep neural networks performed the best, achieving 60% in overall prediction accuracy. We found that even when working with only approximately 22.67% of the full dataset, we can statistically obtain the same results as when working with the full dataset. This finding enables the design of more energy-efficient devices and facilitates cold starts and big data processing of physical activity records."	['Department of Computer Science, Universidad Carlos III de Madrid, 28911 Leganes, Spain. yago.saez@uc3m.es.', 'Department of Computer Science, Universidad Carlos III de Madrid, 28911 Leganes, Spain. abaldomi@inf.uc3m.es.', 'Department of Computer Science, Universidad Carlos III de Madrid, 28911 Leganes, Spain. isasi@ia.uc3m.es.']	['s17010066 [pii]', '10.3390/s17010066 [doi]']	['Saez Y', 'Baldominos A', 'Isasi P']					['The authors declare no conflict of interest.']		['2017/01/03 06:00']	20180205	20161230	2016 Dec 30	2017/01/04 06:00		['Saez, Yago', 'Baldominos, Alejandro', 'Isasi, Pedro']			1		1424-8220 (Electronic) 1424-8220 (Linking)	101204366	Sensors (Basel, Switzerland)	['eng']	E66 [pii] 10.3390/s17010066 [doi]	20181113	['*Algorithms', 'Artificial Intelligence', 'Exercise/*physiology', 'Humans', 'Machine Learning', 'Neural Networks (Computer)']	2018/02/06 06:00		['biomedical signal processing', 'classification', 'deep learning', 'machine learning', 'physical activity recognition', 'time series analysis']	['NOTNLM']	NLM		['2016/11/01 00:00 [received]', '2016/12/20 00:00 [revised]', '2016/12/27 00:00 [accepted]', '2017/01/03 06:00 [entrez]', '2017/01/04 06:00 [pubmed]', '2018/02/06 06:00 [medline]']	Switzerland	PMC5298639		28042838	epublish	['Journal Article']			IM		Sensors (Basel). 2016 Dec 30;17(1). pii: s17010066. doi: 10.3390/s17010066.	MEDLINE	Sensors (Basel)	A Comparison Study of Classifier Algorithms for Cross-Person Physical Activity Recognition.		17	A Comparison Study of Classifier Algorithms for Cross-Person Physical Activity Recognition.
PURPOSE: Detection (diagnosis) of diabetic retinopathy (DR) in optical coherence tomography (OCT) images for patients with type 2 diabetes, but almost clinically normal retina appearances. METHODS: The proposed computer-aided diagnostic (CAD) system detects the DR in three steps: (a) localizing and segmenting 12 distinct retinal layers on the OCT image; (b) deriving features of the segmented layers, and (c) learning most discriminative features and classifying each subject as normal or diabetic. To localise and segment the retinal layers, signals (intensities) of the OCT image are described with a joint Markov-Gibbs random field (MGRF) model of intensities and shape descriptors. Each segmented layer is characterized with cumulative probability distribution functions (CDF) of its locally extracted features, such as reflectivity, curvature, and thickness. A multistage deep fusion classification network (DFCN) with a stack of non-negativity-constrained autoencoders (NCAE) is trained to select the most discriminative retinal layers' features and use their CDFs for detecting the DR. A training atlas was built using the OCT scans for 12 normal subjects and their maps of layers hand-drawn by retina experts. RESULTS: Preliminary experiments on 52 clinical OCT scans (26 normal and 26 with early-stage DR, balanced between 40-79 yr old males and females; 40 training and 12 test subjects) gave the DR detection accuracy, sensitivity, and specificity of 92%; 83%, and 100%, respectively. The 100% accuracy, sensitivity, and specificity have been obtained in the leave-one-out cross-validation test for all the 52 subjects. CONCLUSION: Both the quantitative and visual assessments confirmed the high accuracy of the proposed computer-assisted diagnostic system for early DR detection using the OCT retinal images.	['Department of Mathematical Engineering, Mansoura University, Mansoura, 35516, Egypt.', 'Department of Bioengineering, University of Louisville, Louisville, KY, 40292, USA.', 'Department of Bioengineering, University of Louisville, Louisville, KY, 40292, USA.', 'Department of Bioengineering, University of Louisville, Louisville, KY, 40292, USA.', 'Department of Bioengineering, University of Louisville, Louisville, KY, 40292, USA.', 'Department of Bioengineering, University of Louisville, Louisville, KY, 40292, USA.', 'Department of Ophthalmology and Visual Sciences, School of Medicine, University of Louisville, Louisville, KY, 40202, USA.', 'Intelligent Vision Systems Laboratory, Department of Computer Science, University of Auckland, Auckland, 1142, New Zealand.', 'Department of Mathematics and Physical Engineering, Mansoura University, Mansoura, 35516, Egypt.']	['10.1002/mp.12071 [doi]']	"['ElTanboly A', 'Ismail M', 'Shalaby A', 'Switala A', 'El-Baz A', 'Schaal S', ""Gimel'farb G"", 'El-Azab M']"		['(c) 2016 American Association of Physicists in Medicine.']					['2016/12/31 06:00']	20170328		2017 Mar	2016/12/31 06:00		"['ElTanboly, Ahmed', 'Ismail, Marwa', 'Shalaby, Ahmed', 'Switala, Andy', 'El-Baz, Ayman', 'Schaal, Shlomit', ""Gimel'farb, Georgy"", 'El-Azab, Magdi']"			3		2473-4209 (Electronic) 0094-2405 (Linking)	0425746	Medical physics	['eng']	10.1002/mp.12071 [doi]	20170328	['Adult', 'Aged', 'Diabetic Retinopathy/*diagnostic imaging', 'Female', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', 'Machine Learning', 'Male', 'Middle Aged', 'Pattern Recognition, Automated', 'Retina/*diagnostic imaging', 'Sensitivity and Specificity', 'Tomography, Optical Coherence/*methods']	2017/03/30 06:00		['*Markov-Gibbs random field (MGRF)', '*diabetic retinopathy (DR)', '*joint image-region-map model', '*non-negativity-constrained autoencoder (NCAE)', '*optical coherence tomography (OCT)']	['NOTNLM']	NLM	914-923	['2016/07/29 00:00 [received]', '2016/09/09 00:00 [revised]', '2016/11/15 00:00 [accepted]', '2016/12/31 06:00 [pubmed]', '2017/03/30 06:00 [medline]', '2016/12/31 06:00 [entrez]']	United States			28035657	ppublish	['Journal Article', 'Validation Studies']			IM		Med Phys. 2017 Mar;44(3):914-923. doi: 10.1002/mp.12071.	MEDLINE	Med Phys	A computer-aided diagnostic system for detecting diabetic retinopathy in optical coherence tomography images.		44	A computer-aided diagnostic system for detecting diabetic retinopathy in optical coherence tomography images.
Recent advances in deep learning and specifically in generative adversarial networks have demonstrated surprising results in generating new images and videos upon request even using natural language as input. In this paper we present the first application of generative adversarial autoencoders (AAE) for generating novel molecular fingerprints with a defined set of parameters. We developed a 7-layer AAE architecture with the latent middle layer serving as a discriminator. As an input and output the AAE uses a vector of binary fingerprints and concentration of the molecule. In the latent layer we also introduced a neuron responsible for growth inhibition percentage, which when negative indicates the reduction in the number of tumor cells after the treatment. To train the AAE we used the NCI-60 cell line assay data for 6252 compounds profiled on MCF-7 cell line. The output of the AAE was used to screen 72 million compounds in PubChem and select candidate molecules with potential anti-cancer properties. This approach is a proof of concept of an artificially-intelligent drug discovery engine, where AAEs are used to generate new molecular fingerprints with the desired molecular properties.	['Search Department, Mail.Ru Group Ltd., Moscow, Russia.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, Maryland, USA.', 'Big Data and Text Analysis Laboratory, Kazan Federal University, Kazan, Republic of Tatarstan, Russia.', 'St. Petersburg Department of V.A. Steklov Institute of Mathematics of the Russian Academy of Sciences, Petersburg, Russia.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, Maryland, USA.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, Maryland, USA.', 'Moscow Institute of Physics and Technology, Dolgoprudny, Russia.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, Maryland, USA.', 'Department of Computer Science, University of Oxford, Oxford, UK.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, Maryland, USA.', 'Search Department, Mail.Ru Group Ltd., Moscow, Russia.', 'Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, Maryland, USA.', 'The Biogerontology Research Foundation, Trevissome Park, Truro TR4 8UN, UK.', 'Moscow Institute of Physics and Technology, Dolgoprudny, Russia.']	['14073 [pii]', '10.18632/oncotarget.14073 [doi]']	['Kadurin A', 'Aliper A', 'Kazennov A', 'Mamoshina P', 'Vanhaelen Q', 'Khrabrov K', 'Zhavoronkov A']							['2016/12/29 06:00']	20170707		2017 Feb 14	2016/12/29 06:00		['Kadurin, Artur', 'Aliper, Alexander', 'Kazennov, Andrey', 'Mamoshina, Polina', 'Vanhaelen, Quentin', 'Khrabrov, Kuzma', 'Zhavoronkov, Alex']			7		1949-2553 (Electronic) 1949-2553 (Linking)	101532965	Oncotarget	['eng']	10.18632/oncotarget.14073 [doi]	20190216	['Antineoplastic Agents/pharmacology/therapeutic use', 'Cell Line, Tumor', 'Drug Screening Assays, Antitumor/*methods', 'Drug Therapy/methods', 'High-Throughput Screening Assays/*methods', 'Humans', 'K562 Cells', 'MCF-7 Cells', '*Machine Learning', '*Neural Networks (Computer)', 'Reproducibility of Results']	2017/07/08 06:00		['adversarial autoencoder', 'artificial intelligence', 'deep learning', 'drug discovery', 'generative adversarian networks']	['NOTNLM']	NLM	10883-10890	['2016/06/14 00:00 [received]', '2016/11/24 00:00 [accepted]', '2016/12/29 06:00 [pubmed]', '2017/07/08 06:00 [medline]', '2016/12/29 06:00 [entrez]']	United States	PMC5355231		28029644	ppublish	['Journal Article']		['0 (Antineoplastic Agents)']	IM		Oncotarget. 2017 Feb 14;8(7):10883-10890. doi: 10.18632/oncotarget.14073.	MEDLINE	Oncotarget	The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology.		8	The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology.
PURPOSE: Magnetic resonance imaging (MRI)-based cell tracking has emerged as a useful tool for identifying the location of transplanted cells, and even their migration. Magnetically labeled cells appear as dark contrast in T2*-weighted MRI, with sensitivities of individual cells. One key hurdle to the widespread use of MRI-based cell tracking is the inability to determine the number of transplanted cells based on this contrast feature. In the case of single cell detection, manual enumeration of spots in three-dimensional (3D) MRI in principle is possible; however, it is a tedious and time-consuming task that is prone to subjectivity and inaccuracy on a large scale. This research presents the first comprehensive study on how a computer-based intelligent, automatic, and accurate cell quantification approach can be designed for spot detection in MRI scans. METHODS: Magnetically labeled mesenchymal stem cells (MSCs) were transplanted into rats using an intracardiac injection, accomplishing single cell seeding in the brain. T2*-weighted MRI of these rat brains were performed where labeled MSCs appeared as spots. Using machine learning and computer vision paradigms, approaches were designed to systematically explore the possibility of automatic detection of these spots in MRI. Experiments were validated against known in vitro scenarios. RESULTS: Using the proposed deep convolutional neural network (CNN) architecture, an in vivo accuracy up to 97.3% and in vitro accuracy of up to 99.8% was achieved for automated spot detection in MRI data. CONCLUSION: The proposed approach for automatic quantification of MRI-based cell tracking will facilitate the use of MRI in large-scale cell therapy studies. Magn Reson Med 78:1991-2002, 2017. (c) 2016 International Society for Magnetic Resonance in Medicine.	['Department of Computer Science and Engineering, Michigan State University, East Lansing, Michigan, USA.', 'Department of Computer Science and Engineering, Michigan State University, East Lansing, Michigan, USA.', 'Department of Computer Science and Engineering, Michigan State University, East Lansing, Michigan, USA.', 'Vascular Medicine Institute, University of Pittsburgh, Pittsburgh, Pennsylvania, USA.', 'Department of Radiology, Michigan State University, East Lansing, Michigan, USA.', 'Department of Radiology, Michigan State University, East Lansing, Michigan, USA.']	['10.1002/mrm.26571 [doi]']	['Afridi MJ', 'Ross A', 'Liu X', 'Bennewitz MF', 'Shuboni DD', 'Shapiro EM']		['(c) 2016 International Society for Magnetic Resonance in Medicine.']					['2016/12/27 06:00']	20180625	20161226	2017 Nov	2016/12/27 06:00		['Afridi, Muhammad Jamal', 'Ross, Arun', 'Liu, Xiaoming', 'Bennewitz, Margaret F', 'Shuboni, Dorela D', 'Shapiro, Erik M']		['DP2 OD004362/OD/NIH HHS/United States', 'R01 DK107697/DK/NIDDK NIH HHS/United States', 'R21 AG041266/AG/NIA NIH HHS/United States', 'R21 CA185163/CA/NCI NIH HHS/United States']	5		1522-2594 (Electronic) 0740-3194 (Linking)	8505245	Magnetic resonance in medicine	['eng']	10.1002/mrm.26571 [doi]	20181202	['Algorithms', 'Animals', 'Brain/cytology/diagnostic imaging', 'Cell Tracking/*methods', 'Image Processing, Computer-Assisted', 'Machine Learning', 'Magnetic Resonance Imaging/*methods', '*Mesenchymal Stem Cell Transplantation', 'Mesenchymal Stem Cells/*cytology', 'Pattern Recognition, Automated', 'Rats']	2018/06/26 06:00	['NIHMS830610']	['*MRI', '*Machine learning', '*cell therapy', '*iron oxide']	['NOTNLM']	NLM	1991-2002	['2016/06/02 00:00 [received]', '2016/10/19 00:00 [revised]', '2016/11/16 00:00 [accepted]', '2016/12/27 06:00 [pubmed]', '2018/06/26 06:00 [medline]', '2016/12/27 06:00 [entrez]']	United States	PMC5817897		28019017	ppublish	['Journal Article']			IM		Magn Reson Med. 2017 Nov;78(5):1991-2002. doi: 10.1002/mrm.26571. Epub 2016 Dec 26.	MEDLINE	Magn Reson Med	Intelligent and automatic in vivo detection and quantification of transplanted cells in MRI.		78	Intelligent and automatic in vivo detection and quantification of transplanted cells in MRI.
Driven by high-throughput sequencing techniques, modern genomic and clinical studies are in a strong need of integrative machine learning models for better use of vast volumes of heterogeneous information in the deep understanding of biological systems and the development of predictive models. How data from multiple sources (called multi-view data) are incorporated in a learning system is a key step for successful analysis. In this article, we provide a comprehensive review on omics and clinical data integration techniques, from a machine learning perspective, for various analyses such as prediction, clustering, dimension reduction and association. We shall show that Bayesian models are able to use prior information and model measurements with various distributions; tree-based methods can either build a tree with all features or collectively make a final decision based on trees learned from each view; kernel methods fuse the similarity matrices learned from individual views together for a final similarity matrix or learning model; network-based fusion methods are capable of inferring direct and indirect associations in a heterogeneous network; matrix factorization models have potential to learn interactions among features from different views; and a range of deep neural networks can be integrated in multi-modal learning for capturing the complex mechanism of biological systems.	['Information and Communications Technologies, National Research Council Canada, Ottawa, Ontario, Canada.', 'Department of Mechanical Engineering, University of Saskatchewan, Saskatoon, Saskatchewan, Canada.', 'School of Computer Science, University of Windsor, Windsor, Ontario, Canada.']	['2664338 [pii]', '10.1093/bib/bbw113 [doi]']	['Li Y', 'Wu FX', 'Ngom A']							['2016/12/25 06:00']	20190228		2018 Mar 1	2016/12/25 06:00		['Li, Yifeng', 'Wu, Fang-Xiang', 'Ngom, Alioune']			2		1477-4054 (Electronic) 1467-5463 (Linking)	100912837	Briefings in bioinformatics	['eng']	10.1093/bib/bbw113 [doi]	20190228	['Animals', '*Gene Regulatory Networks', 'Humans', '*Machine Learning', '*Models, Biological', 'Systems Biology/*methods']	2019/03/01 06:00				NLM	325-340	['2016/07/26 00:00 [received]', '2016/12/25 06:00 [pubmed]', '2019/03/01 06:00 [medline]', '2016/12/25 06:00 [entrez]']	England			28011753	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		Brief Bioinform. 2018 Mar 1;19(2):325-340. doi: 10.1093/bib/bbw113.	MEDLINE	Brief Bioinform	A review on machine learning principles for multi-view biological data integration.		19	A review on machine learning principles for multi-view biological data integration.
BACKGROUND: Protein quality assessment (QA) useful for ranking and selecting protein models has long been viewed as one of the major challenges for protein tertiary structure prediction. Especially, estimating the quality of a single protein model, which is important for selecting a few good models out of a large model pool consisting of mostly low-quality models, is still a largely unsolved problem. RESULTS: We introduce a novel single-model quality assessment method DeepQA based on deep belief network that utilizes a number of selected features describing the quality of a model from different perspectives, such as energy, physio-chemical characteristics, and structural information. The deep belief network is trained on several large datasets consisting of models from the Critical Assessment of Protein Structure Prediction (CASP) experiments, several publicly available datasets, and models generated by our in-house ab initio method. Our experiments demonstrate that deep belief network has better performance compared to Support Vector Machines and Neural Networks on the protein model quality assessment problem, and our method DeepQA achieves the state-of-the-art performance on CASP11 dataset. It also outperformed two well-established methods in selecting good outlier models from a large set of models of mostly low quality generated by ab initio modeling methods. CONCLUSION: DeepQA is a useful deep learning tool for protein single model quality assessment and protein structure prediction. The source code, executable, document and training/test datasets of DeepQA for Linux is freely available to non-commercial users at http://cactus.rnet.missouri.edu/DeepQA/ .	['Department of Computer Science, Pacific Lutheran University, Tacoma, WA, 98447, USA.', 'Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, KS, 67260, USA.', 'Department of Computer Science, University of Missouri, Columbia, MO, 65211, USA.', 'Department of Computer Science, University of Missouri, Columbia, MO, 65211, USA. chengji@missouri.edu.', 'Informatics Institute, University of Missouri, Columbia, MO, 65211, USA. chengji@missouri.edu.']	['10.1186/s12859-016-1405-y [doi]', '10.1186/s12859-016-1405-y [pii]']	['Cao R', 'Bhattacharya D', 'Hou J', 'Cheng J']							['2016/12/07 06:00']	20170810	20161205	2016 Dec 5	2016/12/07 06:00		['Cao, Renzhi', 'Bhattacharya, Debswapna', 'Hou, Jie', 'Cheng, Jianlin']		['R01 GM093123/GM/NIGMS NIH HHS/United States']	1		1471-2105 (Electronic) 1471-2105 (Linking)	100965194	BMC bioinformatics	['eng']		20181202	['Algorithms', 'Data Accuracy', '*Machine Learning', '*Models, Molecular', '*Neural Networks (Computer)', 'Protein Structure, Tertiary', 'Proteins/*chemistry/metabolism', '*Support Vector Machine']	2017/08/11 06:00		['Deep belief network', 'Machine learning', 'Protein model quality assessment', 'Protein structure prediction']	['NOTNLM']	NLM	495	['2016/08/11 00:00 [received]', '2016/12/01 00:00 [accepted]', '2016/12/07 06:00 [entrez]', '2016/12/07 06:00 [pubmed]', '2017/08/11 06:00 [medline]']	England	PMC5139030		27919220	epublish	['Journal Article']		['0 (Proteins)']	IM		BMC Bioinformatics. 2016 Dec 5;17(1):495. doi: 10.1186/s12859-016-1405-y.	MEDLINE	BMC Bioinformatics	DeepQA: improving the estimation of single protein model quality with deep belief networks.		17	DeepQA: improving the estimation of single protein model quality with deep belief networks.
Importance: Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation. Objective: To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. Design and Setting: A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency. Exposure: Deep learning-trained algorithm. Main Outcomes and Measures: The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity. Results: The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2% women; prevalence of RDR, 683/8878 fully gradable images [7.8%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6% women; prevalence of RDR, 254/1745 fully gradable images [14.6%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3% (95% CI, 87.5%-92.7%) and the specificity was 98.1% (95% CI, 97.8%-98.5%). For Messidor-2, the sensitivity was 87.0% (95% CI, 81.1%-91.0%) and the specificity was 98.5% (95% CI, 97.7%-99.1%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5% and specificity was 93.4% and for Messidor-2 the sensitivity was 96.1% and specificity was 93.9%. Conclusions and Relevance: In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.	"['Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California2Department of Computer Science, University of Texas, Austin.', 'Google Inc, Mountain View, California.', 'Google Inc, Mountain View, California.', 'EyePACS LLC, San Jose, California4School of Optometry, Vision Science Graduate Group, University of California, Berkeley.', 'Aravind Medical Research Foundation, Aravind Eye Care System, Madurai, India.', 'Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Tamil Nadu, India.', 'Google Inc, Mountain View, California.', ""Verily Life Sciences, Mountain View, California8Cardiovascular Division, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, Boston, Massachusetts."", 'Google Inc, Mountain View, California.']"	['2588763 [pii]', '10.1001/jama.2016.17216 [doi]']	['Gulshan V', 'Peng L', 'Coram M', 'Stumpe MC', 'Wu D', 'Narayanaswamy A', 'Venugopalan S', 'Widner K', 'Madams T', 'Cuadros J', 'Kim R', 'Raman R', 'Nelson PC', 'Mega JL', 'Webster DR']			['JAMA. 2016 Dec 13;316(22):2368-2369. PMID: 27898974', 'JAMA. 2016 Dec 13;316(22):2366-2367. PMID: 27898977', 'Surv Ophthalmol. 2018 May - Jun;63(3):448-449. PMID: 29248535']				['2016/11/30 06:00']	20170208		2016 Dec 13	2016/11/30 06:00		['Gulshan, Varun', 'Peng, Lily', 'Coram, Marc', 'Stumpe, Martin C', 'Wu, Derek', 'Narayanaswamy, Arunachalam', 'Venugopalan, Subhashini', 'Widner, Kasumi', 'Madams, Tom', 'Cuadros, Jorge', 'Kim, Ramasamy', 'Raman, Rajiv', 'Nelson, Philip C', 'Mega, Jessica L', 'Webster, Dale R']			22		1538-3598 (Electronic) 0098-7484 (Linking)	7501160	JAMA	['eng']	10.1001/jama.2016.17216 [doi]	20170208	['*Algorithms', 'Diabetic Retinopathy/*diagnostic imaging', 'Female', '*Fundus Oculi', 'Humans', '*Machine Learning', 'Macular Edema/*diagnostic imaging', 'Male', 'Middle Aged', '*Neural Networks (Computer)', 'Observer Variation', 'Ophthalmologists', '*Photography', 'Sensitivity and Specificity']	2017/02/09 06:00				NLM	2402-2410	['2016/11/30 06:00 [pubmed]', '2017/02/09 06:00 [medline]', '2016/11/30 06:00 [entrez]']	United States			27898976	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			AIM IM		JAMA. 2016 Dec 13;316(22):2402-2410. doi: 10.1001/jama.2016.17216.	MEDLINE	JAMA	Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs.		316	Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs.
In histopathological image analysis, the morphology of histological structures, such as glands and nuclei, has been routinely adopted by pathologists to assess the malignancy degree of adenocarcinomas. Accurate detection and segmentation of these objects of interest from histology images is an essential prerequisite to obtain reliable morphological statistics for quantitative diagnosis. While manual annotation is error-prone, time-consuming and operator-dependant, automated detection and segmentation of objects of interest from histology images can be very challenging due to the large appearance variation, existence of strong mimics, and serious degeneration of histological structures. In order to meet these challenges, we propose a novel deep contour-aware network (DCAN) under a unified multi-task learning framework for more accurate detection and segmentation. In the proposed network, multi-level contextual features are explored based on an end-to-end fully convolutional network (FCN) to deal with the large appearance variation. We further propose to employ an auxiliary supervision mechanism to overcome the problem of vanishing gradients when training such a deep network. More importantly, our network can not only output accurate probability maps of histological objects, but also depict clear contours simultaneously for separating clustered object instances, which further boosts the segmentation performance. Our method ranked the first in two histological object segmentation challenges, including 2015 MICCAI Gland Segmentation Challenge and 2015 MICCAI Nuclei Segmentation Challenge. Extensive experiments on these two challenging datasets demonstrate the superior performance of our method, surpassing all the other methods by a significant margin.	['Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China. Electronic address: hchen@cse.cuhk.edu.hk.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.', 'School of Nursing, The Hong Kong Polytechnic University, Hong Kong, China.', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.']	['S1361-8415(16)30204-3 [pii]', '10.1016/j.media.2016.11.004 [doi]']	['Chen H', 'Qi X', 'Yu L', 'Dou Q', 'Qin J', 'Heng PA']		['Copyright (c) 2016 Elsevier B.V. All rights reserved.']					['2016/11/30 06:00']	20180525	20161116	2017 Feb	2016/11/30 06:00		['Chen, Hao', 'Qi, Xiaojuan', 'Yu, Lequan', 'Dou, Qi', 'Qin, Jing', 'Heng, Pheng-Ann']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(16)30204-3 [pii] 10.1016/j.media.2016.11.004 [doi]	20181202	['Colorectal Neoplasms/diagnostic imaging/pathology', 'Histological Techniques/*methods', 'Humans', '*Machine Learning']	2018/05/26 06:00		['*Deep contour-aware network', '*Deep learning', '*Histopathological image analysis', '*Instance segmentation', '*Object detection', '*Transfer learning']	['NOTNLM']	NLM	135-146	['2016/06/06 00:00 [received]', '2016/11/09 00:00 [revised]', '2016/11/10 00:00 [accepted]', '2016/11/30 06:00 [pubmed]', '2018/05/26 06:00 [medline]', '2016/11/30 06:00 [entrez]']	Netherlands			27898306	ppublish	['Journal Article']			IM		Med Image Anal. 2017 Feb;36:135-146. doi: 10.1016/j.media.2016.11.004. Epub 2016 Nov 16.	MEDLINE	Med Image Anal	DCAN: Deep contour-aware networks for object instance segmentation from histology images.		36	DCAN: Deep contour-aware networks for object instance segmentation from histology images.
Cancer detection from gene expression data continues to pose a challenge due to the high dimensionality and complexity of these data. After decades of research there is still uncertainty in the clinical diagnosis of cancer and the identification of tumor-specific markers. Here we present a deep learning approach to cancer detection, and to the identification of genes critical for the diagnosis of breast cancer. First, we used Stacked Denoising Autoencoder (SDAE) to deeply extract functional features from high dimensional gene expression profiles. Next, we evaluated the performance of the extracted representation through supervised classification models to verify the usefulness of the new features in cancer detection. Lastly, we identified a set of highly interactive genes by analyzing the SDAE connectivity matrices. Our results and analysis illustrate that these highly interactive genes could be useful cancer biomarkers for the detection of breast cancer that deserve further studies.	['School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR 97330, USA, danaeep@oregonstate.edu.']	['9789813207813_0022 [pii]', '10.1142/9789813207813_0022 [doi]']	['Danaee P', 'Ghaeini R', 'Hendrix DA']							['2016/11/30 06:00']	20170626		2017	2016/11/30 06:00		['Danaee, Padideh', 'Ghaeini, Reza', 'Hendrix, David A']		['R21 AG052950/AG/NIA NIH HHS/United States']			2335-6936 (Electronic) 2335-6928 (Linking)	9711271	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	['eng']	10.1142/9789813207813_0022 [doi]	20190115	['Algorithms', 'Biomarkers, Tumor/genetics', 'Breast Neoplasms/classification/*diagnosis/*genetics', 'Computational Biology', 'Databases, Genetic/statistics & numerical data', 'Female', 'Gene Expression Profiling/statistics & numerical data', 'Gene Ontology', 'Humans', 'Principal Component Analysis', 'Supervised Machine Learning']	2017/06/27 06:00	['NIHMS831926']			NLM	219-229	['2016/11/30 06:00 [entrez]', '2016/11/30 06:00 [pubmed]', '2017/06/27 06:00 [medline]']	United States	PMC5177447		27896977	ppublish	['Journal Article']		['0 (Biomarkers, Tumor)']	IM		Pac Symp Biocomput. 2017;22:219-229. doi: 10.1142/9789813207813_0022.	MEDLINE	Pac Symp Biocomput	A DEEP LEARNING APPROACH FOR CANCER DETECTION AND RELEVANT GENE IDENTIFICATION.		22	A DEEP LEARNING APPROACH FOR CANCER DETECTION AND RELEVANT GENE IDENTIFICATION.
In this paper, we propose deep architecture to dynamically learn the most discriminative features from data for both single-cell and object tracking in computational biology and computer vision. Firstly, the discriminative features are automatically learned via a convolutional deep belief network (CDBN). Secondly, we design a simple yet effective method to transfer features learned from CDBNs on the source tasks for generic purpose to the object tracking tasks using only limited amount of training data. Finally, to alleviate the tracker drifting problem caused by model updating, we jointly consider three different types of positive samples. Extensive experiments validate the robustness and effectiveness of the proposed method.	['Department of Computer Science and Engineering, Huaqiao University, Xiamen, China.', 'Department of Computer Science and Engineering, Huaqiao University, Xiamen, China.', 'Department of Computer Science and Engineering, Huaqiao University, Xiamen, China.', 'Department of Computer Science and Engineering, Huaqiao University, Xiamen, China.', 'Department of Computer Science and Engineering, Huaqiao University, Xiamen, China.', 'Department of Computer Science and Engineering, Huaqiao University, Xiamen, China.', 'School of Information Science and Technology, Xiamen University, Xiamen, China.']	['10.1155/2016/9406259 [doi]']	['Zhong B', 'Pan S', 'Zhang H', 'Wang T', 'Du J', 'Chen D', 'Cao L']	['ORCID: 0000-0003-3423-1539']						['2016/11/17 06:00']	20170202	20161026	2016	2016/11/17 06:00		['Zhong, Bineng', 'Pan, Shengnan', 'Zhang, Hongbo', 'Wang, Tian', 'Du, Jixiang', 'Chen, Duansheng', 'Cao, Liujuan']					2314-6141 (Electronic)	101600173	BioMed research international	['eng']		20181113	['Animals', 'Cell Tracking/*methods', 'Computer Simulation', 'Data Interpretation, Statistical', 'Humans', 'Image Enhancement/methods', 'Image Interpretation, Computer-Assisted/*methods', '*Machine Learning', 'Microscopy/*methods', 'Models, Statistical', '*Neural Networks (Computer)', 'Reproducibility of Results', 'Sensitivity and Specificity']	2017/02/06 06:00				NLM	9406259	['2016/06/01 00:00 [received]', '2016/08/14 00:00 [revised]', '2016/09/14 00:00 [accepted]', '2016/11/17 06:00 [entrez]', '2016/11/17 06:00 [pubmed]', '2017/02/06 06:00 [medline]']	United States	PMC5101405		27847827	ppublish	['Journal Article']			IM		Biomed Res Int. 2016;2016:9406259. doi: 10.1155/2016/9406259. Epub 2016 Oct 26.	MEDLINE	Biomed Res Int	Convolutional Deep Belief Networks for Single-Cell/Object Tracking in Computational Biology and Computer Vision.		2016	Convolutional Deep Belief Networks for Single-Cell/Object Tracking in Computational Biology and Computer Vision.
BACKGROUND: Motion-onset visual evoked potentials (mVEP) can provide a softer stimulus with reduced fatigue, and it has potential applications for brain computer interface(BCI)systems. However, the mVEP waveform is seriously masked in the strong background EEG activities, and an effective approach is needed to extract the corresponding mVEP features to perform task recognition for BCI control. NEW METHOD: In the current study, we combine deep learning with compressed sensing to mine discriminative mVEP information to improve the mVEP BCI performance. RESULTS: The deep learning and compressed sensing approach can generate the multi-modality features which can effectively improve the BCI performance with approximately 3.5% accuracy incensement over all 11 subjects and is more effective for those subjects with relatively poor performance when using the conventional features. COMPARISON WITH EXISTING METHODS: Compared with the conventional amplitude-based mVEP feature extraction approach, the deep learning and compressed sensing approach has a higher classification accuracy and is more effective for subjects with relatively poor performance. CONCLUSIONS: According to the results, the deep learning and compressed sensing approach is more effective for extracting the mVEP feature to construct the corresponding BCI system, and the proposed feature extraction framework is easy to extend to other types of BCIs, such as motor imagery (MI), steady-state visual evoked potential (SSVEP)and P300.	['Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China. Electronic address: dyao@uestc.edu.cn.', 'Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China. Electronic address: xupeng@uestc.edu.cn.']	['S0165-0270(16)30268-0 [pii]', '10.1016/j.jneumeth.2016.11.002 [doi]']	['Ma T', 'Li H', 'Yang H', 'Lv X', 'Li P', 'Liu T', 'Yao D', 'Xu P']		['Copyright A(c) 2016 Elsevier B.V. All rights reserved.']					['2016/11/16 06:00']	20171109	20161111	2017 Jan 1	2016/11/16 06:00		['Ma, Teng', 'Li, Hui', 'Yang, Hao', 'Lv, Xulin', 'Li, Peiyang', 'Liu, Tiejun', 'Yao, Dezhong', 'Xu, Peng']					1872-678X (Electronic) 0165-0270 (Linking)	7905558	Journal of neuroscience methods	['eng']	S0165-0270(16)30268-0 [pii] 10.1016/j.jneumeth.2016.11.002 [doi]	20181029	['Brain/*physiology', '*Brain-Computer Interfaces', 'Electroencephalography/*methods', 'Evoked Potentials, Visual/*physiology', 'Female', 'Humans', '*Machine Learning', 'Male', 'Motion Perception/*physiology', 'Signal Processing, Computer-Assisted', 'Young Adult']	2017/11/10 06:00		['*Brain computer interface', '*Compressed sensing', '*Deep learning', '*Motion-onset VEP', '*Multi-modality feature']	['NOTNLM']	NLM	80-92	['2016/04/22 00:00 [received]', '2016/09/28 00:00 [revised]', '2016/11/08 00:00 [accepted]', '2016/11/16 06:00 [pubmed]', '2017/11/10 06:00 [medline]', '2016/11/16 06:00 [entrez]']	Netherlands			27845150	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Neurosci Methods. 2017 Jan 1;275:80-92. doi: 10.1016/j.jneumeth.2016.11.002. Epub 2016 Nov 11.	MEDLINE	J Neurosci Methods	The extraction of motion-onset VEP BCI features based on deep learning and compressed sensing.		275	The extraction of motion-onset VEP BCI features based on deep learning and compressed sensing.
One essential task in information extraction from the medical corpus is drug name recognition. Compared with text sources come from other domains, the medical text mining poses more challenges, for example, more unstructured text, the fast growing of new terms addition, a wide range of name variation for the same drug, the lack of labeled dataset sources and external knowledge, and the multiple token representations for a single drug name. Although many approaches have been proposed to overwhelm the task, some problems remained with poor F-score performance (less than 0.75). This paper presents a new treatment in data representation techniques to overcome some of those challenges. We propose three data representation techniques based on the characteristics of word distribution and word similarities as a result of word embedding training. The first technique is evaluated with the standard NN model, that is, MLP. The second technique involves two deep network classifiers, that is, DBN and SAE. The third technique represents the sentence as a sequence that is evaluated with a recurrent NN model, that is, LSTM. In extracting the drug name entities, the third technique gives the best F-score performance compared to the state of the art, with its average F-score being 0.8645.	['Faculty of Computer Science, Universitas Mercu Buana, l. Meruya Selatan No. 1, Kembangan, Jakarta Barat 11650, Indonesia; Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, West Java 16424, Indonesia.', 'Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, West Java 16424, Indonesia.', 'Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, West Java 16424, Indonesia.']	['10.1155/2016/3483528 [doi]']	['Sadikin M', 'Fanany MI', 'Basaruddin T']	['ORCID: 0000-0003-0639-5245', 'ORCID: 0000-0002-6050-664X']						['2016/11/16 06:00']	20170206	20161024	2016	2016/11/16 06:00		['Sadikin, Mujiono', 'Fanany, Mohamad Ivan', 'Basaruddin, T']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']		20181113	['Algorithms', 'Computational Biology', 'Data Mining/*statistics & numerical data', 'Humans', '*Medical Records Systems, Computerized', '*Natural Language Processing']	2017/02/07 06:00				NLM	3483528	['2016/05/27 00:00 [received]', '2016/08/08 00:00 [revised]', '2016/09/18 00:00 [accepted]', '2016/11/16 06:00 [entrez]', '2016/11/16 06:00 [pubmed]', '2017/02/07 06:00 [medline]']	United States	PMC5098107		27843447	ppublish	['Journal Article']			IM		Comput Intell Neurosci. 2016;2016:3483528. doi: 10.1155/2016/3483528. Epub 2016 Oct 24.	MEDLINE	Comput Intell Neurosci	A New Data Representation Based on Training Data Characteristics to Extract Drug Name Entity in Medical Text.		2016	A New Data Representation Based on Training Data Characteristics to Extract Drug Name Entity in Medical Text.
Disease diagnosis is one of the major data mining questions by the clinicians. The current diagnosis models usually have a strong assumption that one patient has only one disease, i.e. a single-label data mining problem. But the patients, especially when at the late stages, may have more than one disease and require a multi-label diagnosis. The multi-label data mining is much more difficult than a single-label one, and very few algorithms have been developed for this situation. Deep learning is a data mining algorithm with highly dense inner structure and has achieved many successful applications in the other areas. We propose a hypothesis that rectified-linear-unit-based deep learning algorithm may also be good at the clinical questions, by revising the last layer as a multi-label output. The proof-of-concept experimental data support the hypothesis, and the community may be interested in trying more applications.	"[""Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, Guangdong, 518055, People's Republic of China."", ""Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, Guangdong, 518055, People's Republic of China."", ""Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, Jiangxi, 333403, People's Republic of China."", ""Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, Guangdong, 518055, People's Republic of China."", ""Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, Guangdong, 518055, People's Republic of China."", ""Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, Jiangxi, 333403, People's Republic of China."", ""Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, Guangdong, 518055, People's Republic of China. yp.cai@siat.ac.cn."", ""Department of Pathogenobiology, Basic Medical College of Jilin University, Changchun, Jilin, 130012, People's Republic of China. qing@jlu.edu.cn."", ""College of Computer Science and Technology, Jilin University, Changchun, Jilin, 130012, People's Republic of China. FengfengZhou@gmail.com."", ""Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, Jilin, 130012, People's Republic of China. FengfengZhou@gmail.com.""]"	['10.1007/s12539-016-0196-1 [doi]', '10.1007/s12539-016-0196-1 [pii]']	['Wang P', 'Ge R', 'Xiao X', 'Cai Y', 'Wang G', 'Zhou F']	['ORCID: http://orcid.org/0000-0002-8108-6007']						['2016/11/13 06:00']	20180423	20161111	2017 Sep	2016/11/12 06:00		['Wang, Pu', 'Ge, Ruiquan', 'Xiao, Xuan', 'Cai, Yunpeng', 'Wang, Guoqing', 'Zhou, Fengfeng']			3		1867-1462 (Electronic) 1867-1462 (Linking)	101515919	Interdisciplinary sciences, computational life sciences	['eng']	10.1007/s12539-016-0196-1 [doi]	20180423	['*Algorithms', '*Biomedical Technology', '*Machine Learning', 'Saccharomyces cerevisiae/metabolism']	2018/04/24 06:00		['Clinical diagnosis', 'Deep learning', 'Multi-label classification', 'Rectified linear unit', 'Single-label classification']	['NOTNLM']	NLM	419-422	['2016/05/27 00:00 [received]', '2016/10/25 00:00 [accepted]', '2016/10/03 00:00 [revised]', '2016/11/12 06:00 [pubmed]', '2018/04/24 06:00 [medline]', '2016/11/13 06:00 [entrez]']	Germany			27837428	ppublish	['Journal Article']			IM		Interdiscip Sci. 2017 Sep;9(3):419-422. doi: 10.1007/s12539-016-0196-1. Epub 2016 Nov 11.	MEDLINE	Interdiscip Sci	Rectified-Linear-Unit-Based Deep Learning for Biomedical Multi-label Data.		9	Rectified-Linear-Unit-Based Deep Learning for Biomedical Multi-label Data.
Skeletal bone age assessment is a common clinical practice to investigate endocrinology, genetic and growth disorders in children. It is generally performed by radiological examination of the left hand by using either the Greulich and Pyle (G&P) method or the Tanner-Whitehouse (TW) one. However, both clinical procedures show several limitations, from the examination effort of radiologists to (most importantly) significant intra- and inter-operator variability. To address these problems, several automated approaches (especially relying on the TW method) have been proposed; nevertheless, none of them has been proved able to generalize to different races, age ranges and genders. In this paper, we propose and test several deep learning approaches to assess skeletal bone age automatically; the results showed an average discrepancy between manual and automatic evaluation of about 0.8 years, which is state-of-the-art performance. Furthermore, this is the first automated skeletal bone age assessment work tested on a public dataset and for all age ranges, races and genders, for which the source code is available, thus representing an exhaustive baseline for future research in the field. Beside the specific application scenario, this paper aims at providing answers to more general questions about deep learning on medical images: from the comparison between deep-learned features and manually-crafted ones, to the usage of deep-learning methods trained on general imagery for medical problems, to how to train a CNN with few images.	['Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy. Electronic address: cspampin@dieei.unict.it.', 'Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy. Electronic address: simone.palazzo@dieei.unict.it.', 'Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy. Electronic address: dgiordan@dieei.unict.it.', 'Computer Science Department, University of Torino, Corso Svizzera, 185 - 10149 - Torino, Italy. Electronic address: aldinuc@di.unito.it.', 'Department of Orthodontics, University of Catania, Via Santa Sofia, 78 - 95125 - Catania, Italy. Electronic address: rleonardi@unict.it.']	['S1361-8415(16)30184-0 [pii]', '10.1016/j.media.2016.10.010 [doi]']	['Spampinato C', 'Palazzo S', 'Giordano D', 'Aldinucci M', 'Leonardi R']		['Copyright (c) 2016 Elsevier B.V. All rights reserved.']					['2016/11/07 06:00']	20180525	20161029	2017 Feb	2016/11/07 06:00		['Spampinato, C', 'Palazzo, S', 'Giordano, D', 'Aldinucci, M', 'Leonardi, R']					1361-8423 (Electronic) 1361-8415 (Linking)	9713490	Medical image analysis	['eng']	S1361-8415(16)30184-0 [pii] 10.1016/j.media.2016.10.010 [doi]	20181202	['Adolescent', 'Age Determination by Skeleton/*methods', 'Bone and Bones/*diagnostic imaging', 'Child', 'Child, Preschool', 'Female', 'Humans', 'Infant', '*Machine Learning', 'Male', '*Neural Networks (Computer)', 'Radiography/*methods', 'Reproducibility of Results']	2018/05/26 06:00		['*Convolutional neural networks', '*Deep learning for medical images', '*Greulich and Pyle', '*Tanner-Whitehouse']	['NOTNLM']	NLM	41-51	['2016/03/02 00:00 [received]', '2016/10/10 00:00 [revised]', '2016/10/12 00:00 [accepted]', '2016/11/07 06:00 [pubmed]', '2018/05/26 06:00 [medline]', '2016/11/07 06:00 [entrez]']	Netherlands			27816861	ppublish	['Journal Article']			IM		Med Image Anal. 2017 Feb;36:41-51. doi: 10.1016/j.media.2016.10.010. Epub 2016 Oct 29.	MEDLINE	Med Image Anal	Deep learning for automated skeletal bone age assessment in X-ray images.		36	Deep learning for automated skeletal bone age assessment in X-ray images.
MOTIVATION: Histone modifications are among the most important factors that control gene regulation. Computational methods that predict gene expression from histone modification signals are highly desirable for understanding their combinatorial effects in gene regulation. This knowledge can help in developing 'epigenetic drugs' for diseases like cancer. Previous studies for quantifying the relationship between histone modifications and gene expression levels either failed to capture combinatorial effects or relied on multiple methods that separate predictions and combinatorial analysis. This paper develops a unified discriminative framework using a deep convolutional neural network to classify gene expression using histone modification data as input. Our system, called DeepChrome, allows automatic extraction of complex interactions among important features. To simultaneously visualize the combinatorial interactions among histone modifications, we propose a novel optimization-based technique that generates feature pattern maps from the learnt deep model. This provides an intuitive description of underlying epigenetic mechanisms that regulate genes. RESULTS: We show that DeepChrome outperforms state-of-the-art models like Support Vector Machines and Random Forests for gene expression classification task on 56 different cell-types from REMC database. The output of our visualization technique not only validates the previous observations but also allows novel insights about combinatorial interactions among histone modification marks, some of which have recently been observed by experimental studies. AVAILABILITY AND IMPLEMENTATION: Codes and results are available at www.deepchrome.org CONTACT: yanjun@virginia.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA.', 'Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA.']	['btw427 [pii]', '10.1093/bioinformatics/btw427 [doi]']	['Singh R', 'Lanchantin J', 'Robins G', 'Qi Y']		['(c) The Author 2016. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com.']					['2016/09/03 06:00']	20170731		2016 Sep 1	2016/09/03 06:00		['Singh, Ritambhara', 'Lanchantin, Jack', 'Robins, Gabriel', 'Qi, Yanjun']			17		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btw427 [doi]	20181202	['Cluster Analysis', 'Computational Biology', 'Epigenesis, Genetic', '*Gene Expression Regulation', 'Gene Regulatory Networks', '*Histone Code', 'Humans', 'Neural Networks (Computer)', '*Support Vector Machine']	2017/08/02 06:00				NLM	i639-i648	['2016/09/03 06:00 [entrez]', '2016/09/03 06:00 [pubmed]', '2017/08/02 06:00 [medline]']	England			27587684	ppublish	['Journal Article']			IM		Bioinformatics. 2016 Sep 1;32(17):i639-i648. doi: 10.1093/bioinformatics/btw427.	MEDLINE	Bioinformatics	DeepChrome: deep-learning for predicting gene expression from histone modifications.		32	DeepChrome: deep-learning for predicting gene expression from histone modifications.
We present a novel regularization method for a multilayer perceptron (MLP) that learns a regression function in the presence of noise regardless of how smooth the function is. Unlike general MLP regularization methods assuming that a regression function is smooth, the proposed regularization method is also valid when a regression function has discontinuities (non-smoothness). Since a true regression function to be learned is unknown, we examine a training set with our Bayesian approach that identifies non-smooth data, analyzing discontinuities in a regression function. The use of a Bayesian probability distribution identifies the non-smooth data. These identified data is used in a proposed objective function to fit an MLP response to the desired regression function regardless of its smoothness and noise. Experimental simulations show that the MLP with our presented training method yields more accurate fits to non-smooth functions than other MLP training methods. Further, we show that the suggested training methodology can be incorporated with deep learning models.	['School of Computing, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon 305-701, Republic of Korea. Electronic address: jgparknn@kaist.ac.kr.', 'School of Computing, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon 305-701, Republic of Korea. Electronic address: shjo@kaist.ac.kr.']	['S0893-6080(16)30092-2 [pii]', '10.1016/j.neunet.2016.07.010 [doi]']	['Park JG', 'Jo S']		['Copyright (c) 2016 Elsevier Ltd. All rights reserved.']					['2016/09/02 06:00']	20170418	20160810	2016 Nov	2016/09/02 06:00		['Park, Jung-Guk', 'Jo, Sungho']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(16)30092-2 [pii] 10.1016/j.neunet.2016.07.010 [doi]	20181202	['Bayes Theorem', '*Machine Learning', 'Models, Theoretical', '*Neural Networks (Computer)']	2017/04/19 06:00		['*Bayesian method', '*Multilayer perceptron training', '*Non-smooth regression', '*Regularization', '*Weight-decay']	['NOTNLM']	NLM	75-85	['2015/12/28 00:00 [received]', '2016/07/06 00:00 [revised]', '2016/07/18 00:00 [accepted]', '2016/09/02 06:00 [pubmed]', '2017/04/19 06:00 [medline]', '2016/09/02 06:00 [entrez]']	United States			27584575	ppublish	['Journal Article']			IM		Neural Netw. 2016 Nov;83:75-85. doi: 10.1016/j.neunet.2016.07.010. Epub 2016 Aug 10.	MEDLINE	Neural Netw	Approximate Bayesian MLP regularization for regression in the presence of noise.		83	Approximate Bayesian MLP regularization for regression in the presence of noise.
In a physical neural system, where storage and processing are intimately intertwined, the rules for adjusting the synaptic weights can only depend on variables that are available locally, such as the activity of the pre- and post-synaptic neurons, resulting in local learning rules. A systematic framework for studying the space of local learning rules is obtained by first specifying the nature of the local variables, and then the functional form that ties them together into each learning rule. Such a framework enables also the systematic discovery of new learning rules and exploration of relationships between learning rules and group symmetries. We study polynomial local learning rules stratified by their degree and analyze their behavior and capabilities in both linear and non-linear units and networks. Stacking local learning rules in deep feedforward networks leads to deep local learning. While deep local learning can learn interesting representations, it cannot learn complex input-output functions, even when targets are available for the top layer. Learning complex input-output functions requires local deep learning where target information is communicated to the deep layers through a backward learning channel. The nature of the communicated information about the targets and the structure of the learning channel partition the space of learning algorithms. For any learning algorithm, the capacity of the learning channel can be defined as the number of bits provided about the error gradient per weight, divided by the number of required operations per weight. We estimate the capacity associated with several learning algorithms and show that backpropagation outperforms them by simultaneously maximizing the information rate and minimizing the computational cost. This result is also shown to be true for recurrent networks, by unfolding them in time. The theory clarifies the concept of Hebbian learning, establishes the power and limitations of local learning rules, introduces the learning channel which enables a formal analysis of the optimality of backpropagation, and explains the sparsity of the space of learning rules discovered so far.	['Department of Computer Science, University of California, Irvine, Irvine, CA 92697-3435, USA. Electronic address: pfbaldi@uci.edu.', 'Department of Computer Science, University of California, Irvine, Irvine, CA 92697-3435, USA. Electronic address: psadowsk@uci.edu.']	['S0893-6080(16)30088-0 [pii]', '10.1016/j.neunet.2016.07.006 [doi]']	['Baldi P', 'Sadowski P']		['Copyright (c) 2016 Elsevier Ltd. All rights reserved.']					['2016/09/02 06:00']	20170418	20160805	2016 Nov	2016/09/02 06:00		['Baldi, Pierre', 'Sadowski, Peter']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	S0893-6080(16)30088-0 [pii] 10.1016/j.neunet.2016.07.006 [doi]	20181202	['Algorithms', 'Feedback', '*Machine Learning', '*Neural Networks (Computer)']	2017/04/19 06:00		['*Backpropagation', '*Deep learning', '*Hebbian learning', '*Learning channel', '*Supervised learning', '*Unsupervised learning']	['NOTNLM']	NLM	51-74	['2015/10/26 00:00 [received]', '2016/05/31 00:00 [revised]', '2016/07/13 00:00 [accepted]', '2016/09/02 06:00 [pubmed]', '2017/04/19 06:00 [medline]', '2016/09/02 06:00 [entrez]']	United States			27584574	ppublish	['Journal Article']			IM		Neural Netw. 2016 Nov;83:51-74. doi: 10.1016/j.neunet.2016.07.006. Epub 2016 Aug 5.	MEDLINE	Neural Netw	A theory of local learning, the learning channel, and the optimality of backpropagation.		83	A theory of local learning, the learning channel, and the optimality of backpropagation.
To achieve effective visual tracking, a robust feature representation composed of two separate components (i.e., feature learning and selection) for an object is one of the key issues. Typically, a common assumption used in visual tracking is that the raw video sequences are clear, while real-world data is with significant noise and irrelevant patterns. Consequently, the learned features may be not all relevant and noisy. To address this problem, we propose a novel visual tracking method via a point-wise gated convolutional deep network (CPGDN) that jointly performs the feature learning and feature selection in a unified framework. The proposed method performs dynamic feature selection on raw features through a gating mechanism. Therefore, the proposed method can adaptively focus on the task-relevant patterns (i.e., a target object), while ignoring the task-irrelevant patterns (i.e., the surrounding background of a target object). Specifically, inspired by transfer learning, we firstly pre-train an object appearance model offline to learn generic image features and then transfer rich feature hierarchies from an offline pre-trained CPGDN into online tracking. In online tracking, the pre-trained CPGDN model is fine-tuned to adapt to the tracking specific objects. Finally, to alleviate the tracker drifting problem, inspired by an observation that a visual target should be an object rather than not, we combine an edge box-based object proposal method to further improve the tracking accuracy. Extensive evaluation on the widely used CVPR2013 tracking benchmark validates the robustness and effectiveness of the proposed method.	['Department of Computer Science and Technology, Huaqiao University, Xiamen, Fujian, 361021, China.', 'Department of Computer Science and Technology, Huaqiao University, Xiamen, Fujian, 361021, China.', 'Department of Computer Science and Technology, Huaqiao University, Xiamen, Fujian, 361021, China.', 'Department of Computer Science and Technology, Huaqiao University, Xiamen, Fujian, 361021, China.', 'Department of Computer Science and Technology, Huaqiao University, Xiamen, Fujian, 361021, China.']	['10.1371/journal.pone.0161808 [doi]', 'PONE-D-16-23521 [pii]']	['Zhong B', 'Zhang J', 'Wang P', 'Du J', 'Chen D']					['The authors have declared that no competing interests exist.']		['2016/08/31 06:00']	20170821	20160830	2016	2016/08/31 06:00		['Zhong, Bineng', 'Zhang, Jun', 'Wang, Pengfei', 'Du, Jixiang', 'Chen, Duansheng']			8		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0161808 [doi]	20181113	['Image Processing, Computer-Assisted/*methods', 'Machine Learning', 'Models, Theoretical']	2017/08/22 06:00				NLM	e0161808	['2016/06/11 00:00 [received]', '2016/08/14 00:00 [accepted]', '2016/08/31 06:00 [entrez]', '2016/08/31 06:00 [pubmed]', '2017/08/22 06:00 [medline]']	United States	PMC5004979		27575684	epublish	['Journal Article']			IM		PLoS One. 2016 Aug 30;11(8):e0161808. doi: 10.1371/journal.pone.0161808. eCollection 2016.	MEDLINE	PLoS One	Jointly Feature Learning and Selection for Robust Tracking via a Gating Mechanism.		11	Jointly Feature Learning and Selection for Robust Tracking via a Gating Mechanism.
Computational prediction of compound-protein interactions (CPIs) is of great importance for drug design as the first step in in-silico screening. We previously proposed chemical genomics-based virtual screening (CGBVS), which predicts CPIs by using a support vector machine (SVM). However, the CGBVS has problems when training using more than a million datasets of CPIs since SVMs require an exponential increase in the calculation time and computer memory. To solve this problem, we propose the CGBVS-DNN, in which we use deep neural networks, a kind of deep learning technique, instead of the SVM. Deep learning does not require learning all input data at once because the network can be trained with small mini-batches. Experimental results show that the CGBVS-DNN outperformed the original CGBVS with a quarter million CPIs. Results of cross-validation show that the accuracy of the CGBVS-DNN reaches up to 98.2 % (sigma<0.01) with 4 million CPIs.	['Graduate School of Medicine, Kyoto University, Shogoin-kawaharacho, city/>Sakyo-ku Kyoto, 606-8507, Japan.', 'Advanced Institute for Computational Science, RIKEN, 7-1-28, Minatojima-minami-machi, Chuo-ku, Kobe, Hyogo, 650-0047, Japan.', 'Foundation for Biomedical Research and Innovation, 1-6-5, Minatojima-Minamimachi Chuo-ku, Kobe, 650-0047, Japan.', 'Software and Services Group, Intel Corporation, Shanghai, China.', 'Software and Services Group, Intel Corporation, Shanghai, China.', 'Software and Services Group, Intel Corporation, Shanghai, China.', 'Graduate School of Medicine, Kyoto University, Shogoin-kawaharacho, city/>Sakyo-ku Kyoto, 606-8507, Japan.']	['10.1002/minf.201600045 [doi]']	['Hamanaka M', 'Taneishi K', 'Iwata H', 'Ye J', 'Pei J', 'Hou J', 'Okuno Y']		['(c) 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim.']					['2016/08/13 06:00']	20180523	20160812	2017 Jan	2016/08/16 06:00		['Hamanaka, Masatoshi', 'Taneishi, Kei', 'Iwata, Hiroaki', 'Ye, Jun', 'Pei, Jianguo', 'Hou, Jinlong', 'Okuno, Yasushi']			1-2		1868-1751 (Electronic) 1868-1743 (Linking)	101529315	Molecular informatics	['eng']	10.1002/minf.201600045 [doi]	20180926	['Binding Sites', '*Machine Learning', 'Molecular Docking Simulation/*methods/standards', 'Protein Binding', 'Proteome/chemistry/metabolism', 'Software']	2018/05/24 06:00		['*chemical genomics-based virtual screening (cgbvs)', '*compound-protein interactions (cpis)', '*deep learning', '*in-silico screening', '*support vector machine']	['NOTNLM']	NLM		['2016/03/31 00:00 [received]', '2016/07/09 00:00 [accepted]', '2016/08/16 06:00 [pubmed]', '2018/05/24 06:00 [medline]', '2016/08/13 06:00 [entrez]']	Germany			27515489	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteome)']	IM		Mol Inform. 2017 Jan;36(1-2). doi: 10.1002/minf.201600045. Epub 2016 Aug 12.	MEDLINE	Mol Inform	CGBVS-DNN: Prediction of Compound-protein Interactions Based on Deep Learning.		36	CGBVS-DNN: Prediction of Compound-protein Interactions Based on Deep Learning.
Event recognition is the most fundamental and critical task in event-based natural language processing systems. Existing event recognition methods based on rules and shallow neural networks have certain limitations. For example, extracting features using methods based on rules is difficult; methods based on shallow neural networks converge too quickly to a local minimum, resulting in low recognition precision. To address these problems, we propose the Chinese emergency event recognition model based on deep learning (CEERM). Firstly, we use a word segmentation system to segment sentences. According to event elements labeled in the CEC 2.0 corpus, we classify words into five categories: trigger words, participants, objects, time and location. Each word is vectorized according to the following six feature layers: part of speech, dependency grammar, length, location, distance between trigger word and core word and trigger word frequency. We obtain deep semantic features of words by training a feature vector set using a deep belief network (DBN), then analyze those features in order to identify trigger words by means of a back propagation neural network. Extensive testing shows that the CEERM achieves excellent recognition performance, with a maximum F-measure value of 85.17%. Moreover, we propose the dynamic-supervised DBN, which adds supervised fine-tuning to a restricted Boltzmann machine layer by monitoring its training performance. Test analysis reveals that the new DBN improves recognition performance and effectively controls the training time. Although the F-measure increases to 88.11%, the training time increases by only 25.35%.	['Shanghai University, School of Computer Engineering and Science, Shanghai, China.', 'Shanghai University, School of Computer Engineering and Science, Shanghai, China.', 'Shanghai University, School of Computer Engineering and Science, Shanghai, China.']	['10.1371/journal.pone.0160147 [doi]', 'PONE-D-16-11954 [pii]']	['Zhang Y', 'Liu Z', 'Zhou W']				['National Natural Science Foundation of China (NSFC)']			['2016/08/09 06:00']	20170808	20160808	2016	2016/08/09 06:00		['Zhang, Yajun', 'Liu, Zongtian', 'Zhou, Wen']			8		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0160147 [doi]	20181113	['*Algorithms', 'China', 'Humans', '*Machine Learning', '*Natural Language Processing', '*Neural Networks (Computer)', '*Pattern Recognition, Visual', '*Semantics']	2017/08/09 06:00				NLM	e0160147	['2016/03/23 00:00 [received]', '2016/07/14 00:00 [accepted]', '2016/08/09 06:00 [entrez]', '2016/08/09 06:00 [pubmed]', '2017/08/09 06:00 [medline]']	United States	PMC4976888		27501231	epublish	['Journal Article']			IM		PLoS One. 2016 Aug 8;11(8):e0160147. doi: 10.1371/journal.pone.0160147. eCollection 2016.	MEDLINE	PLoS One	Event Recognition Based on Deep Learning in Chinese Texts.		11	Event Recognition Based on Deep Learning in Chinese Texts.
Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.	['European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton Cambridge, UK.', 'Department of Computer Science, University of Tartu, Tartu, Estonia Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton Cambridge, UK.', 'Department of Computer Science, University of Tartu, Tartu, Estonia Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton Cambridge, UK leopold.parts@sanger.ac.uk oliver.stegle@ebi.ac.uk.', 'European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton Cambridge, UK leopold.parts@sanger.ac.uk oliver.stegle@ebi.ac.uk.']	['10.15252/msb.20156651 [doi]']	['Angermueller C', 'Parnamaa T', 'Parts L', 'Stegle O']	['ORCID: 0000-0002-8818-7193']	['(c) 2016 The Authors. Published under the terms of the CC BY 4.0 license.']					['2016/07/31 06:00']	20170605	20160729	2016 Jul 29	2016/07/31 06:00		['Angermueller, Christof', 'Parnamaa, Tanel', 'Parts, Leopold', 'Stegle, Oliver']		['Wellcome Trust/United Kingdom']	7		1744-4292 (Electronic) 1744-4292 (Linking)	101235389	Molecular systems biology	['eng']	10.15252/msb.20156651 [doi]	20190112	['Computational Biology/*methods', 'Genomics/methods', 'Humans', 'Machine Learning', 'Models, Genetic']	2017/06/06 06:00		['*cellular imaging', '*computational biology', '*deep learning', '*machine learning', '*regulatory genomics']	['NOTNLM']	NLM	878	['2016/07/31 06:00 [entrez]', '2016/07/31 06:00 [pubmed]', '2017/06/06 06:00 [medline]']	England	PMC4965871		27474269	epublish	"['Journal Article', 'Review', ""Research Support, Non-U.S. Gov't""]"			IM		Mol Syst Biol. 2016 Jul 29;12(7):878. doi: 10.15252/msb.20156651.	MEDLINE	Mol Syst Biol	Deep learning for computational biology.		12	Deep learning for computational biology.
The identification of interactions between compounds and proteins plays an important role in network pharmacology and drug discovery. However, experimentally identifying compound-protein interactions (CPIs) is generally expensive and time-consuming, computational approaches are thus introduced. Among these, machine-learning based methods have achieved a considerable success. However, due to the nonlinear and imbalanced nature of biological data, many machine learning approaches have their own limitations. Recently, deep learning techniques show advantages over many state-of-the-art machine learning methods in some applications. In this study, we aim at improving the performance of CPI prediction based on deep learning, and propose a method called DL-CPI (the abbreviation of Deep Learning for Compound-Protein Interactions prediction), which employs deep neural network (DNN) to effectively learn the representations of compound-protein pairs. Extensive experiments show that DL-CPI can learn useful features of compound-protein pairs by a layerwise abstraction, and thus achieves better prediction performance than existing methods on both balanced and imbalanced datasets.	['Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai 200433, China. Electronic address: ktian14@fudan.edu.cn.', 'Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai 200433, China. Electronic address: shaomy@fudan.edu.cn.', 'School of Software, Jiangxi Normal University, Nanchang 330022, China. Electronic address: yang1995t@163.com.', 'Department of Computer Science and Technology, Tongji University, Shanghai 201804, China. Electronic address: jhguan@tongji.edu.cn.', 'Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai 200433, China. Electronic address: sgzhou@fudan.edu.cn.']	['S1046-2023(16)30199-2 [pii]', '10.1016/j.ymeth.2016.06.024 [doi]']	['Tian K', 'Shao M', 'Wang Y', 'Guan J', 'Zhou S']		['Copyright (c) 2016 Elsevier Inc. All rights reserved.']					['2016/07/06 06:00']	20180117	20160701	2016 Nov 1	2016/07/06 06:00		['Tian, Kai', 'Shao, Mingyu', 'Wang, Yang', 'Guan, Jihong', 'Zhou, Shuigeng']					1095-9130 (Electronic) 1046-2023 (Linking)	9426302	Methods (San Diego, Calif.)	['eng']	S1046-2023(16)30199-2 [pii] 10.1016/j.ymeth.2016.06.024 [doi]	20190527	['Algorithms', 'Databases, Chemical', 'Databases, Protein', '*Drug Compounding', 'Drug Discovery/*methods', 'Humans', 'Machine Learning', 'Neural Networks (Computer)', 'Pharmaceutical Preparations/chemistry', 'Protein Domains/drug effects', 'Protein Interaction Mapping/*methods', 'Proteins/*chemistry']	2018/01/18 06:00		['*Compound-protein interaction', '*Deep learning', '*Deep neural network (DNN)']	['NOTNLM']	NLM	64-72	['2016/04/12 00:00 [received]', '2016/06/20 00:00 [revised]', '2016/06/28 00:00 [accepted]', '2016/07/06 06:00 [pubmed]', '2018/01/18 06:00 [medline]', '2016/07/06 06:00 [entrez]']	United States			27378654	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Pharmaceutical Preparations)', '0 (Proteins)']	IM		Methods. 2016 Nov 1;110:64-72. doi: 10.1016/j.ymeth.2016.06.024. Epub 2016 Jul 1.	MEDLINE	Methods	Boosting compound-protein interaction prediction by deep learning.		110	Boosting compound-protein interaction prediction by deep learning.
A typical modern optimization technique is usually either heuristic or metaheuristic. This technique has managed to solve some optimization problems in the research area of science, engineering, and industry. However, implementation strategy of metaheuristic for accuracy improvement on convolution neural networks (CNN), a famous deep learning method, is still rarely investigated. Deep learning relates to a type of machine learning technique, where its aim is to move closer to the goal of artificial intelligence of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human. In this paper, we propose the implementation strategy of three popular metaheuristic approaches, that is, simulated annealing, differential evolution, and harmony search, to optimize CNN. The performances of these metaheuristic methods in optimizing CNN on classifying MNIST and CIFAR dataset were evaluated and compared. Furthermore, the proposed methods are also compared with the original CNN. Although the proposed methods show an increase in the computation time, their accuracy has also been improved (up to 7.14 percent).	['Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok 16424, Indonesia; Computer System Laboratory, STMIK Jakarta STI&K, Jakarta 12140, Indonesia.', 'Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok 16424, Indonesia.', 'Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok 16424, Indonesia.']	['10.1155/2016/1537325 [doi]']	['Rere LM', 'Fanany MI', 'Arymurthy AM']	['ORCID: 0000-0001-8257-4152']						['2016/07/05 06:00']	20170206	20160608	2016	2016/07/05 06:00		['Rere, L M Rasdi', 'Fanany, Mohamad Ivan', 'Arymurthy, Aniati Murni']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2016/1537325 [doi]	20181113	['*Algorithms', 'Artificial Intelligence', 'Brain/*physiology', '*Brain Mapping', 'Computer Simulation', 'Heuristics/*physiology', 'Humans', '*Neural Networks (Computer)']	2017/02/07 06:00				NLM	1537325	['2016/01/29 00:00 [received]', '2016/04/15 00:00 [revised]', '2016/05/10 00:00 [accepted]', '2016/07/05 06:00 [entrez]', '2016/07/05 06:00 [pubmed]', '2017/02/07 06:00 [medline]']	United States	PMC4916328		27375738	ppublish	['Journal Article']			IM		Comput Intell Neurosci. 2016;2016:1537325. doi: 10.1155/2016/1537325. Epub 2016 Jun 8.	MEDLINE	Comput Intell Neurosci	Metaheuristic Algorithms for Convolution Neural Network.		2016	Metaheuristic Algorithms for Convolution Neural Network.
This paper presents a neural system-based technique for segmenting short impaired speech utterances into silent, unvoiced, and voiced sections. Moreover, the proposed technique identifies those points of the (voiced) speech where the spectrum becomes steady. The resulting technique thus aims at detecting that limited section of the speech which contains the information about the potential impairment of the speech. This section is of interest to the speech therapist as it corresponds to the possibly incorrect movements of speech organs (lower lip and tongue with respect to the vocal tract). Two segmentation models to detect and identify the various sections of the disordered (impaired) speech signals have been developed and compared. The first makes use of a combination of four artificial neural networks. The second is based on a support vector machine (SVM). The SVM has been trained by means of an ad hoc nested algorithm whose outer layer is a metaheuristic while the inner layer is a convex optimization algorithm. Several metaheuristics have been tested and compared leading to the conclusion that some variants of the compact differential evolution (CDE) algorithm appears to be well-suited to address this problem. Numerical results show that the SVM model with a radial basis function is capable of effective detection of the portion of speech that is of interest to a therapist. The best performance has been achieved when the system is trained by the nested algorithm whose outer layer is hybrid-population-based/CDE. A population-based approach displays the best performance for the isolation of silence/noise sections, and the detection of unvoiced sections. On the other hand, a compact approach appears to be clearly well-suited to detect the beginning of the steady state of the voiced signal. Both the proposed segmentation models display outperformed two modern segmentation techniques based on Gaussian mixture model and deep learning.	['* Centre for Computational Intelligence, School of Computer Science and Informatics, De Montfort University, The Gateway, Leicester LE1 9BH, England, UK.', '* Centre for Computational Intelligence, School of Computer Science and Informatics, De Montfort University, The Gateway, Leicester LE1 9BH, England, UK.', 'dagger Department of Mathematical Information Technology, University of Jyvaskyla Jyvaskyla, Finland.']	['10.1142/S0129065716500234 [doi]']	['Iliya S', 'Neri F']							['2016/06/30 06:00']	20170123	20160329	2016 Sep	2016/06/30 06:00		['Iliya, Sunday', 'Neri, Ferrante']			6		1793-6462 (Electronic) 0129-0657 (Linking)	9100527	International journal of neural systems	['eng']	10.1142/S0129065716500234 [doi]	20170123	['Female', 'Humans', 'Male', '*Neural Networks (Computer)', 'Speech', 'Speech Disorders/diagnosis/physiopathology/therapy', 'Speech Production Measurement/*methods', 'Speech Therapy/*methods', '*Support Vector Machine']	2017/01/24 06:00		['Impaired speech', 'artificial neural network', 'compact differential evolution', 'metaheuristics', 'steady state', 'support vector machine']	['NOTNLM']	NLM	1650023	['2016/06/30 06:00 [entrez]', '2016/06/30 06:00 [pubmed]', '2017/01/24 06:00 [medline]']	Singapore			27354188	ppublish	['Comparative Study', 'Journal Article']			IM		Int J Neural Syst. 2016 Sep;26(6):1650023. doi: 10.1142/S0129065716500234. Epub 2016 Mar 29.	MEDLINE	Int J Neural Syst	Towards Artificial Speech Therapy: A Neural System for Impaired Speech Segmentation.		26	Towards Artificial Speech Therapy: A Neural System for Impaired Speech Segmentation.
Poly-lactide-co-glycolide (PLGA) is a copolymer of lactic and glycolic acid. Drug release from PLGA microspheres depends not only on polymer properties but also on drug type, particle size, morphology of microspheres, release conditions, etc. Selecting a subset of relevant properties for PLGA is a challenging machine learning task as there are over three hundred features to consider. In this work, we formulate the selection of critical attributes for PLGA as a multiobjective optimization problem with the aim of minimizing the error of predicting the dissolution profile while reducing the number of attributes selected. Four bio-inspired optimization algorithms: antlion optimization, binary version of antlion optimization, grey wolf optimization, and social spider optimization are used to select the optimal feature set for predicting the dissolution profile of PLGA. Besides these, LASSO algorithm is also used for comparisons. Selection of crucial variables is performed under the assumption that both predictability and model simplicity are of equal importance to the final result. During the feature selection process, a set of input variables is employed to find minimum generalization error across different predictive models and their settings/architectures. The methodology is evaluated using predictive modeling for which various tools are chosen, such as Cubist, random forests, artificial neural networks (monotonic MLP, deep learning MLP), multivariate adaptive regression splines, classification and regression tree, and hybrid systems of fuzzy logic and evolutionary computations (fugeR). The experimental results are compared with the results reported by Szlek. We obtain a normalized root mean square error (NRMSE) of 15.97% versus 15.4%, and the number of selected input features is smaller, nine versus eleven.	['Faculty of Mathematics and Computer Science, Babes-Bolyai University, Cluj-Napoca, Romania.', 'Faculty of Computers and Information, Beni-Suef University, Beni-Suef, Egypt.', 'Department of Pharmaceutical Technology and Biopharmaceutics, Jagiellonian University Medical College, Krakow, Poland.', 'Faculty of Mathematics and Computer Science, Babes-Bolyai University, Cluj-Napoca, Romania.', 'College of Engineering, Design and Physical Sciences, Brunel University, London, United Kingdom.', 'Department of Pharmaceutical Technology and Biopharmaceutics, Jagiellonian University Medical College, Krakow, Poland.', 'Department of Pharmaceutical Technology and Biopharmaceutics, Jagiellonian University Medical College, Krakow, Poland.']	['10.1371/journal.pone.0157610 [doi]', 'PONE-D-16-12259 [pii]']	['Zawbaa HM', 'Szlek J', 'Grosan C', 'Jachowicz R', 'Mendyk A']							['2016/06/18 06:00']	20170712	20160617	2016	2016/06/18 06:00		['Zawbaa, Hossam M', 'Szlek, Jakub', 'Grosan, Crina', 'Jachowicz, Renata', 'Mendyk, Aleksander']			6		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0157610 [doi]	20190213	['Algorithms', 'Artificial Intelligence', '*Drug Liberation', 'Humans', 'Lactic Acid/*chemistry/therapeutic use', 'Macromolecular Substances/*chemistry/therapeutic use', '*Microspheres', 'Particle Size', 'Polyglycolic Acid/*chemistry/therapeutic use', 'Polylactic Acid-Polyglycolic Acid Copolymer', 'Polymers/chemistry/therapeutic use']	2017/07/14 06:00				NLM	e0157610	['2016/03/24 00:00 [received]', '2016/06/01 00:00 [accepted]', '2016/06/18 06:00 [entrez]', '2016/06/18 06:00 [pubmed]', '2017/07/14 06:00 [medline]']	United States	PMC4912096		27315205	epublish	['Journal Article']		['0 (Macromolecular Substances)', '0 (Polymers)', '1SIA8062RS (Polylactic Acid-Polyglycolic Acid Copolymer)', '26009-03-0 (Polyglycolic Acid)', '33X04XA5AT (Lactic Acid)']	IM		PLoS One. 2016 Jun 17;11(6):e0157610. doi: 10.1371/journal.pone.0157610. eCollection 2016.	MEDLINE	PLoS One	Computational Intelligence Modeling of the Macromolecules Release from PLGA Microspheres-Focus on Feature Selection.		11	Computational Intelligence Modeling of the Macromolecules Release from PLGA Microspheres-Focus on Feature Selection.
MOTIVATION: Circadian rhythms date back to the origins of life, are found in virtually every species and every cell, and play fundamental roles in functions ranging from metabolism to cognition. Modern high-throughput technologies allow the measurement of concentrations of transcripts, metabolites and other species along the circadian cycle creating novel computational challenges and opportunities, including the problems of inferring whether a given species oscillate in circadian fashion or not, and inferring the time at which a set of measurements was taken. RESULTS: We first curate several large synthetic and biological time series datasets containing labels for both periodic and aperiodic signals. We then use deep learning methods to develop and train BIO_CYCLE, a system to robustly estimate which signals are periodic in high-throughput circadian experiments, producing estimates of amplitudes, periods, phases, as well as several statistical significance measures. Using the curated data, BIO_CYCLE is compared to other approaches and shown to achieve state-of-the-art performance across multiple metrics. We then use deep learning methods to develop and train BIO_CLOCK to robustly estimate the time at which a particular single-time-point transcriptomic experiment was carried. In most cases, BIO_CLOCK can reliably predict time, within approximately 1 h, using the expression levels of only a small number of core clock genes. BIO_CLOCK is shown to work reasonably well across tissue types, and often with only small degradation across conditions. BIO_CLOCK is used to annotate most mouse experiments found in the GEO database with an inferred time stamp. AVAILABILITY AND IMPLEMENTATION: All data and software are publicly available on the CircadiOmics web portal: circadiomics.igb.uci.edu/ CONTACTS: fagostin@uci.edu or pfbaldi@uci.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	['Department of Computer Science.', 'Department of Computer Science.', 'Department of Statistics.', 'Department of Biological Chemistry, University of California-Irvine, Irvine, CA 92697, USA.', 'Department of Computer Science, Department of Biological Chemistry, University of California-Irvine, Irvine, CA 92697, USA.']	['btw243 [pii]', '10.1093/bioinformatics/btw243 [doi]']	['Agostinelli F', 'Ceglia N', 'Shahbaba B', 'Sassone-Corsi P', 'Baldi P']		['(c) The Author 2016. Published by Oxford University Press.']					['2016/06/17 06:00']	20170823		2016 Jun 15	2016/06/17 06:00	['Bioinformatics. 2016 Oct 1;32(19):3051. PMID: 27542773']	['Agostinelli, Forest', 'Ceglia, Nicholas', 'Shahbaba, Babak', 'Sassone-Corsi, Paolo', 'Baldi, Pierre']		['R01 DA036984/DA/NIDA NIH HHS/United States']	12		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btw243 [doi]	20190225	['Animals', 'Circadian Clocks', '*Circadian Rhythm', 'Computational Biology/*methods', '*Machine Learning', 'Mice', 'Software', '*Transcriptome']	2016/06/17 06:01				NLM	i8-i17	['2016/06/17 06:00 [entrez]', '2016/06/17 06:00 [pubmed]', '2016/06/17 06:01 [medline]']	England	PMC4908327		27307647	ppublish	['Journal Article']			IM		Bioinformatics. 2016 Jun 15;32(12):i8-i17. doi: 10.1093/bioinformatics/btw243.	MEDLINE	Bioinformatics	What time is it? Deep learning approaches for circadian rhythms.		32	What time is it? Deep learning approaches for circadian rhythms.
INTRODUCTION: Neural networks are becoming a very popular method for solving machine learning and artificial intelligence problems. The variety of neural network types and their application to drug discovery requires expert knowledge to choose the most appropriate approach. AREAS COVERED: In this review, the authors discuss traditional and newly emerging neural network approaches to drug discovery. Their focus is on backpropagation neural networks and their variants, self-organizing maps and associated methods, and a relatively new technique, deep learning. The most important technical issues are discussed including overfitting and its prevention through regularization, ensemble and multitask modeling, model interpretation, and estimation of applicability domain. Different aspects of using neural networks in drug discovery are considered: building structure-activity models with respect to various targets; predicting drug selectivity, toxicity profiles, ADMET and physicochemical properties; characteristics of drug-delivery systems and virtual screening. EXPERT OPINION: Neural networks continue to grow in importance for drug discovery. Recent developments in deep learning suggests further improvements may be gained in the analysis of large chemical data sets. It's anticipated that neural networks will be more widely used in drug discovery in the future, and applied in non-traditional areas such as drug delivery systems, biologically compatible materials, and regenerative medicine.	['a Faculty of Physics , M.V. Lomonosov Moscow State University , Moscow , Russia.', 'b A.M. Butlerov Institute of Chemistry , Kazan Federal University , Kazan , Russia.', 'c CSIRO Manufacturing , Clayton , VIC , Australia.', 'd Monash Institute for Pharmaceutical Sciences , Monash University , Parkville , VIC , Australia.', 'e Latrobe Institute for Molecular Science , Bundoora , VIC , Australia.', 'f School of Chemical and Physical Sciences , Flinders University , Bedford Park , SA , Australia.', 'g Helmholtz Zentrum Munchen - German Research Center for Environmental Health (GmbH) , Institute of Structural Biology , Neuherberg , Germany.', 'h BigChem GmbH , Neuherberg , Germany.']	['10.1080/17460441.2016.1201262 [doi]']	['Baskin II', 'Winkler D', 'Tetko IV']							['2016/06/14 06:00']	20170529	20160704	2016 Aug	2016/06/14 06:00		['Baskin, Igor I', 'Winkler, David', 'Tetko, Igor V']			8		1746-045X (Electronic) 1746-0441 (Linking)	101295755	Expert opinion on drug discovery	['eng']	10.1080/17460441.2016.1201262 [doi]	20170529	['Computer-Aided Design', 'Drug Delivery Systems', '*Drug Design', 'Drug Discovery/*methods', 'Humans', 'Models, Biological', '*Neural Networks (Computer)', 'Pharmaceutical Preparations/administration & dosage/chemistry', 'Structure-Activity Relationship']	2017/05/30 06:00		['*Deep learning', '*neural network ensembles', '*neural networks', '*overfitting', '*structure-activity relationships']	['NOTNLM']	NLM	785-95	['2016/06/14 06:00 [entrez]', '2016/06/14 06:00 [pubmed]', '2017/05/30 06:00 [medline]']	England			27295548	ppublish	['Journal Article', 'Review']		['0 (Pharmaceutical Preparations)']	IM		Expert Opin Drug Discov. 2016 Aug;11(8):785-95. doi: 10.1080/17460441.2016.1201262. Epub 2016 Jul 4.	MEDLINE	Expert Opin Drug Discov	A renaissance of neural networks in drug discovery.		11	A renaissance of neural networks in drug discovery.
Microcalcification is an effective indicator of early breast cancer. To improve the diagnostic accuracy of microcalcifications, this study evaluates the performance of deep learning-based models on large datasets for its discrimination. A semi-automated segmentation method was used to characterize all microcalcifications. A discrimination classifier model was constructed to assess the accuracies of microcalcifications and breast masses, either in isolation or combination, for classifying breast lesions. Performances were compared to benchmark models. Our deep learning model achieved a discriminative accuracy of 87.3% if microcalcifications were characterized alone, compared to 85.8% with a support vector machine. The accuracies were 61.3% for both methods with masses alone and improved to 89.7% and 85.8% after the combined analysis with microcalcifications. Image segmentation with our deep learning model yielded 15, 26 and 41 features for the three scenarios, respectively. Overall, deep learning based on large datasets was superior to standard methods for the discrimination of microcalcifications. Accuracy was increased by adopting a combinatorial approach to detect microcalcifications and masses simultaneously. This may have clinical value for early detection and treatment of breast cancer.	['Department of Radiology, Affiliated Nanhai Hospital of Southern Medical University, Foshan 528200, Guangdong, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, Guangdong, China.', 'School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, Guangdong, China.', 'Department of Radiology, Affiliated Nanhai Hospital of Southern Medical University, Foshan 528200, Guangdong, China.', 'Department of Radiology, Affiliated Nanhai Hospital of Southern Medical University, Foshan 528200, Guangdong, China.', 'Sun Yat-sen University Cancer Center; State Key Laboratory of Oncology in South China; Collaborative Innovation Center for Cancer Medicine, Guangzhou 510060, Guangdong, China.']	['srep27327 [pii]', '10.1038/srep27327 [doi]']	['Wang J', 'Yang X', 'Cai H', 'Tan W', 'Jin C', 'Li L']							['2016/06/09 06:00']	20180416	20160607	2016 Jun 7	2016/06/09 06:00		['Wang, Jinhua', 'Yang, Xi', 'Cai, Hongmin', 'Tan, Wanchang', 'Jin, Cangzheng', 'Li, Li']					2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/srep27327 [doi]	20181113	['Adult', 'Aged', 'Breast Neoplasms/*diagnostic imaging/*pathology', 'Calcinosis/*diagnostic imaging/*pathology', 'China', 'Female', 'Humans', '*Machine Learning', 'Mammography/*methods', 'Middle Aged', 'Sensitivity and Specificity']	2018/04/17 06:00				NLM	27327	['2016/02/11 00:00 [received]', '2016/05/13 00:00 [accepted]', '2016/06/09 06:00 [entrez]', '2016/06/09 06:00 [pubmed]', '2018/04/17 06:00 [medline]']	England	PMC4895132		27273294	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Sci Rep. 2016 Jun 7;6:27327. doi: 10.1038/srep27327.	MEDLINE	Sci Rep	Discrimination of Breast Cancer with Microcalcifications on Mammography by Deep Learning.		6	Discrimination of Breast Cancer with Microcalcifications on Mammography by Deep Learning.
Functional MRI (fMRI) is a popular and important tool for noninvasive mapping of neural activity. As fMRI measures the hemodynamic response, the resulting activation maps do not perfectly reflect the underlying neural activity. The purpose of this work was to design a data-driven model to improve the spatial accuracy of fMRI maps in the rat olfactory bulb. This system is an ideal choice for this investigation since the bulb circuit is well characterized, allowing for an accurate definition of activity patterns in order to train the model. We generated models for both cerebral blood volume weighted (CBVw) and blood oxygen level dependent (BOLD) fMRI data. The results indicate that the spatial accuracy of the activation maps is either significantly improved or at worst not significantly different when using the learned models compared to a conventional general linear model approach, particularly for BOLD images and activity patterns involving deep layers of the bulb. Furthermore, the activation maps computed by CBVw and BOLD data show increased agreement when using the learned models, lending more confidence to their accuracy. The models presented here could have an immediate impact on studies of the olfactory bulb, but perhaps more importantly, demonstrate the potential for similar flexible, data-driven models to improve the quality of activation maps calculated using fMRI data.	['Department of Ophthalmology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA; Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA. Electronic address: murphymc@pitt.edu.', 'Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA.', 'Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA.', 'Department of Ophthalmology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA; Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA, USA.', 'Center for Neuroscience Imaging Research, Institute for Basic Science, Sungkyunkwan University, Suwon, Republic of Korea; Department of Biomedical Engineering, Sungkyunkwan University, Suwon, Republic of Korea; Department of Biological Sciences, Sungkyunkwan University, Suwon, Republic of Korea.', 'Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, USA.']	['S1053-8119(16)30175-6 [pii]', '10.1016/j.neuroimage.2016.05.055 [doi]']	['Murphy MC', 'Poplawsky AJ', 'Vazquez AL', 'Chan KC', 'Kim SG', 'Fukuda M']		['Copyright (c) 2016 Elsevier Inc. All rights reserved.']					['2016/05/29 06:00']	20180123	20160525	2016 Aug 15	2016/05/29 06:00		['Murphy, Matthew C', 'Poplawsky, Alexander J', 'Vazquez, Alberto L', 'Chan, Kevin C', 'Kim, Seong-Gi', 'Fukuda, Mitsuhiro']		['T32 NS007391/NS/NINDS NIH HHS/United States', 'R21 EB018903/EB/NIBIB NIH HHS/United States', 'R21 NS079143/NS/NINDS NIH HHS/United States', 'S10 RR026503/RR/NCRR NIH HHS/United States', 'T32 EY017271/EY/NEI NIH HHS/United States', 'R01 EB003324/EB/NIBIB NIH HHS/United States', 'P30 EY008098/EY/NEI NIH HHS/United States']			1095-9572 (Electronic) 1053-8119 (Linking)	9215515	NeuroImage	['eng']	S1053-8119(16)30175-6 [pii] 10.1016/j.neuroimage.2016.05.055 [doi]	20181113	['Algorithms', 'Animals', 'Brain Mapping/*methods', 'Electric Stimulation', 'Image Enhancement/*methods', 'Image Interpretation, Computer-Assisted/methods', 'Magnetic Resonance Imaging/*methods', 'Male', 'Olfactory Bulb/*physiology', 'Pattern Recognition, Automated/methods', 'Rats', 'Rats, Sprague-Dawley', 'Reproducibility of Results', 'Sensitivity and Specificity', 'Smell/*physiology', '*Spatio-Temporal Analysis', '*Supervised Machine Learning']	2018/01/24 06:00	['NIHMS792107']			NLM	1-8	['2016/01/04 00:00 [received]', '2016/05/11 00:00 [revised]', '2016/05/22 00:00 [accepted]', '2016/05/29 06:00 [entrez]', '2016/05/29 06:00 [pubmed]', '2018/01/24 06:00 [medline]']	United States	PMC4914461		27236085	ppublish	['Evaluation Studies', 'Journal Article']			IM		Neuroimage. 2016 Aug 15;137:1-8. doi: 10.1016/j.neuroimage.2016.05.055. Epub 2016 May 25.	MEDLINE	Neuroimage	Improved spatial accuracy of functional maps in the rat olfactory bulb using supervised machine learning approach.		137	Improved spatial accuracy of functional maps in the rat olfactory bulb using supervised machine learning approach.
Deep learning is rapidly advancing many areas of science and technology with multiple success stories in image, text, voice and video recognition, robotics, and autonomous driving. In this paper we demonstrate how deep neural networks (DNN) trained on large transcriptional response data sets can classify various drugs to therapeutic categories solely based on their transcriptional profiles. We used the perturbation samples of 678 drugs across A549, MCF-7, and PC-3 cell lines from the LINCS Project and linked those to 12 therapeutic use categories derived from MeSH. To train the DNN, we utilized both gene level transcriptomic data and transcriptomic data processed using a pathway activation scoring algorithm, for a pooled data set of samples perturbed with different concentrations of the drug for 6 and 24 hours. In both pathway and gene level classification, DNN achieved high classification accuracy and convincingly outperformed the support vector machine (SVM) model on every multiclass classification problem, however, models based on pathway level data performed significantly better. For the first time we demonstrate a deep learning neural net trained on transcriptomic data to recognize pharmacological properties of multiple drugs across different biological systems and conditions. We also propose using deep neural net confusion matrices for drug repositioning. This work is a proof of principle for applying deep learning to drug discovery and development.	['Insilico Medicine, ETC, B301, Johns Hopkins University , Baltimore, Maryland 21218, United States.', 'Datalytic Solutions , 1101 Yale Boulevard NE, Albuquerque, New Mexico 87106, United States.', 'The Mind Research Network , Albuquerque, New Mexico 87106, United States.', 'Insilico Medicine, ETC, B301, Johns Hopkins University , Baltimore, Maryland 21218, United States.', 'The Mind Research Network , Albuquerque, New Mexico 87106, United States.', 'Insilico Medicine, ETC, B301, Johns Hopkins University , Baltimore, Maryland 21218, United States.', 'Insilico Medicine, ETC, B301, Johns Hopkins University , Baltimore, Maryland 21218, United States.', 'The Biogerontology Research Foundation , Oxford, U.K.']	['10.1021/acs.molpharmaceut.6b00248 [doi]']	['Aliper A', 'Plis S', 'Artemov A', 'Ulloa A', 'Mamoshina P', 'Zhavoronkov A']							['2016/05/21 06:00']	20171020	20160608	2016 Jul 5	2016/05/21 06:00		['Aliper, Alexander', 'Plis, Sergey', 'Artemov, Artem', 'Ulloa, Alvaro', 'Mamoshina, Polina', 'Zhavoronkov, Alex']		['R01 EB005846/EB/NIBIB NIH HHS/United States']	7		1543-8392 (Electronic) 1543-8384 (Linking)	101197791	Molecular pharmaceutics	['eng']	10.1021/acs.molpharmaceut.6b00248 [doi]	20181113	['A549 Cells', '*Algorithms', 'Drug Discovery', 'Drug Repositioning/*methods', 'Humans', 'MCF-7 Cells', 'Neural Networks (Computer)', 'Support Vector Machine', 'Transcriptome/genetics']	2017/10/21 06:00	['NIHMS804810']	['*DNN', '*confusion matrix', '*deep learning', '*deep neural networks', '*drug discovery', '*drug repurposing', '*predictor']	['NOTNLM']	NLM	2524-30	['2016/05/21 06:00 [entrez]', '2016/05/21 06:00 [pubmed]', '2017/10/21 06:00 [medline]']	United States	PMC4965264		27200455	ppublish	['Journal Article']			IM		Mol Pharm. 2016 Jul 5;13(7):2524-30. doi: 10.1021/acs.molpharmaceut.6b00248. Epub 2016 Jun 8.	MEDLINE	Mol Pharm	Deep Learning Applications for Predicting Pharmacological Properties of Drugs and Drug Repurposing Using Transcriptomic Data.		13	Deep Learning Applications for Predicting Pharmacological Properties of Drugs and Drug Repurposing Using Transcriptomic Data.
The complex language of eukaryotic gene expression remains incompletely understood. Despite the importance suggested by many noncoding variants statistically associated with human disease, nearly all such variants have unknown mechanisms. Here, we address this challenge using an approach based on a recent machine learning advance-deep convolutional neural networks (CNNs). We introduce the open source package Basset to apply CNNs to learn the functional activity of DNA sequences from genomics data. We trained Basset on a compendium of accessible genomic sites mapped in 164 cell types by DNase-seq, and demonstrate greater predictive accuracy than previous methods. Basset predictions for the change in accessibility between variant alleles were far greater for Genome-wide association study (GWAS) SNPs that are likely to be causal relative to nearby SNPs in linkage disequilibrium with them. With Basset, a researcher can perform a single sequencing assay in their cell type of interest and simultaneously learn that cell's chromatin accessibility code and annotate every mutation in the genome with its influence on present accessibility and latent potential for accessibility. Thus, Basset offers a powerful computational approach to annotate and interpret the noncoding genome.	['Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, Massachusetts 02138, USA;', 'School of Engineering and Applied Science, Harvard University, Cambridge, Massachusetts 02138, USA.', 'Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, Massachusetts 02138, USA;']	['gr.200535.115 [pii]', '10.1101/gr.200535.115 [doi]']	['Kelley DR', 'Snoek J', 'Rinn JL']		['(c) 2016 Kelley et al.; Published by Cold Spring Harbor Laboratory Press.']					['2016/05/20 06:00']	20170330	20160503	2016 Jul	2016/05/20 06:00		['Kelley, David R', 'Snoek, Jasper', 'Rinn, John L']		['K25 ES022984/ES/NIEHS NIH HHS/United States', 'R01 MH102416/MH/NIMH NIH HHS/United States']	7		1549-5469 (Electronic) 1088-9051 (Linking)	9518021	Genome research	['eng']	10.1101/gr.200535.115 [doi]	20181113	['Base Sequence', 'Binding Sites', 'Consensus Sequence', 'Humans', 'Linkage Disequilibrium', '*Models, Genetic', 'Molecular Sequence Annotation', 'Neural Networks (Computer)', 'Polymorphism, Single Nucleotide', '*Sequence Analysis, DNA', 'Support Vector Machine']	2017/03/31 06:00				NLM	990-9	['2015/10/04 00:00 [received]', '2016/04/26 00:00 [accepted]', '2016/05/20 06:00 [entrez]', '2016/05/20 06:00 [pubmed]', '2017/03/31 06:00 [medline]']	United States	PMC4937568		27197224	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Genome Res. 2016 Jul;26(7):990-9. doi: 10.1101/gr.200535.115. Epub 2016 May 3.	MEDLINE	Genome Res	Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks.		26	Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks.
This study examines the effectiveness of state-of-the-art supervised machine learning methods in conjunction with different feature types for the task of automatic annotation of fragments of clinical text based on codebooks with a large number of categories. We used a collection of motivational interview transcripts consisting of 11,353 utterances, which were manually annotated by two human coders as the gold standard, and experimented with state-of-art classifiers, including Naive Bayes, J48 Decision Tree, Support Vector Machine (SVM), Random Forest (RF), AdaBoost, DiscLDA, Conditional Random Fields (CRF) and Convolutional Neural Network (CNN) in conjunction with lexical, contextual (label of the previous utterance) and semantic (distribution of words in the utterance across the Linguistic Inquiry and Word Count dictionaries) features. We found out that, when the number of classes is large, the performance of CNN and CRF is inferior to SVM. When only lexical features were used, interview transcripts were automatically annotated by SVM with the highest classification accuracy among all classifiers of 70.8%, 61% and 53.7% based on the codebooks consisting of 17, 20 and 41 codes, respectively. Using contextual and semantic features, as well as their combination, in addition to lexical ones, improved the accuracy of SVM for annotation of utterances in motivational interview transcripts with a codebook consisting of 17 classes to 71.5%, 74.2%, and 75.1%, respectively. Our results demonstrate the potential of using machine learning methods in conjunction with lexical, semantic and contextual features for automatic annotation of clinical interview transcripts with near-human accuracy.	['Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, MI 48202, USA.', 'Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, MI 48202, USA.', 'Pediatric Prevention Research Center, School of Medicine, Wayne State University, 540 E Canfield St, Detroit, MI 48201, USA.', 'Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, MI 48202, USA.', 'Pediatric Prevention Research Center, School of Medicine, Wayne State University, 540 E Canfield St, Detroit, MI 48201, USA.', 'Department of Dietetics and Nutrition, Florida International University, 11200 SW 8th St, Miami, FL 33199, USA.']	['10.1016/j.jbi.2016.05.004 [doi]', 'S1532-0464(16)30034-X [pii]']	['Hasan M', 'Kotov A', 'Carcone A', 'Dong M', 'Naar S', 'Hartlieb KB']		['Copyright (c) 2016 Elsevier Inc. All rights reserved.']					['2016/05/18 06:00']	20180212	20160513	2016 Aug	2016/05/18 06:00		['Hasan, Mehedi', 'Kotov, Alexander', 'Carcone, April', 'Dong, Ming', 'Naar, Sylvie', 'Hartlieb, Kathryn Brogan']		['P30 CA022453/CA/NCI NIH HHS/United States', 'U01 HL097889/HL/NHLBI NIH HHS/United States']			1532-0480 (Electronic) 1532-0464 (Linking)	100970413	Journal of biomedical informatics	['eng']	10.1016/j.jbi.2016.05.004 [doi]	20181202	['Bayes Theorem', 'Data Curation/*methods', '*Decision Trees', '*Machine Learning', 'Semantics', 'Support Vector Machine']	2018/02/13 06:00	['NIHMS792098']	['*Annotation of clinical text', '*Deep learning', '*Machine learning', '*Motivational interviewing', '*Text classification']	['NOTNLM']	NLM	21-31	['2016/01/16 00:00 [received]', '2016/05/12 00:00 [revised]', '2016/05/12 00:00 [accepted]', '2016/05/18 06:00 [entrez]', '2016/05/18 06:00 [pubmed]', '2018/02/13 06:00 [medline]']	United States	PMC4987168		27185608	ppublish	['Journal Article']			IM		J Biomed Inform. 2016 Aug;62:21-31. doi: 10.1016/j.jbi.2016.05.004. Epub 2016 May 13.	MEDLINE	J Biomed Inform	A study of the effectiveness of machine learning methods for classification of clinical interview fragments into a large number of categories.		62	A study of the effectiveness of machine learning methods for classification of clinical interview fragments into a large number of categories.
A structural or functional pattern of neuroplasticity that could systematically discriminate between people with impaired and preserved motor performance could help us to understand the brain networks contributing to preservation or compensation of behavior in multiple sclerosis (MS). This study aimed to (1) investigate whether a machine learning-based technique could accurately classify MS participants into groups defined by upper extremity function (i.e. motor function preserved (MP) vs. motor function impaired (MI)) based on their regional grey matter measures (GMM, cortical thickness and deep grey matter volume) and inter-regional functional connection (FC), (2) investigate which features (GMM, FC, or GMM + FC) could classify groups more accurately, and (3) identify the multivariate patterns of GMM and FCs that are most discriminative between MP and MI participants, and between each of these groups and the healthy controls (HCs). With 26 MP, 25 MI, and 21 HCs (age and sex matched) underwent T1-weighted and resting-state functional MRI at 3 T, we applied support vector machine (SVM) based classification to learn discriminant functions indicating regions in which GMM or between which FCs were most discriminative between groups. This study demonstrates that there exist structural and FC patterns sufficient for correct classification of upper limb motor ability of people with MS. The classifier with GMM + FC features yielded the highest accuracy of 85.61 % (p < 0.001) to distinguish between the MS groups using leave-one-out cross-validation. It suggests that a machine-learning approach combining structural and functional features is useful for identifying the specific neural substrates that are necessary and sufficient to preserve motor function among people with MS.	['Research Institute of the McGill University Health Centre, Montreal, QC, Canada. jidanz@gmail.com.', 'Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada. jidanz@gmail.com.', 'Toronto Western Hospital, 399 Bathurst Street, Toronto, ON, M5T 2S8, Canada. jidanz@gmail.com.', 'Institute of Medical Science, University of Toronto, Toronto, ON, Canada.', 'Division of Brain, Imaging and Behaviour-Systems, Neuroscience, Krembil Research Institute, University Health Network, Toronto, ON, Canada.', 'Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada.', 'Integrated Program in Neuroscience, McGill University, Montreal, QC, Canada.', 'Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada.', 'Integrated Program in Neuroscience, McGill University, Montreal, QC, Canada.', 'Institute of Medical Science, University of Toronto, Toronto, ON, Canada.', 'Division of Brain, Imaging and Behaviour-Systems, Neuroscience, Krembil Research Institute, University Health Network, Toronto, ON, Canada.', 'Division of Neurosurgery, Toronto Western Hospital & University of Toronto, Toronto, ON, Canada.', 'Research Institute of the McGill University Health Centre, Montreal, QC, Canada.', 'Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada.', 'Department of Psychology, McGill University, Montreal, QC, Canada.']	['10.1007/s11682-016-9551-4 [doi]', '10.1007/s11682-016-9551-4 [pii]']	['Zhong J', 'Chen DQ', 'Nantes JC', 'Holmes SA', 'Hodaie M', 'Koski L']							['2016/05/06 06:00']	20180327		2017 Jun	2016/05/06 06:00		['Zhong, Jidan', 'Chen, David Qixiang', 'Nantes, Julia C', 'Holmes, Scott A', 'Hodaie, Mojgan', 'Koski, Lisa']			3		1931-7565 (Electronic) 1931-7557 (Linking)	101300405	Brain imaging and behavior	['eng']	10.1007/s11682-016-9551-4 [doi]	20180327	['Area Under Curve', 'Diagnosis, Differential', 'Female', 'Functional Laterality', 'Humans', 'Image Interpretation, Computer-Assisted/*methods', '*Magnetic Resonance Imaging/methods', 'Male', 'Middle Aged', 'Motor Activity', 'Movement Disorders/*diagnostic imaging/drug therapy/etiology/physiopathology', 'Multiple Sclerosis/classification/*diagnostic imaging/drug therapy/physiopathology', 'Multivariate Analysis', 'Organ Size', 'ROC Curve', 'Support Vector Machine', 'Upper Extremity/physiopathology']	2018/03/28 06:00		['Cortical thickness', 'Deep grey matter volume', 'Functional connectivity', 'Motor disability', 'Multiple sclerosis', 'Multivariate analysis', 'Support vector machine']	['NOTNLM']	NLM	754-768	['2016/05/06 06:00 [pubmed]', '2018/03/28 06:00 [medline]', '2016/05/06 06:00 [entrez]']	United States			27146291	ppublish	['Journal Article']			IM		Brain Imaging Behav. 2017 Jun;11(3):754-768. doi: 10.1007/s11682-016-9551-4.	MEDLINE	Brain Imaging Behav	Combined structural and functional patterns discriminating upper limb motor disability in multiple sclerosis using multivariate approaches.		11	Combined structural and functional patterns discriminating upper limb motor disability in multiple sclerosis using multivariate approaches.
TensorFlow is Google's recently released open-source software for deep learning. What are its applications for computational biology?	['SickKids Research Institute, 686 Bay Street, Toronto, ON M5G 0A4, Canada; Department of Computer Science, University of Toronto, 40 St. George Street, Toronto, ON M5S 2E4, Canada.', 'SickKids Research Institute, 686 Bay Street, Toronto, ON M5G 0A4, Canada; Department of Computer Science, University of Toronto, 40 St. George Street, Toronto, ON M5S 2E4, Canada. Electronic address: anna.goldenberg@utoronto.ca.']	['S2405-4712(16)00010-7 [pii]', '10.1016/j.cels.2016.01.009 [doi]']	['Rampasek L', 'Goldenberg A']		['Copyright (c) 2016 Elsevier Inc. All rights reserved.']					['2016/05/03 06:00']	20190103	20160127	2016 Jan 27	2016/05/03 06:00		['Rampasek, Ladislav', 'Goldenberg, Anna']			1		2405-4712 (Print) 2405-4712 (Linking)	101656080	Cell systems	['eng']	10.1016/j.cels.2016.01.009 [doi] S2405-4712(16)00010-7 [pii]	20190103	['Computational Biology', 'Databases, Factual', '*Machine Learning', 'Software', 'Software Design', 'Synthetic Biology']	2019/01/04 06:00				NLM	12-4	['2016/05/03 06:00 [entrez]', '2016/05/03 06:00 [pubmed]', '2019/01/04 06:00 [medline]']	United States			27136685	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Cell Syst. 2016 Jan 27;2(1):12-4. doi: 10.1016/j.cels.2016.01.009. Epub 2016 Jan 27.	MEDLINE	Cell Syst	TensorFlow: Biology's Gateway to Deep Learning?		2	TensorFlow: Biology's Gateway to Deep Learning?
The restricted Boltzmann machine (RBM) is an essential constituent of deep learning, but it is hard to train by using maximum likelihood (ML) learning, which minimizes the Kullback-Leibler (KL) divergence. Instead, contrastive divergence (CD) learning has been developed as an approximation of ML learning and widely used in practice. To clarify the performance of CD learning, in this paper, we analytically derive the fixed points where ML and CDn learning rules converge in two types of RBMs: one with Gaussian visible and Gaussian hidden units and the other with Gaussian visible and Bernoulli hidden units. In addition, we analyze the stability of the fixed points. As a result, we find that the stable points of CDn learning rule coincide with those of ML learning rule in a Gaussian-Gaussian RBM. We also reveal that larger principal components of the input data are extracted at the stable points. Moreover, in a Gaussian-Bernoulli RBM, we find that both ML and CDn learning can extract independent components at one of stable points. Our analysis demonstrates that the same feature components as those extracted by ML learning are extracted simply by performing CD1 learning. Expanding this study should elucidate the specific solutions obtained by CD learning in other types of RBMs or in deep networks.	['Department of Complexity Science and Engineering, The University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa-shi, Chiba 277-8561, Japan. Electronic address: karakida@mns.k.u-tokyo.ac.jp.', 'Department of Complexity Science and Engineering, The University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa-shi, Chiba 277-8561, Japan; RIKEN Brain Science Institute, 2-1 Hirosawa, Wako-shi, Saitama 351-0198, Japan. Electronic address: okada@k.u-tokyo.ac.jp.', 'RIKEN Brain Science Institute, 2-1 Hirosawa, Wako-shi, Saitama 351-0198, Japan. Electronic address: amari@brain.riken.jp.']	['S0893-6080(16)30018-1 [pii]', '10.1016/j.neunet.2016.03.013 [doi]']	['Karakida R', 'Okada M', 'Amari S']		['Copyright (c) 2016 Elsevier Ltd. All rights reserved.']					['2016/05/02 06:00']	20170419	20160412	2016 Jul	2016/05/02 06:00		['Karakida, Ryo', 'Okada, Masato', 'Amari, Shun-Ichi']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	10.1016/j.neunet.2016.03.013 [doi] S0893-6080(16)30018-1 [pii]	20181202	['Algorithms', 'Learning', '*Machine Learning', '*Neural Networks (Computer)', '*Normal Distribution', 'Probability Learning']	2017/04/20 06:00		['Component analysis', 'Contrastive divergence', 'Deep learning', 'Restricted Boltzmann machine', 'Stability of learning algorithms']	['NOTNLM']	NLM	78-87	['2015/10/02 00:00 [received]', '2016/03/23 00:00 [revised]', '2016/03/31 00:00 [accepted]', '2016/05/02 06:00 [entrez]', '2016/05/02 06:00 [pubmed]', '2017/04/20 06:00 [medline]']	United States			27131468	ppublish	['Journal Article']			IM		Neural Netw. 2016 Jul;79:78-87. doi: 10.1016/j.neunet.2016.03.013. Epub 2016 Apr 12.	MEDLINE	Neural Netw	Dynamical analysis of contrastive divergence learning: Restricted Boltzmann machines with Gaussian visible units.		79	Dynamical analysis of contrastive divergence learning: Restricted Boltzmann machines with Gaussian visible units.
In the field of computational structural proteomics, contact predictions have shown new prospects of solving the longstanding problem of ab initio protein structure prediction. In the last few years, application of deep learning algorithms and availability of large protein sequence databases, combined with improvement in methods that derive contacts from multiple sequence alignments, have shown a huge increase in the precision of contact prediction. In addition, these predicted contacts have also been used to build three-dimensional models from scratch.In this chapter, we briefly discuss many elements of protein residue-residue contacts and the methods available for prediction, focusing on a state-of-the-art contact prediction tool, DNcon. Illustrating with a case study, we describe how DNcon can be used to make ab initio contact predictions for a given protein sequence and discuss how the predicted contacts may be analyzed and evaluated.	['Department of Computer Science, University of Missouri, 201 Engineering Building West, Columbia, MO, 65211, USA.', 'Department of Computer Science, University of Missouri, 201 Engineering Building West, Columbia, MO, 65211, USA. chengji@missouri.edu.']	['10.1007/978-1-4939-3572-7_24 [doi]']	['Adhikari B', 'Cheng J']							['2016/04/27 06:00']	20171213		2016	2016/04/27 06:00		['Adhikari, Badri', 'Cheng, Jianlin']		['R01 GM093123/GM/NIGMS NIH HHS/United States']			1940-6029 (Electronic) 1064-3745 (Linking)	9214969	Methods in molecular biology (Clifton, N.J.)	['eng']	10.1007/978-1-4939-3572-7_24 [doi]	20181113	['Binding Sites', 'Computational Biology/*methods', 'Databases, Protein', 'Machine Learning', 'Models, Molecular', 'Protein Binding', 'Protein Conformation', 'Proteins/*chemistry/*metabolism', 'Web Browser']	2017/12/14 06:00	['NIHMS789034']	['*Deep learning', '*Protein contact prediction methods']	['NOTNLM']	NLM	463-76	['2016/04/27 06:00 [entrez]', '2016/04/27 06:00 [pubmed]', '2017/12/14 06:00 [medline]']	United States	PMC4894841		27115648	ppublish	['Journal Article']		['0 (Proteins)']	IM		Methods Mol Biol. 2016;1415:463-76. doi: 10.1007/978-1-4939-3572-7_24.	MEDLINE	Methods Mol Biol	Protein Residue Contacts and Prediction Methods.		1415	Protein Residue Contacts and Prediction Methods.
RaptorX Property (http://raptorx2.uchicago.edu/StructurePropertyPred/predict/) is a web server predicting structure property of a protein sequence without using any templates. It outperforms other servers, especially for proteins without close homologs in PDB or with very sparse sequence profile (i.e. carries little evolutionary information). This server employs a powerful in-house deep learning model DeepCNF (Deep Convolutional Neural Fields) to predict secondary structure (SS), solvent accessibility (ACC) and disorder regions (DISO). DeepCNF not only models complex sequence-structure relationship by a deep hierarchical architecture, but also interdependency between adjacent property labels. Our experimental results show that, tested on CASP10, CASP11 and the other benchmarks, this server can obtain approximately 84% Q3 accuracy for 3-state SS, approximately 72% Q8 accuracy for 8-state SS, approximately 66% Q3 accuracy for 3-state solvent accessibility, and approximately 0.89 area under the ROC curve (AUC) for disorder prediction.	['Toyota Technological Institute at Chicago, Chicago, IL, USA Department of Human Genetics, University of Chicago, Chicago, IL, USA wangsheng@uchicago.edu.', 'School of Biological and Chemical Engineering, Zhejiang University of Science and Technology, Zhejiang, China.', 'School of Biological and Chemical Engineering, Zhejiang University of Science and Technology, Zhejiang, China.', 'Toyota Technological Institute at Chicago, Chicago, IL, USA jinboxu@gmail.com.']	['gkw306 [pii]', '10.1093/nar/gkw306 [doi]']	['Wang S', 'Li W', 'Liu S', 'Xu J']		['(c) The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic', 'Acids Research.']					['2016/04/27 06:00']	20170612	20160425	2016 Jul 8	2016/04/27 06:00		['Wang, Sheng', 'Li, Wei', 'Liu, Shiwang', 'Xu, Jinbo']		['R01 GM089753/GM/NIGMS NIH HHS/United States']	W1		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gkw306 [doi]	20181113	['Amino Acid Sequence', 'Area Under Curve', 'Caspases/chemistry', 'Databases, Protein', '*Internet', 'Machine Learning', 'Neural Networks (Computer)', 'Protein Structure, Secondary', 'Proteins/*chemistry', 'ROC Curve', '*Software', 'Solvents/chemistry', 'Time Factors']	2017/06/13 06:00				NLM	W430-5	['2016/04/12 00:00 [accepted]', '2016/02/19 00:00 [received]', '2016/04/27 06:00 [entrez]', '2016/04/27 06:00 [pubmed]', '2017/06/13 06:00 [medline]']	England	PMC4987890		27112573	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S."", 'Research Support, N.I.H., Extramural']"		['0 (Proteins)', '0 (Solvents)', 'EC 3.4.22.- (Caspases)']	IM		Nucleic Acids Res. 2016 Jul 8;44(W1):W430-5. doi: 10.1093/nar/gkw306. Epub 2016 Apr 25.	MEDLINE	Nucleic Acids Res	RaptorX-Property: a web server for protein structure property prediction.		44	RaptorX-Property: a web server for protein structure property prediction.
Cryosection brain images in Chinese Visible Human (CVH) dataset contain rich anatomical structure information of tissues because of its high resolution (e.g., 0.167 mm per pixel). Fast and accurate segmentation of these images into white matter, gray matter, and cerebrospinal fluid plays a critical role in analyzing and measuring the anatomical structures of human brain. However, most existing automated segmentation methods are designed for computed tomography or magnetic resonance imaging data, and they may not be applicable for cryosection images due to the imaging difference. In this paper, we propose a supervised learning-based CVH brain tissues segmentation method that uses stacked autoencoder (SAE) to automatically learn the deep feature representations. Specifically, our model includes two successive parts where two three-layer SAEs take image patches as input to learn the complex anatomical feature representation, and then these features are sent to Softmax classifier for inferring the labels. Experimental results validated the effectiveness of our method and showed that it outperformed four other classical brain tissue detection strategies. Furthermore, we reconstructed three-dimensional surfaces of these tissues, which show their potential in exploring the high-resolution anatomical structures of human brain.	['Key Laboratory of Optoelectronic Technology and Systems of Ministry of Education, College of Optoelectronic Engineering, Chongqing University, Chongqing 400044, China.', 'Key Laboratory of Optoelectronic Technology and Systems of Ministry of Education, College of Optoelectronic Engineering, Chongqing University, Chongqing 400044, China.', 'College of Computer and Information Science, Chongqing Normal University, Chongqing 400050, China.', 'Institute of Digital Medicine, College of Biomedical Engineering, Third Military Medical University, Chongqing 400038, China.', 'Institute of Digital Medicine, College of Biomedical Engineering, Third Military Medical University, Chongqing 400038, China.']	['10.1155/2016/5284586 [doi]']	['Zhao G', 'Wang X', 'Niu Y', 'Tan L', 'Zhang SX']							['2016/04/09 06:00']	20170103	20160126	2016	2016/04/09 06:00		['Zhao, Guangjun', 'Wang, Xuchu', 'Niu, Yanmin', 'Tan, Liwen', 'Zhang, Shao-Xiang']					2314-6141 (Electronic)	101600173	BioMed research international	['eng']	10.1155/2016/5284586 [doi]	20181113	['Brain/*anatomy & histology/*diagnostic imaging', 'Humans', 'Image Processing, Computer-Assisted/*methods', '*Supervised Machine Learning', '*Visible Human Projects']	2017/01/04 06:00				NLM	5284586	['2015/11/02 00:00 [received]', '2015/12/18 00:00 [revised]', '2015/12/27 00:00 [accepted]', '2016/04/09 06:00 [entrez]', '2016/04/09 06:00 [pubmed]', '2017/01/04 06:00 [medline]']	United States	PMC4807075		27057543	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Biomed Res Int. 2016;2016:5284586. doi: 10.1155/2016/5284586. Epub 2016 Jan 26.	MEDLINE	Biomed Res Int	Segmenting Brain Tissues from Chinese Visible Human Dataset by Deep-Learned Features with Stacked Autoencoder.		2016	Segmenting Brain Tissues from Chinese Visible Human Dataset by Deep-Learned Features with Stacked Autoencoder.
Given genomic variation data from multiple individuals, computing the likelihood of complex population genetic models is often infeasible. To circumvent this problem, we introduce a novel likelihood-free inference framework by applying deep learning, a powerful modern technique in machine learning. Deep learning makes use of multilayer neural networks to learn a feature-based function from the input (e.g., hundreds of correlated summary statistics of data) to the output (e.g., population genetic parameters of interest). We demonstrate that deep learning can be effectively employed for population genetic inference and learning informative features of data. As a concrete application, we focus on the challenging problem of jointly inferring natural selection and demography (in the form of a population size change history). Our method is able to separate the global nature of demography from the local nature of selection, without sequential steps for these two factors. Studying demography and selection jointly is motivated by Drosophila, where pervasive selection confounds demographic analysis. We apply our method to 197 African Drosophila melanogaster genomes from Zambia to infer both their overall demography, and regions of their genome under selection. We find many regions of the genome that have experienced hard sweeps, and fewer under selection on standing variation (soft sweep) or balancing selection. Interestingly, we find that soft sweeps and balancing selection occur more frequently closer to the centromere of each chromosome. In addition, our demographic inference suggests that previously estimated bottlenecks for African Drosophila melanogaster are too extreme.	['Department of Computer Science, Smith College, Northampton, Massachusetts, United States of America.', 'Computer Science Division, UC Berkeley, Berkeley, California, United States of America.', 'Computer Science Division, UC Berkeley, Berkeley, California, United States of America.', 'Department of Statistics, UC Berkeley, Berkeley, California, United States of America.', 'Department of Integrative Biology, UC Berkeley, Berkeley, California, United States of America.', 'Department of Mathematics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America.', 'Department of Biology, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America.']	['10.1371/journal.pcbi.1004845 [doi]', 'PCOMPBIOL-D-15-01668 [pii]']	['Sheehan S', 'Song YS']							['2016/03/29 06:00']	20160808	20160328	2016 Mar	2016/03/29 06:00		['Sheehan, Sara', 'Song, Yun S']		['R01 GM094402/GM/NIGMS NIH HHS/United States', 'R01-GM094402/GM/NIGMS NIH HHS/United States']	3		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1004845 [doi]	20190201	['Animals', 'Drosophila melanogaster/genetics', 'Genetics, Population/*methods', 'Genomics/*methods', '*Machine Learning', 'Models, Genetic']	2016/08/09 06:00				NLM	e1004845	['2015/10/02 00:00 [received]', '2016/03/02 00:00 [accepted]', '2016/03/29 06:00 [entrez]', '2016/03/29 06:00 [pubmed]', '2016/08/09 06:00 [medline]']	United States	PMC4809617		27018908	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		PLoS Comput Biol. 2016 Mar 28;12(3):e1004845. doi: 10.1371/journal.pcbi.1004845. eCollection 2016 Mar.	MEDLINE	PLoS Comput Biol	Deep Learning for Population Genetic Inference.		12	Deep Learning for Population Genetic Inference.
Compound selectivity prediction plays an important role in identifying potential compounds that bind to the target of interest with high affinity. However, there is still short of efficient and accurate computational approaches to analyze and predict compound selectivity. In this paper, we propose two methods to improve the compound selectivity prediction. We employ an improved multitask learning method in Neural Networks (NNs), which not only incorporates both activity and selectivity for other targets, but also uses a probabilistic classifier with a logistic regression. We further improve the compound selectivity prediction by using the multitask learning method in Deep Belief Networks (DBNs) which can build a distributed representation model and improve the generalization of the shared tasks. In addition, we assign different weights to the auxiliary tasks that are related to the primary selectivity prediction task. In contrast to other related work, our methods greatly improve the accuracy of the compound selectivity prediction, in particular, using the multitask learning in DBNs with modified weights obtains the best performance.	['School of Information Science & Engineering, Lanzhou University, Lanzhou, Gansu 730000, China. zhangrs@lzu.edu.cn.']	['CAD-EPUB-73827 [pii]', '10.2174/1573409912666160219113250 [doi]']	['Zhang R', 'Li J', 'Lu J', 'Hu R', 'Yuan Y', 'Zhao Z']							['2016/02/20 06:00']	20161213		2016	2016/02/20 06:00		['Zhang, Ruisheng', 'Li, Juan', 'Lu, Jingjing', 'Hu, Rongjing', 'Yuan, Yongna', 'Zhao, Zhili']			1		1875-6697 (Electronic) 1573-4099 (Linking)	101265750	Current computer-aided drug design	['eng']		20191113	['Algorithms', 'Computer-Aided Design', '*Drug Design', 'Machine Learning', '*Neural Networks (Computer)', 'Probability']	2016/12/15 06:00				NLM	5-14	['2015/07/03 00:00 [received]', '2016/01/13 00:00 [revised]', '2016/02/17 00:00 [accepted]', '2016/02/20 06:00 [entrez]', '2016/02/20 06:00 [pubmed]', '2016/12/15 06:00 [medline]']	United Arab Emirates			26892071	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Curr Comput Aided Drug Des. 2016;12(1):5-14. doi: 10.2174/1573409912666160219113250.	MEDLINE	Curr Comput Aided Drug Des	Using Deep Learning for Compound Selectivity Prediction.		12	Using Deep Learning for Compound Selectivity Prediction.
MOTIVATION: Large-scale gene expression profiling has been widely used to characterize cellular states in response to various disease conditions, genetic perturbations, etc. Although the cost of whole-genome expression profiles has been dropping steadily, generating a compendium of expression profiling over thousands of samples is still very expensive. Recognizing that gene expressions are often highly correlated, researchers from the NIH LINCS program have developed a cost-effective strategy of profiling only approximately 1000 carefully selected landmark genes and relying on computational methods to infer the expression of remaining target genes. However, the computational approach adopted by the LINCS program is currently based on linear regression (LR), limiting its accuracy since it does not capture complex nonlinear relationship between expressions of genes. RESULTS: We present a deep learning method (abbreviated as D-GEX) to infer the expression of target genes from the expression of landmark genes. We used the microarray-based Gene Expression Omnibus dataset, consisting of 111K expression profiles, to train our model and compare its performance to those from other methods. In terms of mean absolute error averaged across all genes, deep learning significantly outperforms LR with 15.33% relative improvement. A gene-wise comparative analysis shows that deep learning achieves lower error than LR in 99.97% of the target genes. We also tested the performance of our learned model on an independent RNA-Seq-based GTEx dataset, which consists of 2921 expression profiles. Deep learning still outperforms LR with 6.57% relative improvement, and achieves lower error in 81.31% of the target genes. AVAILABILITY AND IMPLEMENTATION: D-GEX is available at https://github.com/uci-cbcl/D-GEX CONTACT: xhx@ics.uci.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of California, Irvine, CA 92697, USA Baidu Research-Big Data Lab, Beijing, 100085, China.', 'Department of Computer Science, University of California, Irvine, CA 92697, USA.', 'Broad Institute of MIT And Harvard, Cambridge, MA 02142, USA.', 'Broad Institute of MIT And Harvard, Cambridge, MA 02142, USA.', 'Department of Computer Science, University of California, Irvine, CA 92697, USA Center for Complex Biological Systems, University of California, Irvine, CA 92697, USA.']	['btw074 [pii]', '10.1093/bioinformatics/btw074 [doi]']	['Chen Y', 'Li Y', 'Narayan R', 'Subramanian A', 'Xie X']		['(c) The Author 2016. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com.']					['2016/02/14 06:00']	20170802	20160211	2016 Jun 15	2016/02/14 06:00		['Chen, Yifei', 'Li, Yi', 'Narayan, Rajiv', 'Subramanian, Aravind', 'Xie, Xiaohui']		['P50 GM076516/GM/NIGMS NIH HHS/United States']	12		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btw074 [doi]	20181202	['*Gene Expression', 'Gene Expression Profiling', 'Linear Models', 'Machine Learning', 'RNA']	2017/08/03 06:00				NLM	1832-9	['2015/08/05 00:00 [received]', '2016/02/03 00:00 [accepted]', '2016/02/14 06:00 [entrez]', '2016/02/14 06:00 [pubmed]', '2017/08/03 06:00 [medline]']	England	PMC4908320		26873929	ppublish	['Journal Article']		['63231-63-0 (RNA)']	IM		Bioinformatics. 2016 Jun 15;32(12):1832-9. doi: 10.1093/bioinformatics/btw074. Epub 2016 Feb 11.	MEDLINE	Bioinformatics	Gene expression inference with deep learning.		32	Gene expression inference with deep learning.
One of the major challenges for protein docking methods is to accurately discriminate native-like structures from false positives. Docking methods are often inaccurate and the results have to be refined and re-ranked to obtain native-like complexes and remove outliers. In a previous work, we introduced AccuRefiner, a machine learning based tool for refining protein-protein complexes. Given a docked complex, the refinement tool produces a small set of refined versions of the input complex, with lower root-mean-square-deviation (RMSD) of atomic positions with respect to the native structure. The method employs a unique ranking tool that accurately predicts the RMSD of docked complexes with respect to the native structure. In this work, we use a deep learning network with a similar set of features and five layers. We show that a properly trained deep learning network can accurately predict the RMSD of a docked complex with 1.40 A error margin on average, by approximating the complex relationship between a wide set of scoring function terms and the RMSD of a docked structure. The network was trained on 35000 unbound docking complexes generated by RosettaDock. We tested our method on 25 different putative docked complexes produced also by RosettaDock for five proteins that were not included in the training data. The results demonstrate that the high accuracy of the ranking tool enables AccuRefiner to consistently choose the refinement candidates with lower RMSD values compared to the coarsely docked input structures.	['1 Department of Computer Science, University of Massachusetts Boston, 100 Morrissey Boulevard, Boston, MA 02125, USA.', '1 Department of Computer Science, University of Massachusetts Boston, 100 Morrissey Boulevard, Boston, MA 02125, USA.', '1 Department of Computer Science, University of Massachusetts Boston, 100 Morrissey Boulevard, Boston, MA 02125, USA.', '1 Department of Computer Science, University of Massachusetts Boston, 100 Morrissey Boulevard, Boston, MA 02125, USA.']	['10.1142/S0219720016420026 [doi]']	['Akbal-Delibas B', 'Farhoodi R', 'Pomplun M', 'Haspel N']							['2016/02/06 06:00']	20170705	20151124	2016 Jun	2016/02/06 06:00		['Akbal-Delibas, Bahar', 'Farhoodi, Roshanak', 'Pomplun, Marc', 'Haspel, Nurit']		['CCF-1421871/National Science Foundation/International']	3		1757-6334 (Electronic) 0219-7200 (Linking)	101187344	Journal of bioinformatics and computational biology	['eng']	10.1142/S0219720016420026 [doi]	20180810	['Databases, Protein', 'Molecular Docking Simulation/*methods', 'Neural Networks (Computer)', 'Protein Conformation', 'Proteins/*chemistry/metabolism']	2017/07/06 06:00		['*Protein docking', '*deep learning neural networks', '*ranking and scoring functions']	['NOTNLM']	NLM	1642002	['2016/02/06 06:00 [entrez]', '2016/02/06 06:00 [pubmed]', '2017/07/06 06:00 [medline]']	Singapore			26846813	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Proteins)']	IM		J Bioinform Comput Biol. 2016 Jun;14(3):1642002. doi: 10.1142/S0219720016420026. Epub 2015 Nov 24.	MEDLINE	J Bioinform Comput Biol	Accurate refinement of docked protein complexes using evolutionary information and deep learning.		14	Accurate refinement of docked protein complexes using evolutionary information and deep learning.
"The hypo- or hyper-methylation of the human genome is one of the epigenetic features of leukemia. However, experimental approaches have only determined the methylation state of a small portion of the human genome. We developed deep learning based (stacked denoising autoencoders, or SdAs) software named ""DeepMethyl"" to predict the methylation state of DNA CpG dinucleotides using features inferred from three-dimensional genome topology (based on Hi-C) and DNA sequence patterns. We used the experimental data from immortalised myelogenous leukemia (K562) and healthy lymphoblastoid (GM12878) cell lines to train the learning models and assess prediction performance. We have tested various SdA architectures with different configurations of hidden layer(s) and amount of pre-training data and compared the performance of deep networks relative to support vector machines (SVMs). Using the methylation states of sequentially neighboring regions as one of the learning features, an SdA achieved a blind test accuracy of 89.7% for GM12878 and 88.6% for K562. When the methylation states of sequentially neighboring regions are unknown, the accuracies are 84.82% for GM12878 and 72.01% for K562. We also analyzed the contribution of genome topological features inferred from Hi-C. DeepMethyl can be accessed at http://dna.cs.usm.edu/deepmethyl/."	['School of Computing, University of Southern Mississippi, 118 College Drive #5106, Hattiesburg, MS 39406, USA.', 'School of Computing, University of Southern Mississippi, 118 College Drive #5106, Hattiesburg, MS 39406, USA.', 'Department of Computer Science and Christopher S. Bond Life Sciences Center, University of Missouri, 201 Engineering Building West, Columbia, MO 65211, USA.', 'Department of Biochemistry and Molecular Biology, Georgia Regents University, 1120 15th Street, Augusta, GA 30912, USA.', 'School of Computing, University of Southern Mississippi, 118 College Drive #5106, Hattiesburg, MS 39406, USA.', 'Department of Pharmacology and Toxicology, University of Mississippi Medical Center, 2500 North State Street, Jackson, MS 39216, USA.', 'School of Computing, University of Southern Mississippi, 118 College Drive #5106, Hattiesburg, MS 39406, USA.']	['srep19598 [pii]', '10.1038/srep19598 [doi]']	['Wang Y', 'Liu T', 'Xu D', 'Shi H', 'Zhang C', 'Mo YY', 'Wang Z']							['2016/01/23 06:00']	20170104	20160122	2016 Jan 22	2016/01/23 06:00		['Wang, Yiheng', 'Liu, Tong', 'Xu, Dong', 'Shi, Huidong', 'Zhang, Chaoyang', 'Mo, Yin-Yuan', 'Wang, Zheng']					2045-2322 (Electronic) 2045-2322 (Linking)	101563288	Scientific reports	['eng']	10.1038/srep19598 [doi]	20181113	['Cell Line, Tumor', 'Chromosomes, Human/genetics', 'CpG Islands/genetics', 'DNA Methylation/*genetics', 'Databases, Genetic', 'Dinucleoside Phosphates/*genetics', 'Genetic Loci', '*Genome, Human', 'Humans', 'RNA, Long Noncoding/genetics', 'ROC Curve', 'Reproducibility of Results', '*Software', 'Support Vector Machine']	2017/01/05 06:00				NLM	19598	['2015/06/10 00:00 [received]', '2015/12/14 00:00 [accepted]', '2016/01/23 06:00 [entrez]', '2016/01/23 06:00 [pubmed]', '2017/01/05 06:00 [medline]']	England	PMC4726425		26797014	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		"['0 (Dinucleoside Phosphates)', '0 (RNA, Long Noncoding)', ""2382-65-2 (cytidylyl-3'-5'-guanosine)""]"	IM		Sci Rep. 2016 Jan 22;6:19598. doi: 10.1038/srep19598.	MEDLINE	Sci Rep	Predicting DNA Methylation State of CpG Dinucleotide Using Genome Topological Features and Deep Networks.		6	Predicting DNA Methylation State of CpG Dinucleotide Using Genome Topological Features and Deep Networks.
"People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms-for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world's alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several ""visual Turing tests"" probing the model's creative generalization abilities, which in many cases are indistinguishable from human behavior."	"['Center for Data Science, New York University, 726 Broadway, New York, NY 10003, USA. brenden@nyu.edu.', ""Department of Computer Science and Department of Statistics, University of Toronto, 6 King's College Road, Toronto, ON M5S 3G4, Canada."", 'Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 02139, USA.']"	['350/6266/1332 [pii]', '10.1126/science.aab3050 [doi]']	['Lake BM', 'Salakhutdinov R', 'Tenenbaum JB']		['Copyright (c) 2015, American Association for the Advancement of Science.']					['2015/12/15 06:00']	20160112		2015 Dec 11	2015/12/15 06:00		['Lake, Brenden M', 'Salakhutdinov, Ruslan', 'Tenenbaum, Joshua B']			6266		1095-9203 (Electronic) 0036-8075 (Linking)	0404511	Science (New York, N.Y.)	['eng']	10.1126/science.aab3050 [doi]	20151215	['Algorithms', 'Bayes Theorem', '*Computer Simulation', '*Concept Formation', '*Generalization (Psychology)', 'Humans', '*Machine Learning']	2016/01/13 06:00				NLM	1332-8	['2015/12/15 06:00 [entrez]', '2015/12/15 06:00 [pubmed]', '2016/01/13 06:00 [medline]']	United States			26659050	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Science. 2015 Dec 11;350(6266):1332-8. doi: 10.1126/science.aab3050.	MEDLINE	Science	Human-level concept learning through probabilistic program induction.		350	Human-level concept learning through probabilistic program induction.
"To stimulate progress in automating the reconstruction of neural circuits, we organized the first international challenge on 2D segmentation of electron microscopic (EM) images of the brain. Participants submitted boundary maps predicted for a test set of images, and were scored based on their agreement with a consensus of human expert annotations. The winning team had no prior experience with EM images, and employed a convolutional network. This ""deep learning"" approach has since become accepted as a standard for segmentation of EM images. The challenge has continued to accept submissions, and the best so far has resulted from cooperation between two teams. The challenge has probably saturated, as algorithms cannot progress beyond limits set by ambiguities inherent in 2D scoring and the size of the test dataset. Retrospective evaluation of the challenge scoring system reveals that it was not sufficiently robust to variations in the widths of neurite borders. We propose a solution to this problem, which should be useful for a future 3D segmentation challenge."	['UMR1318 French National Institute for Agricultural Research-AgroParisTech, French National Institute for Agricultural Research Centre de Versailles-Grignon, Institut Jean-Pierre Bourgin Versailles, France.', 'Howard Hughes Medical Institute, Janelia Research Campus Ashburn, VA, USA.', 'Center for Brain Science, Harvard University Cambridge, MA, USA.', 'Swiss AI Lab IDSIA (Dalle Molle Institute for Artificial Intelligence) Universita Della Svizzera Italiana, Scuola Universitaria Professionale Della Svizzera Italiana Lugano, Switzerland.', 'Swiss AI Lab IDSIA (Dalle Molle Institute for Artificial Intelligence) Universita Della Svizzera Italiana, Scuola Universitaria Professionale Della Svizzera Italiana Lugano, Switzerland.', 'Swiss AI Lab IDSIA (Dalle Molle Institute for Artificial Intelligence) Universita Della Svizzera Italiana, Scuola Universitaria Professionale Della Svizzera Italiana Lugano, Switzerland.', 'Swiss AI Lab IDSIA (Dalle Molle Institute for Artificial Intelligence) Universita Della Svizzera Italiana, Scuola Universitaria Professionale Della Svizzera Italiana Lugano, Switzerland.', 'Department of Computer Science, ETH Zurich Zurich, Switzerland.', 'Department of Computer Science, ETH Zurich Zurich, Switzerland.', 'Department of Computer Science, ETH Zurich Zurich, Switzerland.', 'Scientific Computing and Imaging Institute, University of Utah Salt Lake City, UT, USA.', 'Scientific Computing and Imaging Institute, University of Utah Salt Lake City, UT, USA.', 'Scientific Computing and Imaging Institute, University of Utah Salt Lake City, UT, USA.', 'Imaging Platform, Broad Institute Cambridge, MA, USA.', 'Department of Telecommunications, Faculty of Electrical Engineering and Communication, Brno University of Technology Brno, Czech Republic.', 'Department of Telecommunications, Faculty of Electrical Engineering and Communication, Brno University of Technology Brno, Czech Republic.', 'School of Engineering and Information Technology, University of New South Wales Canberra, ACT, Australia.', 'Digital Productivity Flagship, Commonwealth Scientific and Industrial Research Organisation North Ryde, NSW, Australia.', 'Department of Biomedical Engineering, The Institute of Technology, Linkoping University Linkoping, Sweden.', 'Howard Hughes Medical Institute, Janelia Research Campus Ashburn, VA, USA.', 'Computer Science Department, Rutgers University New Brunswick, NJ, USA.', 'Howard Hughes Medical Institute, Janelia Research Campus Ashburn, VA, USA.', 'Laboratory for Optical and Computational Instrumentation, University of Wisconsin-Madison Madison, WI, USA.', 'Princeton Neuroscience Institute and Computer Science Department, Princeton University Princeton, NJ, USA.']	['10.3389/fnana.2015.00142 [doi]']	['Arganda-Carreras I', 'Turaga SC', 'Berger DR', 'Ciresan D', 'Giusti A', 'Gambardella LM', 'Schmidhuber J', 'Laptev D', 'Dwivedi S', 'Buhmann JM', 'Liu T', 'Seyedhosseini M', 'Tasdizen T', 'Kamentsky L', 'Burget R', 'Uher V', 'Tan X', 'Sun C', 'Pham TD', 'Bas E', 'Uzunbas MG', 'Cardona A', 'Schindelin J', 'Seung HS']							['2015/11/24 06:00']	20151123	20151105	2015	2015/11/26 06:00		['Arganda-Carreras, Ignacio', 'Turaga, Srinivas C', 'Berger, Daniel R', 'Ciresan, Dan', 'Giusti, Alessandro', 'Gambardella, Luca M', 'Schmidhuber, Jurgen', 'Laptev, Dmitry', 'Dwivedi, Sarvesh', 'Buhmann, Joachim M', 'Liu, Ting', 'Seyedhosseini, Mojtaba', 'Tasdizen, Tolga', 'Kamentsky, Lee', 'Burget, Radim', 'Uher, Vaclav', 'Tan, Xiao', 'Sun, Changming', 'Pham, Tuan D', 'Bas, Erhan', 'Uzunbas, Mustafa G', 'Cardona, Albert', 'Schindelin, Johannes', 'Seung, H Sebastian']					1662-5129 (Print) 1662-5129 (Linking)	101477943	Frontiers in neuroanatomy	['eng']	10.3389/fnana.2015.00142 [doi]	20181113		2015/11/26 06:01		['connectomics', 'electron microscopy', 'image segmentation', 'machine learning', 'reconstruction']	['NOTNLM']	NLM	142	['2015/05/21 00:00 [received]', '2015/10/19 00:00 [accepted]', '2015/11/24 06:00 [entrez]', '2015/11/26 06:00 [pubmed]', '2015/11/26 06:01 [medline]']	Switzerland	PMC4633678		26594156	epublish	['Journal Article']					Front Neuroanat. 2015 Nov 5;9:142. doi: 10.3389/fnana.2015.00142. eCollection 2015.	PubMed-not-MEDLINE	Front Neuroanat	Crowdsourcing the creation of image segmentation algorithms for connectomics.		9	Crowdsourcing the creation of image segmentation algorithms for connectomics.
A main research direction in the field of evolutionary machine learning is to develop a scalable classifier system to solve high-dimensional problems. Recently work has begun on autonomously reusing learned building blocks of knowledge to scale from low-dimensional problems to high-dimensional ones. An XCS-based classifier system, known as XCSCFC, has been shown to be scalable, through the addition of expression tree-like code fragments, to a limit beyond standard learning classifier systems. XCSCFC is especially beneficial if the target problem can be divided into a hierarchy of subproblems and each of them is solvable in a bottom-up fashion. However, if the hierarchy of subproblems is too deep, then XCSCFC becomes impractical because of the needed computational time and thus eventually hits a limit in problem size. A limitation in this technique is the lack of a cyclic representation, which is inherent in finite state machines (FSMs). However, the evolution of FSMs is a hard task owing to the combinatorially large number of possible states, connections, and interaction. Usually this requires supervised learning to minimize inappropriate FSMs, which for high-dimensional problems necessitates subsampling or incremental testing. To avoid these constraints, this work introduces a state-machine-based encoding scheme into XCS for the first time, termed XCSSMA. The proposed system has been tested on six complex Boolean problem domains: multiplexer, majority-on, carry, even-parity, count ones, and digital design verification problems. The proposed approach outperforms XCSCFA (an XCS that computes actions) and XCSF (an XCS that computes predictions) in three of the six problem domains, while the performance in others is similar. In addition, XCSSMA evolved, for the first time, compact and human readable general classifiers (i.e., solving any n-bit problems) for the even-parity and carry problem domains, demonstrating its ability to produce scalable solutions using a cyclic representation.	['School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand muhammad.iqbal@ecs.vuw.ac.nz.', 'School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand will.browne@ecs.vuw.ac.nz.', 'School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand mengjie.zhang@ecs.vuw.ac.nz.']	['10.1162/EVCO_a_00167 [doi]']	['Iqbal M', 'Browne WN', 'Zhang M']							['2015/09/26 06:00']	20171030	20150925	2017 Summer	2015/09/26 06:00		['Iqbal, Muhammad', 'Browne, Will N', 'Zhang, Mengjie']			2		1530-9304 (Electronic) 1063-6560 (Linking)	9513581	Evolutionary computation	['eng']	10.1162/EVCO_a_00167 [doi]	20181202	['*Algorithms', 'Artificial Intelligence', 'Biological Evolution', 'Humans', 'Machine Learning/standards/*trends']	2017/10/31 06:00		['Learning classifier systems', 'XCS', 'pattern recognition.', 'scalability', 'state machines']	['NOTNLM']	NLM	173-204	['2015/09/26 06:00 [pubmed]', '2017/10/31 06:00 [medline]', '2015/09/26 06:00 [entrez]']	United States			26406166	ppublish	['Journal Article']			IM		Evol Comput. 2017 Summer;25(2):173-204. doi: 10.1162/EVCO_a_00167. Epub 2015 Sep 25.	MEDLINE	Evol Comput	Extending XCS with Cyclic Graphs for Scalability on Complex Boolean Problems.		25	Extending XCS with Cyclic Graphs for Scalability on Complex Boolean Problems.
OBJECTIVE: Correlating electrical activity within the human brain to movement is essential for developing and refining interventions (e.g. deep brain stimulation (DBS)) to treat central nervous system disorders. It also serves as a basis for next generation brain-machine interfaces (BMIs). This study highlights a new decoding strategy for capturing movement and its corresponding laterality from deep brain local field potentials (LFPs). APPROACH: LFPs were recorded with surgically implanted electrodes from the subthalamic nucleus or globus pallidus interna in twelve patients with Parkinson's disease or dystonia during a visually cued finger-clicking task. We introduce a method to extract frequency dependent neural synchronization and inter-hemispheric connectivity features based upon wavelet packet transform (WPT) and Granger causality approaches. A novel weighted sequential feature selection algorithm has been developed to select optimal feature subsets through a feature contribution measure. This is particularly useful when faced with limited trials of high dimensionality data as it enables estimation of feature importance during the decoding process. MAIN RESULTS: This novel approach was able to accurately and informatively decode movement related behaviours from the recorded LFP activity. An average accuracy of 99.8% was achieved for movement identification, whilst subsequent laterality classification was 81.5%. Feature contribution analysis highlighted stronger contralateral causal driving between the basal ganglia hemispheres compared to ipsilateral driving, with causality measures considerably improving laterality discrimination. SIGNIFICANCE: These findings demonstrate optimally selected neural synchronization alongside causality measures related to inter-hemispheric connectivity can provide an effective control signal for augmenting adaptive BMIs. In the case of DBS patients, acquiring such signals requires no additional surgery whilst providing a relatively stable and computationally inexpensive control signal. This has the potential to extend invasive BMI, based on recordings within the motor cortex, by providing additional information from subcortical regions.	['Institute of Sound and Vibration Research, University of Southampton, Southampton, UK. Institute of Biomaterials and Biomedical Engineering, University of Toronto and Bloorview Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto, Canada. Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh.']	['10.1088/1741-2560/12/5/056011 [doi]']	['Mamun KA', 'Mace M', 'Lutman ME', 'Stein J', 'Liu X', 'Aziz T', 'Vaidyanathan R', 'Wang S']							['2015/08/26 06:00']	20160620	20150825	2015 Oct	2015/08/26 06:00		['Mamun, K A', 'Mace, M', 'Lutman, M E', 'Stein, J', 'Liu, X', 'Aziz, T', 'Vaidyanathan, R', 'Wang, S']			5		1741-2552 (Electronic) 1741-2552 (Linking)	101217933	Journal of neural engineering	['eng']	10.1088/1741-2560/12/5/056011 [doi]	20150923	['Adult', 'Aged', 'Algorithms', 'Basal Ganglia/*physiopathology', 'Brain-Computer Interfaces', 'Cortical Synchronization/*physiology', 'Electroencephalography/*methods', '*Evoked Potentials, Motor', 'Female', 'Humans', 'Machine Learning', 'Male', 'Middle Aged', 'Movement', 'Movement Disorders/*physiopathology', 'Pattern Recognition, Automated/*methods', 'Reproducibility of Results', 'Sensitivity and Specificity']	2016/06/21 06:00				NLM	056011	['2015/08/26 06:00 [entrez]', '2015/08/26 06:00 [pubmed]', '2016/06/21 06:00 [medline]']	England			26305124	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		J Neural Eng. 2015 Oct;12(5):056011. doi: 10.1088/1741-2560/12/5/056011. Epub 2015 Aug 25.	MEDLINE	J Neural Eng	Movement decoding using neural synchronization and inter-hemispheric connectivity from deep brain local field potentials.		12	Movement decoding using neural synchronization and inter-hemispheric connectivity from deep brain local field potentials.
Identifying functional effects of noncoding variants is a major challenge in human genetics. To predict the noncoding-variant effects de novo from sequence, we developed a deep learning-based algorithmic framework, DeepSEA (http://deepsea.princeton.edu/), that directly learns a regulatory sequence code from large-scale chromatin-profiling data, enabling prediction of chromatin effects of sequence alterations with single-nucleotide sensitivity. We further used this capability to improve prioritization of functional variants including expression quantitative trait loci (eQTLs) and disease-associated variants.	['Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, New Jersey, USA.', 'Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, New Jersey, USA.', 'Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, New Jersey, USA.', 'Department of Computer Science, Princeton University, Princeton, New Jersey, USA.', 'Simons Center for Data Analysis, Simons Foundation, New York, New York, USA.']	['nmeth.3547 [pii]', '10.1038/nmeth.3547 [doi]']	['Zhou J', 'Troyanskaya OG']			['Nat Methods. 2015 Oct;12(10):925-6. PMID: 26418766']				['2015/08/25 06:00']	20160425	20150824	2015 Oct	2015/08/25 06:00		['Zhou, Jian', 'Troyanskaya, Olga G']		['R01 GM071966/GM/NIGMS NIH HHS/United States', 'R01 HG005998/HG/NHGRI NIH HHS/United States', 'P50 GM071508/GM/NIGMS NIH HHS/United States', 'T32 HG003284/HG/NHGRI NIH HHS/United States']	10		1548-7105 (Electronic) 1548-7091 (Linking)	101215604	Nature methods	['eng']	10.1038/nmeth.3547 [doi]	20181113	['*Algorithms', 'Chromatin/*genetics', 'Epigenomics', 'Genome, Human', 'Hepatocyte Nuclear Factor 3-alpha/genetics', 'Humans', 'Models, Genetic', 'Mutation', '*Polymorphism, Single Nucleotide', '*Quantitative Trait Loci', 'RNA, Untranslated', 'Regulatory Sequences, Nucleic Acid', 'Support Vector Machine', 'Transcription Factors/genetics/metabolism']	2016/04/26 06:00	['NIHMS757739']			NLM	931-4	['2015/02/26 00:00 [received]', '2015/06/11 00:00 [accepted]', '2015/08/25 06:00 [entrez]', '2015/08/25 06:00 [pubmed]', '2016/04/26 06:00 [medline]']	United States	PMC4768299		26301843	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Chromatin)', '0 (FOXA1 protein, human)', '0 (Hepatocyte Nuclear Factor 3-alpha)', '0 (RNA, Untranslated)', '0 (Transcription Factors)']	IM		Nat Methods. 2015 Oct;12(10):931-4. doi: 10.1038/nmeth.3547. Epub 2015 Aug 24.	MEDLINE	Nat Methods	Predicting effects of noncoding variants with deep learning-based sequence model.		12	Predicting effects of noncoding variants with deep learning-based sequence model.
Quantum Neural Networks (QNN) models have attracted great attention since it innovates a new neural computing manner based on quantum entanglement. However, the existing QNN models are mainly based on the real quantum operations, and the potential of quantum entanglement is not fully exploited. In this paper, we proposes a novel quantum neuron model called Complex Quantum Neuron (CQN) that realizes a deep quantum entanglement. Also, a novel hybrid networks model Complex Rotation Quantum Dynamic Neural Networks (CRQDNN) is proposed based on Complex Quantum Neuron (CQN). CRQDNN is a three layer model with both CQN and classical neurons. An infinite impulse response (IIR) filter is embedded in the Networks model to enable the memory function to process time series inputs. The Levenberg-Marquardt (LM) algorithm is used for fast parameter learning. The networks model is developed to conduct time series predictions. Two application studies are done in this paper, including the chaotic time series prediction and electronic remaining useful life (RUL) prediction.	['School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China. Electronic address: yiqiancui@163.com.', 'School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China. Electronic address: shisjy@hotmail.com.', 'School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China. Electronic address: wangzili2014@yahoo.com.']	['S0893-6080(15)00150-1 [pii]', '10.1016/j.neunet.2015.07.013 [doi]']	['Cui Y', 'Shi J', 'Wang Z']		['Copyright (c) 2015 Elsevier Ltd. All rights reserved.']					['2015/08/17 06:00']	20160607	20150731	2015 Nov	2015/08/19 06:00		['Cui, Yiqian', 'Shi, Junyou', 'Wang, Zili']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	10.1016/j.neunet.2015.07.013 [doi] S0893-6080(15)00150-1 [pii]	20181202	['Algorithms', 'Computer Simulation', 'Computers, Hybrid', 'Forecasting', 'Machine Learning', '*Neural Networks (Computer)', '*Neurons', 'Prognosis', 'Quantum Theory', 'Rotation']	2016/06/09 06:00		['Chaotic time series prediction', 'Complex Quantum Neuron (CQN)', 'Infinite Impulse Response (IIR)', 'Quantum entanglement', 'Remaining Useful Life (RUL) prediction']	['NOTNLM']	NLM	11-26	['2014/12/03 00:00 [received]', '2015/07/02 00:00 [revised]', '2015/07/23 00:00 [accepted]', '2015/08/17 06:00 [entrez]', '2015/08/19 06:00 [pubmed]', '2016/06/09 06:00 [medline]']	United States			26277609	ppublish	['Journal Article']			IM		Neural Netw. 2015 Nov;71:11-26. doi: 10.1016/j.neunet.2015.07.013. Epub 2015 Jul 31.	MEDLINE	Neural Netw	Complex Rotation Quantum Dynamic Neural Networks (CRQDNN) using Complex Quantum Neuron (CQN): Applications to time series prediction.		71	Complex Rotation Quantum Dynamic Neural Networks (CRQDNN) using Complex Quantum Neuron (CQN): Applications to time series prediction.
Rapid growth in electronic health records (EHRs) use has led to an unprecedented expansion of available clinical data in electronic formats. However, much of the important healthcare information is locked in the narrative documents. Therefore Natural Language Processing (NLP) technologies, e.g., Named Entity Recognition that identifies boundaries and types of entities, has been extensively studied to unlock important clinical information in free text. In this study, we investigated a novel deep learning method to recognize clinical entities in Chinese clinical documents using the minimal feature engineering approach. We developed a deep neural network (DNN) to generate word embeddings from a large unlabeled corpus through unsupervised learning and another DNN for the NER task. The experiment results showed that the DNN with word embeddings trained from the large unlabeled corpus outperformed the state-of-the-art CRF's model in the minimal feature engineering setting, achieving the highest F1-score of 0.9280. Further analysis showed that word embeddings derived through unsupervised learning from large unlabeled corpus remarkably improved the DNN with randomized embedding, denoting the usefulness of unsupervised feature learning.	['School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.', 'Center for Medical Informatics, Peking University, Beijing, China.', 'School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA.']		['Wu Y', 'Jiang M', 'Lei J', 'Xu H']							['2015/08/12 06:00']	20161213		2015	2015/08/12 06:00		['Wu, Yonghui', 'Jiang, Min', 'Lei, Jianbo', 'Xu, Hua']		['R01 GM102282/GM/NIGMS NIH HHS/United States', 'R01 LM010681/LM/NLM NIH HHS/United States', 'R01LM010681-05/LM/NLM NIH HHS/United States']			1879-8365 (Electronic) 0926-9630 (Linking)	9214582	Studies in health technology and informatics	['eng']		20181113	['Algorithms', 'Biological Ontologies', 'China', 'Data Mining/*methods', 'Electronic Health Records/*classification', '*Language', '*Machine Learning', '*Neural Networks (Computer)', 'Terminology as Topic', '*Vocabulary, Controlled']	2016/12/15 06:00	['NIHMS708181']			NLM	624-8	['2015/08/12 06:00 [entrez]', '2015/08/12 06:00 [pubmed]', '2016/12/15 06:00 [medline]']	Netherlands	PMC4624324		26262126	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"			T		Stud Health Technol Inform. 2015;216:624-8.	MEDLINE	Stud Health Technol Inform	Named Entity Recognition in Chinese Clinical Text Using Deep Neural Network.		216	Named Entity Recognition in Chinese Clinical Text Using Deep Neural Network.
MOTIVATION: Effective computational methods for peptide-protein binding prediction can greatly help clinical peptide vaccine search and design. However, previous computational methods fail to capture key nonlinear high-order dependencies between different amino acid positions. As a result, they often produce low-quality rankings of strong binding peptides. To solve this problem, we propose nonlinear high-order machine learning methods including high-order neural networks (HONNs) with possible deep extensions and high-order kernel support vector machines to predict major histocompatibility complex-peptide binding. RESULTS: The proposed high-order methods improve quality of binding predictions over other prediction methods. With the proposed methods, a significant gain of up to 25-40% is observed on the benchmark and reference peptide datasets and tasks. In addition, for the first time, our experiments show that pre-training with high-order semi-restricted Boltzmann machines significantly improves the performance of feed-forward HONNs. Moreover, our experiments show that the proposed shallow HONN outperform the popular pre-trained deep neural network on most tasks, which demonstrates the effectiveness of modelling high-order feature interactions for predicting major histocompatibility complex-peptide binding. AVAILABILITY AND IMPLEMENTATION: There is no associated distributable software. CONTACT: renqiang@nec-labs.com or mark.gerstein@yale.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	['Institute for Biomedical Informatics, Department of Pathology and Laboratory Medicine, University of Pennsylvania School of Medicine, Philadelphia, PA 19104, USA, Department of Machine Learning, NEC Laboratories America, Princeton, NJ 08540, USA.', 'Department of Machine Learning, NEC Laboratories America, Princeton, NJ 08540, USA.', 'Department of Machine Learning, NEC Laboratories America, Princeton, NJ 08540, USA.', 'Program of Computational Biology and Bioinformatics and Department of Molecular Biophysics and Biochemistry and Department of Computer Science, Yale University, New Haven, CT 06511, USA.']	['btv371 [pii]', '10.1093/bioinformatics/btv371 [doi]']	['Kuksa PP', 'Min MR', 'Dugar R', 'Gerstein M']		['(c) The Author 2015. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com.']					['2015/07/25 06:00']	20160606	20150723	2015 Nov 15	2015/07/25 06:00		['Kuksa, Pavel P', 'Min, Martin Renqiang', 'Dugar, Rishabh', 'Gerstein, Mark']			22		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btv371 [doi]	20181202	['*Algorithms', 'Amino Acid Sequence', 'Area Under Curve', 'Databases, Protein', 'Epitopes/chemistry', 'Humans', '*Major Histocompatibility Complex', 'Molecular Sequence Data', '*Neural Networks (Computer)', 'Peptides/chemistry/*metabolism', 'Protein Binding', 'ROC Curve', 'Support Vector Machine']	2016/06/09 06:00				NLM	3600-7	['2014/12/20 00:00 [received]', '2015/06/11 00:00 [accepted]', '2015/07/25 06:00 [entrez]', '2015/07/25 06:00 [pubmed]', '2016/06/09 06:00 [medline]']	England			26206306	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Epitopes)', '0 (Peptides)']	IM		Bioinformatics. 2015 Nov 15;31(22):3600-7. doi: 10.1093/bioinformatics/btv371. Epub 2015 Jul 23.	MEDLINE	Bioinformatics	High-order neural networks and kernel methods for peptide-MHC binding prediction.		31	High-order neural networks and kernel methods for peptide-MHC binding prediction.
Protein disordered regions are segments of a protein chain that do not adopt a stable structure. Thus far, a variety of protein disorder prediction methods have been developed and have been widely used, not only in traditional bioinformatics domains, including protein structure prediction, protein structure determination and function annotation, but also in many other biomedical fields. The relationship between intrinsically-disordered proteins and some human diseases has played a significant role in disorder prediction in disease identification and epidemiological investigations. Disordered proteins can also serve as potential targets for drug discovery with an emphasis on the disordered-to-ordered transition in the disordered binding regions, and this has led to substantial research in drug discovery or design based on protein disordered region prediction. Furthermore, protein disorder prediction has also been applied to healthcare by predicting the disease risk of mutations in patients and studying the mechanistic basis of diseases. As the applications of disorder prediction increase, so too does the need to make quick and accurate predictions. To fill this need, we also present a new approach to predict protein residue disorder using wide sequence windows that is applicable on the genomic scale.	['Microsoft Corporation, One Microsoft Way, Redmond, WA 98052, USA. xinde@microsoft.com.', 'Department of Computer Science, Central Michigan University, Mount Pleasant, MI 48859, USA. gumm1jn@cmich.edu.', 'Department of Computer Science, Central Michigan University, Mount Pleasant, MI 48859, USA. karki1s@cmich.edu.', 'Department of Computer Science, Central Michigan University, Mount Pleasant, MI 48859, USA. eickh1jl@cmich.edu.', 'Department of Computer Science, University of Missouri, Columbia, MO 65211, USA. chengji@missouri.edu.', 'Informatics Institute, University of Missouri, Columbia, MO 65211, USA. chengji@missouri.edu.']	['ijms160715384 [pii]', '10.3390/ijms160715384 [doi]']	['Deng X', 'Gumm J', 'Karki S', 'Eickholt J', 'Cheng J']							['2015/07/23 06:00']	20160418	20150707	2015 Jul 7	2015/07/23 06:00		['Deng, Xin', 'Gumm, Jordan', 'Karki, Suman', 'Eickholt, Jesse', 'Cheng, Jianlin']		['R01 GM093123/GM/NIGMS NIH HHS/United States', 'R01GM093123/GM/NIGMS NIH HHS/United States']	7		1422-0067 (Electronic) 1422-0067 (Linking)	101092791	International journal of molecular sciences	['eng']	10.3390/ijms160715384 [doi]	20181113	['Area Under Curve', 'Computational Biology/*methods', 'Databases, Protein', 'Drug Design', 'Drug Discovery', 'Intrinsically Disordered Proteins/chemistry', 'Neural Networks (Computer)', 'Proteins/*chemistry']	2016/04/19 06:00		['applications of disorder prediction', 'deep networks', 'machine learning', 'protein disorder prediction']	['NOTNLM']	NLM	15384-404	['2015/05/23 00:00 [received]', '2015/06/22 00:00 [revised]', '2015/06/30 00:00 [accepted]', '2015/07/23 06:00 [entrez]', '2015/07/23 06:00 [pubmed]', '2016/04/19 06:00 [medline]']	Switzerland	PMC4519904		26198229	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't""]"		['0 (Intrinsically Disordered Proteins)', '0 (Proteins)']	IM		Int J Mol Sci. 2015 Jul 7;16(7):15384-404. doi: 10.3390/ijms160715384.	MEDLINE	Int J Mol Sci	An Overview of Practical Applications of Protein Disorder Prediction and Drive for Faster, More Accurate Predictions.		16	An Overview of Practical Applications of Protein Disorder Prediction and Drive for Faster, More Accurate Predictions.
BACKGROUND: User content posted through Twitter has been used for biosurveillance, to characterize public perception of health-related topics, and as a means of distributing information to the general public. Most of the existing work surrounding Twitter and health care has shown Twitter to be an effective medium for these problems but more could be done to provide finer and more efficient access to all pertinent data. Given the diversity of user-generated content, small samples or summary presentations of the data arguably omit a large part of the virtual discussion taking place in the Twittersphere. Still, managing, processing, and querying large amounts of Twitter data is not a trivial task. This work describes tools and techniques capable of handling larger sets of Twitter data and demonstrates their use with the issue of antibiotics. OBJECTIVE: This work has two principle objectives: (1) to provide an open-source means to efficiently explore all collected tweets and query health-related topics on Twitter, specifically, questions such as what users are saying and how messages are spread, and (2) to characterize the larger discourse taking place on Twitter with respect to antibiotics. METHODS: Open-source software suites Hadoop, Flume, and Hive were used to collect and query a large number of Twitter posts. To classify tweets by topic, a deep network classifier was trained using a limited number of manually classified tweets. The particular machine learning approach used also allowed the use of a large number of unclassified tweets to increase performance. RESULTS: Query-based analysis of the collected tweets revealed that a large number of users contributed to the online discussion and that a frequent topic mentioned was resistance. A number of prominent events related to antibiotics led to a number of spikes in activity but these were short in duration. The category-based classifier developed was able to correctly classify 70% of manually labeled tweets (using a 10-fold cross validation procedure and 9 classes). The classifier also performed well when evaluated on a per category basis. CONCLUSIONS: Using existing tools such as Hive, Flume, Hadoop, and machine learning techniques, it is possible to construct tools and workflows to collect and query large amounts of Twitter data to characterize the larger discussion taking place on Twitter with respect to a particular health-related topic. Furthermore, using newer machine learning techniques and a limited number of manually labeled tweets, an entire body of collected tweets can be classified to indicate what topics are driving the virtual, online discussion. The resulting classifier can also be used to efficiently explore collected tweets by category and search for messages of interest or exemplary content.	['Department of Computer Science, Central Michigan University, Mount Pleasant, MI, United States.']	['v17i6e154 [pii]', '10.2196/jmir.4220 [doi]']	['Kendra RL', 'Karki S', 'Eickholt JL', 'Gandy L']	['ORCID: http://orcid.org/0000-0002-7039-0855', 'ORCID: http://orcid.org/0000-0002-1086-8415', 'ORCID: http://orcid.org/0000-0002-1764-1838', 'ORCID: http://orcid.org/0000-0001-6487-8064']						['2015/06/21 06:00']	20160128	20150619	2015 Jun 19	2015/06/21 06:00		['Kendra, Rachel Lynn', 'Karki, Suman', 'Eickholt, Jesse Lee', 'Gandy, Lisa']			6		1438-8871 (Electronic) 1438-8871 (Linking)	100959882	Journal of medical Internet research	['eng']	10.2196/jmir.4220 [doi]	20190318	['*Anti-Bacterial Agents', 'Attitude to Health', '*Drug Resistance, Microbial', 'Humans', 'Information Dissemination', '*Internet', 'Machine Learning', '*Public Opinion', '*Social Media', 'Software']	2016/01/29 06:00		['Internet', 'Twitter messaging', 'Web mining', 'neural network', 'semi-supervised learning', 'social media']	['NOTNLM']	NLM	e154	['2015/01/10 00:00 [received]', '2015/05/09 00:00 [accepted]', '2015/04/25 00:00 [revised]', '2015/06/21 06:00 [entrez]', '2015/06/21 06:00 [pubmed]', '2016/01/29 06:00 [medline]']	Canada	PMC4526952		26091775	epublish	['Journal Article']		['0 (Anti-Bacterial Agents)']	IM		J Med Internet Res. 2015 Jun 19;17(6):e154. doi: 10.2196/jmir.4220.	MEDLINE	J Med Internet Res	Characterizing the Discussion of Antibiotics in the Twittersphere: What is the Bigger Picture?		17	Characterizing the Discussion of Antibiotics in the Twittersphere: What is the Bigger Picture?
Many biological questions, including the estimation of deep evolutionary histories and the detection of remote homology between protein sequences, rely upon multiple sequence alignments and phylogenetic trees of large datasets. However, accurate large-scale multiple sequence alignment is very difficult, especially when the dataset contains fragmentary sequences. We present UPP, a multiple sequence alignment method that uses a new machine learning technique, the ensemble of hidden Markov models, which we propose here. UPP produces highly accurate alignments for both nucleotide and amino acid sequences, even on ultra-large datasets or datasets containing fragmentary sequences. UPP is available at https://github.com/smirarab/sepp .	['Carl R. Woese Institute for Genomic Biology, University of Illinois at Urbana-Champaign, 1206 West Gregory Drive, Urbana, 61801, Illinois, USA. namphuon@illinois.edu.', 'Department of Computer Science, University of Texas at Austin, 2505 Speedway, Austin, 78712, Texas, USA. smirarab@cs.utexas.edu.', 'Department of Computer Science, University of Texas at Austin, 2505 Speedway, Austin, 78712, Texas, USA. kk8@cs.utexas.edu.', 'Carl R. Woese Institute for Genomic Biology, University of Illinois at Urbana-Champaign, 1206 West Gregory Drive, Urbana, 61801, Illinois, USA. warnow@illinois.edu.', 'Department of Bioengineering, University of Illinois at Urbana-Champaign, 1270 Digital Computer Laboratory, Urbana, 61801, Illinois, USA. warnow@illinois.edu.', 'Department of Computer Science, University of Illinois at Urbana-Champaign, 201 North Goodwin Avenue, Urbana, 61801, Illinois, USA. warnow@illinois.edu.']	['10.1186/s13059-015-0688-z [doi]', '10.1186/s13059-015-0688-z [pii]']	['Nguyen NP', 'Mirarab S', 'Kumar K', 'Warnow T']							['2015/06/17 06:00']	20160601	20150616	2015 Jun 16	2015/06/17 06:00		['Nguyen, Nam-Phuong D', 'Mirarab, Siavash', 'Kumar, Keerthana', 'Warnow, Tandy']		['Howard Hughes Medical Institute/United States']			1474-760X (Electronic) 1474-7596 (Linking)	100960660	Genome biology	['eng']	10.1186/s13059-015-0688-z [doi]	20181113	['Algorithms', 'Machine Learning', 'Markov Chains', '*Phylogeny', 'Sequence Alignment/*methods']	2016/06/02 06:00				NLM	124	['2014/10/01 00:00 [received]', '2015/05/29 00:00 [accepted]', '2015/06/17 06:00 [entrez]', '2015/06/17 06:00 [pubmed]', '2016/06/02 06:00 [medline]']	England	PMC4492008		26076734	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Genome Biol. 2015 Jun 16;16:124. doi: 10.1186/s13059-015-0688-z.	MEDLINE	Genome Biol	Ultra-large alignments using phylogeny-aware profiles.		16	Ultra-large alignments using phylogeny-aware profiles.
Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.	"['1] Facebook AI Research, 770 Broadway, New York, New York 10003 USA. [2] New York University, 715 Broadway, New York, New York 10003, USA.', 'Department of Computer Science and Operations Research Universite de Montreal, Pavillon Andre-Aisenstadt, PO Box 6128 Centre-Ville STN Montreal, Quebec H3C 3J7, Canada.', ""1] Google, 1600 Amphitheatre Parkway, Mountain View, California 94043, USA. [2] Department of Computer Science, University of Toronto, 6 King's College Road, Toronto, Ontario M5S 3G4, Canada.""]"	['nature14539 [pii]', '10.1038/nature14539 [doi]']	['LeCun Y', 'Bengio Y', 'Hinton G']							['2015/05/29 06:00']	20150629		2015 May 28	2015/05/29 06:00		['LeCun, Yann', 'Bengio, Yoshua', 'Hinton, Geoffrey']			7553		1476-4687 (Electronic) 0028-0836 (Linking)	0410462	Nature	['eng']	10.1038/nature14539 [doi]	20181113	['Algorithms', '*Artificial Intelligence/trends', 'Computers', 'Language', 'Neural Networks (Computer)']	2015/06/30 06:00				NLM	436-44	['2015/02/25 00:00 [received]', '2015/05/01 00:00 [accepted]', '2015/05/29 06:00 [entrez]', '2015/05/29 06:00 [pubmed]', '2015/06/30 06:00 [medline]']	England			26017442	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S."", 'Review']"			IM		Nature. 2015 May 28;521(7553):436-44. doi: 10.1038/nature14539.	MEDLINE	Nature	Deep learning.		521	Deep learning.
High-level abstraction, for example, semantic representation, is vital for document classification and retrieval. However, how to learn document semantic representation is still a topic open for discussion in information retrieval and natural language processing. In this paper, we propose a new Hybrid Deep Belief Network (HDBN) which uses Deep Boltzmann Machine (DBM) on the lower layers together with Deep Belief Network (DBN) on the upper layers. The advantage of DBM is that it employs undirected connection when training weight parameters which can be used to sample the states of nodes on each layer more successfully and it is also an effective way to remove noise from the different document representation type; the DBN can enhance extract abstract of the document in depth, making the model learn sufficient semantic representation. At the same time, we explore different input strategies for semantic distributed representation. Experimental results show that our model using the word embedding instead of single word has better performance.	['Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China.', 'Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China.', 'Key Laboratory of Computational Linguistics, Peking University, Ministry of Education, Beijing 100871, China.', 'Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China.', 'Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.']	['10.1155/2015/650527 [doi]']	['Yan Y', 'Yin XC', 'Li S', 'Yang M', 'Hao HW']							['2015/04/17 06:00']	20151021	20150323	2015	2015/04/17 06:00		['Yan, Yan', 'Yin, Xu-Cheng', 'Li, Sujian', 'Yang, Mingyuan', 'Hao, Hong-Wei']					1687-5273 (Electronic)	101279357	Computational intelligence and neuroscience	['eng']	10.1155/2015/650527 [doi]	20181113	['*Algorithms', '*Information Storage and Retrieval', 'Models, Statistical', '*Natural Language Processing', 'Neural Networks (Computer)', '*Semantics']	2015/10/22 06:00				NLM	650527	['2014/09/26 00:00 [received]', '2015/03/02 00:00 [revised]', '2015/03/09 00:00 [accepted]', '2015/04/17 06:00 [entrez]', '2015/04/17 06:00 [pubmed]', '2015/10/22 06:00 [medline]']	United States	PMC4386712		25878657	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Comput Intell Neurosci. 2015;2015:650527. doi: 10.1155/2015/650527. Epub 2015 Mar 23.	MEDLINE	Comput Intell Neurosci	Learning document semantic representation with hybrid deep belief network.		2015	Learning document semantic representation with hybrid deep belief network.
Understanding how congestion at one location can cause ripples throughout large-scale transportation network is vital for transportation researchers and practitioners to pinpoint traffic bottlenecks for congestion mitigation. Traditional studies rely on either mathematical equations or simulation techniques to model traffic congestion dynamics. However, most of the approaches have limitations, largely due to unrealistic assumptions and cumbersome parameter calibration process. With the development of Intelligent Transportation Systems (ITS) and Internet of Things (IoT), transportation data become more and more ubiquitous. This triggers a series of data-driven research to investigate transportation phenomena. Among them, deep learning theory is considered one of the most promising techniques to tackle tremendous high-dimensional data. This study attempts to extend deep learning theory into large-scale transportation network analysis. A deep Restricted Boltzmann Machine and Recurrent Neural Network architecture is utilized to model and predict traffic congestion evolution based on Global Positioning System (GPS) data from taxi. A numerical study in Ningbo, China is conducted to validate the effectiveness and efficiency of the proposed method. Results show that the prediction accuracy can achieve as high as 88% within less than 6 minutes when the model is implemented in a Graphic Processing Unit (GPU)-based parallel computing environment. The predicted congestion evolution patterns can be visualized temporally and spatially through a map-based platform to identify the vulnerable links for proactive congestion mitigation.	['School of Transportation Science and Engineering, Beijing Key Laboratory for Cooperative Vehicle Infrastructure, Systems, and Safety Control, Beihang University, Beijing, China; Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, SiPaiLou #2, Nanjing, China.', 'School of Transportation Science and Engineering, Beijing Key Laboratory for Cooperative Vehicle Infrastructure, Systems, and Safety Control, Beihang University, Beijing, China; Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, SiPaiLou #2, Nanjing, China.', 'School of Transportation Science and Engineering, Beijing Key Laboratory for Cooperative Vehicle Infrastructure, Systems, and Safety Control, Beihang University, Beijing, China; Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, SiPaiLou #2, Nanjing, China.', 'Department of Civil and Environmental Engineering, University of Washington, Seattle, Washington, United States of America.']	['10.1371/journal.pone.0119044 [doi]', 'PONE-D-14-25701 [pii]']	['Ma X', 'Yu H', 'Wang Y', 'Wang Y']							['2015/03/18 06:00']	20160223	20150317	2015	2015/03/18 06:00		['Ma, Xiaolei', 'Yu, Haiyang', 'Wang, Yunpeng', 'Wang, Yinhai']			3		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0119044 [doi]	20181113	['China', 'Geographic Information Systems', 'Learning', '*Models, Theoretical', '*Neural Networks (Computer)', 'Transportation/*methods']	2016/02/26 06:00				NLM	e0119044	['2014/06/09 00:00 [received]', '2015/01/09 00:00 [accepted]', '2015/03/18 06:00 [entrez]', '2015/03/18 06:00 [pubmed]', '2016/02/26 06:00 [medline]']	United States	PMC4363621		25780910	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"			IM		PLoS One. 2015 Mar 17;10(3):e0119044. doi: 10.1371/journal.pone.0119044. eCollection 2015.	MEDLINE	PLoS One	Large-scale transportation network congestion evolution prediction using deep learning theory.		10	Large-scale transportation network congestion evolution prediction using deep learning theory.
OBJECTIVE: The objective of this paper is to highlight the state-of-the-art machine learning (ML) techniques in computational docking. The use of smart computational methods in the life cycle of drug design is relatively a recent development that has gained much popularity and interest over the last few years. Central to this methodology is the notion of computational docking which is the process of predicting the best pose (orientation + conformation) of a small molecule (drug candidate) when bound to a target larger receptor molecule (protein) in order to form a stable complex molecule. In computational docking, a large number of binding poses are evaluated and ranked using a scoring function. The scoring function is a mathematical predictive model that produces a score that represents the binding free energy, and hence the stability, of the resulting complex molecule. Generally, such a function should produce a set of plausible ligands ranked according to their binding stability along with their binding poses. In more practical terms, an effective scoring function should produce promising drug candidates which can then be synthesized and physically screened using high throughput screening process. Therefore, the key to computer-aided drug design is the design of an efficient highly accurate scoring function (using ML techniques). METHODS: The methods presented in this paper are specifically based on ML techniques. Despite many traditional techniques have been proposed, the performance was generally poor. Only in the last few years started the application of the ML technology in the design of scoring functions; and the results have been very promising. MATERIAL: The ML-based techniques are based on various molecular features extracted from the abundance of protein-ligand information in the public molecular databases, e.g., protein data bank bind (PDBbind). RESULTS: In this paper, we present this paradigm shift elaborating on the main constituent elements of the ML approach to molecular docking along with the state-of-the-art research in this area. For instance, the best random forest (RF)-based scoring function on PDBbind v2007 achieves a Pearson correlation coefficient between the predicted and experimentally determined binding affinities of 0.803 while the best conventional scoring function achieves 0.644. The best RF-based ranking power ranks the ligands correctly based on their experimentally determined binding affinities with accuracy 62.5% and identifies the top binding ligand with accuracy 78.1%. CONCLUSIONS: We conclude with open questions and potential future research directions that can be pursued in smart computational docking; using molecular features of different nature (geometrical, energy terms, pharmacophore), advanced ML techniques (e.g., deep learning), combining more than one ML models.	['Cyber-Physical Systems Lab, Egypt-Japan University of Science and Technology (E-JUST), P.O. Box 179, New Borg El-Arab City, 21934 Alexandria, Egypt. Electronic address: mohamed.khamis@ejust.edu.eg.', 'Cyber-Physical Systems Lab, Egypt-Japan University of Science and Technology (E-JUST), P.O. Box 179, New Borg El-Arab City, 21934 Alexandria, Egypt; Faculty of Engineering, Alexandria University, Alexandria 21544, Egypt. Electronic address: walid.gomaa@ejust.edu.eg.', 'Cyber-Physical Systems Lab, Egypt-Japan University of Science and Technology (E-JUST), P.O. Box 179, New Borg El-Arab City, 21934 Alexandria, Egypt. Electronic address: wella_dba@yahoo.com.']	['S0933-3657(15)00003-2 [pii]', '10.1016/j.artmed.2015.02.002 [doi]']	['Khamis MA', 'Gomaa W', 'Ahmed WF']		['Copyright (c) 2015 Elsevier B.V. All rights reserved.']					['2015/03/01 06:00']	20160120	20150216	2015 Mar	2015/03/01 06:00		['Khamis, Mohamed A', 'Gomaa, Walid', 'Ahmed, Walaa F']			3		1873-2860 (Electronic) 0933-3657 (Linking)	8915031	Artificial intelligence in medicine	['eng']	10.1016/j.artmed.2015.02.002 [doi] S0933-3657(15)00003-2 [pii]	20150430	['Computational Biology/*methods', 'Data Interpretation, Statistical', 'Databases, Protein', 'Humans', 'Ligands', '*Machine Learning', 'Protein Binding', 'Protein Conformation', 'Proteins/*chemistry', 'Quantum Theory']	2016/01/21 06:00		['Complex binding affinity', 'Computational docking', 'Drug discovery', 'Force field interaction', 'Ligands ranking accuracy', 'Machine learning', 'Pharmacophore fingerprint', 'Random forest', 'Scoring function', 'Support vector machine', 'Virtual screening']	['NOTNLM']	NLM	135-52	['2014/07/27 00:00 [received]', '2015/01/08 00:00 [revised]', '2015/02/09 00:00 [accepted]', '2015/03/01 06:00 [entrez]', '2015/03/01 06:00 [pubmed]', '2016/01/21 06:00 [medline]']	Netherlands			25724101	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Ligands)', '0 (Proteins)']	IM		Artif Intell Med. 2015 Mar;63(3):135-52. doi: 10.1016/j.artmed.2015.02.002. Epub 2015 Feb 16.	MEDLINE	Artif Intell Med	Machine learning in computational docking.		63	Machine learning in computational docking.
"The primate visual system achieves remarkable visual object recognition performance even in brief presentations, and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations, such as the amount of noise, the number of neural recording sites, and the number of trials, and computational limitations, such as the complexity of the decoding classifier and the number of classifier training examples. In this work, we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of ""kernel analysis"" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT, and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds."	['Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America; Harvard-MIT Division of Health Sciences and Technology, Institute for Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.', 'Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America.']	['10.1371/journal.pcbi.1003963 [doi]', 'PCOMPBIOL-D-14-01126 [pii]']	['Cadieu CF', 'Hong H', 'Yamins DL', 'Pinto N', 'Ardila D', 'Solomon EA', 'Majaj NJ', 'DiCarlo JJ']							['2014/12/19 06:00']	20151228	20141218	2014 Dec	2014/12/19 06:00		['Cadieu, Charles F', 'Hong, Ha', 'Yamins, Daniel L K', 'Pinto, Nicolas', 'Ardila, Diego', 'Solomon, Ethan A', 'Majaj, Najib J', 'DiCarlo, James J']		['5R01EY014970-09/EY/NEI NIH HHS/United States', 'F32 EY022845-01/EY/NEI NIH HHS/United States']	12		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1003963 [doi]	20181113	['Algorithms', 'Animals', 'Macaca mulatta', 'Male', '*Models, Neurological', 'Nerve Net/*physiology', '*Neural Networks (Computer)', 'Pattern Recognition, Visual/*physiology', 'Temporal Lobe/*physiology']	2015/12/29 06:00				NLM	e1003963	['2014/06/23 00:00 [received]', '2014/10/03 00:00 [accepted]', '2014/12/19 06:00 [entrez]', '2014/12/19 06:00 [pubmed]', '2015/12/29 06:00 [medline]']	United States	PMC4270441		25521294	epublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		PLoS Comput Biol. 2014 Dec 18;10(12):e1003963. doi: 10.1371/journal.pcbi.1003963. eCollection 2014 Dec.	MEDLINE	PLoS Comput Biol	Deep neural networks rival the representation of primate IT cortex for core visual object recognition.		10	Deep neural networks rival the representation of primate IT cortex for core visual object recognition.
Transcription regulation in multicellular eukaryotes is orchestrated by a number of DNA functional elements located at gene regulatory regions. Some regulatory regions (e.g. enhancers) are located far away from the gene they affect. Identification of distal regulatory elements is a challenge for the bioinformatics research. Although existing methodologies increased the number of computationally predicted enhancers, performance inconsistency of computational models across different cell-lines, class imbalance within the learning sets and ad hoc rules for selecting enhancer candidates for supervised learning, are some key questions that require further examination. In this study we developed DEEP, a novel ensemble prediction framework. DEEP integrates three components with diverse characteristics that streamline the analysis of enhancer's properties in a great variety of cellular conditions. In our method we train many individual classification models that we combine to classify DNA regions as enhancers or non-enhancers. DEEP uses features derived from histone modification marks or attributes coming from sequence characteristics. Experimental results indicate that DEEP performs better than four state-of-the-art methods on the ENCODE data. We report the first computational enhancer prediction results on FANTOM5 data where DEEP achieves 90.2% accuracy and 90% geometric mean (GM) of specificity and sensitivity across 36 different tissues. We further present results derived using in vivo-derived enhancer data from VISTA database. DEEP-VISTA, when tested on an independent test set, achieved GM of 80.1% and accuracy of 89.64%. DEEP framework is publicly available at http://cbrc.kaust.edu.sa/deep/.	['Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia.', 'Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia.', 'Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering Division (CEMSE), King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia vladimir.bajic@kaust.edu.sa.']	['gku1058 [pii]', '10.1093/nar/gku1058 [doi]']	['Kleftogiannis D', 'Kalnis P', 'Bajic VB']		['(c) The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic', 'Acids Research.']					['2014/11/08 06:00']	20150320	20141105	2015 Jan	2014/11/08 06:00		['Kleftogiannis, Dimitrios', 'Kalnis, Panos', 'Bajic, Vladimir B']			1		1362-4962 (Electronic) 0305-1048 (Linking)	0411011	Nucleic acids research	['eng']	10.1093/nar/gku1058 [doi]	20181113	['Chromatin Immunoprecipitation/methods', '*Enhancer Elements, Genetic', 'Genomics/methods', 'HeLa Cells', 'Histones/metabolism', 'Humans', 'K562 Cells', 'Sequence Analysis, DNA/*methods', 'Support Vector Machine', 'Transcription Factors/metabolism']	2015/03/21 06:00				NLM	e6	['2014/11/08 06:00 [entrez]', '2014/11/08 06:00 [pubmed]', '2015/03/21 06:00 [medline]']	England	PMC4288148		25378307	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Validation Studies']"		['0 (Histones)', '0 (Transcription Factors)']	IM		Nucleic Acids Res. 2015 Jan;43(1):e6. doi: 10.1093/nar/gku1058. Epub 2014 Nov 5.	MEDLINE	Nucleic Acids Res	DEEP: a general computational framework for predicting enhancers.		43	DEEP: a general computational framework for predicting enhancers.
Given sufficient large protein families, and using a global statistical inference approach, it is possible to obtain sufficient accuracy in protein residue contact predictions to predict the structure of many proteins. However, these approaches do not consider the fact that the contacts in a protein are neither randomly, nor independently distributed, but actually follow precise rules governed by the structure of the protein and thus are interdependent. Here, we present PconsC2, a novel method that uses a deep learning approach to identify protein-like contact patterns to improve contact predictions. A substantial enhancement can be seen for all contacts independently on the number of aligned sequences, residue separation or secondary structure type, but is largest for beta-sheet containing proteins. In addition to being superior to earlier methods based on statistical inferences, in comparison to state of the art methods using machine learning, PconsC2 is superior for families with more than 100 effective sequence homologs. The improved contact prediction enables improved structure prediction.	['Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden; Science for Life Laboratory, Stockholm University, Solna, Sweden; Department of Information and Computer Science, Aalto University, Aalto, Finland.', 'Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden; Science for Life Laboratory, Stockholm University, Solna, Sweden; Interuniversity Institute of Bioinformatics in Brussels, ULB-VUB, La Plaine Campus, Triomflaan, Brussels, Belgium.', 'Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden; Science for Life Laboratory, Stockholm University, Solna, Sweden.', 'Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden; Science for Life Laboratory, Stockholm University, Solna, Sweden.']	['10.1371/journal.pcbi.1003889 [doi]', 'PCOMPBIOL-D-14-00766 [pii]']	['Skwark MJ', 'Raimondi D', 'Michel M', 'Elofsson A']							['2014/11/07 06:00']	20151113	20141106	2014 Nov	2014/11/07 06:00		['Skwark, Marcin J', 'Raimondi, Daniele', 'Michel, Mirco', 'Elofsson, Arne']			11		1553-7358 (Electronic) 1553-734X (Linking)	101238922	PLoS computational biology	['eng']	10.1371/journal.pcbi.1003889 [doi]	20181113	['Artificial Intelligence', 'Computational Biology/*methods', 'Databases, Protein', 'Pattern Recognition, Automated/*methods', 'Protein Conformation', 'Protein Structure, Secondary', 'Proteins/*chemistry', 'Sequence Analysis, Protein/*methods']	2015/11/14 06:00				NLM	e1003889	['2014/05/01 00:00 [received]', '2014/09/03 00:00 [accepted]', '2014/11/07 06:00 [entrez]', '2014/11/07 06:00 [pubmed]', '2015/11/14 06:00 [medline]']	United States	PMC4222596		25375897	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"		['0 (Proteins)']	IM		PLoS Comput Biol. 2014 Nov 6;10(11):e1003889. doi: 10.1371/journal.pcbi.1003889. eCollection 2014 Nov.	MEDLINE	PLoS Comput Biol	Improved contact predictions using the recognition of protein like contact patterns.		10	Improved contact predictions using the recognition of protein like contact patterns.
UNLABELLED: Annotating genetic variants, especially non-coding variants, for the purpose of identifying pathogenic variants remains a challenge. Combined annotation-dependent depletion (CADD) is an algorithm designed to annotate both coding and non-coding variants, and has been shown to outperform other annotation algorithms. CADD trains a linear kernel support vector machine (SVM) to differentiate evolutionarily derived, likely benign, alleles from simulated, likely deleterious, variants. However, SVMs cannot capture non-linear relationships among the features, which can limit performance. To address this issue, we have developed DANN. DANN uses the same feature set and training data as CADD to train a deep neural network (DNN). DNNs can capture non-linear relationships among features and are better suited than SVMs for problems with a large number of samples and features. We exploit Compute Unified Device Architecture-compatible graphics processing units and deep learning techniques such as dropout and momentum training to accelerate the DNN training. DANN achieves about a 19% relative reduction in the error rate and about a 14% relative increase in the area under the curve (AUC) metric over CADD's SVM methodology. AVAILABILITY AND IMPLEMENTATION: All data and source code are available at https://cbcl.ics.uci.edu/public_data/DANN/.	['Department of Computer Science and Center for Complex Biological Systems, University of California, Irvine, CA 92697, USA Department of Computer Science and Center for Complex Biological Systems, University of California, Irvine, CA 92697, USA.', 'Department of Computer Science and Center for Complex Biological Systems, University of California, Irvine, CA 92697, USA.', 'Department of Computer Science and Center for Complex Biological Systems, University of California, Irvine, CA 92697, USA Department of Computer Science and Center for Complex Biological Systems, University of California, Irvine, CA 92697, USA.']	['btu703 [pii]', '10.1093/bioinformatics/btu703 [doi]']	['Quang D', 'Chen Y', 'Xie X']		['(c) The Author 2014. Published by Oxford University Press. All rights reserved.', 'For Permissions, please e-mail: journals.permissions@oup.com.']					['2014/10/24 06:00']	20150918	20141022	2015 Mar 1	2014/10/24 06:00		['Quang, Daniel', 'Chen, Yifei', 'Xie, Xiaohui']		['T32 EB009418/EB/NIBIB NIH HHS/United States', 'EB009418/EB/NIBIB NIH HHS/United States', 'R01HG006870/HG/NHGRI NIH HHS/United States', 'R01 HG006870/HG/NHGRI NIH HHS/United States', 'P50 GM076516/GM/NIGMS NIH HHS/United States']	5		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btu703 [doi]	20181202	['*Algorithms', 'Area Under Curve', 'Computer Graphics', 'Genetic Variation/*genetics', '*Genome, Human', 'Humans', '*Molecular Sequence Annotation', '*Neural Networks (Computer)', 'Selection, Genetic', 'Support Vector Machine']	2015/09/19 06:00				NLM	761-3	['2014/10/24 06:00 [entrez]', '2014/10/24 06:00 [pubmed]', '2015/09/19 06:00 [medline]']	England	PMC4341060		25338716	ppublish	['Journal Article', 'Research Support, N.I.H., Extramural']			IM		Bioinformatics. 2015 Mar 1;31(5):761-3. doi: 10.1093/bioinformatics/btu703. Epub 2014 Oct 22.	MEDLINE	Bioinformatics	DANN: a deep learning approach for annotating the pathogenicity of genetic variants.		31	DANN: a deep learning approach for annotating the pathogenicity of genetic variants.
Restricted Boltzmann machines (RBMs) and deep Boltzmann machines (DBMs) are important models in deep learning, but it is often difficult to measure their performance in general, or measure the importance of individual hidden units in specific. We propose to use mutual information to measure the usefulness of individual hidden units in Boltzmann machines. The measure is fast to compute, and serves as an upper bound for the information the neuron can pass on, enabling detection of a particular kind of poor training results. We confirm experimentally that the proposed measure indicates how much the performance of the model drops when some of the units of an RBM are pruned away. We demonstrate the usefulness of the measure for early detection of poor training in DBMs.	['Department of Information and Computer Science, Aalto University School of Science, Finland. Electronic address: mathias.berglund@aalto.fi.', 'Department of Information and Computer Science, Aalto University School of Science, Finland.', 'Department of Information and Computer Science, Aalto University School of Science, Finland.']	['S0893-6080(14)00214-7 [pii]', '10.1016/j.neunet.2014.09.004 [doi]']	['Berglund M', 'Raiko T', 'Cho K']		['Copyright (c) 2014 Elsevier Ltd. All rights reserved.']					['2014/10/17 06:00']	20150527	20140928	2015 Apr	2014/10/17 06:00		['Berglund, Mathias', 'Raiko, Tapani', 'Cho, Kyunghyun']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	10.1016/j.neunet.2014.09.004 [doi] S0893-6080(14)00214-7 [pii]	20181202	['*Algorithms', '*Neural Networks (Computer)']	2015/05/28 06:00		['Deep Boltzmann machine', 'Deep learning', 'Mutual information', 'Pruning', 'Restricted Boltzmann machine', 'Structural learning']	['NOTNLM']	NLM	12-8	['2014/01/21 00:00 [received]', '2014/08/29 00:00 [revised]', '2014/09/17 00:00 [accepted]', '2014/10/17 06:00 [entrez]', '2014/10/17 06:00 [pubmed]', '2015/05/28 06:00 [medline]']	United States			25318376	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Neural Netw. 2015 Apr;64:12-8. doi: 10.1016/j.neunet.2014.09.004. Epub 2014 Sep 28.	MEDLINE	Neural Netw	Measuring the usefulness of hidden units in Boltzmann machines with mutual information.		64	Measuring the usefulness of hidden units in Boltzmann machines with mutual information.
In classification tasks, restricted Boltzmann machines (RBMs) have predominantly been used in the first stage, either as feature extractors or to provide initialization of neural networks. In this study, we propose a discriminative learning approach to provide a self-contained RBM method for classification, inspired by free-energy based function approximation (FE-RBM), originally proposed for reinforcement learning. For classification, the FE-RBM method computes the output for an input vector and a class vector by the negative free energy of an RBM. Learning is achieved by stochastic gradient-descent using a mean-squared error training objective. In an earlier study, we demonstrated that the performance and the robustness of FE-RBM function approximation can be improved by scaling the free energy by a constant that is related to the size of network. In this study, we propose that the learning performance of RBM function approximation can be further improved by computing the output by the negative expected energy (EE-RBM), instead of the negative free energy. To create a deep learning architecture, we stack several RBMs on top of each other. We also connect the class nodes to all hidden layers to try to improve the performance even further. We validate the classification performance of EE-RBM using the MNIST data set and the NORB data set, achieving competitive performance compared with other classifiers such as standard neural networks, deep belief networks, classification RBMs, and support vector machines. The purpose of using the NORB data set is to demonstrate that EE-RBM with binary input nodes can achieve high performance in the continuous input domain.	['Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa 904-0495, Japan. Electronic address: elfwing@oist.jp.', 'Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa 904-0495, Japan. Electronic address: uchibe@oist.jp.', 'Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa 904-0495, Japan. Electronic address: doya@oist.jp.']	['S0893-6080(14)00216-0 [pii]', '10.1016/j.neunet.2014.09.006 [doi]']	['Elfwing S', 'Uchibe E', 'Doya K']		['Copyright (c) 2014 The Authors. Published by Elsevier Ltd.. All rights reserved.']					['2014/10/17 06:00']	20150527	20140928	2015 Apr	2014/10/17 06:00		['Elfwing, S', 'Uchibe, E', 'Doya, K']					1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	10.1016/j.neunet.2014.09.006 [doi] S0893-6080(14)00216-0 [pii]	20181202	['Classification/methods', '*Neural Networks (Computer)']	2015/05/28 06:00		['Classification', 'Expected energy', 'Free energy', 'Restricted Boltzmann machine']	['NOTNLM']	NLM	29-38	['2014/01/15 00:00 [received]', '2014/08/31 00:00 [revised]', '2014/09/17 00:00 [accepted]', '2014/10/17 06:00 [entrez]', '2014/10/17 06:00 [pubmed]', '2015/05/28 06:00 [medline]']	United States			25318375	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Neural Netw. 2015 Apr;64:29-38. doi: 10.1016/j.neunet.2014.09.006. Epub 2014 Sep 28.	MEDLINE	Neural Netw	Expected energy-based restricted Boltzmann machine for classification.		64	Expected energy-based restricted Boltzmann machine for classification.
Automatic emotion recognition is one of the most challenging tasks. To detect emotion from nonstationary EEG signals, a sophisticated learning algorithm that can represent high-level abstraction is required. This study proposes the utilization of a deep learning network (DLN) to discover unknown feature correlation between input signals that is crucial for the learning task. The DLN is implemented with a stacked autoencoder (SAE) using hierarchical feature learning approach. Input features of the network are power spectral densities of 32-channel EEG signals from 32 subjects. To alleviate overfitting problem, principal component analysis (PCA) is applied to extract the most important components of initial input features. Furthermore, covariate shift adaptation of the principal components is implemented to minimize the nonstationary effect of EEG signals. Experimental results show that the DLN is capable of classifying three different levels of valence and arousal with accuracy of 49.52% and 46.03%, respectively. Principal component based covariate shift adaptation enhances the respective classification accuracy by 5.55% and 6.53%. Moreover, DLN provides better performance compared to SVM and naive Bayes classifiers.	['Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok 10330, Thailand ; National Electronics and Computer Technology Center, Thailand Science Park, Khlong Luang, Pathum Thani 12120, Thailand.', 'Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok 10330, Thailand.', 'National Electronics and Computer Technology Center, Thailand Science Park, Khlong Luang, Pathum Thani 12120, Thailand.']	['10.1155/2014/627892 [doi]']	['Jirayucharoensak S', 'Pan-Ngum S', 'Israsena P']							['2014/09/27 06:00']	20150622	20140901	2014	2014/09/27 06:00		['Jirayucharoensak, Suwicha', 'Pan-Ngum, Setha', 'Israsena, Pasin']					1537-744X (Electronic) 1537-744X (Linking)	101131163	TheScientificWorldJournal	['eng']	10.1155/2014/627892 [doi]	20181113	['*Algorithms', 'Arousal/physiology', 'Electroencephalography/*methods', 'Emotions/*physiology', 'Humans', 'Nerve Net', 'Neural Networks (Computer)', 'Principal Component Analysis/*methods', 'Reproducibility of Results', 'Support Vector Machine', 'Task Performance and Analysis']	2015/06/24 06:00				NLM	627892	['2014/05/02 00:00 [received]', '2014/07/30 00:00 [revised]', '2014/07/30 00:00 [accepted]', '2014/09/27 06:00 [entrez]', '2014/09/27 06:00 [pubmed]', '2015/06/24 06:00 [medline]']	United States	PMC4165739		25258728	ppublish	['Journal Article']			IM		ScientificWorldJournal. 2014;2014:627892. doi: 10.1155/2014/627892. Epub 2014 Sep 1.	MEDLINE	ScientificWorldJournal	EEG-based emotion recognition using deep learning network with principal component based covariate shift adaptation.		2014	EEG-based emotion recognition using deep learning network with principal component based covariate shift adaptation.
OBJECTIVES: Recent research has shown that machine learning techniques can accurately predict activity classes from accelerometer data in adolescents and adults. The purpose of this study is to develop and test machine learning models for predicting activity type in preschool-aged children. DESIGN: Participants completed 12 standardised activity trials (TV, reading, tablet game, quiet play, art, treasure hunt, cleaning up, active game, obstacle course, bicycle riding) over two laboratory visits. METHODS: Eleven children aged 3-6 years (mean age=4.8+/-0.87; 55% girls) completed the activity trials while wearing an ActiGraph GT3X+ accelerometer on the right hip. Activities were categorised into five activity classes: sedentary activities, light activities, moderate to vigorous activities, walking, and running. A standard feed-forward Artificial Neural Network and a Deep Learning Ensemble Network were trained on features in the accelerometer data used in previous investigations (10th, 25th, 50th, 75th and 90th percentiles and the lag-one autocorrelation). RESULTS: Overall recognition accuracy for the standard feed forward Artificial Neural Network was 69.7%. Recognition accuracy for sedentary activities, light activities and games, moderate-to-vigorous activities, walking, and running was 82%, 79%, 64%, 36% and 46%, respectively. In comparison, overall recognition accuracy for the Deep Learning Ensemble Network was 82.6%. For sedentary activities, light activities and games, moderate-to-vigorous activities, walking, and running recognition accuracy was 84%, 91%, 79%, 73% and 73%, respectively. CONCLUSIONS: Ensemble machine learning approaches such as Deep Learning Ensemble Network can accurately predict activity type from accelerometer data in preschool children.	['Faculty of Engineering and Information Science, University of Wollongong, Australia. Electronic address: markus@uow.edu.au.', 'Faculty of Social Sciences, Early Start Research Institute, University of Wollongong, Australia. Electronic address: dylanc@uow.edu.au.', 'Institute of Health and Biomedical Innovation, Queensland University of Technology, Australia. Electronic address: s.trost@qut.edu.au.', 'Faculty of Engineering and Information Science, University of Wollongong, Australia. Electronic address: vtn966@uow.edu.au.', 'School of Medicine, University of Wollongong, Australia. Electronic address: greg_peoples@uow.edu.au.']	['S1440-2440(14)00114-5 [pii]', '10.1016/j.jsams.2014.06.003 [doi]']	['Hagenbuchner M', 'Cliff DP', 'Trost SG', 'Van Tuc N', 'Peoples GE']		['Copyright (c) 2014 Sports Medicine Australia. Published by Elsevier Ltd. All', 'rights reserved.']					['2014/08/05 06:00']	20160307	20140624	2015 Jul	2014/08/05 06:00		['Hagenbuchner, Markus', 'Cliff, Dylan P', 'Trost, Stewart G', 'Van Tuc, Nguyen', 'Peoples, Gregory E']			4		1878-1861 (Electronic) 1878-1861 (Linking)	9812598	Journal of science and medicine in sport	['eng']	10.1016/j.jsams.2014.06.003 [doi] S1440-2440(14)00114-5 [pii]	20161020	['*Accelerometry', 'Activities of Daily Living', 'Bicycling', 'Child', 'Child, Preschool', 'Female', 'Humans', '*Machine Learning', 'Male', '*Models, Theoretical', '*Motor Activity', 'Neural Networks (Computer)', 'Play and Playthings', 'Running', 'Walking']	2016/03/08 06:00		['Accelerometry', 'Exercise', 'Neural networks', 'Pattern recognition', 'Physical activity', 'Validity']	['NOTNLM']	NLM	426-31	['2014/01/27 00:00 [received]', '2014/06/02 00:00 [revised]', '2014/06/07 00:00 [accepted]', '2014/08/05 06:00 [entrez]', '2014/08/05 06:00 [pubmed]', '2016/03/08 06:00 [medline]']	Australia			25088983	ppublish	['Journal Article']			IM		J Sci Med Sport. 2015 Jul;18(4):426-31. doi: 10.1016/j.jsams.2014.06.003. Epub 2014 Jun 24.	MEDLINE	J Sci Med Sport	Prediction of activity type in preschool children using machine learning techniques.		18	Prediction of activity type in preschool children using machine learning techniques.
"This paper introduces a special issue of Cognitive Science initiated on the 25th anniversary of the publication of Parallel Distributed Processing (PDP), a two-volume work that introduced the use of neural network models as vehicles for understanding cognition. The collection surveys the core commitments of the PDP framework, the key issues the framework has addressed, and the debates the framework has spawned, and presents viewpoints on the current status of these issues. The articles focus on both historical roots and contemporary developments in learning, optimality theory, perception, memory, language, conceptual knowledge, cognitive control, and consciousness. Here we consider the approach more generally, reviewing the original motivations, the resulting framework, and the central tenets of the underlying theory. We then evaluate the impact of PDP both on the field at large and within specific subdomains of cognitive science and consider the current role of PDP models within the broader landscape of contemporary theoretical frameworks in cognitive science. Looking to the future, we consider the implications for cognitive science of the recent success of machine learning systems called ""deep networks""-systems that build on key ideas presented in the PDP volumes."	['Department of Psychology, University of Wisconsin-Madison.']	['10.1111/cogs.12148 [doi]']	['Rogers TT', 'McClelland JL']		['Copyright (c) 2014 Cognitive Science Society, Inc.']					['2014/08/05 06:00']	20150423	20140804	2014 Aug	2014/08/05 06:00		['Rogers, Timothy T', 'McClelland, James L']			6		1551-6709 (Electronic) 0364-0213 (Linking)	7708195	Cognitive science	['eng']	10.1111/cogs.12148 [doi]	20140819	['*Cognition', '*Cognitive Science', 'Consciousness', 'Humans', 'Language', '*Models, Neurological', '*Neural Networks (Computer)']	2015/04/24 06:00		['Cognition', 'Cognitive control', 'Connectionist models', 'Language', 'Learning', 'Memory', 'Neural networks', 'Perception']	['NOTNLM']	NLM	1024-77	['2013/07/29 00:00 [received]', '2014/04/02 00:00 [revised]', '2014/04/09 00:00 [accepted]', '2014/08/05 06:00 [entrez]', '2014/08/05 06:00 [pubmed]', '2015/04/24 06:00 [medline]']	United States			25087578	ppublish	['Festschrift']			IM		Cogn Sci. 2014 Aug;38(6):1024-77. doi: 10.1111/cogs.12148. Epub 2014 Aug 4.	MEDLINE	Cogn Sci	Parallel Distributed Processing at 25: further explorations in the microstructure of cognition.		38	Parallel Distributed Processing at 25: further explorations in the microstructure of cognition.
A key problem in spoken language identification (LID) is to design effective representations which are specific to language information. For example, in recent years, representations based on both phonotactic and acoustic features have proven their effectiveness for LID. Although advances in machine learning have led to significant improvements, LID performance is still lacking, especially for short duration speech utterances. With the hypothesis that language information is weak and represented only latently in speech, and is largely dependent on the statistical properties of the speech content, existing representations may be insufficient. Furthermore they may be susceptible to the variations caused by different speakers, specific content of the speech segments, and background noise. To address this, we propose using Deep Bottleneck Features (DBF) for spoken LID, motivated by the success of Deep Neural Networks (DNN) in speech recognition. We show that DBFs can form a low-dimensional compact representation of the original inputs with a powerful descriptive and discriminative capability. To evaluate the effectiveness of this, we design two acoustic models, termed DBF-TV and parallel DBF-TV (PDBF-TV), using a DBF based i-vector representation for each speech utterance. Results on NIST language recognition evaluation 2009 (LRE09) show significant improvements over state-of-the-art systems. By fusing the output of phonotactic and acoustic approaches, we achieve an EER of 1.08%, 1.89% and 7.01% for 30 s, 10 s and 3 s test utterances respectively. Furthermore, various DBF configurations have been extensively evaluated, and an optimal system proposed.	['National Engineering Laboratory of Speech and Language Information Processing, University of Science and Technology of China, Hefei, AnHui, China.', 'National Engineering Laboratory of Speech and Language Information Processing, University of Science and Technology of China, Hefei, AnHui, China.', 'iFlytek Research, Anhui USTC iFlytek Co., Ltd., Hefei, AnHui, China.', 'iFlytek Research, Anhui USTC iFlytek Co., Ltd., Hefei, AnHui, China.', 'National Engineering Laboratory of Speech and Language Information Processing, University of Science and Technology of China, Hefei, AnHui, China.', 'National Engineering Laboratory of Speech and Language Information Processing, University of Science and Technology of China, Hefei, AnHui, China.']	['10.1371/journal.pone.0100795 [doi]', 'PONE-D-14-10583 [pii]']	['Jiang B', 'Song Y', 'Wei S', 'Liu JH', 'McLoughlin IV', 'Dai LR']							['2014/07/02 06:00']	20151106	20140701	2014	2014/07/02 06:00		['Jiang, Bing', 'Song, Yan', 'Wei, Si', 'Liu, Jun-Hua', 'McLoughlin, Ian Vince', 'Dai, Li-Rong']			7		1932-6203 (Electronic) 1932-6203 (Linking)	101285081	PloS one	['eng']	10.1371/journal.pone.0100795 [doi]	20181113	['*Artificial Intelligence', '*Language', '*Natural Language Processing', '*Neural Networks (Computer)', '*Speech Recognition Software', '*Support Vector Machine']	2015/11/07 06:00				NLM	e100795	['2014/03/11 00:00 [received]', '2014/05/29 00:00 [accepted]', '2014/07/02 06:00 [entrez]', '2014/07/02 06:00 [pubmed]', '2015/11/07 06:00 [medline]']	United States	PMC4077656		24983963	epublish	"['Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		PLoS One. 2014 Jul 1;9(7):e100795. doi: 10.1371/journal.pone.0100795. eCollection 2014.	MEDLINE	PLoS One	Deep bottleneck features for spoken language identification.		9	Deep bottleneck features for spoken language identification.
MOTIVATION: Despite much dynamical cellular behaviour being achieved by accurate regulation of protein concentrations, messenger RNA abundances, measured by microarray technology, and more recently by deep sequencing techniques, are widely used as proxies for protein measurements. Although for some species and under some conditions, there is good correlation between transcriptome and proteome level measurements, such correlation is by no means universal due to post-transcriptional and post-translational regulation, both of which are highly prevalent in cells. Here, we seek to develop a data-driven machine learning approach to bridging the gap between these two levels of high-throughput omic measurements on Saccharomyces cerevisiae and deploy the model in a novel way to uncover mRNA-protein pairs that are candidates for post-translational regulation. RESULTS: The application of feature selection by sparsity inducing regression (l(1) norm regularization) leads to a stable set of features: i.e. mRNA, ribosomal occupancy, ribosome density, tRNA adaptation index and codon bias while achieving a feature reduction from 37 to 5. A linear predictor used with these features is capable of predicting protein concentrations fairly accurately (R(2) = 0.86). Proteins whose concentration cannot be predicted accurately, taken as outliers with respect to the predictor, are shown to have annotation evidence of post-translational modification, significantly more than random subsets of similar size P < 0.02. In a data mining sense, this work also shows a wider point that outliers with respect to a learning method can carry meaningful information about a problem domain.	['School of Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, UK.']	['btt537 [pii]', '10.1093/bioinformatics/btt537 [doi]']	['Gunawardana Y', 'Niranjan M']							['2013/09/19 06:00']	20140508	20130916	2013 Dec 1	2013/09/21 06:00		['Gunawardana, Yawwani', 'Niranjan, Mahesan']			23		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btt537 [doi]	20181202	['Artificial Intelligence', 'Codon/metabolism', 'Computational Biology/*methods', '*Gene Expression Regulation, Fungal', '*Protein Processing, Post-Translational', 'Proteome/*analysis', 'RNA, Messenger/genetics/metabolism', 'RNA, Transfer/genetics/metabolism', 'Ribosomes/metabolism', 'Saccharomyces cerevisiae/*genetics/metabolism', 'Saccharomyces cerevisiae Proteins/*genetics/metabolism', '*Transcriptome']	2014/05/09 06:00				NLM	3060-6	['2013/09/19 06:00 [entrez]', '2013/09/21 06:00 [pubmed]', '2014/05/09 06:00 [medline]']	England			24045772	ppublish	['Journal Article']		['0 (Codon)', '0 (Proteome)', '0 (RNA, Messenger)', '0 (Saccharomyces cerevisiae Proteins)', '9014-25-9 (RNA, Transfer)']	IM		Bioinformatics. 2013 Dec 1;29(23):3060-6. doi: 10.1093/bioinformatics/btt537. Epub 2013 Sep 16.	MEDLINE	Bioinformatics	Bridging the gap between transcriptome and proteome measurements identifies post-translationally regulated genes.		29	Bridging the gap between transcriptome and proteome measurements identifies post-translationally regulated genes.
MOTIVATION: RNA-seq techniques provide an unparalleled means for exploring a transcriptome with deep coverage and base pair level resolution. Various analysis tools have been developed to align and assemble RNA-seq data, such as the widely used TopHat/Cufflinks pipeline. A common observation is that a sizable fraction of the fragments/reads align to multiple locations of the genome. These multiple alignments pose substantial challenges to existing RNA-seq analysis tools. Inappropriate treatment may result in reporting spurious expressed genes (false positives) and missing the real expressed genes (false negatives). Such errors impact the subsequent analysis, such as differential expression analysis. In our study, we observe that ~3.5% of transcripts reported by TopHat/Cufflinks pipeline correspond to annotated nonfunctional pseudogenes. Moreover, ~10.0% of reported transcripts are not annotated in the Ensembl database. These genes could be either novel expressed genes or false discoveries. RESULTS: We examine the underlying genomic features that lead to multiple alignments and investigate how they generate systematic errors in RNA-seq analysis. We develop a general tool, GeneScissors, which exploits machine learning techniques guided by biological knowledge to detect and correct spurious transcriptome inference by existing RNA-seq analysis methods. In our simulated study, GeneScissors can predict spurious transcriptome calls owing to misalignment with an accuracy close to 90%. It provides substantial improvement over the widely used TopHat/Cufflinks or MapSplice/Cufflinks pipelines in both precision and F-measurement. On real data, GeneScissors reports 53.6% less pseudogenes and 0.97% more expressed and annotated transcripts, when compared with the TopHat/Cufflinks pipeline. In addition, among the 10.0% unannotated transcripts reported by TopHat/Cufflinks, GeneScissors finds that >16.3% of them are false positives. AVAILABILITY: The software can be downloaded at http://csbio.unc.edu/genescissors/. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of North Carolina at Chapel Hill, NC 27599, USA.']	['btt216 [pii]', '10.1093/bioinformatics/btt216 [doi]']	['Zhang Z', 'Huang S', 'Wang J', 'Zhang X', 'Pardo Manuel de Villena F', 'McMillan L', 'Wang W']							['2013/07/02 06:00']	20131217		2013 Jul 1	2013/07/03 06:00		['Zhang, Zhaojun', 'Huang, Shunping', 'Wang, Jack', 'Zhang, Xiang', 'Pardo Manuel de Villena, Fernando', 'McMillan, Leonard', 'Wang, Wei']		['P50 GM076468/GM/NIGMS NIH HHS/United States', 'P50 MH090338/MH/NIMH NIH HHS/United States', 'GM P50 GM076468/GM/NIGMS NIH HHS/United States']	13		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']	10.1093/bioinformatics/btt216 [doi]	20191008	['Animals', 'Artificial Intelligence', 'Gene Expression Profiling/*methods', 'Genomics', 'Mice', 'Pseudogenes', 'Sequence Alignment/*methods', 'Sequence Analysis, RNA/*methods', '*Software']	2013/12/18 06:00				NLM	i291-9	['2013/07/02 06:00 [entrez]', '2013/07/03 06:00 [pubmed]', '2013/12/18 06:00 [medline]']	England	PMC3694649		23812996	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		Bioinformatics. 2013 Jul 1;29(13):i291-9. doi: 10.1093/bioinformatics/btt216.	MEDLINE	Bioinformatics	GeneScissors: a comprehensive approach to detecting and correcting spurious transcriptome inference owing to RNA-seq reads misalignment.		29	GeneScissors: a comprehensive approach to detecting and correcting spurious transcriptome inference owing to RNA-seq reads misalignment.
It is possible to learn multiple layers of non-linear features by backpropagating error derivatives through a feedforward neural network. This is a very effective learning procedure when there is a huge amount of labeled training data, but for many learning tasks very few labeled examples are available. In an effort to overcome the need for labeled data, several different generative models were developed that learned interesting features by modeling the higher order statistical structure of a set of input vectors. One of these generative models, the restricted Boltzmann machine (RBM), has no connections between its hidden units and this makes perceptual inference and learning much simpler. More significantly, after a layer of hidden features has been learned, the activities of these features can be used as training data for another RBM. By applying this idea recursively, it is possible to learn a deep hierarchy of progressively more complicated features without requiring any labeled data. This deep hierarchy can then be treated as a feedforward neural network which can be discriminatively fine-tuned using backpropagation. Using a stack of RBMs to initialize the weights of a feedforward neural network allows backpropagation to work effectively in much deeper networks and it leads to much better generalization. A stack of RBMs can also be used to initialize a deep Boltzmann machine that has many hidden layers. Combining this initialization method with a new method for fine-tuning the weights finally leads to the first efficient way of training Boltzmann machines with many hidden layers and millions of weights.	['Department of Computer Science, University of Toronto.']	['10.1111/cogs.12049 [doi]']	['Hinton G']		['Copyright (c) 2013 Cognitive Science Society, Inc.']					['2013/06/27 06:00']	20150423	20130625	2014 Aug	2013/06/27 06:00		['Hinton, Geoffrey']			6		1551-6709 (Electronic) 0364-0213 (Linking)	7708195	Cognitive science	['eng']	10.1111/cogs.12049 [doi]	20140819	['Artificial Intelligence', 'Computer Simulation', 'Humans', '*Learning', '*Models, Neurological', '*Neural Networks (Computer)']	2015/04/24 06:00		['Backpropagation', 'Boltzmann machines', 'Contrastive divergence', 'Deep learning', 'Distributed representations', 'Learning features', 'Learning graphical models', 'Variational learning']	['NOTNLM']	NLM	1078-101	['2010/10/11 00:00 [received]', '2012/05/22 00:00 [revised]', '2012/07/10 00:00 [accepted]', '2013/06/27 06:00 [entrez]', '2013/06/27 06:00 [pubmed]', '2015/04/24 06:00 [medline]']	United States			23800216	ppublish	['Journal Article']			IM		Cogn Sci. 2014 Aug;38(6):1078-101. doi: 10.1111/cogs.12049. Epub 2013 Jun 25.	MEDLINE	Cogn Sci	Where do features come from?		38	Where do features come from?
Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief overview of deep learning methods and show in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties. However, molecules are typically described by undirected cyclic graphs, while recursive approaches typically use directed acyclic graphs. Thus, we develop methods to address this discrepancy, essentially by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph. One advantage of this approach is that it relies only minimally on the identification of suitable molecular descriptors because suitable representations are learned automatically from the data. Several variants of this approach are applied to the problem of predicting aqueous solubility and tested on four benchmark data sets. Experimental results show that the performance of the deep learning methods matches or exceeds the performance of other state-of-the-art methods according to several evaluation metrics and expose the fundamental limitations arising from training sets that are too small or too noisy. A Web-based predictor, AquaSol, is available online through the ChemDB portal ( cdb.ics.uci.edu ) together with additional material.	['School of Computer Science and Informatics, University College Dublin, Belfield, Dublin 4, Ireland. alessandro.lusci@ucdconnect.ie']	['10.1021/ci400187y [doi]']	['Lusci A', 'Pollastri G', 'Baldi P']							['2013/06/26 06:00']	20140220	20130702	2013 Jul 22	2013/06/26 06:00		['Lusci, Alessandro', 'Pollastri, Gianluca', 'Baldi, Pierre']		['R01 LM010235/LM/NLM NIH HHS/United States', 'T15 LM007443/LM/NLM NIH HHS/United States', 'LM010235/LM/NLM NIH HHS/United States', 'T15 LM07443/LM/NLM NIH HHS/United States']	7		1549-960X (Electronic) 1549-9596 (Linking)	101230060	Journal of chemical information and modeling	['eng']	10.1021/ci400187y [doi]	20181113	['Acetic Acid/chemistry', '*Artificial Intelligence', 'Computer Graphics', 'Databases, Pharmaceutical', 'Informatics/*methods', 'Internet', 'Neural Networks (Computer)', 'Pharmaceutical Preparations/*chemistry', 'Solubility', 'Water/*chemistry']	2014/02/22 06:00	['NIHMS501706']			NLM	1563-75	['2013/06/26 06:00 [entrez]', '2013/06/26 06:00 [pubmed]', '2014/02/22 06:00 [medline]']	United States	PMC3739985		23795551	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Pharmaceutical Preparations)', '059QF0KO0R (Water)', 'Q40Q9N063P (Acetic Acid)']	IM		J Chem Inf Model. 2013 Jul 22;53(7):1563-75. doi: 10.1021/ci400187y. Epub 2013 Jul 2.	MEDLINE	J Chem Inf Model	Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules.		53	Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules.
We introduce HD (or &#x201C;Hierarchical-Deep&#x201D;) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.	['Department of Statistics and Computer Science, University of Toronto, Toronto, ON M5S 3G3, Canada. rsalakhu@utstat.toronto.edu']	['10.1109/TPAMI.2012.269 [doi]']	['Salakhutdinov R', 'Tenenbaum JB', 'Torralba A']							['2013/06/22 06:00']	20140217		2013 Aug	2013/06/22 06:00		['Salakhutdinov, Ruslan', 'Tenenbaum, Joshua B', 'Torralba, Antonio']			8		1939-3539 (Electronic) 0098-5589 (Linking)	9885960	IEEE transactions on pattern analysis and machine intelligence	['eng']	10.1109/TPAMI.2012.269 [doi]	20130621	['*Algorithms', 'Artificial Intelligence', 'Bayes Theorem', 'Humans', 'Motion', 'Pattern Recognition, Automated/*methods', 'Visual Perception']	2014/02/18 06:00				NLM	1958-71	['2013/06/22 06:00 [entrez]', '2013/06/22 06:00 [pubmed]', '2014/02/18 06:00 [medline]']	United States			23787346	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", ""Research Support, U.S. Gov't, Non-P.H.S.""]"			IM		IEEE Trans Pattern Anal Mach Intell. 2013 Aug;35(8):1958-71. doi: 10.1109/TPAMI.2012.269.	MEDLINE	IEEE Trans Pattern Anal Mach Intell	Learning with hierarchical-deep models.		35	Learning with hierarchical-deep models.
The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.	['Department of Computer Science and Operations Research, University of Montreal, Montreal, Quebec H3C 3J7, Canada.']	['10.1109/TPAMI.2013.50 [doi]']	['Bengio Y', 'Courville A', 'Vincent P']							['2013/06/22 06:00']	20140217		2013 Aug	2013/06/22 06:00		['Bengio, Yoshua', 'Courville, Aaron', 'Vincent, Pascal']			8		1939-3539 (Electronic) 0098-5589 (Linking)	9885960	IEEE transactions on pattern analysis and machine intelligence	['eng']	10.1109/TPAMI.2013.50 [doi]	20130621	['Algorithms', 'Artificial Intelligence/*trends', 'Humans', 'Neural Networks (Computer)']	2014/02/18 06:00				NLM	1798-828	['2013/06/22 06:00 [entrez]', '2013/06/22 06:00 [pubmed]', '2014/02/18 06:00 [medline]']	United States			23787338	ppublish	"['Journal Article', ""Research Support, Non-U.S. Gov't"", 'Review']"			IM		IEEE Trans Pattern Anal Mach Intell. 2013 Aug;35(8):1798-828. doi: 10.1109/TPAMI.2013.50.	MEDLINE	IEEE Trans Pattern Anal Mach Intell	Representation learning: a review and new perspectives.		35	Representation learning: a review and new perspectives.
MOTIVATION: Residue-residue contact prediction is important for protein structure prediction and other applications. However, the accuracy of current contact predictors often barely exceeds 20% on long-range contacts, falling short of the level required for ab initio structure prediction. RESULTS: Here, we develop a novel machine learning approach for contact map prediction using three steps of increasing resolution. First, we use 2D recursive neural networks to predict coarse contacts and orientations between secondary structure elements. Second, we use an energy-based method to align secondary structure elements and predict contact probabilities between residues in contacting alpha-helices or strands. Third, we use a deep neural network architecture to organize and progressively refine the prediction of contacts, integrating information over both space and time. We train the architecture on a large set of non-redundant proteins and test it on a large set of non-homologous domains, as well as on the set of protein domains used for contact prediction in the two most recent CASP8 and CASP9 experiments. For long-range contacts, the accuracy of the new CMAPpro predictor is close to 30%, a significant increase over existing approaches. AVAILABILITY: CMAPpro is available as part of the SCRATCH suite at http://scratch.proteomics.ics.uci.edu/. CONTACT: pfbaldi@uci.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	['Department of Computer Science, University of California, Irvine, CA 92697, USA.']	['bts475 [pii]', '10.1093/bioinformatics/bts475 [doi]']	['Di Lena P', 'Nagata K', 'Baldi P']							['2012/08/01 06:00']	20130605	20120730	2012 Oct 1	2012/08/01 06:00		['Di Lena, Pietro', 'Nagata, Ken', 'Baldi, Pierre']		['LM010235/LM/NLM NIH HHS/United States', 'T15 LM07443/LM/NLM NIH HHS/United States']	19		1367-4811 (Electronic) 1367-4803 (Linking)	9808944	Bioinformatics (Oxford, England)	['eng']		20181202	['Algorithms', '*Artificial Intelligence', 'Computational Biology/*methods', '*Neural Networks (Computer)', 'Protein Structure, Secondary', 'Protein Structure, Tertiary', 'Proteins/*chemistry']	2013/06/06 06:00				NLM	2449-57	['2012/08/01 06:00 [entrez]', '2012/08/01 06:00 [pubmed]', '2013/06/06 06:00 [medline]']	England	PMC3463120		22847931	ppublish	"['Journal Article', 'Research Support, N.I.H., Extramural', ""Research Support, U.S. Gov't, Non-P.H.S.""]"		['0 (Proteins)']	IM		Bioinformatics. 2012 Oct 1;28(19):2449-57. doi: 10.1093/bioinformatics/bts475. Epub 2012 Jul 30.	MEDLINE	Bioinformatics	Deep architectures for protein contact map prediction.		28	Deep architectures for protein contact map prediction.
Autoencoders are unsupervised machine learning circuits, with typically one hidden layer, whose learning goal is to minimize an average distortion measure between inputs and outputs. Linear autoencoders correspond to the special case where only linear transformations between visible and hidden variables are used. While linear autoencoders can be defined over any field, only real-valued linear autoencoders have been studied so far. Here we study complex-valued linear autoencoders where the components of the training vectors and adjustable matrices are defined over the complex field with the L(2) norm. We provide simpler and more general proofs that unify the real-valued and complex-valued cases, showing that in both cases the landscape of the error function is invariant under certain groups of transformations. The landscape has no local minima, a family of global minima associated with Principal Component Analysis, and many families of saddle points associated with orthogonal projections onto sub-space spanned by sub-optimal subsets of eigenvectors of the covariance matrix. The theory yields several iterative, convergent, learning algorithms, a clear understanding of the generalization properties of the trained autoencoders, and can equally be applied to the hetero-associative case when external targets are provided. Partial results on deep architecture as well as the differential geometry of autoencoders are also presented. The general framework described here is useful to classify autoencoders and identify general properties that ought to be investigated for each class, illuminating some of the connections between autoencoders, unsupervised learning, clustering, Hebbian learning, and information theory.	['Department of Computer Science, UCI, Irvine, CA 92697-3435, USA. pfbaldi@ics.uci.edu']	['S0893-6080(12)00127-X [pii]', '10.1016/j.neunet.2012.04.011 [doi]']	['Baldi P', 'Lu Z']		['Copyright (c) 2012 Elsevier Ltd. All rights reserved.']					['2012/05/25 06:00']	20130523	20120504	2012 Sep	2012/05/25 06:00		['Baldi, Pierre', 'Lu, Zhiqin']		['R01 LM010235/LM/NLM NIH HHS/United States', 'T15 LM007443/LM/NLM NIH HHS/United States', 'LM010235/LM/NLM NIH HHS/United States', 'T15 LM07443/LM/NLM NIH HHS/United States']			1879-2782 (Electronic) 0893-6080 (Linking)	8805018	Neural networks : the official journal of the International Neural Network Society	['eng']	10.1016/j.neunet.2012.04.011 [doi]	20181113	['*Artificial Intelligence', '*Neural Networks (Computer)', 'Principal Component Analysis/methods']	2013/05/25 06:00	['NIHMS375415']			NLM	136-47	['2011/08/18 00:00 [received]', '2012/04/20 00:00 [revised]', '2012/04/22 00:00 [accepted]', '2012/05/25 06:00 [entrez]', '2012/05/25 06:00 [pubmed]', '2013/05/25 06:00 [medline]']	United States	PMC3399055		22622264	ppublish	"['Journal Article', ""Research Support, U.S. Gov't, Non-P.H.S."", ""Research Support, U.S. Gov't, P.H.S.""]"			IM		Neural Netw. 2012 Sep;33:136-47. doi: 10.1016/j.neunet.2012.04.011. Epub 2012 May 4.	MEDLINE	Neural Netw	Complex-valued autoencoders.		33	Complex-valued autoencoders.
One of the central problems in computational neuroscience is to understand how the object-recognition pathway of the cortex learns a deep hierarchy of nonlinear feature detectors. Recent progress in machine learning shows that it is possible to learn deep hierarchies without requiring any labelled data. The feature detectors are learned one layer at a time and the goal of the learning procedure is to form a good generative model of images, not to predict the class of each image. The learning procedure only requires the pairwise correlations between the activations of neuron-like processing units in adjacent layers. The original version of the learning procedure is derived from a quadratic 'energy' function but it can be extended to allow third-order, multiplicative interactions in which neurons gate the pairwise interactions between other neurons. A technique for factoring the third-order interactions leads to a learning module that again has a simple learning rule based on pairwise correlations. This module looks remarkably like modules that have been proposed by both biologists trying to explain the responses of neurons and engineers trying to create systems that can recognize objects.	['Department of Computer Science, University of Toronto, Toronto, Canada. hinton@cs.toronto.edu']	['365/1537/177 [pii]', '10.1098/rstb.2009.0200 [doi]']	['Hinton GE']							['2009/12/17 06:00']	20100322		2010 Jan 12	2009/12/17 06:00		['Hinton, Geoffrey E']			1537		1471-2970 (Electronic) 0962-8436 (Linking)	7503623	Philosophical transactions of the Royal Society of London. Series B, Biological sciences	['eng']	10.1098/rstb.2009.0200 [doi]	20181113	['Computer Simulation', 'Humans', 'Learning/*physiology', '*Models, Neurological', '*Neural Networks (Computer)', 'Visual Pathways/*physiology']	2010/03/23 06:00				NLM	177-84	['2009/12/17 06:00 [entrez]', '2009/12/17 06:00 [pubmed]', '2010/03/23 06:00 [medline]']	England	PMC2842706		20008395	ppublish	['Journal Article', 'Review']	33		IM		Philos Trans R Soc Lond B Biol Sci. 2010 Jan 12;365(1537):177-84. doi: 10.1098/rstb.2009.0200.	MEDLINE	Philos Trans R Soc Lond B Biol Sci	Learning to represent visual input.		365	Learning to represent visual input.
Automatic methods for recognizing topically relevant documents supported by high quality research can assist clinicians in practicing evidence-based medicine. We approach the challenge of identifying articles with high quality clinical evidence as a binary classification problem. Combining predictions from supervised machine learning methods and using deep semantic features, we achieve 73.5% precision and 67% recall.	['Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada.']		['Kilicoglu H', 'Demner-Fushman D', 'Rindflesch TC', 'Wilczynski NL', 'Haynes RB']							['2008/11/13 09:00']	20100108	20081106	2008 Nov 6	2008/11/13 09:00		['Kilicoglu, Halil', 'Demner-Fushman, Dina', 'Rindflesch, Thomas C', 'Wilczynski, Nancy L', 'Haynes, R Brian']					1942-597X (Electronic) 1559-4076 (Linking)	101209213	AMIA ... Annual Symposium proceedings. AMIA Symposium	['eng']		20181113	['*Algorithms', '*Artificial Intelligence', 'Canada', '*Evidence-Based Medicine', '*MEDLINE', '*Natural Language Processing', 'Pattern Recognition, Automated/*methods', '*Periodicals as Topic', 'Quality Control', 'Semantics', 'Vocabulary, Controlled']	2010/01/09 06:00				NLM	368	['2008/03/13 00:00 [received]', '2008/07/11 00:00 [revised]', '2008/11/13 09:00 [pubmed]', '2010/01/09 06:00 [medline]', '2008/11/13 09:00 [entrez]']	United States	PMC2656036		18998881	epublish	['Journal Article']			IM		AMIA Annu Symp Proc. 2008 Nov 6:368.	MEDLINE	AMIA Annu Symp Proc	Toward automatic recognition of high quality clinical evidence.			Toward automatic recognition of high quality clinical evidence.
Learning from patient records may aid knowledge acquisition and decision making. Existing inductive machine learning (ML) systems such us NewId, CN2, C4.5 and AQ15 learn from past case histories using symbolic and/or numeric values. These systems learn symbolic rules (IF... THEN like) which link an antecedent set of clinical factors to a consequent class or decision. This paper compares the learning performance of alternative ML systems with each other and with respect to a novel approach using logic minimization, called LML, to learn from data. Patient cases were taken from the archives of the Paediatric Surgery Clinic of the University Hospital of Crete, Heraklion, Greece. Comparison of ML system performance is based both on classification accuracy and on informal expert assessment of learned knowledge.	['Institute of Computer Science, Foundation for Research and Technology, Hellas, Greece. mblaza@ics.forth.gr']	['S0933365796003545 [pii]', '10.1016/s0933-3657(96)00354-5 [doi]']	['Blazadonakis M', 'Moustakis V', 'Charissis G']							['1996/11/01 00:00']	19970403		1996 Nov	1996/11/01 00:00		['Blazadonakis, M', 'Moustakis, V', 'Charissis, G']			6		0933-3657 (Print) 0933-3657 (Linking)	8915031	Artificial intelligence in medicine	['eng']		20191101	['Abdomen, Acute/classification/surgery/*therapy', 'Abdominal Pain/classification/surgery/*therapy', 'Algorithms', 'Analysis of Variance', '*Artificial Intelligence', 'Child', 'Decision Making', 'Decision Trees', 'Expert Systems', 'Female', 'Follow-Up Studies', 'Humans', 'Logic', 'Male', 'Medical Records', 'Patient Care Planning', 'Patient Discharge', 'Software', '*Therapy, Computer-Assisted']	1996/11/01 00:01				NLM	527-42	['1996/11/01 00:00 [pubmed]', '1996/11/01 00:01 [medline]', '1996/11/01 00:00 [entrez]']	Netherlands			8985539	ppublish	"['Comparative Study', 'Journal Article', ""Research Support, Non-U.S. Gov't""]"			IM		Artif Intell Med. 1996 Nov;8(6):527-42. doi: 10.1016/s0933-3657(96)00354-5.	MEDLINE	Artif Intell Med	Deep assessment of machine learning techniques using patient treatment in acute abdominal pain in children.		8	Deep assessment of machine learning techniques using patient treatment in acute abdominal pain in children.
